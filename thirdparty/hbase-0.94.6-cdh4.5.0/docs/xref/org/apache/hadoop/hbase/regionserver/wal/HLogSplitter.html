<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>HLogSplitter xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../../apidocs/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Copyright 2010 The Apache Software Foundation</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> *</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> *</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="18" href="#18">18</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="19" href="#19">19</a>  <em class="jxr_javadoccomment"> */</em>
<a name="20" href="#20">20</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.regionserver.wal;
<a name="21" href="#21">21</a>  
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.io.EOFException;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="24" href="#24">24</a>  <strong class="jxr_keyword">import</strong> java.io.InterruptedIOException;
<a name="25" href="#25">25</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.Constructor;
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.InvocationTargetException;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> java.text.ParseException;
<a name="28" href="#28">28</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> java.util.Collections;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> java.util.LinkedList;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> java.util.List;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> java.util.Map;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> java.util.Set;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> java.util.TreeMap;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> java.util.TreeSet;
<a name="36" href="#36">36</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.atomic.AtomicReference;
<a name="37" href="#37">37</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.CountDownLatch;
<a name="38" href="#38">38</a>  
<a name="39" href="#39">39</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.Log;
<a name="40" href="#40">40</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.LogFactory;
<a name="41" href="#41">41</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configuration;
<a name="42" href="#42">42</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileStatus;
<a name="43" href="#43">43</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileSystem;
<a name="44" href="#44">44</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.Path;
<a name="45" href="#45">45</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HBaseFileSystem;
<a name="46" href="#46">46</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HConstants;
<a name="47" href="#47">47</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HTableDescriptor;
<a name="48" href="#48">48</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.RemoteExceptionHandler;
<a name="49" href="#49">49</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.HeapSize;
<a name="50" href="#50">50</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.monitoring.MonitoredTask;
<a name="51" href="#51">51</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.monitoring.TaskMonitor;
<a name="52" href="#52">52</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.HRegion;
<a name="53" href="#53">53</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.wal.HLog.Entry;
<a name="54" href="#54">54</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.wal.HLog.Reader;
<a name="55" href="#55">55</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.wal.HLog.Writer;
<a name="56" href="#56">56</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Bytes;
<a name="57" href="#57">57</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.CancelableProgressable;
<a name="58" href="#58">58</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.ClassSize;
<a name="59" href="#59">59</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
<a name="60" href="#60">60</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.FSUtils;
<a name="61" href="#61">61</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.zookeeper.ZKSplitLog;
<a name="62" href="#62">62</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.MultipleIOException;
<a name="63" href="#63">63</a>  
<a name="64" href="#64">64</a>  <strong class="jxr_keyword">import</strong> com.google.common.base.Preconditions;
<a name="65" href="#65">65</a>  <strong class="jxr_keyword">import</strong> com.google.common.collect.Lists;
<a name="66" href="#66">66</a>  
<a name="67" href="#67">67</a>  <em class="jxr_javadoccomment">/**</em>
<a name="68" href="#68">68</a>  <em class="jxr_javadoccomment"> * This class is responsible for splitting up a bunch of regionserver commit log</em>
<a name="69" href="#69">69</a>  <em class="jxr_javadoccomment"> * files that are no longer being written to, into new files, one per region for</em>
<a name="70" href="#70">70</a>  <em class="jxr_javadoccomment"> * region to replay on startup. Delete the old log files when finished.</em>
<a name="71" href="#71">71</a>  <em class="jxr_javadoccomment"> */</em>
<a name="72" href="#72">72</a>  <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">HLogSplitter</a> {
<a name="73" href="#73">73</a>    <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String LOG_SPLITTER_IMPL = <span class="jxr_string">"hbase.hlog.splitter.impl"</span>;
<a name="74" href="#74">74</a>  
<a name="75" href="#75">75</a>    <em class="jxr_javadoccomment">/**</em>
<a name="76" href="#76">76</a>  <em class="jxr_javadoccomment">   * Name of file that holds recovered edits written by the wal log splitting</em>
<a name="77" href="#77">77</a>  <em class="jxr_javadoccomment">   * code, one per region</em>
<a name="78" href="#78">78</a>  <em class="jxr_javadoccomment">   */</em>
<a name="79" href="#79">79</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String RECOVERED_EDITS = <span class="jxr_string">"recovered.edits"</span>;
<a name="80" href="#80">80</a>  
<a name="81" href="#81">81</a>  
<a name="82" href="#82">82</a>    <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> Log LOG = LogFactory.getLog(HLogSplitter.<strong class="jxr_keyword">class</strong>);
<a name="83" href="#83">83</a>  
<a name="84" href="#84">84</a>    <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> hasSplit = false;
<a name="85" href="#85">85</a>    <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> splitTime = 0;
<a name="86" href="#86">86</a>    <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> splitSize = 0;
<a name="87" href="#87">87</a>  
<a name="88" href="#88">88</a>  
<a name="89" href="#89">89</a>    <em class="jxr_comment">// Parameters for split process</em>
<a name="90" href="#90">90</a>    <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> Path rootDir;
<a name="91" href="#91">91</a>    <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> Path srcDir;
<a name="92" href="#92">92</a>    <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> Path oldLogDir;
<a name="93" href="#93">93</a>    <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> FileSystem fs;
<a name="94" href="#94">94</a>    <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> Configuration conf;
<a name="95" href="#95">95</a>    <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogFileSystem.html">HLogFileSystem</a> hlogFs;
<a name="96" href="#96">96</a>  
<a name="97" href="#97">97</a>    <em class="jxr_comment">// Major subcomponents of the split process.</em>
<a name="98" href="#98">98</a>    <em class="jxr_comment">// These are separated into inner classes to make testing easier.</em>
<a name="99" href="#99">99</a>    <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">OutputSink</a> outputSink;
<a name="100" href="#100">100</a>   <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">EntryBuffers</a> entryBuffers;
<a name="101" href="#101">101</a> 
<a name="102" href="#102">102</a>   <em class="jxr_comment">// If an exception is thrown by one of the other threads, it will be</em>
<a name="103" href="#103">103</a>   <em class="jxr_comment">// stored here.</em>
<a name="104" href="#104">104</a>   <strong class="jxr_keyword">protected</strong> AtomicReference&lt;Throwable&gt; thrown = <strong class="jxr_keyword">new</strong> AtomicReference&lt;Throwable&gt;();
<a name="105" href="#105">105</a> 
<a name="106" href="#106">106</a>   <em class="jxr_comment">// Wait/notify for when data has been produced by the reader thread,</em>
<a name="107" href="#107">107</a>   <em class="jxr_comment">// consumed by the reader thread, or an exception occurred</em>
<a name="108" href="#108">108</a>   Object dataAvailable = <strong class="jxr_keyword">new</strong> Object();
<a name="109" href="#109">109</a>   
<a name="110" href="#110">110</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status;
<a name="111" href="#111">111</a> 
<a name="112" href="#112">112</a>   <em class="jxr_javadoccomment">/**</em>
<a name="113" href="#113">113</a> <em class="jxr_javadoccomment">   * Create a new HLogSplitter using the given {@link Configuration} and the</em>
<a name="114" href="#114">114</a> <em class="jxr_javadoccomment">   * &lt;code&gt;hbase.hlog.splitter.impl&lt;/code&gt; property to derived the instance</em>
<a name="115" href="#115">115</a> <em class="jxr_javadoccomment">   * class to use.</em>
<a name="116" href="#116">116</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="117" href="#117">117</a> <em class="jxr_javadoccomment">   * @param conf</em>
<a name="118" href="#118">118</a> <em class="jxr_javadoccomment">   * @param rootDir hbase directory</em>
<a name="119" href="#119">119</a> <em class="jxr_javadoccomment">   * @param srcDir logs directory</em>
<a name="120" href="#120">120</a> <em class="jxr_javadoccomment">   * @param oldLogDir directory where processed logs are archived to</em>
<a name="121" href="#121">121</a> <em class="jxr_javadoccomment">   * @param fs FileSystem</em>
<a name="122" href="#122">122</a> <em class="jxr_javadoccomment">   * @return New HLogSplitter instance</em>
<a name="123" href="#123">123</a> <em class="jxr_javadoccomment">   */</em>
<a name="124" href="#124">124</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">HLogSplitter</a> createLogSplitter(Configuration conf,
<a name="125" href="#125">125</a>       <strong class="jxr_keyword">final</strong> Path rootDir, <strong class="jxr_keyword">final</strong> Path srcDir,
<a name="126" href="#126">126</a>       Path oldLogDir, <strong class="jxr_keyword">final</strong> FileSystem fs)  {
<a name="127" href="#127">127</a> 
<a name="128" href="#128">128</a>     @SuppressWarnings(<span class="jxr_string">"unchecked"</span>)
<a name="129" href="#129">129</a>     Class&lt;? <strong class="jxr_keyword">extends</strong> HLogSplitter&gt; splitterClass = (Class&lt;? <strong class="jxr_keyword">extends</strong> HLogSplitter&gt;) conf
<a name="130" href="#130">130</a>         .getClass(LOG_SPLITTER_IMPL, HLogSplitter.<strong class="jxr_keyword">class</strong>);
<a name="131" href="#131">131</a>     <strong class="jxr_keyword">try</strong> {
<a name="132" href="#132">132</a>        Constructor&lt;? <strong class="jxr_keyword">extends</strong> HLogSplitter&gt; constructor =
<a name="133" href="#133">133</a>          splitterClass.getConstructor(
<a name="134" href="#134">134</a>           Configuration.<strong class="jxr_keyword">class</strong>, <em class="jxr_comment">// conf</em>
<a name="135" href="#135">135</a>           Path.<strong class="jxr_keyword">class</strong>, <em class="jxr_comment">// rootDir</em>
<a name="136" href="#136">136</a>           Path.<strong class="jxr_keyword">class</strong>, <em class="jxr_comment">// srcDir</em>
<a name="137" href="#137">137</a>           Path.<strong class="jxr_keyword">class</strong>, <em class="jxr_comment">// oldLogDir</em>
<a name="138" href="#138">138</a>           FileSystem.<strong class="jxr_keyword">class</strong>); <em class="jxr_comment">// fs</em>
<a name="139" href="#139">139</a>       <strong class="jxr_keyword">return</strong> constructor.newInstance(conf, rootDir, srcDir, oldLogDir, fs);
<a name="140" href="#140">140</a>     } <strong class="jxr_keyword">catch</strong> (IllegalArgumentException e) {
<a name="141" href="#141">141</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="142" href="#142">142</a>     } <strong class="jxr_keyword">catch</strong> (InstantiationException e) {
<a name="143" href="#143">143</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="144" href="#144">144</a>     } <strong class="jxr_keyword">catch</strong> (IllegalAccessException e) {
<a name="145" href="#145">145</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="146" href="#146">146</a>     } <strong class="jxr_keyword">catch</strong> (InvocationTargetException e) {
<a name="147" href="#147">147</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="148" href="#148">148</a>     } <strong class="jxr_keyword">catch</strong> (SecurityException e) {
<a name="149" href="#149">149</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="150" href="#150">150</a>     } <strong class="jxr_keyword">catch</strong> (NoSuchMethodException e) {
<a name="151" href="#151">151</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="152" href="#152">152</a>     }
<a name="153" href="#153">153</a>   }
<a name="154" href="#154">154</a> 
<a name="155" href="#155">155</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">HLogSplitter</a>(Configuration conf, Path rootDir, Path srcDir,
<a name="156" href="#156">156</a>       Path oldLogDir, FileSystem fs) {
<a name="157" href="#157">157</a>     <strong class="jxr_keyword">this</strong>.conf = conf;
<a name="158" href="#158">158</a>     <strong class="jxr_keyword">this</strong>.rootDir = rootDir;
<a name="159" href="#159">159</a>     <strong class="jxr_keyword">this</strong>.srcDir = srcDir;
<a name="160" href="#160">160</a>     <strong class="jxr_keyword">this</strong>.oldLogDir = oldLogDir;
<a name="161" href="#161">161</a>     <strong class="jxr_keyword">this</strong>.fs = fs;
<a name="162" href="#162">162</a> 
<a name="163" href="#163">163</a>     entryBuffers = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">EntryBuffers</a>(
<a name="164" href="#164">164</a>         conf.getInt(<span class="jxr_string">"hbase.regionserver.hlog.splitlog.buffersize"</span>,
<a name="165" href="#165">165</a>             128*1024*1024));
<a name="166" href="#166">166</a>     outputSink = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">OutputSink</a>();
<a name="167" href="#167">167</a>     <strong class="jxr_keyword">this</strong>.hlogFs = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogFileSystem.html">HLogFileSystem</a>(conf);
<a name="168" href="#168">168</a>   }
<a name="169" href="#169">169</a> 
<a name="170" href="#170">170</a>   <em class="jxr_javadoccomment">/**</em>
<a name="171" href="#171">171</a> <em class="jxr_javadoccomment">   * Split up a bunch of regionserver commit log files that are no longer being</em>
<a name="172" href="#172">172</a> <em class="jxr_javadoccomment">   * written to, into new files, one per region for region to replay on startup.</em>
<a name="173" href="#173">173</a> <em class="jxr_javadoccomment">   * Delete the old log files when finished.</em>
<a name="174" href="#174">174</a> <em class="jxr_javadoccomment">   *</em>
<a name="175" href="#175">175</a> <em class="jxr_javadoccomment">   * @throws IOException will throw if corrupted hlogs aren't tolerated</em>
<a name="176" href="#176">176</a> <em class="jxr_javadoccomment">   * @return the list of splits</em>
<a name="177" href="#177">177</a> <em class="jxr_javadoccomment">   */</em>
<a name="178" href="#178">178</a>   <strong class="jxr_keyword">public</strong> List&lt;Path&gt; splitLog()
<a name="179" href="#179">179</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="180" href="#180">180</a>     <strong class="jxr_keyword">return</strong> splitLog((CountDownLatch) <strong class="jxr_keyword">null</strong>);
<a name="181" href="#181">181</a>   }
<a name="182" href="#182">182</a> 
<a name="183" href="#183">183</a>   <em class="jxr_javadoccomment">/**</em>
<a name="184" href="#184">184</a> <em class="jxr_javadoccomment">   * Split up a bunch of regionserver commit log files that are no longer being</em>
<a name="185" href="#185">185</a> <em class="jxr_javadoccomment">   * written to, into new files, one per region for region to replay on startup.</em>
<a name="186" href="#186">186</a> <em class="jxr_javadoccomment">   * Delete the old log files when finished.</em>
<a name="187" href="#187">187</a> <em class="jxr_javadoccomment">   *</em>
<a name="188" href="#188">188</a> <em class="jxr_javadoccomment">   * @param latch</em>
<a name="189" href="#189">189</a> <em class="jxr_javadoccomment">   * @throws IOException will throw if corrupted hlogs aren't tolerated</em>
<a name="190" href="#190">190</a> <em class="jxr_javadoccomment">   * @return the list of splits</em>
<a name="191" href="#191">191</a> <em class="jxr_javadoccomment">   */</em>
<a name="192" href="#192">192</a>   <strong class="jxr_keyword">public</strong> List&lt;Path&gt; splitLog(CountDownLatch latch)
<a name="193" href="#193">193</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="194" href="#194">194</a>     Preconditions.checkState(!hasSplit,
<a name="195" href="#195">195</a>         <span class="jxr_string">"An HLogSplitter instance may only be used once"</span>);
<a name="196" href="#196">196</a>     hasSplit = <strong class="jxr_keyword">true</strong>;
<a name="197" href="#197">197</a> 
<a name="198" href="#198">198</a>     status = TaskMonitor.get().createStatus(
<a name="199" href="#199">199</a>         <span class="jxr_string">"Splitting logs in "</span> + srcDir);
<a name="200" href="#200">200</a>     
<a name="201" href="#201">201</a>     <strong class="jxr_keyword">long</strong> startTime = EnvironmentEdgeManager.currentTimeMillis();
<a name="202" href="#202">202</a>     
<a name="203" href="#203">203</a>     status.setStatus(<span class="jxr_string">"Determining files to split..."</span>);
<a name="204" href="#204">204</a>     List&lt;Path&gt; splits = <strong class="jxr_keyword">null</strong>;
<a name="205" href="#205">205</a>     <strong class="jxr_keyword">if</strong> (!fs.exists(srcDir)) {
<a name="206" href="#206">206</a>       <em class="jxr_comment">// Nothing to do</em>
<a name="207" href="#207">207</a>       status.markComplete(<span class="jxr_string">"No log directory existed to split."</span>);
<a name="208" href="#208">208</a>       <strong class="jxr_keyword">return</strong> splits;
<a name="209" href="#209">209</a>     }
<a name="210" href="#210">210</a>     FileStatus[] logfiles = fs.listStatus(srcDir);
<a name="211" href="#211">211</a>     <strong class="jxr_keyword">if</strong> (logfiles == <strong class="jxr_keyword">null</strong> || logfiles.length == 0) {
<a name="212" href="#212">212</a>       <em class="jxr_comment">// Nothing to do</em>
<a name="213" href="#213">213</a>       <strong class="jxr_keyword">return</strong> splits;
<a name="214" href="#214">214</a>     }
<a name="215" href="#215">215</a>     logAndReport(<span class="jxr_string">"Splitting "</span> + logfiles.length + <span class="jxr_string">" hlog(s) in "</span>
<a name="216" href="#216">216</a>     + srcDir.toString());
<a name="217" href="#217">217</a>     splits = splitLog(logfiles, latch);
<a name="218" href="#218">218</a> 
<a name="219" href="#219">219</a>     splitTime = EnvironmentEdgeManager.currentTimeMillis() - startTime;
<a name="220" href="#220">220</a>     String msg = <span class="jxr_string">"hlog file splitting completed in "</span> + splitTime +
<a name="221" href="#221">221</a>         <span class="jxr_string">" ms for "</span> + srcDir.toString();
<a name="222" href="#222">222</a>     status.markComplete(msg);
<a name="223" href="#223">223</a>     LOG.info(msg);
<a name="224" href="#224">224</a>     <strong class="jxr_keyword">return</strong> splits;
<a name="225" href="#225">225</a>   }
<a name="226" href="#226">226</a>   
<a name="227" href="#227">227</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> logAndReport(String msg) {
<a name="228" href="#228">228</a>     status.setStatus(msg);
<a name="229" href="#229">229</a>     LOG.info(msg);
<a name="230" href="#230">230</a>   }
<a name="231" href="#231">231</a> 
<a name="232" href="#232">232</a>   <em class="jxr_javadoccomment">/**</em>
<a name="233" href="#233">233</a> <em class="jxr_javadoccomment">   * @return time that this split took</em>
<a name="234" href="#234">234</a> <em class="jxr_javadoccomment">   */</em>
<a name="235" href="#235">235</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getTime() {
<a name="236" href="#236">236</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.splitTime;
<a name="237" href="#237">237</a>   }
<a name="238" href="#238">238</a> 
<a name="239" href="#239">239</a>   <em class="jxr_javadoccomment">/**</em>
<a name="240" href="#240">240</a> <em class="jxr_javadoccomment">   * @return aggregate size of hlogs that were split</em>
<a name="241" href="#241">241</a> <em class="jxr_javadoccomment">   */</em>
<a name="242" href="#242">242</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getSize() {
<a name="243" href="#243">243</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.splitSize;
<a name="244" href="#244">244</a>   }
<a name="245" href="#245">245</a> 
<a name="246" href="#246">246</a>   <em class="jxr_javadoccomment">/**</em>
<a name="247" href="#247">247</a> <em class="jxr_javadoccomment">   * @return a map from encoded region ID to the number of edits written out</em>
<a name="248" href="#248">248</a> <em class="jxr_javadoccomment">   * for that region.</em>
<a name="249" href="#249">249</a> <em class="jxr_javadoccomment">   */</em>
<a name="250" href="#250">250</a>   Map&lt;byte[], Long&gt; getOutputCounts() {
<a name="251" href="#251">251</a>     Preconditions.checkState(hasSplit);
<a name="252" href="#252">252</a>     <strong class="jxr_keyword">return</strong> outputSink.getOutputCounts();
<a name="253" href="#253">253</a>   }
<a name="254" href="#254">254</a> 
<a name="255" href="#255">255</a>   <em class="jxr_javadoccomment">/**</em>
<a name="256" href="#256">256</a> <em class="jxr_javadoccomment">   * Splits the HLog edits in the given list of logfiles (that are a mix of edits</em>
<a name="257" href="#257">257</a> <em class="jxr_javadoccomment">   * on multiple regions) by region and then splits them per region directories,</em>
<a name="258" href="#258">258</a> <em class="jxr_javadoccomment">   * in batches of (hbase.hlog.split.batch.size)</em>
<a name="259" href="#259">259</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="260" href="#260">260</a> <em class="jxr_javadoccomment">   * This process is split into multiple threads. In the main thread, we loop</em>
<a name="261" href="#261">261</a> <em class="jxr_javadoccomment">   * through the logs to be split. For each log, we:</em>
<a name="262" href="#262">262</a> <em class="jxr_javadoccomment">   * &lt;ul&gt;</em>
<a name="263" href="#263">263</a> <em class="jxr_javadoccomment">   *   &lt;li&gt; Recover it (take and drop HDFS lease) to ensure no other process can write&lt;/li&gt;</em>
<a name="264" href="#264">264</a> <em class="jxr_javadoccomment">   *   &lt;li&gt; Read each edit (see {@link #parseHLog}&lt;/li&gt;</em>
<a name="265" href="#265">265</a> <em class="jxr_javadoccomment">   *   &lt;li&gt; Mark as "processed" or "corrupt" depending on outcome&lt;/li&gt;</em>
<a name="266" href="#266">266</a> <em class="jxr_javadoccomment">   * &lt;/ul&gt;</em>
<a name="267" href="#267">267</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="268" href="#268">268</a> <em class="jxr_javadoccomment">   * Each edit is passed into the EntryBuffers instance, which takes care of</em>
<a name="269" href="#269">269</a> <em class="jxr_javadoccomment">   * memory accounting and splitting the edits by region.</em>
<a name="270" href="#270">270</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="271" href="#271">271</a> <em class="jxr_javadoccomment">   * The OutputSink object then manages N other WriterThreads which pull chunks</em>
<a name="272" href="#272">272</a> <em class="jxr_javadoccomment">   * of edits from EntryBuffers and write them to the output region directories.</em>
<a name="273" href="#273">273</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="274" href="#274">274</a> <em class="jxr_javadoccomment">   * After the process is complete, the log files are archived to a separate</em>
<a name="275" href="#275">275</a> <em class="jxr_javadoccomment">   * directory.</em>
<a name="276" href="#276">276</a> <em class="jxr_javadoccomment">   */</em>
<a name="277" href="#277">277</a>   <strong class="jxr_keyword">private</strong> List&lt;Path&gt; splitLog(<strong class="jxr_keyword">final</strong> FileStatus[] logfiles, CountDownLatch latch)
<a name="278" href="#278">278</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="279" href="#279">279</a>     List&lt;Path&gt; processedLogs = <strong class="jxr_keyword">new</strong> ArrayList&lt;Path&gt;();
<a name="280" href="#280">280</a>     List&lt;Path&gt; corruptedLogs = <strong class="jxr_keyword">new</strong> ArrayList&lt;Path&gt;();
<a name="281" href="#281">281</a>     List&lt;Path&gt; splits = <strong class="jxr_keyword">null</strong>;
<a name="282" href="#282">282</a> 
<a name="283" href="#283">283</a>     <strong class="jxr_keyword">boolean</strong> skipErrors = conf.getBoolean(<span class="jxr_string">"hbase.hlog.split.skip.errors"</span>, <strong class="jxr_keyword">true</strong>);
<a name="284" href="#284">284</a> 
<a name="285" href="#285">285</a>     countTotalBytes(logfiles);
<a name="286" href="#286">286</a>     splitSize = 0;
<a name="287" href="#287">287</a> 
<a name="288" href="#288">288</a>     outputSink.startWriterThreads(entryBuffers);
<a name="289" href="#289">289</a> 
<a name="290" href="#290">290</a>     <strong class="jxr_keyword">try</strong> {
<a name="291" href="#291">291</a>       <strong class="jxr_keyword">int</strong> i = 0;
<a name="292" href="#292">292</a>       <strong class="jxr_keyword">for</strong> (FileStatus log : logfiles) {
<a name="293" href="#293">293</a>        Path logPath = log.getPath();
<a name="294" href="#294">294</a>         <strong class="jxr_keyword">long</strong> logLength = log.getLen();
<a name="295" href="#295">295</a>         splitSize += logLength;
<a name="296" href="#296">296</a>         logAndReport(<span class="jxr_string">"Splitting hlog "</span> + (i++ + 1) + <span class="jxr_string">" of "</span> + logfiles.length
<a name="297" href="#297">297</a>             + <span class="jxr_string">": "</span> + logPath + <span class="jxr_string">", length="</span> + logLength);
<a name="298" href="#298">298</a>         <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> in;
<a name="299" href="#299">299</a>         <strong class="jxr_keyword">try</strong> {
<a name="300" href="#300">300</a>           in = getReader(fs, log, conf, skipErrors, <strong class="jxr_keyword">null</strong>);
<a name="301" href="#301">301</a>           <strong class="jxr_keyword">if</strong> (in != <strong class="jxr_keyword">null</strong>) {
<a name="302" href="#302">302</a>             parseHLog(in, logPath, entryBuffers, fs, conf, skipErrors);
<a name="303" href="#303">303</a>             <strong class="jxr_keyword">try</strong> {
<a name="304" href="#304">304</a>               in.close();
<a name="305" href="#305">305</a>             } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="306" href="#306">306</a>               LOG.warn(<span class="jxr_string">"Close log reader threw exception -- continuing"</span>,
<a name="307" href="#307">307</a>                   e);
<a name="308" href="#308">308</a>             }
<a name="309" href="#309">309</a>           }
<a name="310" href="#310">310</a>           processedLogs.add(logPath);
<a name="311" href="#311">311</a>         } <strong class="jxr_keyword">catch</strong> (CorruptedLogFileException e) {
<a name="312" href="#312">312</a>           LOG.info(<span class="jxr_string">"Got while parsing hlog "</span> + logPath +
<a name="313" href="#313">313</a>               <span class="jxr_string">". Marking as corrupted"</span>, e);
<a name="314" href="#314">314</a>           corruptedLogs.add(logPath);
<a name="315" href="#315">315</a>           <strong class="jxr_keyword">continue</strong>;
<a name="316" href="#316">316</a>         }
<a name="317" href="#317">317</a>       }
<a name="318" href="#318">318</a>       status.setStatus(<span class="jxr_string">"Log splits complete. Checking for orphaned logs."</span>);
<a name="319" href="#319">319</a> 
<a name="320" href="#320">320</a>       <strong class="jxr_keyword">if</strong> (latch != <strong class="jxr_keyword">null</strong>) {
<a name="321" href="#321">321</a>         <strong class="jxr_keyword">try</strong> {
<a name="322" href="#322">322</a>           latch.await();
<a name="323" href="#323">323</a>         } <strong class="jxr_keyword">catch</strong> (InterruptedException ie) {
<a name="324" href="#324">324</a>           LOG.warn(<span class="jxr_string">"wait for latch interrupted"</span>);
<a name="325" href="#325">325</a>           Thread.currentThread().interrupt();
<a name="326" href="#326">326</a>         }
<a name="327" href="#327">327</a>       }
<a name="328" href="#328">328</a>       FileStatus[] currFiles = fs.listStatus(srcDir);
<a name="329" href="#329">329</a>       <strong class="jxr_keyword">if</strong> (currFiles.length &gt; processedLogs.size()
<a name="330" href="#330">330</a>           + corruptedLogs.size()) {
<a name="331" href="#331">331</a>         <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/OrphanHLogAfterSplitException.html">OrphanHLogAfterSplitException</a>(
<a name="332" href="#332">332</a>           <span class="jxr_string">"Discovered orphan hlog after split. Maybe the "</span>
<a name="333" href="#333">333</a>             + <span class="jxr_string">"HRegionServer was not dead when we started"</span>);
<a name="334" href="#334">334</a>       }
<a name="335" href="#335">335</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="336" href="#336">336</a>       status.setStatus(<span class="jxr_string">"Finishing writing output logs and closing down."</span>);
<a name="337" href="#337">337</a>       splits = outputSink.finishWritingAndClose();
<a name="338" href="#338">338</a>     }
<a name="339" href="#339">339</a>     status.setStatus(<span class="jxr_string">"Archiving logs after completed split"</span>);
<a name="340" href="#340">340</a>     archiveLogs(srcDir, corruptedLogs, processedLogs, oldLogDir, fs, conf);
<a name="341" href="#341">341</a>     <strong class="jxr_keyword">return</strong> splits;
<a name="342" href="#342">342</a>   }
<a name="343" href="#343">343</a> 
<a name="344" href="#344">344</a>   <em class="jxr_javadoccomment">/**</em>
<a name="345" href="#345">345</a> <em class="jxr_javadoccomment">   * @return the total size of the passed list of files.</em>
<a name="346" href="#346">346</a> <em class="jxr_javadoccomment">   */</em>
<a name="347" href="#347">347</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">long</strong> countTotalBytes(FileStatus[] logfiles) {
<a name="348" href="#348">348</a>     <strong class="jxr_keyword">long</strong> ret = 0;
<a name="349" href="#349">349</a>     <strong class="jxr_keyword">for</strong> (FileStatus stat : logfiles) {
<a name="350" href="#350">350</a>       ret += stat.getLen();
<a name="351" href="#351">351</a>     }
<a name="352" href="#352">352</a>     <strong class="jxr_keyword">return</strong> ret;
<a name="353" href="#353">353</a>   }
<a name="354" href="#354">354</a> 
<a name="355" href="#355">355</a>   <em class="jxr_javadoccomment">/**</em>
<a name="356" href="#356">356</a> <em class="jxr_javadoccomment">   * Splits a HLog file into region's recovered-edits directory</em>
<a name="357" href="#357">357</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="358" href="#358">358</a> <em class="jxr_javadoccomment">   * If the log file has N regions then N recovered.edits files will be</em>
<a name="359" href="#359">359</a> <em class="jxr_javadoccomment">   * produced. There is no buffering in this code. Instead it relies on the</em>
<a name="360" href="#360">360</a> <em class="jxr_javadoccomment">   * buffering in the SequenceFileWriter.</em>
<a name="361" href="#361">361</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="362" href="#362">362</a> <em class="jxr_javadoccomment">   * @param rootDir</em>
<a name="363" href="#363">363</a> <em class="jxr_javadoccomment">   * @param logfile</em>
<a name="364" href="#364">364</a> <em class="jxr_javadoccomment">   * @param fs</em>
<a name="365" href="#365">365</a> <em class="jxr_javadoccomment">   * @param conf</em>
<a name="366" href="#366">366</a> <em class="jxr_javadoccomment">   * @param reporter</em>
<a name="367" href="#367">367</a> <em class="jxr_javadoccomment">   * @return false if it is interrupted by the progress-able.</em>
<a name="368" href="#368">368</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="369" href="#369">369</a> <em class="jxr_javadoccomment">   */</em>
<a name="370" href="#370">370</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> splitLogFile(Path rootDir, FileStatus logfile,
<a name="371" href="#371">371</a>       FileSystem fs, Configuration conf, <a href="../../../../../../org/apache/hadoop/hbase/util/CancelableProgressable.html">CancelableProgressable</a> reporter)
<a name="372" href="#372">372</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="373" href="#373">373</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">HLogSplitter</a> s = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">HLogSplitter</a>(conf, rootDir, <strong class="jxr_keyword">null</strong>, <strong class="jxr_keyword">null</strong> <em class="jxr_comment">/*<em class="jxr_comment"> oldLogDir */</em>,</em>
<a name="374" href="#374">374</a>         fs);
<a name="375" href="#375">375</a>     <strong class="jxr_keyword">return</strong> s.splitLogFile(logfile, reporter);
<a name="376" href="#376">376</a>   }
<a name="377" href="#377">377</a> 
<a name="378" href="#378">378</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> splitLogFile(FileStatus logfile,
<a name="379" href="#379">379</a>       <a href="../../../../../../org/apache/hadoop/hbase/util/CancelableProgressable.html">CancelableProgressable</a> reporter) <strong class="jxr_keyword">throws</strong> IOException {
<a name="380" href="#380">380</a>     <strong class="jxr_keyword">final</strong> Map&lt;byte[], Object&gt; logWriters = Collections.
<a name="381" href="#381">381</a>     synchronizedMap(<strong class="jxr_keyword">new</strong> TreeMap&lt;byte[], Object&gt;(Bytes.BYTES_COMPARATOR));
<a name="382" href="#382">382</a>     <strong class="jxr_keyword">boolean</strong> isCorrupted = false;
<a name="383" href="#383">383</a>     Preconditions.checkState(status == <strong class="jxr_keyword">null</strong>);
<a name="384" href="#384">384</a> 
<a name="385" href="#385">385</a>     Object BAD_WRITER = <strong class="jxr_keyword">new</strong> Object();
<a name="386" href="#386">386</a> 
<a name="387" href="#387">387</a>     <strong class="jxr_keyword">boolean</strong> skipErrors = conf.getBoolean(<span class="jxr_string">"hbase.hlog.split.skip.errors"</span>,
<a name="388" href="#388">388</a>         HLog.SPLIT_SKIP_ERRORS_DEFAULT);
<a name="389" href="#389">389</a>     <strong class="jxr_keyword">int</strong> interval = conf.getInt(<span class="jxr_string">"hbase.splitlog.report.interval.loglines"</span>, 1024);
<a name="390" href="#390">390</a>     Path logPath = logfile.getPath();
<a name="391" href="#391">391</a>     <strong class="jxr_keyword">boolean</strong> progress_failed = false;
<a name="392" href="#392">392</a>     <strong class="jxr_keyword">int</strong> editsCount = 0;
<a name="393" href="#393">393</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> in = <strong class="jxr_keyword">null</strong>;
<a name="394" href="#394">394</a> 
<a name="395" href="#395">395</a>     <strong class="jxr_keyword">try</strong> {
<a name="396" href="#396">396</a>       status = TaskMonitor.get().createStatus(
<a name="397" href="#397">397</a>         <span class="jxr_string">"Splitting log file "</span> + logfile.getPath() +
<a name="398" href="#398">398</a>         <span class="jxr_string">"into a temporary staging area."</span>);
<a name="399" href="#399">399</a>       <strong class="jxr_keyword">long</strong> logLength = logfile.getLen();
<a name="400" href="#400">400</a>       LOG.info(<span class="jxr_string">"Splitting hlog: "</span> + logPath + <span class="jxr_string">", length="</span> + logLength);
<a name="401" href="#401">401</a>       status.setStatus(<span class="jxr_string">"Opening log file"</span>);
<a name="402" href="#402">402</a>       <strong class="jxr_keyword">if</strong> (reporter != <strong class="jxr_keyword">null</strong> &amp;&amp; !reporter.progress()) {
<a name="403" href="#403">403</a>         progress_failed = <strong class="jxr_keyword">true</strong>;
<a name="404" href="#404">404</a>         <strong class="jxr_keyword">return</strong> false;
<a name="405" href="#405">405</a>       }
<a name="406" href="#406">406</a>       <strong class="jxr_keyword">try</strong> {
<a name="407" href="#407">407</a>         in = getReader(fs, logfile, conf, skipErrors, reporter);
<a name="408" href="#408">408</a>       } <strong class="jxr_keyword">catch</strong> (CorruptedLogFileException e) {
<a name="409" href="#409">409</a>         LOG.warn(<span class="jxr_string">"Could not get reader, corrupted log file "</span> + logPath, e);
<a name="410" href="#410">410</a>         ZKSplitLog.markCorrupted(rootDir, logfile.getPath().getName(), fs);
<a name="411" href="#411">411</a>         isCorrupted = <strong class="jxr_keyword">true</strong>;
<a name="412" href="#412">412</a>       }
<a name="413" href="#413">413</a>       <strong class="jxr_keyword">if</strong> (in == <strong class="jxr_keyword">null</strong>) {
<a name="414" href="#414">414</a>         status.markComplete(<span class="jxr_string">"Was nothing to split in log file"</span>);
<a name="415" href="#415">415</a>         LOG.warn(<span class="jxr_string">"Nothing to split in log file "</span> + logPath);
<a name="416" href="#416">416</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">true</strong>;
<a name="417" href="#417">417</a>       }
<a name="418" href="#418">418</a> 
<a name="419" href="#419">419</a>       <strong class="jxr_keyword">int</strong> numOpenedFilesBeforeReporting =
<a name="420" href="#420">420</a>         conf.getInt(<span class="jxr_string">"hbase.splitlog.report.openedfiles"</span>, 3);
<a name="421" href="#421">421</a>       <strong class="jxr_keyword">int</strong> numNewlyOpenedFiles = 0;
<a name="422" href="#422">422</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry;
<a name="423" href="#423">423</a> 
<a name="424" href="#424">424</a>       <strong class="jxr_keyword">while</strong> ((entry = getNextLogLine(in,logPath, skipErrors)) != <strong class="jxr_keyword">null</strong>) {
<a name="425" href="#425">425</a>         byte[] region = entry.getKey().getEncodedRegionName();
<a name="426" href="#426">426</a>         Object o = logWriters.get(region);
<a name="427" href="#427">427</a>         <strong class="jxr_keyword">if</strong> (o == BAD_WRITER) {
<a name="428" href="#428">428</a>           <strong class="jxr_keyword">continue</strong>;
<a name="429" href="#429">429</a>         }
<a name="430" href="#430">430</a>         <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> wap = (WriterAndPath)o;
<a name="431" href="#431">431</a>         <strong class="jxr_keyword">if</strong> (wap == <strong class="jxr_keyword">null</strong>) {
<a name="432" href="#432">432</a>           wap = createWAP(region, entry, rootDir, fs, conf);
<a name="433" href="#433">433</a>           numNewlyOpenedFiles++;
<a name="434" href="#434">434</a>           <strong class="jxr_keyword">if</strong> (wap == <strong class="jxr_keyword">null</strong>) {
<a name="435" href="#435">435</a>             <em class="jxr_comment">// ignore edits from this region. It doesn't exist anymore.</em>
<a name="436" href="#436">436</a>             <em class="jxr_comment">// It was probably already split.</em>
<a name="437" href="#437">437</a>             logWriters.put(region, BAD_WRITER);
<a name="438" href="#438">438</a>             <strong class="jxr_keyword">continue</strong>;
<a name="439" href="#439">439</a>           } <strong class="jxr_keyword">else</strong> {
<a name="440" href="#440">440</a>             logWriters.put(region, wap);
<a name="441" href="#441">441</a>           }
<a name="442" href="#442">442</a>         }
<a name="443" href="#443">443</a>         wap.w.append(entry);
<a name="444" href="#444">444</a>         outputSink.updateRegionMaximumEditLogSeqNum(entry);
<a name="445" href="#445">445</a>         editsCount++;
<a name="446" href="#446">446</a>         <em class="jxr_comment">// If sufficient edits have passed OR we've opened a few files, check if</em>
<a name="447" href="#447">447</a>         <em class="jxr_comment">// we should report progress.</em>
<a name="448" href="#448">448</a>         <strong class="jxr_keyword">if</strong> (editsCount % interval == 0 ||
<a name="449" href="#449">449</a>             (numNewlyOpenedFiles &gt; numOpenedFilesBeforeReporting)) {
<a name="450" href="#450">450</a>           <em class="jxr_comment">// Zero out files counter each time we fall in here.</em>
<a name="451" href="#451">451</a>           numNewlyOpenedFiles = 0;
<a name="452" href="#452">452</a>           String countsStr = <span class="jxr_string">"edits="</span> + editsCount + <span class="jxr_string">", files="</span> + logWriters.size();
<a name="453" href="#453">453</a>           status.setStatus(<span class="jxr_string">"Split "</span> + countsStr);
<a name="454" href="#454">454</a>           <strong class="jxr_keyword">if</strong> (reporter != <strong class="jxr_keyword">null</strong> &amp;&amp; reporter.progress() == false) {
<a name="455" href="#455">455</a>             status.markComplete(<span class="jxr_string">"Failed: reporter.progress asked us to terminate; "</span> + countsStr);
<a name="456" href="#456">456</a>             progress_failed = <strong class="jxr_keyword">true</strong>;
<a name="457" href="#457">457</a>             <strong class="jxr_keyword">return</strong> false;
<a name="458" href="#458">458</a>           }
<a name="459" href="#459">459</a>         }
<a name="460" href="#460">460</a>       }
<a name="461" href="#461">461</a>     } <strong class="jxr_keyword">catch</strong> (CorruptedLogFileException e) {
<a name="462" href="#462">462</a>       LOG.warn(<span class="jxr_string">"Could not parse, corrupted log file "</span> + logPath, e);
<a name="463" href="#463">463</a>       ZKSplitLog.markCorrupted(rootDir, logfile.getPath().getName(), fs);
<a name="464" href="#464">464</a>       isCorrupted = <strong class="jxr_keyword">true</strong>;
<a name="465" href="#465">465</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="466" href="#466">466</a>       e = RemoteExceptionHandler.checkIOException(e);
<a name="467" href="#467">467</a>       <strong class="jxr_keyword">throw</strong> e;
<a name="468" href="#468">468</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="469" href="#469">469</a>       <strong class="jxr_keyword">boolean</strong> allWritersClosed = false;
<a name="470" href="#470">470</a>       <strong class="jxr_keyword">int</strong> n = 0;
<a name="471" href="#471">471</a>       <strong class="jxr_keyword">try</strong> {
<a name="472" href="#472">472</a>         <strong class="jxr_keyword">for</strong> (Map.Entry&lt;byte[], Object&gt; logWritersEntry : logWriters.entrySet()) {
<a name="473" href="#473">473</a>           Object o = logWritersEntry.getValue();
<a name="474" href="#474">474</a>           <strong class="jxr_keyword">if</strong> ((progress_failed == false) &amp;&amp; (reporter != <strong class="jxr_keyword">null</strong>) &amp;&amp; (reporter.progress() == false)) {
<a name="475" href="#475">475</a>             progress_failed = <strong class="jxr_keyword">true</strong>;
<a name="476" href="#476">476</a>           }
<a name="477" href="#477">477</a>           <strong class="jxr_keyword">if</strong> (o == BAD_WRITER) {
<a name="478" href="#478">478</a>             <strong class="jxr_keyword">continue</strong>;
<a name="479" href="#479">479</a>           }
<a name="480" href="#480">480</a>           n++;
<a name="481" href="#481">481</a>           <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> wap = (WriterAndPath) o;
<a name="482" href="#482">482</a>           wap.writerClosed = <strong class="jxr_keyword">true</strong>;
<a name="483" href="#483">483</a>           wap.w.close();
<a name="484" href="#484">484</a>           LOG.debug(<span class="jxr_string">"Closed "</span> + wap.p);
<a name="485" href="#485">485</a>           Path dst = getCompletedRecoveredEditsFilePath(wap.p,
<a name="486" href="#486">486</a>               outputSink.getRegionMaximumEditLogSeqNum(logWritersEntry.getKey()));
<a name="487" href="#487">487</a>           <strong class="jxr_keyword">if</strong> (!dst.equals(wap.p) &amp;&amp; fs.exists(dst)) {
<a name="488" href="#488">488</a>             LOG.warn(<span class="jxr_string">"Found existing old edits file. It could be the "</span>
<a name="489" href="#489">489</a>                 + <span class="jxr_string">"result of a previous failed split attempt. Deleting "</span> + dst + <span class="jxr_string">", length="</span>
<a name="490" href="#490">490</a>                 + fs.getFileStatus(dst).getLen());
<a name="491" href="#491">491</a>             <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.deleteFileFromFileSystem(fs, dst)) {
<a name="492" href="#492">492</a>               LOG.warn(<span class="jxr_string">"Failed deleting of old "</span> + dst);
<a name="493" href="#493">493</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed deleting of old "</span> + dst);
<a name="494" href="#494">494</a>             }
<a name="495" href="#495">495</a>           }
<a name="496" href="#496">496</a>           <em class="jxr_comment">// Skip the unit tests which create a splitter that reads and writes the</em>
<a name="497" href="#497">497</a>           <em class="jxr_comment">// data without touching disk. TestHLogSplit#testThreading is an</em>
<a name="498" href="#498">498</a>           <em class="jxr_comment">// example.</em>
<a name="499" href="#499">499</a>           <strong class="jxr_keyword">if</strong> (fs.exists(wap.p)) {
<a name="500" href="#500">500</a>             <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, wap.p, dst)) {
<a name="501" href="#501">501</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed renaming "</span> + wap.p + <span class="jxr_string">" to "</span> + dst);
<a name="502" href="#502">502</a>             }
<a name="503" href="#503">503</a>             LOG.debug(<span class="jxr_string">"Rename "</span> + wap.p + <span class="jxr_string">" to "</span> + dst);
<a name="504" href="#504">504</a>           }
<a name="505" href="#505">505</a>         }
<a name="506" href="#506">506</a>         allWritersClosed = <strong class="jxr_keyword">true</strong>;
<a name="507" href="#507">507</a>       } <strong class="jxr_keyword">finally</strong> {
<a name="508" href="#508">508</a>         String msg = <span class="jxr_string">"Processed "</span> + editsCount + <span class="jxr_string">" edits across "</span> + n + <span class="jxr_string">" regions"</span>
<a name="509" href="#509">509</a>             + <span class="jxr_string">" threw away edits for "</span> + (logWriters.size() - n) + <span class="jxr_string">" regions"</span> + <span class="jxr_string">"; log file="</span>
<a name="510" href="#510">510</a>             + logPath + <span class="jxr_string">" is corrupted = "</span> + isCorrupted + <span class="jxr_string">" progress failed = "</span> + progress_failed;
<a name="511" href="#511">511</a>         LOG.info(msg);
<a name="512" href="#512">512</a>         status.markComplete(msg);
<a name="513" href="#513">513</a>         <strong class="jxr_keyword">if</strong> (!allWritersClosed) {
<a name="514" href="#514">514</a>           <strong class="jxr_keyword">for</strong> (Map.Entry&lt;byte[], Object&gt; logWritersEntry : logWriters.entrySet()) {
<a name="515" href="#515">515</a>             Object o = logWritersEntry.getValue();
<a name="516" href="#516">516</a>             <strong class="jxr_keyword">if</strong> (o != BAD_WRITER) {
<a name="517" href="#517">517</a>               <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> wap = (WriterAndPath) o;
<a name="518" href="#518">518</a>               <strong class="jxr_keyword">try</strong> {
<a name="519" href="#519">519</a>                 <strong class="jxr_keyword">if</strong> (!wap.writerClosed) {
<a name="520" href="#520">520</a>                   wap.writerClosed = <strong class="jxr_keyword">true</strong>;
<a name="521" href="#521">521</a>                   wap.w.close();
<a name="522" href="#522">522</a>                 }
<a name="523" href="#523">523</a>               } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="524" href="#524">524</a>                 LOG.debug(<span class="jxr_string">"Exception while closing the writer :"</span>, e);
<a name="525" href="#525">525</a>               }
<a name="526" href="#526">526</a>             }
<a name="527" href="#527">527</a>           }
<a name="528" href="#528">528</a>         }
<a name="529" href="#529">529</a>         <strong class="jxr_keyword">if</strong> (in != <strong class="jxr_keyword">null</strong>) {
<a name="530" href="#530">530</a>           in.close();
<a name="531" href="#531">531</a>         }
<a name="532" href="#532">532</a>       }
<a name="533" href="#533">533</a>     }
<a name="534" href="#534">534</a>     <strong class="jxr_keyword">return</strong> !progress_failed;
<a name="535" href="#535">535</a>   }
<a name="536" href="#536">536</a> 
<a name="537" href="#537">537</a>   <em class="jxr_javadoccomment">/**</em>
<a name="538" href="#538">538</a> <em class="jxr_javadoccomment">   * Completes the work done by splitLogFile by archiving logs</em>
<a name="539" href="#539">539</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="540" href="#540">540</a> <em class="jxr_javadoccomment">   * It is invoked by SplitLogManager once it knows that one of the</em>
<a name="541" href="#541">541</a> <em class="jxr_javadoccomment">   * SplitLogWorkers have completed the splitLogFile() part. If the master</em>
<a name="542" href="#542">542</a> <em class="jxr_javadoccomment">   * crashes then this function might get called multiple times.</em>
<a name="543" href="#543">543</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="544" href="#544">544</a> <em class="jxr_javadoccomment">   * @param logfile</em>
<a name="545" href="#545">545</a> <em class="jxr_javadoccomment">   * @param conf</em>
<a name="546" href="#546">546</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="547" href="#547">547</a> <em class="jxr_javadoccomment">   */</em>
<a name="548" href="#548">548</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> finishSplitLogFile(String logfile, Configuration conf)
<a name="549" href="#549">549</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="550" href="#550">550</a>     Path rootdir = FSUtils.getRootDir(conf);
<a name="551" href="#551">551</a>     Path oldLogDir = <strong class="jxr_keyword">new</strong> Path(rootdir, HConstants.HREGION_OLDLOGDIR_NAME);
<a name="552" href="#552">552</a>     finishSplitLogFile(rootdir, oldLogDir, logfile, conf);
<a name="553" href="#553">553</a>   }
<a name="554" href="#554">554</a> 
<a name="555" href="#555">555</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> finishSplitLogFile(Path rootdir, Path oldLogDir,
<a name="556" href="#556">556</a>       String logfile, Configuration conf) <strong class="jxr_keyword">throws</strong> IOException {
<a name="557" href="#557">557</a>     List&lt;Path&gt; processedLogs = <strong class="jxr_keyword">new</strong> ArrayList&lt;Path&gt;();
<a name="558" href="#558">558</a>     List&lt;Path&gt; corruptedLogs = <strong class="jxr_keyword">new</strong> ArrayList&lt;Path&gt;();
<a name="559" href="#559">559</a>     FileSystem fs;
<a name="560" href="#560">560</a>     fs = rootdir.getFileSystem(conf);
<a name="561" href="#561">561</a>     Path logPath = <strong class="jxr_keyword">new</strong> Path(logfile);
<a name="562" href="#562">562</a>     <strong class="jxr_keyword">if</strong> (ZKSplitLog.isCorrupted(rootdir, logPath.getName(), fs)) {
<a name="563" href="#563">563</a>       corruptedLogs.add(logPath);
<a name="564" href="#564">564</a>     } <strong class="jxr_keyword">else</strong> {
<a name="565" href="#565">565</a>       processedLogs.add(logPath);
<a name="566" href="#566">566</a>     }
<a name="567" href="#567">567</a>     archiveLogs(<strong class="jxr_keyword">null</strong>, corruptedLogs, processedLogs, oldLogDir, fs, conf);
<a name="568" href="#568">568</a>     Path stagingDir = ZKSplitLog.getSplitLogDir(rootdir, logPath.getName());
<a name="569" href="#569">569</a>     HBaseFileSystem.deleteDirFromFileSystem(fs, stagingDir);
<a name="570" href="#570">570</a>   }
<a name="571" href="#571">571</a> 
<a name="572" href="#572">572</a>   <em class="jxr_javadoccomment">/**</em>
<a name="573" href="#573">573</a> <em class="jxr_javadoccomment">   * Moves processed logs to a oldLogDir after successful processing Moves</em>
<a name="574" href="#574">574</a> <em class="jxr_javadoccomment">   * corrupted logs (any log that couldn't be successfully parsed to corruptDir</em>
<a name="575" href="#575">575</a> <em class="jxr_javadoccomment">   * (.corrupt) for later investigation</em>
<a name="576" href="#576">576</a> <em class="jxr_javadoccomment">   *</em>
<a name="577" href="#577">577</a> <em class="jxr_javadoccomment">   * @param corruptedLogs</em>
<a name="578" href="#578">578</a> <em class="jxr_javadoccomment">   * @param processedLogs</em>
<a name="579" href="#579">579</a> <em class="jxr_javadoccomment">   * @param oldLogDir</em>
<a name="580" href="#580">580</a> <em class="jxr_javadoccomment">   * @param fs</em>
<a name="581" href="#581">581</a> <em class="jxr_javadoccomment">   * @param conf</em>
<a name="582" href="#582">582</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="583" href="#583">583</a> <em class="jxr_javadoccomment">   */</em>
<a name="584" href="#584">584</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> archiveLogs(
<a name="585" href="#585">585</a>       <strong class="jxr_keyword">final</strong> Path srcDir,
<a name="586" href="#586">586</a>       <strong class="jxr_keyword">final</strong> List&lt;Path&gt; corruptedLogs,
<a name="587" href="#587">587</a>       <strong class="jxr_keyword">final</strong> List&lt;Path&gt; processedLogs, <strong class="jxr_keyword">final</strong> Path oldLogDir,
<a name="588" href="#588">588</a>       <strong class="jxr_keyword">final</strong> FileSystem fs, <strong class="jxr_keyword">final</strong> Configuration conf) <strong class="jxr_keyword">throws</strong> IOException {
<a name="589" href="#589">589</a>     <strong class="jxr_keyword">final</strong> Path corruptDir = <strong class="jxr_keyword">new</strong> Path(conf.get(HConstants.HBASE_DIR), conf.get(
<a name="590" href="#590">590</a>         <span class="jxr_string">"hbase.regionserver.hlog.splitlog.corrupt.dir"</span>,  HConstants.CORRUPT_DIR_NAME));
<a name="591" href="#591">591</a> 
<a name="592" href="#592">592</a>     <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.makeDirOnFileSystem(fs, corruptDir)) {
<a name="593" href="#593">593</a>       LOG.info(<span class="jxr_string">"Unable to mkdir "</span> + corruptDir);
<a name="594" href="#594">594</a>     }
<a name="595" href="#595">595</a>     HBaseFileSystem.makeDirOnFileSystem(fs, oldLogDir);
<a name="596" href="#596">596</a> 
<a name="597" href="#597">597</a>     <em class="jxr_comment">// this method can get restarted or called multiple times for archiving</em>
<a name="598" href="#598">598</a>     <em class="jxr_comment">// the same log files.</em>
<a name="599" href="#599">599</a>     <strong class="jxr_keyword">for</strong> (Path corrupted : corruptedLogs) {
<a name="600" href="#600">600</a>       Path p = <strong class="jxr_keyword">new</strong> Path(corruptDir, corrupted.getName());
<a name="601" href="#601">601</a>       <strong class="jxr_keyword">if</strong> (fs.exists(corrupted)) {
<a name="602" href="#602">602</a>         <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, corrupted, p)) {
<a name="603" href="#603">603</a>           LOG.warn(<span class="jxr_string">"Unable to move corrupted log "</span> + corrupted + <span class="jxr_string">" to "</span> + p);
<a name="604" href="#604">604</a>         } <strong class="jxr_keyword">else</strong> {
<a name="605" href="#605">605</a>           LOG.warn(<span class="jxr_string">"Moving corrupted log "</span> + corrupted + <span class="jxr_string">" to "</span> + p);
<a name="606" href="#606">606</a>         }
<a name="607" href="#607">607</a>       }
<a name="608" href="#608">608</a>     }
<a name="609" href="#609">609</a> 
<a name="610" href="#610">610</a>     <strong class="jxr_keyword">for</strong> (Path p : processedLogs) {
<a name="611" href="#611">611</a>       Path newPath = HLog.getHLogArchivePath(oldLogDir, p);
<a name="612" href="#612">612</a>       <strong class="jxr_keyword">if</strong> (fs.exists(p)) {
<a name="613" href="#613">613</a>         <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, p, newPath)) {
<a name="614" href="#614">614</a>           LOG.warn(<span class="jxr_string">"Unable to move  "</span> + p + <span class="jxr_string">" to "</span> + newPath);
<a name="615" href="#615">615</a>         } <strong class="jxr_keyword">else</strong> {
<a name="616" href="#616">616</a>           LOG.debug(<span class="jxr_string">"Archived processed log "</span> + p + <span class="jxr_string">" to "</span> + newPath);
<a name="617" href="#617">617</a>         }
<a name="618" href="#618">618</a>       }
<a name="619" href="#619">619</a>     }
<a name="620" href="#620">620</a> 
<a name="621" href="#621">621</a>     <em class="jxr_comment">// distributed log splitting removes the srcDir (region's log dir) later</em>
<a name="622" href="#622">622</a>     <em class="jxr_comment">// when all the log files in that srcDir have been successfully processed</em>
<a name="623" href="#623">623</a>     <strong class="jxr_keyword">if</strong> (srcDir != <strong class="jxr_keyword">null</strong> &amp;&amp; !HBaseFileSystem.deleteDirFromFileSystem(fs, srcDir)) {
<a name="624" href="#624">624</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Unable to delete src dir: "</span> + srcDir);
<a name="625" href="#625">625</a>     }
<a name="626" href="#626">626</a>   }
<a name="627" href="#627">627</a> 
<a name="628" href="#628">628</a>   <em class="jxr_javadoccomment">/**</em>
<a name="629" href="#629">629</a> <em class="jxr_javadoccomment">   * Path to a file under RECOVERED_EDITS_DIR directory of the region found in</em>
<a name="630" href="#630">630</a> <em class="jxr_javadoccomment">   * &lt;code&gt;logEntry&lt;/code&gt; named for the sequenceid in the passed</em>
<a name="631" href="#631">631</a> <em class="jxr_javadoccomment">   * &lt;code&gt;logEntry&lt;/code&gt;: e.g. /hbase/some_table/2323432434/recovered.edits/2332.</em>
<a name="632" href="#632">632</a> <em class="jxr_javadoccomment">   * This method also ensures existence of RECOVERED_EDITS_DIR under the region</em>
<a name="633" href="#633">633</a> <em class="jxr_javadoccomment">   * creating it if necessary.</em>
<a name="634" href="#634">634</a> <em class="jxr_javadoccomment">   * @param fs</em>
<a name="635" href="#635">635</a> <em class="jxr_javadoccomment">   * @param logEntry</em>
<a name="636" href="#636">636</a> <em class="jxr_javadoccomment">   * @param rootDir HBase root dir.</em>
<a name="637" href="#637">637</a> <em class="jxr_javadoccomment">   * @return Path to file into which to dump split log edits.</em>
<a name="638" href="#638">638</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="639" href="#639">639</a> <em class="jxr_javadoccomment">   */</em>
<a name="640" href="#640">640</a>   <strong class="jxr_keyword">static</strong> Path getRegionSplitEditsPath(<strong class="jxr_keyword">final</strong> FileSystem fs,
<a name="641" href="#641">641</a>       <strong class="jxr_keyword">final</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> logEntry, <strong class="jxr_keyword">final</strong> Path rootDir, <strong class="jxr_keyword">boolean</strong> isCreate)
<a name="642" href="#642">642</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="643" href="#643">643</a>     Path tableDir = HTableDescriptor.getTableDir(rootDir, logEntry.getKey().getTablename());
<a name="644" href="#644">644</a>     String encodedRegionName = Bytes.toString(logEntry.getKey().getEncodedRegionName());
<a name="645" href="#645">645</a>     Path regiondir = HRegion.getRegionDir(tableDir, encodedRegionName);
<a name="646" href="#646">646</a>     Path dir = HLog.getRegionDirRecoveredEditsDir(regiondir);
<a name="647" href="#647">647</a> 
<a name="648" href="#648">648</a>     <strong class="jxr_keyword">if</strong> (!fs.exists(regiondir)) {
<a name="649" href="#649">649</a>       LOG.info(<span class="jxr_string">"This region's directory doesn't exist: "</span>
<a name="650" href="#650">650</a>           + regiondir.toString() + <span class="jxr_string">". It is very likely that it was"</span> +
<a name="651" href="#651">651</a>           <span class="jxr_string">" already split so it's safe to discard those edits."</span>);
<a name="652" href="#652">652</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="653" href="#653">653</a>     }
<a name="654" href="#654">654</a>     <strong class="jxr_keyword">if</strong> (fs.exists(dir) &amp;&amp; fs.isFile(dir)) {
<a name="655" href="#655">655</a>       Path tmp = <strong class="jxr_keyword">new</strong> Path(<span class="jxr_string">"/tmp"</span>);
<a name="656" href="#656">656</a>       <strong class="jxr_keyword">if</strong> (!fs.exists(tmp)) {
<a name="657" href="#657">657</a>         HBaseFileSystem.makeDirOnFileSystem(fs, tmp);
<a name="658" href="#658">658</a>       }
<a name="659" href="#659">659</a>       tmp = <strong class="jxr_keyword">new</strong> Path(tmp,
<a name="660" href="#660">660</a>         HLog.RECOVERED_EDITS_DIR + <span class="jxr_string">"_"</span> + encodedRegionName);
<a name="661" href="#661">661</a>       LOG.warn(<span class="jxr_string">"Found existing old file: "</span> + dir + <span class="jxr_string">". It could be some "</span>
<a name="662" href="#662">662</a>         + <span class="jxr_string">"leftover of an old installation. It should be a folder instead. "</span>
<a name="663" href="#663">663</a>         + <span class="jxr_string">"So moving it to "</span> + tmp);
<a name="664" href="#664">664</a>       <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, dir, tmp)) {
<a name="665" href="#665">665</a>         LOG.warn(<span class="jxr_string">"Failed to sideline old file "</span> + dir);
<a name="666" href="#666">666</a>       }
<a name="667" href="#667">667</a>     }
<a name="668" href="#668">668</a> 
<a name="669" href="#669">669</a>     <strong class="jxr_keyword">if</strong> (isCreate &amp;&amp; !fs.exists(dir) &amp;&amp; 
<a name="670" href="#670">670</a>         !HBaseFileSystem.makeDirOnFileSystem(fs, dir)) {
<a name="671" href="#671">671</a>       LOG.warn(<span class="jxr_string">"mkdir failed on "</span> + dir);
<a name="672" href="#672">672</a>     }
<a name="673" href="#673">673</a>     <em class="jxr_comment">// Append file name ends with RECOVERED_LOG_TMPFILE_SUFFIX to ensure</em>
<a name="674" href="#674">674</a>     <em class="jxr_comment">// region's replayRecoveredEdits will not delete it</em>
<a name="675" href="#675">675</a>     String fileName = formatRecoveredEditsFileName(logEntry.getKey()
<a name="676" href="#676">676</a>         .getLogSeqNum());
<a name="677" href="#677">677</a>     fileName = getTmpRecoveredEditsFileName(fileName);
<a name="678" href="#678">678</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> Path(dir, fileName);
<a name="679" href="#679">679</a>   }
<a name="680" href="#680">680</a> 
<a name="681" href="#681">681</a>   <strong class="jxr_keyword">static</strong> String getTmpRecoveredEditsFileName(String fileName) {
<a name="682" href="#682">682</a>     <strong class="jxr_keyword">return</strong> fileName + HLog.RECOVERED_LOG_TMPFILE_SUFFIX;
<a name="683" href="#683">683</a>   }
<a name="684" href="#684">684</a> 
<a name="685" href="#685">685</a>   <em class="jxr_javadoccomment">/**</em>
<a name="686" href="#686">686</a> <em class="jxr_javadoccomment">   * Get the completed recovered edits file path, renaming it to be by last edit</em>
<a name="687" href="#687">687</a> <em class="jxr_javadoccomment">   * in the file from its first edit. Then we could use the name to skip</em>
<a name="688" href="#688">688</a> <em class="jxr_javadoccomment">   * recovered edits when doing {@link HRegion#replayRecoveredEditsIfAny}.</em>
<a name="689" href="#689">689</a> <em class="jxr_javadoccomment">   * @param srcPath</em>
<a name="690" href="#690">690</a> <em class="jxr_javadoccomment">   * @param maximumEditLogSeqNum</em>
<a name="691" href="#691">691</a> <em class="jxr_javadoccomment">   * @return dstPath take file's last edit log seq num as the name</em>
<a name="692" href="#692">692</a> <em class="jxr_javadoccomment">   */</em>
<a name="693" href="#693">693</a>   <strong class="jxr_keyword">static</strong> Path getCompletedRecoveredEditsFilePath(Path srcPath,
<a name="694" href="#694">694</a>       Long maximumEditLogSeqNum) {
<a name="695" href="#695">695</a>     String fileName = formatRecoveredEditsFileName(maximumEditLogSeqNum);
<a name="696" href="#696">696</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> Path(srcPath.getParent(), fileName);
<a name="697" href="#697">697</a>   }
<a name="698" href="#698">698</a> 
<a name="699" href="#699">699</a>   <strong class="jxr_keyword">static</strong> String formatRecoveredEditsFileName(<strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> seqid) {
<a name="700" href="#700">700</a>     <strong class="jxr_keyword">return</strong> String.format(<span class="jxr_string">"%019d"</span>, seqid);
<a name="701" href="#701">701</a>   }
<a name="702" href="#702">702</a> 
<a name="703" href="#703">703</a>   <em class="jxr_javadoccomment">/**</em>
<a name="704" href="#704">704</a> <em class="jxr_javadoccomment">   * Parse a single hlog and put the edits in entryBuffers</em>
<a name="705" href="#705">705</a> <em class="jxr_javadoccomment">   *</em>
<a name="706" href="#706">706</a> <em class="jxr_javadoccomment">   * @param in the hlog reader</em>
<a name="707" href="#707">707</a> <em class="jxr_javadoccomment">   * @param path the path of the log file</em>
<a name="708" href="#708">708</a> <em class="jxr_javadoccomment">   * @param entryBuffers the buffer to hold the parsed edits</em>
<a name="709" href="#709">709</a> <em class="jxr_javadoccomment">   * @param fs the file system</em>
<a name="710" href="#710">710</a> <em class="jxr_javadoccomment">   * @param conf the configuration</em>
<a name="711" href="#711">711</a> <em class="jxr_javadoccomment">   * @param skipErrors indicator if CorruptedLogFileException should be thrown instead of IOException</em>
<a name="712" href="#712">712</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="713" href="#713">713</a> <em class="jxr_javadoccomment">   * @throws CorruptedLogFileException if hlog is corrupted</em>
<a name="714" href="#714">714</a> <em class="jxr_javadoccomment">   */</em>
<a name="715" href="#715">715</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> parseHLog(<strong class="jxr_keyword">final</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> in, Path path,
<a name="716" href="#716">716</a> 		EntryBuffers entryBuffers, <strong class="jxr_keyword">final</strong> FileSystem fs,
<a name="717" href="#717">717</a>     <strong class="jxr_keyword">final</strong> Configuration conf, <strong class="jxr_keyword">boolean</strong> skipErrors)
<a name="718" href="#718">718</a> 	<strong class="jxr_keyword">throws</strong> IOException, <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a> {
<a name="719" href="#719">719</a>     <strong class="jxr_keyword">int</strong> editsCount = 0;
<a name="720" href="#720">720</a>     <strong class="jxr_keyword">try</strong> {
<a name="721" href="#721">721</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry;
<a name="722" href="#722">722</a>       <strong class="jxr_keyword">while</strong> ((entry = getNextLogLine(in, path, skipErrors)) != <strong class="jxr_keyword">null</strong>) {
<a name="723" href="#723">723</a>         entryBuffers.appendEntry(entry);
<a name="724" href="#724">724</a>         editsCount++;
<a name="725" href="#725">725</a>       }
<a name="726" href="#726">726</a>     } <strong class="jxr_keyword">catch</strong> (InterruptedException ie) {
<a name="727" href="#727">727</a>       IOException t = <strong class="jxr_keyword">new</strong> InterruptedIOException();
<a name="728" href="#728">728</a>       t.initCause(ie);
<a name="729" href="#729">729</a>       <strong class="jxr_keyword">throw</strong> t;
<a name="730" href="#730">730</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="731" href="#731">731</a>       LOG.debug(<span class="jxr_string">"Pushed="</span> + editsCount + <span class="jxr_string">" entries from "</span> + path);
<a name="732" href="#732">732</a>     }
<a name="733" href="#733">733</a>   }
<a name="734" href="#734">734</a> 
<a name="735" href="#735">735</a>   <em class="jxr_javadoccomment">/**</em>
<a name="736" href="#736">736</a> <em class="jxr_javadoccomment">   * Create a new {@link Reader} for reading logs to split.</em>
<a name="737" href="#737">737</a> <em class="jxr_javadoccomment">   *</em>
<a name="738" href="#738">738</a> <em class="jxr_javadoccomment">   * @param fs</em>
<a name="739" href="#739">739</a> <em class="jxr_javadoccomment">   * @param file</em>
<a name="740" href="#740">740</a> <em class="jxr_javadoccomment">   * @param conf</em>
<a name="741" href="#741">741</a> <em class="jxr_javadoccomment">   * @return A new Reader instance</em>
<a name="742" href="#742">742</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="743" href="#743">743</a> <em class="jxr_javadoccomment">   * @throws CorruptedLogFile</em>
<a name="744" href="#744">744</a> <em class="jxr_javadoccomment">   */</em>
<a name="745" href="#745">745</a>   <strong class="jxr_keyword">protected</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> getReader(FileSystem fs, FileStatus file, Configuration conf,
<a name="746" href="#746">746</a>       <strong class="jxr_keyword">boolean</strong> skipErrors, <a href="../../../../../../org/apache/hadoop/hbase/util/CancelableProgressable.html">CancelableProgressable</a> reporter)
<a name="747" href="#747">747</a>       <strong class="jxr_keyword">throws</strong> IOException, <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a> {
<a name="748" href="#748">748</a>     Path path = file.getPath();
<a name="749" href="#749">749</a>     <strong class="jxr_keyword">long</strong> length = file.getLen();
<a name="750" href="#750">750</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> in;
<a name="751" href="#751">751</a> 
<a name="752" href="#752">752</a> 
<a name="753" href="#753">753</a>     <em class="jxr_comment">// Check for possibly empty file. With appends, currently Hadoop reports a</em>
<a name="754" href="#754">754</a>     <em class="jxr_comment">// zero length even if the file has been sync'd. Revisit if HDFS-376 or</em>
<a name="755" href="#755">755</a>     <em class="jxr_comment">// HDFS-878 is committed.</em>
<a name="756" href="#756">756</a>     <strong class="jxr_keyword">if</strong> (length &lt;= 0) {
<a name="757" href="#757">757</a>       LOG.warn(<span class="jxr_string">"File "</span> + path + <span class="jxr_string">" might be still open, length is 0"</span>);
<a name="758" href="#758">758</a>     }
<a name="759" href="#759">759</a> 
<a name="760" href="#760">760</a>     <strong class="jxr_keyword">try</strong> {
<a name="761" href="#761">761</a>       FSUtils.getInstance(fs, conf).recoverFileLease(fs, path, conf, reporter);
<a name="762" href="#762">762</a>       <strong class="jxr_keyword">try</strong> {
<a name="763" href="#763">763</a>         in = getReader(fs, path, conf, reporter);
<a name="764" href="#764">764</a>       } <strong class="jxr_keyword">catch</strong> (EOFException e) {
<a name="765" href="#765">765</a>         <strong class="jxr_keyword">if</strong> (length &lt;= 0) {
<a name="766" href="#766">766</a>           <em class="jxr_comment">// TODO should we ignore an empty, not-last log file if skip.errors</em>
<a name="767" href="#767">767</a>           <em class="jxr_comment">// is false? Either way, the caller should decide what to do. E.g.</em>
<a name="768" href="#768">768</a>           <em class="jxr_comment">// ignore if this is the last log in sequence.</em>
<a name="769" href="#769">769</a>           <em class="jxr_comment">// TODO is this scenario still possible if the log has been</em>
<a name="770" href="#770">770</a>           <em class="jxr_comment">// recovered (i.e. closed)</em>
<a name="771" href="#771">771</a>           LOG.warn(<span class="jxr_string">"Could not open "</span> + path + <span class="jxr_string">" for reading. File is empty"</span>, e);
<a name="772" href="#772">772</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="773" href="#773">773</a>         } <strong class="jxr_keyword">else</strong> {
<a name="774" href="#774">774</a>           <em class="jxr_comment">// EOFException being ignored</em>
<a name="775" href="#775">775</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="776" href="#776">776</a>         }
<a name="777" href="#777">777</a>       }
<a name="778" href="#778">778</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="779" href="#779">779</a>       <strong class="jxr_keyword">if</strong> (!skipErrors || e instanceof InterruptedIOException) {
<a name="780" href="#780">780</a>         <strong class="jxr_keyword">throw</strong> e; <em class="jxr_comment">// Don't mark the file corrupted if interrupted, or not skipErrors</em>
<a name="781" href="#781">781</a>       }
<a name="782" href="#782">782</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a> t =
<a name="783" href="#783">783</a>         <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a>(<span class="jxr_string">"skipErrors=true Could not open hlog "</span> +
<a name="784" href="#784">784</a>             path + <span class="jxr_string">" ignoring"</span>);
<a name="785" href="#785">785</a>       t.initCause(e);
<a name="786" href="#786">786</a>       <strong class="jxr_keyword">throw</strong> t;
<a name="787" href="#787">787</a>     }
<a name="788" href="#788">788</a>     <strong class="jxr_keyword">return</strong> in;
<a name="789" href="#789">789</a>   }
<a name="790" href="#790">790</a> 
<a name="791" href="#791">791</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> getNextLogLine(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> in, Path path, <strong class="jxr_keyword">boolean</strong> skipErrors)
<a name="792" href="#792">792</a>   <strong class="jxr_keyword">throws</strong> CorruptedLogFileException, IOException {
<a name="793" href="#793">793</a>     <strong class="jxr_keyword">try</strong> {
<a name="794" href="#794">794</a>       <strong class="jxr_keyword">return</strong> in.next();
<a name="795" href="#795">795</a>     } <strong class="jxr_keyword">catch</strong> (EOFException eof) {
<a name="796" href="#796">796</a>       <em class="jxr_comment">// truncated files are expected if a RS crashes (see HBASE-2643)</em>
<a name="797" href="#797">797</a>       LOG.info(<span class="jxr_string">"EOF from hlog "</span> + path + <span class="jxr_string">".  continuing"</span>);
<a name="798" href="#798">798</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="799" href="#799">799</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="800" href="#800">800</a>       <em class="jxr_comment">// If the IOE resulted from bad file format,</em>
<a name="801" href="#801">801</a>       <em class="jxr_comment">// then this problem is idempotent and retrying won't help</em>
<a name="802" href="#802">802</a>       <strong class="jxr_keyword">if</strong> (e.getCause() != <strong class="jxr_keyword">null</strong> &amp;&amp;
<a name="803" href="#803">803</a>           (e.getCause() instanceof ParseException ||
<a name="804" href="#804">804</a>            e.getCause() instanceof org.apache.hadoop.fs.ChecksumException)) {
<a name="805" href="#805">805</a>         LOG.warn(<span class="jxr_string">"Parse exception "</span> + e.getCause().toString() + <span class="jxr_string">" from hlog "</span>
<a name="806" href="#806">806</a>            + path + <span class="jxr_string">".  continuing"</span>);
<a name="807" href="#807">807</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="808" href="#808">808</a>       }
<a name="809" href="#809">809</a>       <strong class="jxr_keyword">if</strong> (!skipErrors) {
<a name="810" href="#810">810</a>         <strong class="jxr_keyword">throw</strong> e;
<a name="811" href="#811">811</a>       }
<a name="812" href="#812">812</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a> t =
<a name="813" href="#813">813</a>         <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a>(<span class="jxr_string">"skipErrors=true Ignoring exception"</span> +
<a name="814" href="#814">814</a>             <span class="jxr_string">" while parsing hlog "</span> + path + <span class="jxr_string">". Marking as corrupted"</span>);
<a name="815" href="#815">815</a>       t.initCause(e);
<a name="816" href="#816">816</a>       <strong class="jxr_keyword">throw</strong> t;
<a name="817" href="#817">817</a>     }
<a name="818" href="#818">818</a>   }
<a name="819" href="#819">819</a> 
<a name="820" href="#820">820</a> 
<a name="821" href="#821">821</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> writerThreadError(Throwable t) {
<a name="822" href="#822">822</a>     thrown.compareAndSet(<strong class="jxr_keyword">null</strong>, t);
<a name="823" href="#823">823</a>   }
<a name="824" href="#824">824</a> 
<a name="825" href="#825">825</a>   <em class="jxr_javadoccomment">/**</em>
<a name="826" href="#826">826</a> <em class="jxr_javadoccomment">   * Check for errors in the writer threads. If any is found, rethrow it.</em>
<a name="827" href="#827">827</a> <em class="jxr_javadoccomment">   */</em>
<a name="828" href="#828">828</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> checkForErrors() <strong class="jxr_keyword">throws</strong> IOException {
<a name="829" href="#829">829</a>     Throwable thrown = <strong class="jxr_keyword">this</strong>.thrown.get();
<a name="830" href="#830">830</a>     <strong class="jxr_keyword">if</strong> (thrown == <strong class="jxr_keyword">null</strong>) <strong class="jxr_keyword">return</strong>;
<a name="831" href="#831">831</a>     <strong class="jxr_keyword">if</strong> (thrown instanceof IOException) {
<a name="832" href="#832">832</a>       <strong class="jxr_keyword">throw</strong> (IOException)thrown;
<a name="833" href="#833">833</a>     } <strong class="jxr_keyword">else</strong> {
<a name="834" href="#834">834</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(thrown);
<a name="835" href="#835">835</a>     }
<a name="836" href="#836">836</a>   }
<a name="837" href="#837">837</a>   <em class="jxr_javadoccomment">/**</em>
<a name="838" href="#838">838</a> <em class="jxr_javadoccomment">   * Create a new {@link Writer} for writing log splits.</em>
<a name="839" href="#839">839</a> <em class="jxr_javadoccomment">   */</em>
<a name="840" href="#840">840</a>   <strong class="jxr_keyword">protected</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Writer</a> createWriter(FileSystem fs, Path logfile, Configuration conf)
<a name="841" href="#841">841</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="842" href="#842">842</a>     <strong class="jxr_keyword">return</strong> hlogFs.createWriter(fs, conf, logfile);
<a name="843" href="#843">843</a>   }
<a name="844" href="#844">844</a> 
<a name="845" href="#845">845</a>   <em class="jxr_javadoccomment">/**</em>
<a name="846" href="#846">846</a> <em class="jxr_javadoccomment">   * Create a new {@link Reader} for reading logs to split.</em>
<a name="847" href="#847">847</a> <em class="jxr_javadoccomment">   */</em>
<a name="848" href="#848">848</a>   <strong class="jxr_keyword">protected</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Reader</a> getReader(FileSystem fs, Path curLogFile,
<a name="849" href="#849">849</a>       Configuration conf, <a href="../../../../../../org/apache/hadoop/hbase/util/CancelableProgressable.html">CancelableProgressable</a> reporter) <strong class="jxr_keyword">throws</strong> IOException {
<a name="850" href="#850">850</a>     <strong class="jxr_keyword">return</strong> HLog.getReader(fs, curLogFile, conf, reporter);
<a name="851" href="#851">851</a>   }
<a name="852" href="#852">852</a> 
<a name="853" href="#853">853</a>   <em class="jxr_javadoccomment">/**</em>
<a name="854" href="#854">854</a> <em class="jxr_javadoccomment">   * Class which accumulates edits and separates them into a buffer per region</em>
<a name="855" href="#855">855</a> <em class="jxr_javadoccomment">   * while simultaneously accounting RAM usage. Blocks if the RAM usage crosses</em>
<a name="856" href="#856">856</a> <em class="jxr_javadoccomment">   * a predefined threshold.</em>
<a name="857" href="#857">857</a> <em class="jxr_javadoccomment">   *</em>
<a name="858" href="#858">858</a> <em class="jxr_javadoccomment">   * Writer threads then pull region-specific buffers from this class.</em>
<a name="859" href="#859">859</a> <em class="jxr_javadoccomment">   */</em>
<a name="860" href="#860">860</a>   <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">EntryBuffers</a> {
<a name="861" href="#861">861</a>     Map&lt;byte[], RegionEntryBuffer&gt; buffers =
<a name="862" href="#862">862</a>       <strong class="jxr_keyword">new</strong> TreeMap&lt;byte[], RegionEntryBuffer&gt;(Bytes.BYTES_COMPARATOR);
<a name="863" href="#863">863</a> 
<a name="864" href="#864">864</a>     <em class="jxr_comment">/*<em class="jxr_comment"> Track which regions are currently in the middle of writing. We don't allow</em></em>
<a name="865" href="#865">865</a> <em class="jxr_comment">       an IO thread to pick up bytes from a region if we're already writing</em>
<a name="866" href="#866">866</a> <em class="jxr_comment">       data for that region in a different IO thread. */</em>
<a name="867" href="#867">867</a>     Set&lt;byte[]&gt; currentlyWriting = <strong class="jxr_keyword">new</strong> TreeSet&lt;byte[]&gt;(Bytes.BYTES_COMPARATOR);
<a name="868" href="#868">868</a> 
<a name="869" href="#869">869</a>     <strong class="jxr_keyword">long</strong> totalBuffered = 0;
<a name="870" href="#870">870</a>     <strong class="jxr_keyword">long</strong> maxHeapUsage;
<a name="871" href="#871">871</a> 
<a name="872" href="#872">872</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">EntryBuffers</a>(<strong class="jxr_keyword">long</strong> maxHeapUsage) {
<a name="873" href="#873">873</a>       <strong class="jxr_keyword">this</strong>.maxHeapUsage = maxHeapUsage;
<a name="874" href="#874">874</a>     }
<a name="875" href="#875">875</a> 
<a name="876" href="#876">876</a>     <em class="jxr_javadoccomment">/**</em>
<a name="877" href="#877">877</a> <em class="jxr_javadoccomment">     * Append a log entry into the corresponding region buffer.</em>
<a name="878" href="#878">878</a> <em class="jxr_javadoccomment">     * Blocks if the total heap usage has crossed the specified threshold.</em>
<a name="879" href="#879">879</a> <em class="jxr_javadoccomment">     *</em>
<a name="880" href="#880">880</a> <em class="jxr_javadoccomment">     * @throws InterruptedException</em>
<a name="881" href="#881">881</a> <em class="jxr_javadoccomment">     * @throws IOException</em>
<a name="882" href="#882">882</a> <em class="jxr_javadoccomment">     */</em>
<a name="883" href="#883">883</a>     <strong class="jxr_keyword">void</strong> appendEntry(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry) <strong class="jxr_keyword">throws</strong> InterruptedException, IOException {
<a name="884" href="#884">884</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogKey.html">HLogKey</a> key = entry.getKey();
<a name="885" href="#885">885</a> 
<a name="886" href="#886">886</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> buffer;
<a name="887" href="#887">887</a>       <strong class="jxr_keyword">long</strong> incrHeap;
<a name="888" href="#888">888</a>       <strong class="jxr_keyword">synchronized</strong> (<strong class="jxr_keyword">this</strong>) {
<a name="889" href="#889">889</a>         buffer = buffers.get(key.getEncodedRegionName());
<a name="890" href="#890">890</a>         <strong class="jxr_keyword">if</strong> (buffer == <strong class="jxr_keyword">null</strong>) {
<a name="891" href="#891">891</a>           buffer = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a>(key.getTablename(), key.getEncodedRegionName());
<a name="892" href="#892">892</a>           buffers.put(key.getEncodedRegionName(), buffer);
<a name="893" href="#893">893</a>         }
<a name="894" href="#894">894</a>         incrHeap= buffer.appendEntry(entry);        
<a name="895" href="#895">895</a>       }
<a name="896" href="#896">896</a> 
<a name="897" href="#897">897</a>       <em class="jxr_comment">// If we crossed the chunk threshold, wait for more space to be available</em>
<a name="898" href="#898">898</a>       <strong class="jxr_keyword">synchronized</strong> (dataAvailable) {
<a name="899" href="#899">899</a>         totalBuffered += incrHeap;
<a name="900" href="#900">900</a>         <strong class="jxr_keyword">while</strong> (totalBuffered &gt; maxHeapUsage &amp;&amp; thrown.get() == <strong class="jxr_keyword">null</strong>) {
<a name="901" href="#901">901</a>           LOG.debug(<span class="jxr_string">"Used "</span> + totalBuffered + <span class="jxr_string">" bytes of buffered edits, waiting for IO threads..."</span>);
<a name="902" href="#902">902</a>           dataAvailable.wait(3000);
<a name="903" href="#903">903</a>         }
<a name="904" href="#904">904</a>         dataAvailable.notifyAll();
<a name="905" href="#905">905</a>       }
<a name="906" href="#906">906</a>       checkForErrors();
<a name="907" href="#907">907</a>     }
<a name="908" href="#908">908</a> 
<a name="909" href="#909">909</a>     <strong class="jxr_keyword">synchronized</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> getChunkToWrite() {
<a name="910" href="#910">910</a>       <strong class="jxr_keyword">long</strong> biggestSize=0;
<a name="911" href="#911">911</a>       byte[] biggestBufferKey=<strong class="jxr_keyword">null</strong>;
<a name="912" href="#912">912</a> 
<a name="913" href="#913">913</a>       <strong class="jxr_keyword">for</strong> (Map.Entry&lt;byte[], RegionEntryBuffer&gt; entry : buffers.entrySet()) {
<a name="914" href="#914">914</a>         <strong class="jxr_keyword">long</strong> size = entry.getValue().heapSize();
<a name="915" href="#915">915</a>         <strong class="jxr_keyword">if</strong> (size &gt; biggestSize &amp;&amp; !currentlyWriting.contains(entry.getKey())) {
<a name="916" href="#916">916</a>           biggestSize = size;
<a name="917" href="#917">917</a>           biggestBufferKey = entry.getKey();
<a name="918" href="#918">918</a>         }
<a name="919" href="#919">919</a>       }
<a name="920" href="#920">920</a>       <strong class="jxr_keyword">if</strong> (biggestBufferKey == <strong class="jxr_keyword">null</strong>) {
<a name="921" href="#921">921</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="922" href="#922">922</a>       }
<a name="923" href="#923">923</a> 
<a name="924" href="#924">924</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> buffer = buffers.remove(biggestBufferKey);
<a name="925" href="#925">925</a>       currentlyWriting.add(biggestBufferKey);
<a name="926" href="#926">926</a>       <strong class="jxr_keyword">return</strong> buffer;
<a name="927" href="#927">927</a>     }
<a name="928" href="#928">928</a> 
<a name="929" href="#929">929</a>     <strong class="jxr_keyword">void</strong> doneWriting(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> buffer) {
<a name="930" href="#930">930</a>       <strong class="jxr_keyword">synchronized</strong> (<strong class="jxr_keyword">this</strong>) {
<a name="931" href="#931">931</a>         <strong class="jxr_keyword">boolean</strong> removed = currentlyWriting.remove(buffer.encodedRegionName);
<a name="932" href="#932">932</a>         assert removed;
<a name="933" href="#933">933</a>       }
<a name="934" href="#934">934</a>       <strong class="jxr_keyword">long</strong> size = buffer.heapSize();
<a name="935" href="#935">935</a> 
<a name="936" href="#936">936</a>       <strong class="jxr_keyword">synchronized</strong> (dataAvailable) {
<a name="937" href="#937">937</a>         totalBuffered -= size;
<a name="938" href="#938">938</a>         <em class="jxr_comment">// We may unblock writers</em>
<a name="939" href="#939">939</a>         dataAvailable.notifyAll();
<a name="940" href="#940">940</a>       }
<a name="941" href="#941">941</a>     }
<a name="942" href="#942">942</a> 
<a name="943" href="#943">943</a>     <strong class="jxr_keyword">synchronized</strong> <strong class="jxr_keyword">boolean</strong> isRegionCurrentlyWriting(byte[] region) {
<a name="944" href="#944">944</a>       <strong class="jxr_keyword">return</strong> currentlyWriting.contains(region);
<a name="945" href="#945">945</a>     }
<a name="946" href="#946">946</a>   }
<a name="947" href="#947">947</a> 
<a name="948" href="#948">948</a>   <em class="jxr_javadoccomment">/**</em>
<a name="949" href="#949">949</a> <em class="jxr_javadoccomment">   * A buffer of some number of edits for a given region.</em>
<a name="950" href="#950">950</a> <em class="jxr_javadoccomment">   * This accumulates edits and also provides a memory optimization in order to</em>
<a name="951" href="#951">951</a> <em class="jxr_javadoccomment">   * share a single byte array instance for the table and region name.</em>
<a name="952" href="#952">952</a> <em class="jxr_javadoccomment">   * Also tracks memory usage of the accumulated edits.</em>
<a name="953" href="#953">953</a> <em class="jxr_javadoccomment">   */</em>
<a name="954" href="#954">954</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> implements <a href="../../../../../../org/apache/hadoop/hbase/io/HeapSize.html">HeapSize</a> {
<a name="955" href="#955">955</a>     <strong class="jxr_keyword">long</strong> heapInBuffer = 0;
<a name="956" href="#956">956</a>     List&lt;Entry&gt; entryBuffer;
<a name="957" href="#957">957</a>     byte[] tableName;
<a name="958" href="#958">958</a>     byte[] encodedRegionName;
<a name="959" href="#959">959</a> 
<a name="960" href="#960">960</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a>(byte[] table, byte[] region) {
<a name="961" href="#961">961</a>       <strong class="jxr_keyword">this</strong>.tableName = table;
<a name="962" href="#962">962</a>       <strong class="jxr_keyword">this</strong>.encodedRegionName = region;
<a name="963" href="#963">963</a>       <strong class="jxr_keyword">this</strong>.entryBuffer = <strong class="jxr_keyword">new</strong> LinkedList&lt;Entry&gt;();
<a name="964" href="#964">964</a>     }
<a name="965" href="#965">965</a> 
<a name="966" href="#966">966</a>     <strong class="jxr_keyword">long</strong> appendEntry(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry) {
<a name="967" href="#967">967</a>       internify(entry);
<a name="968" href="#968">968</a>       entryBuffer.add(entry);
<a name="969" href="#969">969</a>       <strong class="jxr_keyword">long</strong> incrHeap = entry.getEdit().heapSize() +
<a name="970" href="#970">970</a>         ClassSize.align(2 * ClassSize.REFERENCE) + <em class="jxr_comment">// HLogKey pointers</em>
<a name="971" href="#971">971</a>         0; <em class="jxr_comment">// TODO linkedlist entry</em>
<a name="972" href="#972">972</a>       heapInBuffer += incrHeap;
<a name="973" href="#973">973</a>       <strong class="jxr_keyword">return</strong> incrHeap;
<a name="974" href="#974">974</a>     }
<a name="975" href="#975">975</a> 
<a name="976" href="#976">976</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> internify(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry) {
<a name="977" href="#977">977</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogKey.html">HLogKey</a> k = entry.getKey();
<a name="978" href="#978">978</a>       k.internTableName(<strong class="jxr_keyword">this</strong>.tableName);
<a name="979" href="#979">979</a>       k.internEncodedRegionName(<strong class="jxr_keyword">this</strong>.encodedRegionName);
<a name="980" href="#980">980</a>     }
<a name="981" href="#981">981</a> 
<a name="982" href="#982">982</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> heapSize() {
<a name="983" href="#983">983</a>       <strong class="jxr_keyword">return</strong> heapInBuffer;
<a name="984" href="#984">984</a>     }
<a name="985" href="#985">985</a>   }
<a name="986" href="#986">986</a> 
<a name="987" href="#987">987</a> 
<a name="988" href="#988">988</a>   <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterThread</a> <strong class="jxr_keyword">extends</strong> Thread {
<a name="989" href="#989">989</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">volatile</strong> <strong class="jxr_keyword">boolean</strong> shouldStop = false;
<a name="990" href="#990">990</a> 
<a name="991" href="#991">991</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterThread</a>(<strong class="jxr_keyword">int</strong> i) {
<a name="992" href="#992">992</a>       <strong class="jxr_keyword">super</strong>(<span class="jxr_string">"WriterThread-"</span> + i);
<a name="993" href="#993">993</a>     }
<a name="994" href="#994">994</a> 
<a name="995" href="#995">995</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> run()  {
<a name="996" href="#996">996</a>       <strong class="jxr_keyword">try</strong> {
<a name="997" href="#997">997</a>         doRun();
<a name="998" href="#998">998</a>       } <strong class="jxr_keyword">catch</strong> (Throwable t) {
<a name="999" href="#999">999</a>         LOG.error(<span class="jxr_string">"Error in log splitting write thread"</span>, t);
<a name="1000" href="#1000">1000</a>         writerThreadError(t);
<a name="1001" href="#1001">1001</a>       }
<a name="1002" href="#1002">1002</a>     }
<a name="1003" href="#1003">1003</a> 
<a name="1004" href="#1004">1004</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> doRun() <strong class="jxr_keyword">throws</strong> IOException {
<a name="1005" href="#1005">1005</a>       LOG.debug(<span class="jxr_string">"Writer thread "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": starting"</span>);
<a name="1006" href="#1006">1006</a>       <strong class="jxr_keyword">while</strong> (<strong class="jxr_keyword">true</strong>) {
<a name="1007" href="#1007">1007</a>         <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> buffer = entryBuffers.getChunkToWrite();
<a name="1008" href="#1008">1008</a>         <strong class="jxr_keyword">if</strong> (buffer == <strong class="jxr_keyword">null</strong>) {
<a name="1009" href="#1009">1009</a>           <em class="jxr_comment">// No data currently available, wait on some more to show up</em>
<a name="1010" href="#1010">1010</a>           <strong class="jxr_keyword">synchronized</strong> (dataAvailable) {
<a name="1011" href="#1011">1011</a>             <strong class="jxr_keyword">if</strong> (shouldStop) <strong class="jxr_keyword">return</strong>;
<a name="1012" href="#1012">1012</a>             <strong class="jxr_keyword">try</strong> {
<a name="1013" href="#1013">1013</a>               dataAvailable.wait(1000);
<a name="1014" href="#1014">1014</a>             } <strong class="jxr_keyword">catch</strong> (InterruptedException ie) {
<a name="1015" href="#1015">1015</a>               <strong class="jxr_keyword">if</strong> (!shouldStop) {
<a name="1016" href="#1016">1016</a>                 <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(ie);
<a name="1017" href="#1017">1017</a>               }
<a name="1018" href="#1018">1018</a>             }
<a name="1019" href="#1019">1019</a>           }
<a name="1020" href="#1020">1020</a>           <strong class="jxr_keyword">continue</strong>;
<a name="1021" href="#1021">1021</a>         }
<a name="1022" href="#1022">1022</a> 
<a name="1023" href="#1023">1023</a>         assert buffer != <strong class="jxr_keyword">null</strong>;
<a name="1024" href="#1024">1024</a>         <strong class="jxr_keyword">try</strong> {
<a name="1025" href="#1025">1025</a>           writeBuffer(buffer);
<a name="1026" href="#1026">1026</a>         } <strong class="jxr_keyword">finally</strong> {
<a name="1027" href="#1027">1027</a>           entryBuffers.doneWriting(buffer);
<a name="1028" href="#1028">1028</a>         }
<a name="1029" href="#1029">1029</a>       }
<a name="1030" href="#1030">1030</a>     }
<a name="1031" href="#1031">1031</a> 
<a name="1032" href="#1032">1032</a> 
<a name="1033" href="#1033">1033</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> writeBuffer(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">RegionEntryBuffer</a> buffer) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1034" href="#1034">1034</a>       List&lt;Entry&gt; entries = buffer.entryBuffer;
<a name="1035" href="#1035">1035</a>       <strong class="jxr_keyword">if</strong> (entries.isEmpty()) {
<a name="1036" href="#1036">1036</a>         LOG.warn(<strong class="jxr_keyword">this</strong>.getName() + <span class="jxr_string">" got an empty buffer, skipping"</span>);
<a name="1037" href="#1037">1037</a>         <strong class="jxr_keyword">return</strong>;
<a name="1038" href="#1038">1038</a>       }
<a name="1039" href="#1039">1039</a> 
<a name="1040" href="#1040">1040</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> wap = <strong class="jxr_keyword">null</strong>;
<a name="1041" href="#1041">1041</a> 
<a name="1042" href="#1042">1042</a>       <strong class="jxr_keyword">long</strong> startTime = System.nanoTime();
<a name="1043" href="#1043">1043</a>       <strong class="jxr_keyword">try</strong> {
<a name="1044" href="#1044">1044</a>         <strong class="jxr_keyword">int</strong> editsCount = 0;
<a name="1045" href="#1045">1045</a> 
<a name="1046" href="#1046">1046</a>         <strong class="jxr_keyword">for</strong> (Entry logEntry : entries) {
<a name="1047" href="#1047">1047</a>           <strong class="jxr_keyword">if</strong> (wap == <strong class="jxr_keyword">null</strong>) {
<a name="1048" href="#1048">1048</a>             wap = outputSink.getWriterAndPath(logEntry);
<a name="1049" href="#1049">1049</a>             <strong class="jxr_keyword">if</strong> (wap == <strong class="jxr_keyword">null</strong>) {
<a name="1050" href="#1050">1050</a>               <em class="jxr_comment">// getWriterAndPath decided we don't need to write these edits</em>
<a name="1051" href="#1051">1051</a>               <em class="jxr_comment">// Message was already logged</em>
<a name="1052" href="#1052">1052</a>               <strong class="jxr_keyword">return</strong>;
<a name="1053" href="#1053">1053</a>             }
<a name="1054" href="#1054">1054</a>           }
<a name="1055" href="#1055">1055</a>           wap.w.append(logEntry);
<a name="1056" href="#1056">1056</a>           outputSink.updateRegionMaximumEditLogSeqNum(logEntry);
<a name="1057" href="#1057">1057</a>           editsCount++;
<a name="1058" href="#1058">1058</a>         }
<a name="1059" href="#1059">1059</a>         <em class="jxr_comment">// Pass along summary statistics</em>
<a name="1060" href="#1060">1060</a>         wap.incrementEdits(editsCount);
<a name="1061" href="#1061">1061</a>         wap.incrementNanoTime(System.nanoTime() - startTime);
<a name="1062" href="#1062">1062</a>       } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="1063" href="#1063">1063</a>         e = RemoteExceptionHandler.checkIOException(e);
<a name="1064" href="#1064">1064</a>         LOG.fatal(<strong class="jxr_keyword">this</strong>.getName() + <span class="jxr_string">" Got while writing log entry to log"</span>, e);
<a name="1065" href="#1065">1065</a>         <strong class="jxr_keyword">throw</strong> e;
<a name="1066" href="#1066">1066</a>       }
<a name="1067" href="#1067">1067</a>     }
<a name="1068" href="#1068">1068</a> 
<a name="1069" href="#1069">1069</a>     <strong class="jxr_keyword">void</strong> finish() {
<a name="1070" href="#1070">1070</a>       <strong class="jxr_keyword">synchronized</strong> (dataAvailable) {
<a name="1071" href="#1071">1071</a>         shouldStop = <strong class="jxr_keyword">true</strong>;
<a name="1072" href="#1072">1072</a>         dataAvailable.notifyAll();
<a name="1073" href="#1073">1073</a>       }
<a name="1074" href="#1074">1074</a>     }
<a name="1075" href="#1075">1075</a>   }
<a name="1076" href="#1076">1076</a> 
<a name="1077" href="#1077">1077</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> createWAP(byte[] region, <a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry, Path rootdir,
<a name="1078" href="#1078">1078</a>       FileSystem fs, Configuration conf)
<a name="1079" href="#1079">1079</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="1080" href="#1080">1080</a>     Path regionedits = getRegionSplitEditsPath(fs, entry, rootdir, <strong class="jxr_keyword">true</strong>);
<a name="1081" href="#1081">1081</a>     <strong class="jxr_keyword">if</strong> (regionedits == <strong class="jxr_keyword">null</strong>) {
<a name="1082" href="#1082">1082</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1083" href="#1083">1083</a>     }
<a name="1084" href="#1084">1084</a>     <strong class="jxr_keyword">if</strong> (fs.exists(regionedits)) {
<a name="1085" href="#1085">1085</a>       LOG.warn(<span class="jxr_string">"Found existing old edits file. It could be the "</span>
<a name="1086" href="#1086">1086</a>           + <span class="jxr_string">"result of a previous failed split attempt. Deleting "</span>
<a name="1087" href="#1087">1087</a>           + regionedits + <span class="jxr_string">", length="</span>
<a name="1088" href="#1088">1088</a>           + fs.getFileStatus(regionedits).getLen());
<a name="1089" href="#1089">1089</a>       <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.deleteFileFromFileSystem(fs, regionedits)) {
<a name="1090" href="#1090">1090</a>         LOG.warn(<span class="jxr_string">"Failed delete of old "</span> + regionedits);
<a name="1091" href="#1091">1091</a>       }
<a name="1092" href="#1092">1092</a>     }
<a name="1093" href="#1093">1093</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Writer</a> w = createWriter(fs, regionedits, conf);
<a name="1094" href="#1094">1094</a>     LOG.debug(<span class="jxr_string">"Creating writer path="</span> + regionedits + <span class="jxr_string">" region="</span>
<a name="1095" href="#1095">1095</a>         + Bytes.toStringBinary(region));
<a name="1096" href="#1096">1096</a>     <strong class="jxr_keyword">return</strong> (<strong class="jxr_keyword">new</strong> WriterAndPath(regionedits, w));
<a name="1097" href="#1097">1097</a>   }
<a name="1098" href="#1098">1098</a> 
<a name="1099" href="#1099">1099</a>   Path convertRegionEditsToTemp(Path rootdir, Path edits, String tmpname) {
<a name="1100" href="#1100">1100</a>     List&lt;String&gt; components = <strong class="jxr_keyword">new</strong> ArrayList&lt;String&gt;(10);
<a name="1101" href="#1101">1101</a>     <strong class="jxr_keyword">do</strong> {
<a name="1102" href="#1102">1102</a>       components.add(edits.getName());
<a name="1103" href="#1103">1103</a>       edits = edits.getParent();
<a name="1104" href="#1104">1104</a>     } <strong class="jxr_keyword">while</strong> (edits.depth() &gt; rootdir.depth());
<a name="1105" href="#1105">1105</a>     Path ret = ZKSplitLog.getSplitLogDir(rootdir, tmpname);
<a name="1106" href="#1106">1106</a>     <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = components.size() - 1; i &gt;= 0; i--) {
<a name="1107" href="#1107">1107</a>       ret = <strong class="jxr_keyword">new</strong> Path(ret, components.get(i));
<a name="1108" href="#1108">1108</a>     }
<a name="1109" href="#1109">1109</a>     <strong class="jxr_keyword">try</strong> {
<a name="1110" href="#1110">1110</a>       <strong class="jxr_keyword">if</strong> (fs.exists(ret)) {
<a name="1111" href="#1111">1111</a>         LOG.warn(<span class="jxr_string">"Found existing old temporary edits file. It could be the "</span>
<a name="1112" href="#1112">1112</a>             + <span class="jxr_string">"result of a previous failed split attempt. Deleting "</span>
<a name="1113" href="#1113">1113</a>             + ret + <span class="jxr_string">", length="</span>
<a name="1114" href="#1114">1114</a>             + fs.getFileStatus(ret).getLen());
<a name="1115" href="#1115">1115</a>         <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.deleteFileFromFileSystem(fs, ret)) {
<a name="1116" href="#1116">1116</a>           LOG.warn(<span class="jxr_string">"Failed delete of old "</span> + ret);
<a name="1117" href="#1117">1117</a>         }
<a name="1118" href="#1118">1118</a>       }
<a name="1119" href="#1119">1119</a>       Path dir = ret.getParent();
<a name="1120" href="#1120">1120</a>       <strong class="jxr_keyword">if</strong> (!fs.exists(dir) &amp;&amp; !HBaseFileSystem.makeDirOnFileSystem(fs, dir)) { 
<a name="1121" href="#1121">1121</a>           LOG.warn(<span class="jxr_string">"mkdir failed on "</span> + dir);
<a name="1122" href="#1122">1122</a>       }
<a name="1123" href="#1123">1123</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="1124" href="#1124">1124</a>       LOG.warn(<span class="jxr_string">"Could not prepare temp staging area "</span>, e);
<a name="1125" href="#1125">1125</a>       <em class="jxr_comment">// ignore, exceptions will be thrown elsewhere</em>
<a name="1126" href="#1126">1126</a>     }
<a name="1127" href="#1127">1127</a>     <strong class="jxr_keyword">return</strong> ret;
<a name="1128" href="#1128">1128</a>   }
<a name="1129" href="#1129">1129</a> 
<a name="1130" href="#1130">1130</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1131" href="#1131">1131</a> <em class="jxr_javadoccomment">   * Class that manages the output streams from the log splitting process.</em>
<a name="1132" href="#1132">1132</a> <em class="jxr_javadoccomment">   */</em>
<a name="1133" href="#1133">1133</a>   <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">OutputSink</a> {
<a name="1134" href="#1134">1134</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> Map&lt;byte[], WriterAndPath&gt; logWriters = Collections.synchronizedMap(
<a name="1135" href="#1135">1135</a>           <strong class="jxr_keyword">new</strong> TreeMap&lt;byte[], WriterAndPath&gt;(Bytes.BYTES_COMPARATOR));
<a name="1136" href="#1136">1136</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> Map&lt;byte[], Long&gt; regionMaximumEditLogSeqNum = Collections
<a name="1137" href="#1137">1137</a>         .synchronizedMap(<strong class="jxr_keyword">new</strong> TreeMap&lt;byte[], Long&gt;(Bytes.BYTES_COMPARATOR));
<a name="1138" href="#1138">1138</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> List&lt;WriterThread&gt; writerThreads = Lists.newArrayList();
<a name="1139" href="#1139">1139</a> 
<a name="1140" href="#1140">1140</a>     <em class="jxr_comment">/*<em class="jxr_comment"> Set of regions which we've decided should not output edits */</em></em>
<a name="1141" href="#1141">1141</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> Set&lt;byte[]&gt; blacklistedRegions = Collections.synchronizedSet(
<a name="1142" href="#1142">1142</a>         <strong class="jxr_keyword">new</strong> TreeSet&lt;byte[]&gt;(Bytes.BYTES_COMPARATOR));
<a name="1143" href="#1143">1143</a> 
<a name="1144" href="#1144">1144</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> closeAndCleanCompleted = false;
<a name="1145" href="#1145">1145</a>     
<a name="1146" href="#1146">1146</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> logWritersClosed  = false;
<a name="1147" href="#1147">1147</a> 
<a name="1148" href="#1148">1148</a>     <em class="jxr_javadoccomment">/**</em>
<a name="1149" href="#1149">1149</a> <em class="jxr_javadoccomment">     * Start the threads that will pump data from the entryBuffers</em>
<a name="1150" href="#1150">1150</a> <em class="jxr_javadoccomment">     * to the output files.</em>
<a name="1151" href="#1151">1151</a> <em class="jxr_javadoccomment">     * @return the list of started threads</em>
<a name="1152" href="#1152">1152</a> <em class="jxr_javadoccomment">     */</em>
<a name="1153" href="#1153">1153</a>     <strong class="jxr_keyword">synchronized</strong> <strong class="jxr_keyword">void</strong> startWriterThreads(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">EntryBuffers</a> entryBuffers) {
<a name="1154" href="#1154">1154</a>       <em class="jxr_comment">// More threads could potentially write faster at the expense</em>
<a name="1155" href="#1155">1155</a>       <em class="jxr_comment">// of causing more disk seeks as the logs are split.</em>
<a name="1156" href="#1156">1156</a>       <em class="jxr_comment">// 3. After a certain setting (probably around 3) the</em>
<a name="1157" href="#1157">1157</a>       <em class="jxr_comment">// process will be bound on the reader in the current</em>
<a name="1158" href="#1158">1158</a>       <em class="jxr_comment">// implementation anyway.</em>
<a name="1159" href="#1159">1159</a>       <strong class="jxr_keyword">int</strong> numThreads = conf.getInt(
<a name="1160" href="#1160">1160</a>           <span class="jxr_string">"hbase.regionserver.hlog.splitlog.writer.threads"</span>, 3);
<a name="1161" href="#1161">1161</a> 
<a name="1162" href="#1162">1162</a>       <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; numThreads; i++) {
<a name="1163" href="#1163">1163</a>         <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterThread</a> t = <strong class="jxr_keyword">new</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterThread</a>(i);
<a name="1164" href="#1164">1164</a>         t.start();
<a name="1165" href="#1165">1165</a>         writerThreads.add(t);
<a name="1166" href="#1166">1166</a>       }
<a name="1167" href="#1167">1167</a>     }
<a name="1168" href="#1168">1168</a> 
<a name="1169" href="#1169">1169</a>     List&lt;Path&gt; finishWritingAndClose() <strong class="jxr_keyword">throws</strong> IOException {
<a name="1170" href="#1170">1170</a>       LOG.info(<span class="jxr_string">"Waiting for split writer threads to finish"</span>);
<a name="1171" href="#1171">1171</a>       <strong class="jxr_keyword">try</strong> {
<a name="1172" href="#1172">1172</a>         <strong class="jxr_keyword">for</strong> (WriterThread t : writerThreads) {
<a name="1173" href="#1173">1173</a>           t.finish();
<a name="1174" href="#1174">1174</a>         }
<a name="1175" href="#1175">1175</a>         <strong class="jxr_keyword">for</strong> (WriterThread t : writerThreads) {
<a name="1176" href="#1176">1176</a>           <strong class="jxr_keyword">try</strong> {
<a name="1177" href="#1177">1177</a>             t.join();
<a name="1178" href="#1178">1178</a>           } <strong class="jxr_keyword">catch</strong> (InterruptedException ie) {
<a name="1179" href="#1179">1179</a>             <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(ie);
<a name="1180" href="#1180">1180</a>           }
<a name="1181" href="#1181">1181</a>           checkForErrors();
<a name="1182" href="#1182">1182</a>         }
<a name="1183" href="#1183">1183</a>         LOG.info(<span class="jxr_string">"Split writers finished"</span>);
<a name="1184" href="#1184">1184</a> 
<a name="1185" href="#1185">1185</a>         <strong class="jxr_keyword">return</strong> closeStreams();
<a name="1186" href="#1186">1186</a>       } <strong class="jxr_keyword">finally</strong> {
<a name="1187" href="#1187">1187</a>         List&lt;IOException&gt; thrown = closeLogWriters(<strong class="jxr_keyword">null</strong>);
<a name="1188" href="#1188">1188</a>         <strong class="jxr_keyword">if</strong> (thrown != <strong class="jxr_keyword">null</strong> &amp;&amp; !thrown.isEmpty()) {
<a name="1189" href="#1189">1189</a>           <strong class="jxr_keyword">throw</strong> MultipleIOException.createIOException(thrown);
<a name="1190" href="#1190">1190</a>         }
<a name="1191" href="#1191">1191</a>       }
<a name="1192" href="#1192">1192</a>     }
<a name="1193" href="#1193">1193</a> 
<a name="1194" href="#1194">1194</a>     <em class="jxr_javadoccomment">/**</em>
<a name="1195" href="#1195">1195</a> <em class="jxr_javadoccomment">     * Close all of the output streams.</em>
<a name="1196" href="#1196">1196</a> <em class="jxr_javadoccomment">     * @return the list of paths written.</em>
<a name="1197" href="#1197">1197</a> <em class="jxr_javadoccomment">     */</em>
<a name="1198" href="#1198">1198</a>     <strong class="jxr_keyword">private</strong> List&lt;Path&gt; closeStreams() <strong class="jxr_keyword">throws</strong> IOException {
<a name="1199" href="#1199">1199</a>       Preconditions.checkState(!closeAndCleanCompleted);
<a name="1200" href="#1200">1200</a> 
<a name="1201" href="#1201">1201</a>       List&lt;Path&gt; paths = <strong class="jxr_keyword">new</strong> ArrayList&lt;Path&gt;();
<a name="1202" href="#1202">1202</a>       List&lt;IOException&gt; thrown = Lists.newArrayList();
<a name="1203" href="#1203">1203</a>       closeLogWriters(thrown);
<a name="1204" href="#1204">1204</a>       <strong class="jxr_keyword">for</strong> (Map.Entry&lt;byte[], WriterAndPath&gt; logWritersEntry : logWriters
<a name="1205" href="#1205">1205</a>           .entrySet()) {
<a name="1206" href="#1206">1206</a>         <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> wap = logWritersEntry.getValue();
<a name="1207" href="#1207">1207</a>         Path dst = getCompletedRecoveredEditsFilePath(wap.p,
<a name="1208" href="#1208">1208</a>             regionMaximumEditLogSeqNum.get(logWritersEntry.getKey()));
<a name="1209" href="#1209">1209</a>         <strong class="jxr_keyword">try</strong> {
<a name="1210" href="#1210">1210</a>           <strong class="jxr_keyword">if</strong> (!dst.equals(wap.p) &amp;&amp; fs.exists(dst)) {
<a name="1211" href="#1211">1211</a>             LOG.warn(<span class="jxr_string">"Found existing old edits file. It could be the "</span>
<a name="1212" href="#1212">1212</a>                 + <span class="jxr_string">"result of a previous failed split attempt. Deleting "</span> + dst
<a name="1213" href="#1213">1213</a>                 + <span class="jxr_string">", length="</span> + fs.getFileStatus(dst).getLen());
<a name="1214" href="#1214">1214</a>             <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.deleteFileFromFileSystem(fs, dst)) {
<a name="1215" href="#1215">1215</a>               LOG.warn(<span class="jxr_string">"Failed deleting of old "</span> + dst);
<a name="1216" href="#1216">1216</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed deleting of old "</span> + dst);
<a name="1217" href="#1217">1217</a>             }
<a name="1218" href="#1218">1218</a>           }
<a name="1219" href="#1219">1219</a>           <em class="jxr_comment">// Skip the unit tests which create a splitter that reads and writes</em>
<a name="1220" href="#1220">1220</a>           <em class="jxr_comment">// the data without touching disk. TestHLogSplit#testThreading is an</em>
<a name="1221" href="#1221">1221</a>           <em class="jxr_comment">// example.</em>
<a name="1222" href="#1222">1222</a>           <strong class="jxr_keyword">if</strong> (fs.exists(wap.p)) {
<a name="1223" href="#1223">1223</a>             <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, wap.p, dst)) {
<a name="1224" href="#1224">1224</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed renaming "</span> + wap.p + <span class="jxr_string">" to "</span> + dst);
<a name="1225" href="#1225">1225</a>             }
<a name="1226" href="#1226">1226</a>             LOG.debug(<span class="jxr_string">"Rename "</span> + wap.p + <span class="jxr_string">" to "</span> + dst);
<a name="1227" href="#1227">1227</a>           }
<a name="1228" href="#1228">1228</a>         } <strong class="jxr_keyword">catch</strong> (IOException ioe) {
<a name="1229" href="#1229">1229</a>           LOG.error(<span class="jxr_string">"Couldn't rename "</span> + wap.p + <span class="jxr_string">" to "</span> + dst, ioe);
<a name="1230" href="#1230">1230</a>           thrown.add(ioe);
<a name="1231" href="#1231">1231</a>           <strong class="jxr_keyword">continue</strong>;
<a name="1232" href="#1232">1232</a>         }
<a name="1233" href="#1233">1233</a>         paths.add(dst);
<a name="1234" href="#1234">1234</a>       }
<a name="1235" href="#1235">1235</a>       <strong class="jxr_keyword">if</strong> (!thrown.isEmpty()) {
<a name="1236" href="#1236">1236</a>         <strong class="jxr_keyword">throw</strong> MultipleIOException.createIOException(thrown);
<a name="1237" href="#1237">1237</a>       }
<a name="1238" href="#1238">1238</a> 
<a name="1239" href="#1239">1239</a>       closeAndCleanCompleted = <strong class="jxr_keyword">true</strong>;
<a name="1240" href="#1240">1240</a>       <strong class="jxr_keyword">return</strong> paths;
<a name="1241" href="#1241">1241</a>     }
<a name="1242" href="#1242">1242</a>     
<a name="1243" href="#1243">1243</a>     <strong class="jxr_keyword">private</strong> List&lt;IOException&gt; closeLogWriters(List&lt;IOException&gt; thrown)
<a name="1244" href="#1244">1244</a>         <strong class="jxr_keyword">throws</strong> IOException {
<a name="1245" href="#1245">1245</a>       <strong class="jxr_keyword">if</strong> (!logWritersClosed) {
<a name="1246" href="#1246">1246</a>         <strong class="jxr_keyword">if</strong> (thrown == <strong class="jxr_keyword">null</strong>) {
<a name="1247" href="#1247">1247</a>           thrown = Lists.newArrayList();
<a name="1248" href="#1248">1248</a>         }
<a name="1249" href="#1249">1249</a>         <strong class="jxr_keyword">try</strong> {
<a name="1250" href="#1250">1250</a>           <strong class="jxr_keyword">for</strong> (WriterThread t : writerThreads) {
<a name="1251" href="#1251">1251</a>             <strong class="jxr_keyword">while</strong> (t.isAlive()) {
<a name="1252" href="#1252">1252</a>               t.shouldStop = <strong class="jxr_keyword">true</strong>;
<a name="1253" href="#1253">1253</a>               t.interrupt();
<a name="1254" href="#1254">1254</a>               <strong class="jxr_keyword">try</strong> {
<a name="1255" href="#1255">1255</a>                 t.join(10);
<a name="1256" href="#1256">1256</a>               } <strong class="jxr_keyword">catch</strong> (InterruptedException e) {
<a name="1257" href="#1257">1257</a>                 IOException iie = <strong class="jxr_keyword">new</strong> InterruptedIOException();
<a name="1258" href="#1258">1258</a>                 iie.initCause(e);
<a name="1259" href="#1259">1259</a>                 <strong class="jxr_keyword">throw</strong> iie;
<a name="1260" href="#1260">1260</a>               }
<a name="1261" href="#1261">1261</a>             }
<a name="1262" href="#1262">1262</a>           }
<a name="1263" href="#1263">1263</a>         } <strong class="jxr_keyword">finally</strong> {
<a name="1264" href="#1264">1264</a>           <strong class="jxr_keyword">synchronized</strong> (logWriters) {
<a name="1265" href="#1265">1265</a>             <strong class="jxr_keyword">for</strong> (WriterAndPath wap : logWriters.values()) {
<a name="1266" href="#1266">1266</a>               <strong class="jxr_keyword">try</strong> {
<a name="1267" href="#1267">1267</a>                 wap.w.close();
<a name="1268" href="#1268">1268</a>               } <strong class="jxr_keyword">catch</strong> (IOException ioe) {
<a name="1269" href="#1269">1269</a>                 LOG.error(<span class="jxr_string">"Couldn't close log at "</span> + wap.p, ioe);
<a name="1270" href="#1270">1270</a>                 thrown.add(ioe);
<a name="1271" href="#1271">1271</a>                 <strong class="jxr_keyword">continue</strong>;
<a name="1272" href="#1272">1272</a>               }
<a name="1273" href="#1273">1273</a>               LOG.info(<span class="jxr_string">"Closed path "</span> + wap.p + <span class="jxr_string">" (wrote "</span> + wap.editsWritten
<a name="1274" href="#1274">1274</a>                   + <span class="jxr_string">" edits in "</span> + (wap.nanosSpent / 1000 / 1000) + <span class="jxr_string">"ms)"</span>);
<a name="1275" href="#1275">1275</a>             }
<a name="1276" href="#1276">1276</a>           }
<a name="1277" href="#1277">1277</a>           logWritersClosed = <strong class="jxr_keyword">true</strong>;
<a name="1278" href="#1278">1278</a>         }
<a name="1279" href="#1279">1279</a>       }
<a name="1280" href="#1280">1280</a>       <strong class="jxr_keyword">return</strong> thrown;
<a name="1281" href="#1281">1281</a>     }
<a name="1282" href="#1282">1282</a> 
<a name="1283" href="#1283">1283</a>     <em class="jxr_javadoccomment">/**</em>
<a name="1284" href="#1284">1284</a> <em class="jxr_javadoccomment">     * Get a writer and path for a log starting at the given entry.</em>
<a name="1285" href="#1285">1285</a> <em class="jxr_javadoccomment">     *</em>
<a name="1286" href="#1286">1286</a> <em class="jxr_javadoccomment">     * This function is threadsafe so long as multiple threads are always</em>
<a name="1287" href="#1287">1287</a> <em class="jxr_javadoccomment">     * acting on different regions.</em>
<a name="1288" href="#1288">1288</a> <em class="jxr_javadoccomment">     *</em>
<a name="1289" href="#1289">1289</a> <em class="jxr_javadoccomment">     * @return null if this region shouldn't output any logs</em>
<a name="1290" href="#1290">1290</a> <em class="jxr_javadoccomment">     */</em>
<a name="1291" href="#1291">1291</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> getWriterAndPath(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1292" href="#1292">1292</a>       byte region[] = entry.getKey().getEncodedRegionName();
<a name="1293" href="#1293">1293</a>       <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> ret = logWriters.get(region);
<a name="1294" href="#1294">1294</a>       <strong class="jxr_keyword">if</strong> (ret != <strong class="jxr_keyword">null</strong>) {
<a name="1295" href="#1295">1295</a>         <strong class="jxr_keyword">return</strong> ret;
<a name="1296" href="#1296">1296</a>       }
<a name="1297" href="#1297">1297</a>       <em class="jxr_comment">// If we already decided that this region doesn't get any output</em>
<a name="1298" href="#1298">1298</a>       <em class="jxr_comment">// we don't need to check again.</em>
<a name="1299" href="#1299">1299</a>       <strong class="jxr_keyword">if</strong> (blacklistedRegions.contains(region)) {
<a name="1300" href="#1300">1300</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1301" href="#1301">1301</a>       }
<a name="1302" href="#1302">1302</a>       ret = createWAP(region, entry, rootDir, fs, conf);
<a name="1303" href="#1303">1303</a>       <strong class="jxr_keyword">if</strong> (ret == <strong class="jxr_keyword">null</strong>) {
<a name="1304" href="#1304">1304</a>         blacklistedRegions.add(region);
<a name="1305" href="#1305">1305</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1306" href="#1306">1306</a>       }
<a name="1307" href="#1307">1307</a>       logWriters.put(region, ret);
<a name="1308" href="#1308">1308</a>       <strong class="jxr_keyword">return</strong> ret;
<a name="1309" href="#1309">1309</a>     }
<a name="1310" href="#1310">1310</a> 
<a name="1311" href="#1311">1311</a>     <em class="jxr_javadoccomment">/**</em>
<a name="1312" href="#1312">1312</a> <em class="jxr_javadoccomment">     * Update region's maximum edit log SeqNum.</em>
<a name="1313" href="#1313">1313</a> <em class="jxr_javadoccomment">     */</em>
<a name="1314" href="#1314">1314</a>     <strong class="jxr_keyword">void</strong> updateRegionMaximumEditLogSeqNum(<a href="../../../../../../org/apache/hadoop/hbase/regionserver/LruHashMap.html">Entry</a> entry) {
<a name="1315" href="#1315">1315</a>       <strong class="jxr_keyword">synchronized</strong> (regionMaximumEditLogSeqNum) {
<a name="1316" href="#1316">1316</a>         Long currentMaxSeqNum=regionMaximumEditLogSeqNum.get(entry.getKey().getEncodedRegionName());
<a name="1317" href="#1317">1317</a>         <strong class="jxr_keyword">if</strong> (currentMaxSeqNum == <strong class="jxr_keyword">null</strong>
<a name="1318" href="#1318">1318</a>             || entry.getKey().getLogSeqNum() &gt; currentMaxSeqNum) {
<a name="1319" href="#1319">1319</a>           regionMaximumEditLogSeqNum.put(entry.getKey().getEncodedRegionName(),
<a name="1320" href="#1320">1320</a>               entry.getKey().getLogSeqNum());
<a name="1321" href="#1321">1321</a>         }
<a name="1322" href="#1322">1322</a>       }
<a name="1323" href="#1323">1323</a> 
<a name="1324" href="#1324">1324</a>     }
<a name="1325" href="#1325">1325</a> 
<a name="1326" href="#1326">1326</a>     Long getRegionMaximumEditLogSeqNum(byte[] region) {
<a name="1327" href="#1327">1327</a>       <strong class="jxr_keyword">return</strong> regionMaximumEditLogSeqNum.get(region);
<a name="1328" href="#1328">1328</a>     }
<a name="1329" href="#1329">1329</a> 
<a name="1330" href="#1330">1330</a>     <em class="jxr_javadoccomment">/**</em>
<a name="1331" href="#1331">1331</a> <em class="jxr_javadoccomment">     * @return a map from encoded region ID to the number of edits written out</em>
<a name="1332" href="#1332">1332</a> <em class="jxr_javadoccomment">     * for that region.</em>
<a name="1333" href="#1333">1333</a> <em class="jxr_javadoccomment">     */</em>
<a name="1334" href="#1334">1334</a>     <strong class="jxr_keyword">private</strong> Map&lt;byte[], Long&gt; getOutputCounts() {
<a name="1335" href="#1335">1335</a>       TreeMap&lt;byte[], Long&gt; ret = <strong class="jxr_keyword">new</strong> TreeMap&lt;byte[], Long&gt;(
<a name="1336" href="#1336">1336</a>           Bytes.BYTES_COMPARATOR);
<a name="1337" href="#1337">1337</a>       <strong class="jxr_keyword">synchronized</strong> (logWriters) {
<a name="1338" href="#1338">1338</a>         <strong class="jxr_keyword">for</strong> (Map.Entry&lt;byte[], WriterAndPath&gt; entry : logWriters.entrySet()) {
<a name="1339" href="#1339">1339</a>           ret.put(entry.getKey(), entry.getValue().editsWritten);
<a name="1340" href="#1340">1340</a>         }
<a name="1341" href="#1341">1341</a>       }
<a name="1342" href="#1342">1342</a>       <strong class="jxr_keyword">return</strong> ret;
<a name="1343" href="#1343">1343</a>     }
<a name="1344" href="#1344">1344</a>   }
<a name="1345" href="#1345">1345</a> 
<a name="1346" href="#1346">1346</a> 
<a name="1347" href="#1347">1347</a> 
<a name="1348" href="#1348">1348</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1349" href="#1349">1349</a> <em class="jxr_javadoccomment">   *  Private data structure that wraps a Writer and its Path,</em>
<a name="1350" href="#1350">1350</a> <em class="jxr_javadoccomment">   *  also collecting statistics about the data written to this</em>
<a name="1351" href="#1351">1351</a> <em class="jxr_javadoccomment">   *  output.</em>
<a name="1352" href="#1352">1352</a> <em class="jxr_javadoccomment">   */</em>
<a name="1353" href="#1353">1353</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a> {
<a name="1354" href="#1354">1354</a>     <strong class="jxr_keyword">final</strong> Path p;
<a name="1355" href="#1355">1355</a>     <strong class="jxr_keyword">final</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Writer</a> w;
<a name="1356" href="#1356">1356</a> 
<a name="1357" href="#1357">1357</a>     <em class="jxr_comment">/*<em class="jxr_comment"> Count of edits written to this path */</em></em>
<a name="1358" href="#1358">1358</a>     <strong class="jxr_keyword">long</strong> editsWritten = 0;
<a name="1359" href="#1359">1359</a>     <em class="jxr_comment">/*<em class="jxr_comment"> Number of nanos spent writing to this log */</em></em>
<a name="1360" href="#1360">1360</a>     <strong class="jxr_keyword">long</strong> nanosSpent = 0;
<a name="1361" href="#1361">1361</a>     
<a name="1362" href="#1362">1362</a>     <em class="jxr_comment">/*<em class="jxr_comment"> To check whether a close has already been tried on the</em></em>
<a name="1363" href="#1363">1363</a> <em class="jxr_comment">     * writer</em>
<a name="1364" href="#1364">1364</a> <em class="jxr_comment">     */</em>
<a name="1365" href="#1365">1365</a>     <strong class="jxr_keyword">boolean</strong> writerClosed = false;
<a name="1366" href="#1366">1366</a> 
<a name="1367" href="#1367">1367</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">WriterAndPath</a>(<strong class="jxr_keyword">final</strong> Path p, <strong class="jxr_keyword">final</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">Writer</a> w) {
<a name="1368" href="#1368">1368</a>       <strong class="jxr_keyword">this</strong>.p = p;
<a name="1369" href="#1369">1369</a>       <strong class="jxr_keyword">this</strong>.w = w;
<a name="1370" href="#1370">1370</a>     }
<a name="1371" href="#1371">1371</a> 
<a name="1372" href="#1372">1372</a>     <strong class="jxr_keyword">void</strong> incrementEdits(<strong class="jxr_keyword">int</strong> edits) {
<a name="1373" href="#1373">1373</a>       editsWritten += edits;
<a name="1374" href="#1374">1374</a>     }
<a name="1375" href="#1375">1375</a> 
<a name="1376" href="#1376">1376</a>     <strong class="jxr_keyword">void</strong> incrementNanoTime(<strong class="jxr_keyword">long</strong> nanos) {
<a name="1377" href="#1377">1377</a>       nanosSpent += nanos;
<a name="1378" href="#1378">1378</a>     }
<a name="1379" href="#1379">1379</a>   }
<a name="1380" href="#1380">1380</a> 
<a name="1381" href="#1381">1381</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a> <strong class="jxr_keyword">extends</strong> Exception {
<a name="1382" href="#1382">1382</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> serialVersionUID = 1L;
<a name="1383" href="#1383">1383</a>     <a href="../../../../../../org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.html">CorruptedLogFileException</a>(String s) {
<a name="1384" href="#1384">1384</a>       <strong class="jxr_keyword">super</strong>(s);
<a name="1385" href="#1385">1385</a>     }
<a name="1386" href="#1386">1386</a>   }
<a name="1387" href="#1387">1387</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

