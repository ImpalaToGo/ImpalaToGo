<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>TableMapReduceUtil xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../apidocs/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Copyright 2008 The Apache Software Foundation</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> *</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> *</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="18" href="#18">18</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="19" href="#19">19</a>  <em class="jxr_javadoccomment"> */</em>
<a name="20" href="#20">20</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.mapreduce;
<a name="21" href="#21">21</a>  
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.io.ByteArrayInputStream;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.io.ByteArrayOutputStream;
<a name="24" href="#24">24</a>  <strong class="jxr_keyword">import</strong> java.io.DataInputStream;
<a name="25" href="#25">25</a>  <strong class="jxr_keyword">import</strong> java.io.DataOutputStream;
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.Method;
<a name="28" href="#28">28</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.InvocationTargetException;
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> java.net.URL;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> java.net.URLDecoder;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> java.util.Enumeration;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> java.util.HashSet;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> java.util.List;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> java.util.Set;
<a name="36" href="#36">36</a>  
<a name="37" href="#37">37</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.Log;
<a name="38" href="#38">38</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.LogFactory;
<a name="39" href="#39">39</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configuration;
<a name="40" href="#40">40</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileSystem;
<a name="41" href="#41">41</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.Path;
<a name="42" href="#42">42</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HConstants;
<a name="43" href="#43">43</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HBaseConfiguration;
<a name="44" href="#44">44</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.HTable;
<a name="45" href="#45">45</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Scan;
<a name="46" href="#46">46</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.ImmutableBytesWritable;
<a name="47" href="#47">47</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.security.User;
<a name="48" href="#48">48</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Base64;
<a name="49" href="#49">49</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Bytes;
<a name="50" href="#50">50</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.zookeeper.ClusterId;
<a name="51" href="#51">51</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.zookeeper.ZKUtil;
<a name="52" href="#52">52</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
<a name="53" href="#53">53</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.Writable;
<a name="54" href="#54">54</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.WritableComparable;
<a name="55" href="#55">55</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.InputFormat;
<a name="56" href="#56">56</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.Job;
<a name="57" href="#57">57</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.security.token.Token;
<a name="58" href="#58">58</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.util.StringUtils;
<a name="59" href="#59">59</a>  <strong class="jxr_keyword">import</strong> org.apache.zookeeper.KeeperException;
<a name="60" href="#60">60</a>  
<a name="61" href="#61">61</a>  <em class="jxr_javadoccomment">/**</em>
<a name="62" href="#62">62</a>  <em class="jxr_javadoccomment"> * Utility for {@link TableMapper} and {@link TableReducer}</em>
<a name="63" href="#63">63</a>  <em class="jxr_javadoccomment"> */</em>
<a name="64" href="#64">64</a>  @SuppressWarnings(<span class="jxr_string">"unchecked"</span>)
<a name="65" href="#65">65</a>  <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.html">TableMapReduceUtil</a> {
<a name="66" href="#66">66</a>    <strong class="jxr_keyword">static</strong> Log LOG = LogFactory.getLog(TableMapReduceUtil.<strong class="jxr_keyword">class</strong>);
<a name="67" href="#67">67</a>    
<a name="68" href="#68">68</a>    <em class="jxr_javadoccomment">/**</em>
<a name="69" href="#69">69</a>  <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="70" href="#70">70</a>  <em class="jxr_javadoccomment">   * the job.</em>
<a name="71" href="#71">71</a>  <em class="jxr_javadoccomment">   *</em>
<a name="72" href="#72">72</a>  <em class="jxr_javadoccomment">   * @param table  The table name to read from.</em>
<a name="73" href="#73">73</a>  <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="74" href="#74">74</a>  <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="75" href="#75">75</a>  <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="76" href="#76">76</a>  <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="77" href="#77">77</a>  <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="78" href="#78">78</a>  <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="79" href="#79">79</a>  <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="80" href="#80">80</a>  <em class="jxr_javadoccomment">   */</em>
<a name="81" href="#81">81</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(String table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="82" href="#82">82</a>        Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="83" href="#83">83</a>        Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="84" href="#84">84</a>        Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job)
<a name="85" href="#85">85</a>    <strong class="jxr_keyword">throws</strong> IOException {
<a name="86" href="#86">86</a>      initTableMapperJob(table, scan, mapper, outputKeyClass, outputValueClass,
<a name="87" href="#87">87</a>          job, <strong class="jxr_keyword">true</strong>);
<a name="88" href="#88">88</a>    }
<a name="89" href="#89">89</a>  
<a name="90" href="#90">90</a>  
<a name="91" href="#91">91</a>    <em class="jxr_javadoccomment">/**</em>
<a name="92" href="#92">92</a>  <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="93" href="#93">93</a>  <em class="jxr_javadoccomment">   * the job.</em>
<a name="94" href="#94">94</a>  <em class="jxr_javadoccomment">   *</em>
<a name="95" href="#95">95</a>  <em class="jxr_javadoccomment">   * @param table Binary representation of the table name to read from.</em>
<a name="96" href="#96">96</a>  <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="97" href="#97">97</a>  <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="98" href="#98">98</a>  <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="99" href="#99">99</a>  <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="100" href="#100">100</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="101" href="#101">101</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="102" href="#102">102</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="103" href="#103">103</a> <em class="jxr_javadoccomment">   */</em>
<a name="104" href="#104">104</a>    <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(byte[] table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="105" href="#105">105</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="106" href="#106">106</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="107" href="#107">107</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job)
<a name="108" href="#108">108</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="109" href="#109">109</a>       initTableMapperJob(Bytes.toString(table), scan, mapper, outputKeyClass, outputValueClass,
<a name="110" href="#110">110</a>               job, <strong class="jxr_keyword">true</strong>);
<a name="111" href="#111">111</a>   }
<a name="112" href="#112">112</a> 
<a name="113" href="#113">113</a>   <em class="jxr_javadoccomment">/**</em>
<a name="114" href="#114">114</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="115" href="#115">115</a> <em class="jxr_javadoccomment">   * the job.</em>
<a name="116" href="#116">116</a> <em class="jxr_javadoccomment">   *</em>
<a name="117" href="#117">117</a> <em class="jxr_javadoccomment">   * @param table  The table name to read from.</em>
<a name="118" href="#118">118</a> <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="119" href="#119">119</a> <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="120" href="#120">120</a> <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="121" href="#121">121</a> <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="122" href="#122">122</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="123" href="#123">123</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="124" href="#124">124</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the configured</em>
<a name="125" href="#125">125</a> <em class="jxr_javadoccomment">   *           job classes via the distributed cache (tmpjars).</em>
<a name="126" href="#126">126</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="127" href="#127">127</a> <em class="jxr_javadoccomment">   */</em>
<a name="128" href="#128">128</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(String table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="129" href="#129">129</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="130" href="#130">130</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="131" href="#131">131</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job,
<a name="132" href="#132">132</a>       <strong class="jxr_keyword">boolean</strong> addDependencyJars, Class&lt;? <strong class="jxr_keyword">extends</strong> InputFormat&gt; inputFormatClass)
<a name="133" href="#133">133</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="134" href="#134">134</a>     job.setInputFormatClass(inputFormatClass);
<a name="135" href="#135">135</a>     <strong class="jxr_keyword">if</strong> (outputValueClass != <strong class="jxr_keyword">null</strong>) job.setMapOutputValueClass(outputValueClass);
<a name="136" href="#136">136</a>     <strong class="jxr_keyword">if</strong> (outputKeyClass != <strong class="jxr_keyword">null</strong>) job.setMapOutputKeyClass(outputKeyClass);
<a name="137" href="#137">137</a>     job.setMapperClass(mapper);
<a name="138" href="#138">138</a>     Configuration conf = job.getConfiguration();
<a name="139" href="#139">139</a>     HBaseConfiguration.merge(conf, HBaseConfiguration.create(conf));
<a name="140" href="#140">140</a>     conf.set(TableInputFormat.INPUT_TABLE, table);
<a name="141" href="#141">141</a>     conf.set(TableInputFormat.SCAN, convertScanToString(scan));
<a name="142" href="#142">142</a>     <strong class="jxr_keyword">if</strong> (addDependencyJars) {
<a name="143" href="#143">143</a>       addDependencyJars(job);
<a name="144" href="#144">144</a>     }
<a name="145" href="#145">145</a>     initCredentials(job);
<a name="146" href="#146">146</a>   }
<a name="147" href="#147">147</a>   
<a name="148" href="#148">148</a>   <em class="jxr_javadoccomment">/**</em>
<a name="149" href="#149">149</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="150" href="#150">150</a> <em class="jxr_javadoccomment">   * the job.</em>
<a name="151" href="#151">151</a> <em class="jxr_javadoccomment">   *</em>
<a name="152" href="#152">152</a> <em class="jxr_javadoccomment">   * @param table Binary representation of the table name to read from.</em>
<a name="153" href="#153">153</a> <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="154" href="#154">154</a> <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="155" href="#155">155</a> <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="156" href="#156">156</a> <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="157" href="#157">157</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="158" href="#158">158</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="159" href="#159">159</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the configured</em>
<a name="160" href="#160">160</a> <em class="jxr_javadoccomment">   *           job classes via the distributed cache (tmpjars).</em>
<a name="161" href="#161">161</a> <em class="jxr_javadoccomment">   * @param inputFormatClass The class of the input format</em>
<a name="162" href="#162">162</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="163" href="#163">163</a> <em class="jxr_javadoccomment">   */</em>
<a name="164" href="#164">164</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(byte[] table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="165" href="#165">165</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="166" href="#166">166</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="167" href="#167">167</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job,
<a name="168" href="#168">168</a>       <strong class="jxr_keyword">boolean</strong> addDependencyJars, Class&lt;? <strong class="jxr_keyword">extends</strong> InputFormat&gt; inputFormatClass)
<a name="169" href="#169">169</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="170" href="#170">170</a>       initTableMapperJob(Bytes.toString(table), scan, mapper, outputKeyClass,
<a name="171" href="#171">171</a>               outputValueClass, job, addDependencyJars, inputFormatClass);
<a name="172" href="#172">172</a>   }
<a name="173" href="#173">173</a>   
<a name="174" href="#174">174</a>   <em class="jxr_javadoccomment">/**</em>
<a name="175" href="#175">175</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="176" href="#176">176</a> <em class="jxr_javadoccomment">   * the job.</em>
<a name="177" href="#177">177</a> <em class="jxr_javadoccomment">   *</em>
<a name="178" href="#178">178</a> <em class="jxr_javadoccomment">   * @param table Binary representation of the table name to read from.</em>
<a name="179" href="#179">179</a> <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="180" href="#180">180</a> <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="181" href="#181">181</a> <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="182" href="#182">182</a> <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="183" href="#183">183</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="184" href="#184">184</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="185" href="#185">185</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the configured</em>
<a name="186" href="#186">186</a> <em class="jxr_javadoccomment">   *           job classes via the distributed cache (tmpjars).</em>
<a name="187" href="#187">187</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="188" href="#188">188</a> <em class="jxr_javadoccomment">   */</em>
<a name="189" href="#189">189</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(byte[] table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="190" href="#190">190</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="191" href="#191">191</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="192" href="#192">192</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job,
<a name="193" href="#193">193</a>       <strong class="jxr_keyword">boolean</strong> addDependencyJars)
<a name="194" href="#194">194</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="195" href="#195">195</a>       initTableMapperJob(Bytes.toString(table), scan, mapper, outputKeyClass,
<a name="196" href="#196">196</a>               outputValueClass, job, addDependencyJars, TableInputFormat.<strong class="jxr_keyword">class</strong>);
<a name="197" href="#197">197</a>   }
<a name="198" href="#198">198</a>   
<a name="199" href="#199">199</a>   <em class="jxr_javadoccomment">/**</em>
<a name="200" href="#200">200</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableMap job. It will appropriately set up</em>
<a name="201" href="#201">201</a> <em class="jxr_javadoccomment">   * the job.</em>
<a name="202" href="#202">202</a> <em class="jxr_javadoccomment">   *</em>
<a name="203" href="#203">203</a> <em class="jxr_javadoccomment">   * @param table The table name to read from.</em>
<a name="204" href="#204">204</a> <em class="jxr_javadoccomment">   * @param scan  The scan instance with the columns, time range etc.</em>
<a name="205" href="#205">205</a> <em class="jxr_javadoccomment">   * @param mapper  The mapper class to use.</em>
<a name="206" href="#206">206</a> <em class="jxr_javadoccomment">   * @param outputKeyClass  The class of the output key.</em>
<a name="207" href="#207">207</a> <em class="jxr_javadoccomment">   * @param outputValueClass  The class of the output value.</em>
<a name="208" href="#208">208</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="209" href="#209">209</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="210" href="#210">210</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the configured</em>
<a name="211" href="#211">211</a> <em class="jxr_javadoccomment">   *           job classes via the distributed cache (tmpjars).</em>
<a name="212" href="#212">212</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="213" href="#213">213</a> <em class="jxr_javadoccomment">   */</em>
<a name="214" href="#214">214</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(String table, <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="215" href="#215">215</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="216" href="#216">216</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="217" href="#217">217</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job,
<a name="218" href="#218">218</a>       <strong class="jxr_keyword">boolean</strong> addDependencyJars)
<a name="219" href="#219">219</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="220" href="#220">220</a>       initTableMapperJob(table, scan, mapper, outputKeyClass,
<a name="221" href="#221">221</a>               outputValueClass, job, addDependencyJars, TableInputFormat.<strong class="jxr_keyword">class</strong>);
<a name="222" href="#222">222</a>   }
<a name="223" href="#223">223</a>   
<a name="224" href="#224">224</a>   <em class="jxr_javadoccomment">/**</em>
<a name="225" href="#225">225</a> <em class="jxr_javadoccomment">   * Use this before submitting a Multi TableMap job. It will appropriately set</em>
<a name="226" href="#226">226</a> <em class="jxr_javadoccomment">   * up the job.</em>
<a name="227" href="#227">227</a> <em class="jxr_javadoccomment">   *</em>
<a name="228" href="#228">228</a> <em class="jxr_javadoccomment">   * @param scans The list of {@link Scan} objects to read from.</em>
<a name="229" href="#229">229</a> <em class="jxr_javadoccomment">   * @param mapper The mapper class to use.</em>
<a name="230" href="#230">230</a> <em class="jxr_javadoccomment">   * @param outputKeyClass The class of the output key.</em>
<a name="231" href="#231">231</a> <em class="jxr_javadoccomment">   * @param outputValueClass The class of the output value.</em>
<a name="232" href="#232">232</a> <em class="jxr_javadoccomment">   * @param job The current job to adjust. Make sure the passed job is carrying</em>
<a name="233" href="#233">233</a> <em class="jxr_javadoccomment">   *          all necessary HBase configuration.</em>
<a name="234" href="#234">234</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="235" href="#235">235</a> <em class="jxr_javadoccomment">   */</em>
<a name="236" href="#236">236</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(List&lt;Scan&gt; scans,
<a name="237" href="#237">237</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="238" href="#238">238</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="239" href="#239">239</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job) <strong class="jxr_keyword">throws</strong> IOException {
<a name="240" href="#240">240</a>     initTableMapperJob(scans, mapper, outputKeyClass, outputValueClass, job,
<a name="241" href="#241">241</a>         <strong class="jxr_keyword">true</strong>);
<a name="242" href="#242">242</a>   }
<a name="243" href="#243">243</a> 
<a name="244" href="#244">244</a>   <em class="jxr_javadoccomment">/**</em>
<a name="245" href="#245">245</a> <em class="jxr_javadoccomment">   * Use this before submitting a Multi TableMap job. It will appropriately set</em>
<a name="246" href="#246">246</a> <em class="jxr_javadoccomment">   * up the job.</em>
<a name="247" href="#247">247</a> <em class="jxr_javadoccomment">   *</em>
<a name="248" href="#248">248</a> <em class="jxr_javadoccomment">   * @param scans The list of {@link Scan} objects to read from.</em>
<a name="249" href="#249">249</a> <em class="jxr_javadoccomment">   * @param mapper The mapper class to use.</em>
<a name="250" href="#250">250</a> <em class="jxr_javadoccomment">   * @param outputKeyClass The class of the output key.</em>
<a name="251" href="#251">251</a> <em class="jxr_javadoccomment">   * @param outputValueClass The class of the output value.</em>
<a name="252" href="#252">252</a> <em class="jxr_javadoccomment">   * @param job The current job to adjust. Make sure the passed job is carrying</em>
<a name="253" href="#253">253</a> <em class="jxr_javadoccomment">   *          all necessary HBase configuration.</em>
<a name="254" href="#254">254</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the</em>
<a name="255" href="#255">255</a> <em class="jxr_javadoccomment">   *          configured job classes via the distributed cache (tmpjars).</em>
<a name="256" href="#256">256</a> <em class="jxr_javadoccomment">   * @throws IOException When setting up the details fails.</em>
<a name="257" href="#257">257</a> <em class="jxr_javadoccomment">   */</em>
<a name="258" href="#258">258</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableMapperJob(List&lt;Scan&gt; scans,
<a name="259" href="#259">259</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> TableMapper&gt; mapper,
<a name="260" href="#260">260</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> WritableComparable&gt; outputKeyClass,
<a name="261" href="#261">261</a>       Class&lt;? <strong class="jxr_keyword">extends</strong> Writable&gt; outputValueClass, Job job,
<a name="262" href="#262">262</a>       <strong class="jxr_keyword">boolean</strong> addDependencyJars) <strong class="jxr_keyword">throws</strong> IOException {
<a name="263" href="#263">263</a>     job.setInputFormatClass(MultiTableInputFormat.<strong class="jxr_keyword">class</strong>);
<a name="264" href="#264">264</a>     <strong class="jxr_keyword">if</strong> (outputValueClass != <strong class="jxr_keyword">null</strong>) {
<a name="265" href="#265">265</a>       job.setMapOutputValueClass(outputValueClass);
<a name="266" href="#266">266</a>     }
<a name="267" href="#267">267</a>     <strong class="jxr_keyword">if</strong> (outputKeyClass != <strong class="jxr_keyword">null</strong>) {
<a name="268" href="#268">268</a>       job.setMapOutputKeyClass(outputKeyClass);
<a name="269" href="#269">269</a>     }
<a name="270" href="#270">270</a>     job.setMapperClass(mapper);
<a name="271" href="#271">271</a>     HBaseConfiguration.addHbaseResources(job.getConfiguration());
<a name="272" href="#272">272</a>     List&lt;String&gt; scanStrings = <strong class="jxr_keyword">new</strong> ArrayList&lt;String&gt;();
<a name="273" href="#273">273</a> 
<a name="274" href="#274">274</a>     <strong class="jxr_keyword">for</strong> (Scan scan : scans) {
<a name="275" href="#275">275</a>       scanStrings.add(convertScanToString(scan));
<a name="276" href="#276">276</a>     }
<a name="277" href="#277">277</a>     job.getConfiguration().setStrings(MultiTableInputFormat.SCANS,
<a name="278" href="#278">278</a>       scanStrings.toArray(<strong class="jxr_keyword">new</strong> String[scanStrings.size()]));
<a name="279" href="#279">279</a> 
<a name="280" href="#280">280</a>     <strong class="jxr_keyword">if</strong> (addDependencyJars) {
<a name="281" href="#281">281</a>       addDependencyJars(job);
<a name="282" href="#282">282</a>     }
<a name="283" href="#283">283</a>   }
<a name="284" href="#284">284</a> 
<a name="285" href="#285">285</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initCredentials(Job job) <strong class="jxr_keyword">throws</strong> IOException {
<a name="286" href="#286">286</a>     <strong class="jxr_keyword">if</strong> (User.isHBaseSecurityEnabled(job.getConfiguration())) {
<a name="287" href="#287">287</a>       <em class="jxr_comment">// propagate delegation related props from launcher job to MR job</em>
<a name="288" href="#288">288</a>       <strong class="jxr_keyword">if</strong> (System.getenv(<span class="jxr_string">"HADOOP_TOKEN_FILE_LOCATION"</span>) != <strong class="jxr_keyword">null</strong>) {
<a name="289" href="#289">289</a>         job.getConfiguration().set(<span class="jxr_string">"mapreduce.job.credentials.binary"</span>,
<a name="290" href="#290">290</a>                                    System.getenv(<span class="jxr_string">"HADOOP_TOKEN_FILE_LOCATION"</span>));
<a name="291" href="#291">291</a>       }
<a name="292" href="#292">292</a> 
<a name="293" href="#293">293</a>       <strong class="jxr_keyword">try</strong> {
<a name="294" href="#294">294</a>         <em class="jxr_comment">// init credentials for remote cluster</em>
<a name="295" href="#295">295</a>         String quorumAddress = job.getConfiguration().get(TableOutputFormat.QUORUM_ADDRESS);
<a name="296" href="#296">296</a>         <a href="../../../../../org/apache/hadoop/hbase/security/User.html">User</a> user = User.getCurrent();
<a name="297" href="#297">297</a>         <strong class="jxr_keyword">if</strong> (quorumAddress != <strong class="jxr_keyword">null</strong>) {
<a name="298" href="#298">298</a>           String[] parts = ZKUtil.transformClusterKey(quorumAddress);
<a name="299" href="#299">299</a>           Configuration peerConf = HBaseConfiguration.create(job
<a name="300" href="#300">300</a>               .getConfiguration());
<a name="301" href="#301">301</a>           peerConf.set(HConstants.ZOOKEEPER_QUORUM, parts[0]);
<a name="302" href="#302">302</a>           peerConf.set(<span class="jxr_string">"hbase.zookeeper.client.port"</span>, parts[1]);
<a name="303" href="#303">303</a>           peerConf.set(HConstants.ZOOKEEPER_ZNODE_PARENT, parts[2]);
<a name="304" href="#304">304</a>           obtainAuthTokenForJob(job, peerConf, user);
<a name="305" href="#305">305</a>         }
<a name="306" href="#306">306</a> 
<a name="307" href="#307">307</a>         obtainAuthTokenForJob(job, job.getConfiguration(), user);
<a name="308" href="#308">308</a>       } <strong class="jxr_keyword">catch</strong> (InterruptedException ie) {
<a name="309" href="#309">309</a>         LOG.info(<span class="jxr_string">"Interrupted obtaining user authentication token"</span>);
<a name="310" href="#310">310</a>         Thread.interrupted();
<a name="311" href="#311">311</a>       }
<a name="312" href="#312">312</a>     }
<a name="313" href="#313">313</a>   }
<a name="314" href="#314">314</a> 
<a name="315" href="#315">315</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> obtainAuthTokenForJob(Job job, Configuration conf, <a href="../../../../../org/apache/hadoop/hbase/security/User.html">User</a> user)
<a name="316" href="#316">316</a>       <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="317" href="#317">317</a>     Token&lt;?&gt; authToken = getAuthToken(conf, user);
<a name="318" href="#318">318</a>     <strong class="jxr_keyword">if</strong> (authToken == <strong class="jxr_keyword">null</strong>) {
<a name="319" href="#319">319</a>       user.obtainAuthTokenForJob(conf, job);
<a name="320" href="#320">320</a>     } <strong class="jxr_keyword">else</strong> {
<a name="321" href="#321">321</a>       job.getCredentials().addToken(authToken.getService(), authToken);
<a name="322" href="#322">322</a>     }
<a name="323" href="#323">323</a>   }
<a name="324" href="#324">324</a> 
<a name="325" href="#325">325</a>   <em class="jxr_javadoccomment">/**</em>
<a name="326" href="#326">326</a> <em class="jxr_javadoccomment">   * Get the authentication token of the user for the cluster specified in the configuration</em>
<a name="327" href="#327">327</a> <em class="jxr_javadoccomment">   * @return null if the user does not have the token, otherwise the auth token for the cluster.</em>
<a name="328" href="#328">328</a> <em class="jxr_javadoccomment">   */</em>
<a name="329" href="#329">329</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> Token&lt;?&gt; getAuthToken(Configuration conf, <a href="../../../../../org/apache/hadoop/hbase/security/User.html">User</a> user)
<a name="330" href="#330">330</a>       <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="331" href="#331">331</a>     <a href="../../../../../org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.html">ZooKeeperWatcher</a> zkw = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.html">ZooKeeperWatcher</a>(conf, <span class="jxr_string">"mr-init-credentials"</span>, <strong class="jxr_keyword">null</strong>);
<a name="332" href="#332">332</a>     <strong class="jxr_keyword">try</strong> {
<a name="333" href="#333">333</a>       String clusterId = ClusterId.readClusterIdZNode(zkw);
<a name="334" href="#334">334</a>       <strong class="jxr_keyword">return</strong> user.getToken(<span class="jxr_string">"HBASE_AUTH_TOKEN"</span>, clusterId);
<a name="335" href="#335">335</a>     } <strong class="jxr_keyword">catch</strong> (KeeperException e) {
<a name="336" href="#336">336</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(e);
<a name="337" href="#337">337</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="338" href="#338">338</a>       zkw.close();
<a name="339" href="#339">339</a>     }
<a name="340" href="#340">340</a>   }
<a name="341" href="#341">341</a> 
<a name="342" href="#342">342</a>   <em class="jxr_javadoccomment">/**</em>
<a name="343" href="#343">343</a> <em class="jxr_javadoccomment">   * Writes the given scan into a Base64 encoded string.</em>
<a name="344" href="#344">344</a> <em class="jxr_javadoccomment">   *</em>
<a name="345" href="#345">345</a> <em class="jxr_javadoccomment">   * @param scan  The scan to write out.</em>
<a name="346" href="#346">346</a> <em class="jxr_javadoccomment">   * @return The scan saved in a Base64 encoded string.</em>
<a name="347" href="#347">347</a> <em class="jxr_javadoccomment">   * @throws IOException When writing the scan fails.</em>
<a name="348" href="#348">348</a> <em class="jxr_javadoccomment">   */</em>
<a name="349" href="#349">349</a>   <strong class="jxr_keyword">static</strong> String convertScanToString(<a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan) <strong class="jxr_keyword">throws</strong> IOException {
<a name="350" href="#350">350</a>     ByteArrayOutputStream out = <strong class="jxr_keyword">new</strong> ByteArrayOutputStream();
<a name="351" href="#351">351</a>     DataOutputStream dos = <strong class="jxr_keyword">new</strong> DataOutputStream(out);
<a name="352" href="#352">352</a>     scan.write(dos);
<a name="353" href="#353">353</a>     <strong class="jxr_keyword">return</strong> Base64.encodeBytes(out.toByteArray());
<a name="354" href="#354">354</a>   }
<a name="355" href="#355">355</a> 
<a name="356" href="#356">356</a>   <em class="jxr_javadoccomment">/**</em>
<a name="357" href="#357">357</a> <em class="jxr_javadoccomment">   * Converts the given Base64 string back into a Scan instance.</em>
<a name="358" href="#358">358</a> <em class="jxr_javadoccomment">   *</em>
<a name="359" href="#359">359</a> <em class="jxr_javadoccomment">   * @param base64  The scan details.</em>
<a name="360" href="#360">360</a> <em class="jxr_javadoccomment">   * @return The newly created Scan instance.</em>
<a name="361" href="#361">361</a> <em class="jxr_javadoccomment">   * @throws IOException When reading the scan instance fails.</em>
<a name="362" href="#362">362</a> <em class="jxr_javadoccomment">   */</em>
<a name="363" href="#363">363</a>   <strong class="jxr_keyword">static</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> convertStringToScan(String base64) <strong class="jxr_keyword">throws</strong> IOException {
<a name="364" href="#364">364</a>     ByteArrayInputStream bis = <strong class="jxr_keyword">new</strong> ByteArrayInputStream(Base64.decode(base64));
<a name="365" href="#365">365</a>     DataInputStream dis = <strong class="jxr_keyword">new</strong> DataInputStream(bis);
<a name="366" href="#366">366</a>     <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a>();
<a name="367" href="#367">367</a>     scan.readFields(dis);
<a name="368" href="#368">368</a>     <strong class="jxr_keyword">return</strong> scan;
<a name="369" href="#369">369</a>   }
<a name="370" href="#370">370</a> 
<a name="371" href="#371">371</a>   <em class="jxr_javadoccomment">/**</em>
<a name="372" href="#372">372</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableReduce job. It will</em>
<a name="373" href="#373">373</a> <em class="jxr_javadoccomment">   * appropriately set up the JobConf.</em>
<a name="374" href="#374">374</a> <em class="jxr_javadoccomment">   *</em>
<a name="375" href="#375">375</a> <em class="jxr_javadoccomment">   * @param table  The output table.</em>
<a name="376" href="#376">376</a> <em class="jxr_javadoccomment">   * @param reducer  The reducer class to use.</em>
<a name="377" href="#377">377</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.</em>
<a name="378" href="#378">378</a> <em class="jxr_javadoccomment">   * @throws IOException When determining the region count fails.</em>
<a name="379" href="#379">379</a> <em class="jxr_javadoccomment">   */</em>
<a name="380" href="#380">380</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableReducerJob(String table,
<a name="381" href="#381">381</a>     Class&lt;? <strong class="jxr_keyword">extends</strong> TableReducer&gt; reducer, Job job)
<a name="382" href="#382">382</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="383" href="#383">383</a>     initTableReducerJob(table, reducer, job, <strong class="jxr_keyword">null</strong>);
<a name="384" href="#384">384</a>   }
<a name="385" href="#385">385</a> 
<a name="386" href="#386">386</a>   <em class="jxr_javadoccomment">/**</em>
<a name="387" href="#387">387</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableReduce job. It will</em>
<a name="388" href="#388">388</a> <em class="jxr_javadoccomment">   * appropriately set up the JobConf.</em>
<a name="389" href="#389">389</a> <em class="jxr_javadoccomment">   *</em>
<a name="390" href="#390">390</a> <em class="jxr_javadoccomment">   * @param table  The output table.</em>
<a name="391" href="#391">391</a> <em class="jxr_javadoccomment">   * @param reducer  The reducer class to use.</em>
<a name="392" href="#392">392</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.</em>
<a name="393" href="#393">393</a> <em class="jxr_javadoccomment">   * @param partitioner  Partitioner to use. Pass &lt;code&gt;null&lt;/code&gt; to use</em>
<a name="394" href="#394">394</a> <em class="jxr_javadoccomment">   * default partitioner.</em>
<a name="395" href="#395">395</a> <em class="jxr_javadoccomment">   * @throws IOException When determining the region count fails.</em>
<a name="396" href="#396">396</a> <em class="jxr_javadoccomment">   */</em>
<a name="397" href="#397">397</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableReducerJob(String table,
<a name="398" href="#398">398</a>     Class&lt;? <strong class="jxr_keyword">extends</strong> TableReducer&gt; reducer, Job job,
<a name="399" href="#399">399</a>     Class partitioner) <strong class="jxr_keyword">throws</strong> IOException {
<a name="400" href="#400">400</a>     initTableReducerJob(table, reducer, job, partitioner, <strong class="jxr_keyword">null</strong>, <strong class="jxr_keyword">null</strong>, <strong class="jxr_keyword">null</strong>);
<a name="401" href="#401">401</a>   }
<a name="402" href="#402">402</a> 
<a name="403" href="#403">403</a>   <em class="jxr_javadoccomment">/**</em>
<a name="404" href="#404">404</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableReduce job. It will</em>
<a name="405" href="#405">405</a> <em class="jxr_javadoccomment">   * appropriately set up the JobConf.</em>
<a name="406" href="#406">406</a> <em class="jxr_javadoccomment">   *</em>
<a name="407" href="#407">407</a> <em class="jxr_javadoccomment">   * @param table  The output table.</em>
<a name="408" href="#408">408</a> <em class="jxr_javadoccomment">   * @param reducer  The reducer class to use.</em>
<a name="409" href="#409">409</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="410" href="#410">410</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="411" href="#411">411</a> <em class="jxr_javadoccomment">   * @param partitioner  Partitioner to use. Pass &lt;code&gt;null&lt;/code&gt; to use</em>
<a name="412" href="#412">412</a> <em class="jxr_javadoccomment">   * default partitioner.</em>
<a name="413" href="#413">413</a> <em class="jxr_javadoccomment">   * @param quorumAddress Distant cluster to write to; default is null for</em>
<a name="414" href="#414">414</a> <em class="jxr_javadoccomment">   * output to the cluster that is designated in &lt;code&gt;hbase-site.xml&lt;/code&gt;.</em>
<a name="415" href="#415">415</a> <em class="jxr_javadoccomment">   * Set this String to the zookeeper ensemble of an alternate remote cluster</em>
<a name="416" href="#416">416</a> <em class="jxr_javadoccomment">   * when you would have the reduce write a cluster that is other than the</em>
<a name="417" href="#417">417</a> <em class="jxr_javadoccomment">   * default; e.g. copying tables between clusters, the source would be</em>
<a name="418" href="#418">418</a> <em class="jxr_javadoccomment">   * designated by &lt;code&gt;hbase-site.xml&lt;/code&gt; and this param would have the</em>
<a name="419" href="#419">419</a> <em class="jxr_javadoccomment">   * ensemble address of the remote cluster.  The format to pass is particular.</em>
<a name="420" href="#420">420</a> <em class="jxr_javadoccomment">   * Pass &lt;code&gt; &amp;lt;hbase.zookeeper.quorum&gt;:&amp;lt;hbase.zookeeper.client.port&gt;:&amp;lt;zookeeper.znode.parent&gt;</em>
<a name="421" href="#421">421</a> <em class="jxr_javadoccomment">   * &lt;/code&gt; such as &lt;code&gt;server,server2,server3:2181:/hbase&lt;/code&gt;.</em>
<a name="422" href="#422">422</a> <em class="jxr_javadoccomment">   * @param serverClass redefined hbase.regionserver.class</em>
<a name="423" href="#423">423</a> <em class="jxr_javadoccomment">   * @param serverImpl redefined hbase.regionserver.impl</em>
<a name="424" href="#424">424</a> <em class="jxr_javadoccomment">   * @throws IOException When determining the region count fails.</em>
<a name="425" href="#425">425</a> <em class="jxr_javadoccomment">   */</em>
<a name="426" href="#426">426</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableReducerJob(String table,
<a name="427" href="#427">427</a>     Class&lt;? <strong class="jxr_keyword">extends</strong> TableReducer&gt; reducer, Job job,
<a name="428" href="#428">428</a>     Class partitioner, String quorumAddress, String serverClass,
<a name="429" href="#429">429</a>     String serverImpl) <strong class="jxr_keyword">throws</strong> IOException {
<a name="430" href="#430">430</a>     initTableReducerJob(table, reducer, job, partitioner, quorumAddress,
<a name="431" href="#431">431</a>         serverClass, serverImpl, <strong class="jxr_keyword">true</strong>);
<a name="432" href="#432">432</a>   }
<a name="433" href="#433">433</a> 
<a name="434" href="#434">434</a>   <em class="jxr_javadoccomment">/**</em>
<a name="435" href="#435">435</a> <em class="jxr_javadoccomment">   * Use this before submitting a TableReduce job. It will</em>
<a name="436" href="#436">436</a> <em class="jxr_javadoccomment">   * appropriately set up the JobConf.</em>
<a name="437" href="#437">437</a> <em class="jxr_javadoccomment">   *</em>
<a name="438" href="#438">438</a> <em class="jxr_javadoccomment">   * @param table  The output table.</em>
<a name="439" href="#439">439</a> <em class="jxr_javadoccomment">   * @param reducer  The reducer class to use.</em>
<a name="440" href="#440">440</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.  Make sure the passed job is</em>
<a name="441" href="#441">441</a> <em class="jxr_javadoccomment">   * carrying all necessary HBase configuration.</em>
<a name="442" href="#442">442</a> <em class="jxr_javadoccomment">   * @param partitioner  Partitioner to use. Pass &lt;code&gt;null&lt;/code&gt; to use</em>
<a name="443" href="#443">443</a> <em class="jxr_javadoccomment">   * default partitioner.</em>
<a name="444" href="#444">444</a> <em class="jxr_javadoccomment">   * @param quorumAddress Distant cluster to write to; default is null for</em>
<a name="445" href="#445">445</a> <em class="jxr_javadoccomment">   * output to the cluster that is designated in &lt;code&gt;hbase-site.xml&lt;/code&gt;.</em>
<a name="446" href="#446">446</a> <em class="jxr_javadoccomment">   * Set this String to the zookeeper ensemble of an alternate remote cluster</em>
<a name="447" href="#447">447</a> <em class="jxr_javadoccomment">   * when you would have the reduce write a cluster that is other than the</em>
<a name="448" href="#448">448</a> <em class="jxr_javadoccomment">   * default; e.g. copying tables between clusters, the source would be</em>
<a name="449" href="#449">449</a> <em class="jxr_javadoccomment">   * designated by &lt;code&gt;hbase-site.xml&lt;/code&gt; and this param would have the</em>
<a name="450" href="#450">450</a> <em class="jxr_javadoccomment">   * ensemble address of the remote cluster.  The format to pass is particular.</em>
<a name="451" href="#451">451</a> <em class="jxr_javadoccomment">   * Pass &lt;code&gt; &amp;lt;hbase.zookeeper.quorum&gt;:&amp;lt;hbase.zookeeper.client.port&gt;:&amp;lt;zookeeper.znode.parent&gt;</em>
<a name="452" href="#452">452</a> <em class="jxr_javadoccomment">   * &lt;/code&gt; such as &lt;code&gt;server,server2,server3:2181:/hbase&lt;/code&gt;.</em>
<a name="453" href="#453">453</a> <em class="jxr_javadoccomment">   * @param serverClass redefined hbase.regionserver.class</em>
<a name="454" href="#454">454</a> <em class="jxr_javadoccomment">   * @param serverImpl redefined hbase.regionserver.impl</em>
<a name="455" href="#455">455</a> <em class="jxr_javadoccomment">   * @param addDependencyJars upload HBase jars and jars for any of the configured</em>
<a name="456" href="#456">456</a> <em class="jxr_javadoccomment">   *           job classes via the distributed cache (tmpjars).</em>
<a name="457" href="#457">457</a> <em class="jxr_javadoccomment">   * @throws IOException When determining the region count fails.</em>
<a name="458" href="#458">458</a> <em class="jxr_javadoccomment">   */</em>
<a name="459" href="#459">459</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> initTableReducerJob(String table,
<a name="460" href="#460">460</a>     Class&lt;? <strong class="jxr_keyword">extends</strong> TableReducer&gt; reducer, Job job,
<a name="461" href="#461">461</a>     Class partitioner, String quorumAddress, String serverClass,
<a name="462" href="#462">462</a>     String serverImpl, <strong class="jxr_keyword">boolean</strong> addDependencyJars) <strong class="jxr_keyword">throws</strong> IOException {
<a name="463" href="#463">463</a> 
<a name="464" href="#464">464</a>     Configuration conf = job.getConfiguration();    
<a name="465" href="#465">465</a>     HBaseConfiguration.merge(conf, HBaseConfiguration.create(conf));
<a name="466" href="#466">466</a>     job.setOutputFormatClass(TableOutputFormat.<strong class="jxr_keyword">class</strong>);
<a name="467" href="#467">467</a>     <strong class="jxr_keyword">if</strong> (reducer != <strong class="jxr_keyword">null</strong>) job.setReducerClass(reducer);
<a name="468" href="#468">468</a>     conf.set(TableOutputFormat.OUTPUT_TABLE, table);
<a name="469" href="#469">469</a>     <em class="jxr_comment">// If passed a quorum/ensemble address, pass it on to TableOutputFormat.</em>
<a name="470" href="#470">470</a>     <strong class="jxr_keyword">if</strong> (quorumAddress != <strong class="jxr_keyword">null</strong>) {
<a name="471" href="#471">471</a>       <em class="jxr_comment">// Calling this will validate the format</em>
<a name="472" href="#472">472</a>       ZKUtil.transformClusterKey(quorumAddress);
<a name="473" href="#473">473</a>       conf.set(TableOutputFormat.QUORUM_ADDRESS,quorumAddress);
<a name="474" href="#474">474</a>     }
<a name="475" href="#475">475</a>     <strong class="jxr_keyword">if</strong> (serverClass != <strong class="jxr_keyword">null</strong> &amp;&amp; serverImpl != <strong class="jxr_keyword">null</strong>) {
<a name="476" href="#476">476</a>       conf.set(TableOutputFormat.REGION_SERVER_CLASS, serverClass);
<a name="477" href="#477">477</a>       conf.set(TableOutputFormat.REGION_SERVER_IMPL, serverImpl);
<a name="478" href="#478">478</a>     }
<a name="479" href="#479">479</a>     job.setOutputKeyClass(ImmutableBytesWritable.<strong class="jxr_keyword">class</strong>);
<a name="480" href="#480">480</a>     job.setOutputValueClass(Writable.<strong class="jxr_keyword">class</strong>);
<a name="481" href="#481">481</a>     <strong class="jxr_keyword">if</strong> (partitioner == HRegionPartitioner.<strong class="jxr_keyword">class</strong>) {
<a name="482" href="#482">482</a>       job.setPartitionerClass(HRegionPartitioner.<strong class="jxr_keyword">class</strong>);
<a name="483" href="#483">483</a>       <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> outputTable = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a>(conf, table);
<a name="484" href="#484">484</a>       <strong class="jxr_keyword">int</strong> regions = outputTable.getRegionsInfo().size();
<a name="485" href="#485">485</a>       <strong class="jxr_keyword">if</strong> (job.getNumReduceTasks() &gt; regions) {
<a name="486" href="#486">486</a>         job.setNumReduceTasks(outputTable.getRegionsInfo().size());
<a name="487" href="#487">487</a>       }
<a name="488" href="#488">488</a>     } <strong class="jxr_keyword">else</strong> <strong class="jxr_keyword">if</strong> (partitioner != <strong class="jxr_keyword">null</strong>) {
<a name="489" href="#489">489</a>       job.setPartitionerClass(partitioner);
<a name="490" href="#490">490</a>     }
<a name="491" href="#491">491</a> 
<a name="492" href="#492">492</a>     <strong class="jxr_keyword">if</strong> (addDependencyJars) {
<a name="493" href="#493">493</a>       addDependencyJars(job);
<a name="494" href="#494">494</a>     }
<a name="495" href="#495">495</a> 
<a name="496" href="#496">496</a>     initCredentials(job);
<a name="497" href="#497">497</a>   }
<a name="498" href="#498">498</a> 
<a name="499" href="#499">499</a>   <em class="jxr_javadoccomment">/**</em>
<a name="500" href="#500">500</a> <em class="jxr_javadoccomment">   * Ensures that the given number of reduce tasks for the given job</em>
<a name="501" href="#501">501</a> <em class="jxr_javadoccomment">   * configuration does not exceed the number of regions for the given table.</em>
<a name="502" href="#502">502</a> <em class="jxr_javadoccomment">   *</em>
<a name="503" href="#503">503</a> <em class="jxr_javadoccomment">   * @param table  The table to get the region count for.</em>
<a name="504" href="#504">504</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.</em>
<a name="505" href="#505">505</a> <em class="jxr_javadoccomment">   * @throws IOException When retrieving the table details fails.</em>
<a name="506" href="#506">506</a> <em class="jxr_javadoccomment">   */</em>
<a name="507" href="#507">507</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> limitNumReduceTasks(String table, Job job)
<a name="508" href="#508">508</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="509" href="#509">509</a>     <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> outputTable = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a>(job.getConfiguration(), table);
<a name="510" href="#510">510</a>     <strong class="jxr_keyword">int</strong> regions = outputTable.getRegionsInfo().size();
<a name="511" href="#511">511</a>     <strong class="jxr_keyword">if</strong> (job.getNumReduceTasks() &gt; regions)
<a name="512" href="#512">512</a>       job.setNumReduceTasks(regions);
<a name="513" href="#513">513</a>   }
<a name="514" href="#514">514</a> 
<a name="515" href="#515">515</a>   <em class="jxr_javadoccomment">/**</em>
<a name="516" href="#516">516</a> <em class="jxr_javadoccomment">   * Sets the number of reduce tasks for the given job configuration to the</em>
<a name="517" href="#517">517</a> <em class="jxr_javadoccomment">   * number of regions the given table has.</em>
<a name="518" href="#518">518</a> <em class="jxr_javadoccomment">   *</em>
<a name="519" href="#519">519</a> <em class="jxr_javadoccomment">   * @param table  The table to get the region count for.</em>
<a name="520" href="#520">520</a> <em class="jxr_javadoccomment">   * @param job  The current job to adjust.</em>
<a name="521" href="#521">521</a> <em class="jxr_javadoccomment">   * @throws IOException When retrieving the table details fails.</em>
<a name="522" href="#522">522</a> <em class="jxr_javadoccomment">   */</em>
<a name="523" href="#523">523</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> setNumReduceTasks(String table, Job job)
<a name="524" href="#524">524</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="525" href="#525">525</a>     <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a> outputTable = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/HTable.html">HTable</a>(job.getConfiguration(), table);
<a name="526" href="#526">526</a>     <strong class="jxr_keyword">int</strong> regions = outputTable.getRegionsInfo().size();
<a name="527" href="#527">527</a>     job.setNumReduceTasks(regions);
<a name="528" href="#528">528</a>   }
<a name="529" href="#529">529</a> 
<a name="530" href="#530">530</a>   <em class="jxr_javadoccomment">/**</em>
<a name="531" href="#531">531</a> <em class="jxr_javadoccomment">   * Sets the number of rows to return and cache with each scanner iteration.</em>
<a name="532" href="#532">532</a> <em class="jxr_javadoccomment">   * Higher caching values will enable faster mapreduce jobs at the expense of</em>
<a name="533" href="#533">533</a> <em class="jxr_javadoccomment">   * requiring more heap to contain the cached rows.</em>
<a name="534" href="#534">534</a> <em class="jxr_javadoccomment">   *</em>
<a name="535" href="#535">535</a> <em class="jxr_javadoccomment">   * @param job The current job to adjust.</em>
<a name="536" href="#536">536</a> <em class="jxr_javadoccomment">   * @param batchSize The number of rows to return in batch with each scanner</em>
<a name="537" href="#537">537</a> <em class="jxr_javadoccomment">   * iteration.</em>
<a name="538" href="#538">538</a> <em class="jxr_javadoccomment">   */</em>
<a name="539" href="#539">539</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> setScannerCaching(Job job, <strong class="jxr_keyword">int</strong> batchSize) {
<a name="540" href="#540">540</a>     job.getConfiguration().setInt(<span class="jxr_string">"hbase.client.scanner.caching"</span>, batchSize);
<a name="541" href="#541">541</a>   }
<a name="542" href="#542">542</a> 
<a name="543" href="#543">543</a>   <em class="jxr_javadoccomment">/**</em>
<a name="544" href="#544">544</a> <em class="jxr_javadoccomment">   * Add the HBase dependency jars as well as jars for any of the configured</em>
<a name="545" href="#545">545</a> <em class="jxr_javadoccomment">   * job classes to the job configuration, so that JobClient will ship them</em>
<a name="546" href="#546">546</a> <em class="jxr_javadoccomment">   * to the cluster and add them to the DistributedCache.</em>
<a name="547" href="#547">547</a> <em class="jxr_javadoccomment">   */</em>
<a name="548" href="#548">548</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> addDependencyJars(Job job) <strong class="jxr_keyword">throws</strong> IOException {
<a name="549" href="#549">549</a>     <strong class="jxr_keyword">try</strong> {
<a name="550" href="#550">550</a>       addDependencyJars(job.getConfiguration(),
<a name="551" href="#551">551</a>           org.apache.zookeeper.ZooKeeper.<strong class="jxr_keyword">class</strong>,
<a name="552" href="#552">552</a>           com.google.protobuf.Message.<strong class="jxr_keyword">class</strong>,
<a name="553" href="#553">553</a>           com.google.common.collect.ImmutableSet.<strong class="jxr_keyword">class</strong>,
<a name="554" href="#554">554</a>           job.getMapOutputKeyClass(),
<a name="555" href="#555">555</a>           job.getMapOutputValueClass(),
<a name="556" href="#556">556</a>           job.getInputFormatClass(),
<a name="557" href="#557">557</a>           job.getOutputKeyClass(),
<a name="558" href="#558">558</a>           job.getOutputValueClass(),
<a name="559" href="#559">559</a>           job.getOutputFormatClass(),
<a name="560" href="#560">560</a>           job.getPartitionerClass(),
<a name="561" href="#561">561</a>           job.getCombinerClass());
<a name="562" href="#562">562</a>     } <strong class="jxr_keyword">catch</strong> (ClassNotFoundException e) {
<a name="563" href="#563">563</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(e);
<a name="564" href="#564">564</a>     }    
<a name="565" href="#565">565</a>   }
<a name="566" href="#566">566</a>   
<a name="567" href="#567">567</a>   <em class="jxr_javadoccomment">/**</em>
<a name="568" href="#568">568</a> <em class="jxr_javadoccomment">   * Add the jars containing the given classes to the job's configuration</em>
<a name="569" href="#569">569</a> <em class="jxr_javadoccomment">   * such that JobClient will ship them to the cluster and add them to</em>
<a name="570" href="#570">570</a> <em class="jxr_javadoccomment">   * the DistributedCache.</em>
<a name="571" href="#571">571</a> <em class="jxr_javadoccomment">   */</em>
<a name="572" href="#572">572</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> addDependencyJars(Configuration conf,
<a name="573" href="#573">573</a>       Class... classes) <strong class="jxr_keyword">throws</strong> IOException {
<a name="574" href="#574">574</a> 
<a name="575" href="#575">575</a>     FileSystem localFs = FileSystem.getLocal(conf);
<a name="576" href="#576">576</a> 
<a name="577" href="#577">577</a>     Set&lt;String&gt; jars = <strong class="jxr_keyword">new</strong> HashSet&lt;String&gt;();
<a name="578" href="#578">578</a> 
<a name="579" href="#579">579</a>     <em class="jxr_comment">// Add jars that are already in the tmpjars variable</em>
<a name="580" href="#580">580</a>     jars.addAll( conf.getStringCollection(<span class="jxr_string">"tmpjars"</span>) );
<a name="581" href="#581">581</a> 
<a name="582" href="#582">582</a>     <em class="jxr_comment">// Add jars containing the specified classes</em>
<a name="583" href="#583">583</a>     <strong class="jxr_keyword">for</strong> (Class clazz : classes) {
<a name="584" href="#584">584</a>       <strong class="jxr_keyword">if</strong> (clazz == <strong class="jxr_keyword">null</strong>) <strong class="jxr_keyword">continue</strong>;
<a name="585" href="#585">585</a> 
<a name="586" href="#586">586</a>       String pathStr = findOrCreateJar(clazz);
<a name="587" href="#587">587</a>       <strong class="jxr_keyword">if</strong> (pathStr == <strong class="jxr_keyword">null</strong>) {
<a name="588" href="#588">588</a>         LOG.warn(<span class="jxr_string">"Could not find jar for class "</span> + clazz +
<a name="589" href="#589">589</a>                  <span class="jxr_string">" in order to ship it to the cluster."</span>);
<a name="590" href="#590">590</a>         <strong class="jxr_keyword">continue</strong>;
<a name="591" href="#591">591</a>       }
<a name="592" href="#592">592</a>       Path path = <strong class="jxr_keyword">new</strong> Path(pathStr);
<a name="593" href="#593">593</a>       <strong class="jxr_keyword">if</strong> (!localFs.exists(path)) {
<a name="594" href="#594">594</a>         LOG.warn(<span class="jxr_string">"Could not validate jar file "</span> + path + <span class="jxr_string">" for class "</span>
<a name="595" href="#595">595</a>                  + clazz);
<a name="596" href="#596">596</a>         <strong class="jxr_keyword">continue</strong>;
<a name="597" href="#597">597</a>       }
<a name="598" href="#598">598</a>       jars.add(path.makeQualified(localFs).toString());
<a name="599" href="#599">599</a>     }
<a name="600" href="#600">600</a>     <strong class="jxr_keyword">if</strong> (jars.isEmpty()) <strong class="jxr_keyword">return</strong>;
<a name="601" href="#601">601</a> 
<a name="602" href="#602">602</a>     conf.set(<span class="jxr_string">"tmpjars"</span>,
<a name="603" href="#603">603</a>              StringUtils.arrayToString(jars.toArray(<strong class="jxr_keyword">new</strong> String[0])));
<a name="604" href="#604">604</a>   }
<a name="605" href="#605">605</a> 
<a name="606" href="#606">606</a>   <em class="jxr_javadoccomment">/**</em>
<a name="607" href="#607">607</a> <em class="jxr_javadoccomment">   * If org.apache.hadoop.util.JarFinder is available (0.23+ hadoop),</em>
<a name="608" href="#608">608</a> <em class="jxr_javadoccomment">   * finds the Jar for a class or creates it if it doesn't exist. If</em>
<a name="609" href="#609">609</a> <em class="jxr_javadoccomment">   * the class is in a directory in the classpath, it creates a Jar</em>
<a name="610" href="#610">610</a> <em class="jxr_javadoccomment">   * on the fly with the contents of the directory and returns the path</em>
<a name="611" href="#611">611</a> <em class="jxr_javadoccomment">   * to that Jar. If a Jar is created, it is created in</em>
<a name="612" href="#612">612</a> <em class="jxr_javadoccomment">   * the system temporary directory.</em>
<a name="613" href="#613">613</a> <em class="jxr_javadoccomment">   *</em>
<a name="614" href="#614">614</a> <em class="jxr_javadoccomment">   * Otherwise, returns an existing jar that contains a class of the</em>
<a name="615" href="#615">615</a> <em class="jxr_javadoccomment">   * same name.</em>
<a name="616" href="#616">616</a> <em class="jxr_javadoccomment">   *</em>
<a name="617" href="#617">617</a> <em class="jxr_javadoccomment">   * @param my_class the class to find.</em>
<a name="618" href="#618">618</a> <em class="jxr_javadoccomment">   * @return a jar file that contains the class, or null.</em>
<a name="619" href="#619">619</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="620" href="#620">620</a> <em class="jxr_javadoccomment">   */</em>
<a name="621" href="#621">621</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> String findOrCreateJar(Class my_<strong class="jxr_keyword">class</strong>)
<a name="622" href="#622">622</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="623" href="#623">623</a>     <strong class="jxr_keyword">try</strong> {
<a name="624" href="#624">624</a>       Class&lt;?&gt; jarFinder = Class.forName(<span class="jxr_string">"org.apache.hadoop.util.JarFinder"</span>);
<a name="625" href="#625">625</a>       <em class="jxr_comment">// hadoop-0.23 has a JarFinder class that will create the jar</em>
<a name="626" href="#626">626</a>       <em class="jxr_comment">// if it doesn't exist.  Note that this is needed to run the mapreduce</em>
<a name="627" href="#627">627</a>       <em class="jxr_comment">// unit tests post-0.23, because mapreduce v2 requires the relevant jars</em>
<a name="628" href="#628">628</a>       <em class="jxr_comment">// to be in the mr cluster to do output, split, etc.  At unit test time,</em>
<a name="629" href="#629">629</a>       <em class="jxr_comment">// the hbase jars do not exist, so we need to create some.  Note that we</em>
<a name="630" href="#630">630</a>       <em class="jxr_comment">// can safely fall back to findContainingJars for pre-0.23 mapreduce.</em>
<a name="631" href="#631">631</a>       Method m = jarFinder.getMethod(<span class="jxr_string">"getJar"</span>, Class.<strong class="jxr_keyword">class</strong>);
<a name="632" href="#632">632</a>       <strong class="jxr_keyword">return</strong> (String)m.invoke(<strong class="jxr_keyword">null</strong>,my_<strong class="jxr_keyword">class</strong>);
<a name="633" href="#633">633</a>     } <strong class="jxr_keyword">catch</strong> (InvocationTargetException ite) {
<a name="634" href="#634">634</a>       <em class="jxr_comment">// function was properly called, but threw it's own exception</em>
<a name="635" href="#635">635</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(ite.getCause());
<a name="636" href="#636">636</a>     } <strong class="jxr_keyword">catch</strong> (Exception e) {
<a name="637" href="#637">637</a>       <em class="jxr_comment">// ignore all other exceptions. related to reflection failure</em>
<a name="638" href="#638">638</a>   }
<a name="639" href="#639">639</a> 
<a name="640" href="#640">640</a>   LOG.debug(<span class="jxr_string">"New JarFinder: org.apache.hadoop.util.JarFinder.getJar "</span> +
<a name="641" href="#641">641</a> 	<span class="jxr_string">"not available.  Using old findContainingJar"</span>);
<a name="642" href="#642">642</a>   <strong class="jxr_keyword">return</strong> findContainingJar(my_<strong class="jxr_keyword">class</strong>);
<a name="643" href="#643">643</a> }
<a name="644" href="#644">644</a> 
<a name="645" href="#645">645</a>   <em class="jxr_javadoccomment">/**</em>
<a name="646" href="#646">646</a> <em class="jxr_javadoccomment">   * Find a jar that contains a class of the same name, if any.</em>
<a name="647" href="#647">647</a> <em class="jxr_javadoccomment">   * It will return a jar file, even if that is not the first thing</em>
<a name="648" href="#648">648</a> <em class="jxr_javadoccomment">   * on the class path that has a class with the same name.</em>
<a name="649" href="#649">649</a> <em class="jxr_javadoccomment">   * </em>
<a name="650" href="#650">650</a> <em class="jxr_javadoccomment">   * This is shamelessly copied from JobConf</em>
<a name="651" href="#651">651</a> <em class="jxr_javadoccomment">   * </em>
<a name="652" href="#652">652</a> <em class="jxr_javadoccomment">   * @param my_class the class to find.</em>
<a name="653" href="#653">653</a> <em class="jxr_javadoccomment">   * @return a jar file that contains the class, or null.</em>
<a name="654" href="#654">654</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="655" href="#655">655</a> <em class="jxr_javadoccomment">   */</em>
<a name="656" href="#656">656</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> String findContainingJar(Class my_<strong class="jxr_keyword">class</strong>) {
<a name="657" href="#657">657</a>     ClassLoader loader = my_<strong class="jxr_keyword">class</strong>.getClassLoader();
<a name="658" href="#658">658</a>     String <strong class="jxr_keyword">class</strong>_file = my_<strong class="jxr_keyword">class</strong>.getName().replaceAll(<span class="jxr_string">"&#92;&#92;."</span>, <span class="jxr_string">"/"</span>) + <span class="jxr_string">".class"</span>;
<a name="659" href="#659">659</a>     <strong class="jxr_keyword">try</strong> {
<a name="660" href="#660">660</a>       <strong class="jxr_keyword">for</strong>(Enumeration itr = loader.getResources(<strong class="jxr_keyword">class</strong>_file);
<a name="661" href="#661">661</a>           itr.hasMoreElements();) {
<a name="662" href="#662">662</a>         URL url = (URL) itr.nextElement();
<a name="663" href="#663">663</a>         <strong class="jxr_keyword">if</strong> (<span class="jxr_string">"jar"</span>.equals(url.getProtocol())) {
<a name="664" href="#664">664</a>           String toReturn = url.getPath();
<a name="665" href="#665">665</a>           <strong class="jxr_keyword">if</strong> (toReturn.startsWith(<span class="jxr_string">"file:"</span>)) {
<a name="666" href="#666">666</a>             toReturn = toReturn.substring(<span class="jxr_string">"file:"</span>.length());
<a name="667" href="#667">667</a>           }
<a name="668" href="#668">668</a>           <em class="jxr_comment">// URLDecoder is a misnamed class, since it actually decodes</em>
<a name="669" href="#669">669</a>           <em class="jxr_comment">// x-www-form-urlencoded MIME type rather than actual</em>
<a name="670" href="#670">670</a>           <em class="jxr_comment">// URL encoding (which the file path has). Therefore it would</em>
<a name="671" href="#671">671</a>           <em class="jxr_comment">// decode +s to ' 's which is incorrect (spaces are actually</em>
<a name="672" href="#672">672</a>           <em class="jxr_comment">// either unencoded or encoded as "%20"). Replace +s first, so</em>
<a name="673" href="#673">673</a>           <em class="jxr_comment">// that they are kept sacred during the decoding process.</em>
<a name="674" href="#674">674</a>           toReturn = toReturn.replaceAll(<span class="jxr_string">"&#92;&#92;+"</span>, <span class="jxr_string">"%2B"</span>);
<a name="675" href="#675">675</a>           toReturn = URLDecoder.decode(toReturn, <span class="jxr_string">"UTF-8"</span>);
<a name="676" href="#676">676</a>           <strong class="jxr_keyword">return</strong> toReturn.replaceAll(<span class="jxr_string">"!.*$"</span>, <span class="jxr_string">""</span>);
<a name="677" href="#677">677</a>         }
<a name="678" href="#678">678</a>       }
<a name="679" href="#679">679</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="680" href="#680">680</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(e);
<a name="681" href="#681">681</a>     }
<a name="682" href="#682">682</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="683" href="#683">683</a>   }
<a name="684" href="#684">684</a> 
<a name="685" href="#685">685</a> 
<a name="686" href="#686">686</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

