<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>Store xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../apidocs/org/apache/hadoop/hbase/regionserver/Store.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Copyright 2010 The Apache Software Foundation</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> *</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> *</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="18" href="#18">18</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="19" href="#19">19</a>  <em class="jxr_javadoccomment"> */</em>
<a name="20" href="#20">20</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.regionserver;
<a name="21" href="#21">21</a>  
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.io.InterruptedIOException;
<a name="24" href="#24">24</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="25" href="#25">25</a>  <strong class="jxr_keyword">import</strong> java.util.Collection;
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> java.util.Collections;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> java.util.List;
<a name="28" href="#28">28</a>  <strong class="jxr_keyword">import</strong> java.util.NavigableSet;
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> java.util.Random;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> java.util.SortedSet;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.Callable;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.CompletionService;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.CopyOnWriteArraySet;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.ExecutionException;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.ExecutorCompletionService;
<a name="36" href="#36">36</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.Future;
<a name="37" href="#37">37</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.ThreadPoolExecutor;
<a name="38" href="#38">38</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.atomic.AtomicLong;
<a name="39" href="#39">39</a>  <strong class="jxr_keyword">import</strong> java.util.concurrent.locks.ReentrantReadWriteLock;
<a name="40" href="#40">40</a>  
<a name="41" href="#41">41</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.Log;
<a name="42" href="#42">42</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.LogFactory;
<a name="43" href="#43">43</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configuration;
<a name="44" href="#44">44</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileStatus;
<a name="45" href="#45">45</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileSystem;
<a name="46" href="#46">46</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileUtil;
<a name="47" href="#47">47</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.Path;
<a name="48" href="#48">48</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HBaseFileSystem;
<a name="49" href="#49">49</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HColumnDescriptor;
<a name="50" href="#50">50</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HConstants;
<a name="51" href="#51">51</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HRegionInfo;
<a name="52" href="#52">52</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.KeyValue;
<a name="53" href="#53">53</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.KeyValue.KVComparator;
<a name="54" href="#54">54</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.RemoteExceptionHandler;
<a name="55" href="#55">55</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.backup.HFileArchiver;
<a name="56" href="#56">56</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Scan;
<a name="57" href="#57">57</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.fs.HFileSystem;
<a name="58" href="#58">58</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.HFileLink;
<a name="59" href="#59">59</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.HeapSize;
<a name="60" href="#60">60</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.CacheConfig;
<a name="61" href="#61">61</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.Compression;
<a name="62" href="#62">62</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.HFile;
<a name="63" href="#63">63</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoder;
<a name="64" href="#64">64</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.HFileDataBlockEncoderImpl;
<a name="65" href="#65">65</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.HFileScanner;
<a name="66" href="#66">66</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.InvalidHFileException;
<a name="67" href="#67">67</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.hfile.NoOpDataBlockEncoder;
<a name="68" href="#68">68</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.monitoring.MonitoredTask;
<a name="69" href="#69">69</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.compactions.CompactSelection;
<a name="70" href="#70">70</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.compactions.CompactionProgress;
<a name="71" href="#71">71</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest;
<a name="72" href="#72">72</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.metrics.SchemaConfigured;
<a name="73" href="#73">73</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.metrics.SchemaMetrics;
<a name="74" href="#74">74</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Bytes;
<a name="75" href="#75">75</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.ChecksumType;
<a name="76" href="#76">76</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.ClassSize;
<a name="77" href="#77">77</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.CollectionBackedScanner;
<a name="78" href="#78">78</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
<a name="79" href="#79">79</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.FSUtils;
<a name="80" href="#80">80</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.util.StringUtils;
<a name="81" href="#81">81</a>  
<a name="82" href="#82">82</a>  <strong class="jxr_keyword">import</strong> com.google.common.base.Preconditions;
<a name="83" href="#83">83</a>  <strong class="jxr_keyword">import</strong> com.google.common.base.Predicate;
<a name="84" href="#84">84</a>  <strong class="jxr_keyword">import</strong> com.google.common.collect.Collections2;
<a name="85" href="#85">85</a>  <strong class="jxr_keyword">import</strong> com.google.common.collect.ImmutableList;
<a name="86" href="#86">86</a>  <strong class="jxr_keyword">import</strong> com.google.common.collect.Lists;
<a name="87" href="#87">87</a>  
<a name="88" href="#88">88</a>  <em class="jxr_javadoccomment">/**</em>
<a name="89" href="#89">89</a>  <em class="jxr_javadoccomment"> * A Store holds a column family in a Region.  Its a memstore and a set of zero</em>
<a name="90" href="#90">90</a>  <em class="jxr_javadoccomment"> * or more StoreFiles, which stretch backwards over time.</em>
<a name="91" href="#91">91</a>  <em class="jxr_javadoccomment"> *</em>
<a name="92" href="#92">92</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;There's no reason to consider append-logging at this level; all logging</em>
<a name="93" href="#93">93</a>  <em class="jxr_javadoccomment"> * and locking is handled at the HRegion level.  Store just provides</em>
<a name="94" href="#94">94</a>  <em class="jxr_javadoccomment"> * services to manage sets of StoreFiles.  One of the most important of those</em>
<a name="95" href="#95">95</a>  <em class="jxr_javadoccomment"> * services is compaction services where files are aggregated once they pass</em>
<a name="96" href="#96">96</a>  <em class="jxr_javadoccomment"> * a configurable threshold.</em>
<a name="97" href="#97">97</a>  <em class="jxr_javadoccomment"> *</em>
<a name="98" href="#98">98</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;The only thing having to do with logs that Store needs to deal with is</em>
<a name="99" href="#99">99</a>  <em class="jxr_javadoccomment"> * the reconstructionLog.  This is a segment of an HRegion's log that might</em>
<a name="100" href="#100">100</a> <em class="jxr_javadoccomment"> * NOT be present upon startup.  If the param is NULL, there's nothing to do.</em>
<a name="101" href="#101">101</a> <em class="jxr_javadoccomment"> * If the param is non-NULL, we need to process the log to reconstruct</em>
<a name="102" href="#102">102</a> <em class="jxr_javadoccomment"> * a TreeMap that might not have been written to disk before the process</em>
<a name="103" href="#103">103</a> <em class="jxr_javadoccomment"> * died.</em>
<a name="104" href="#104">104</a> <em class="jxr_javadoccomment"> *</em>
<a name="105" href="#105">105</a> <em class="jxr_javadoccomment"> * &lt;p&gt;It's assumed that after this constructor returns, the reconstructionLog</em>
<a name="106" href="#106">106</a> <em class="jxr_javadoccomment"> * file will be deleted (by whoever has instantiated the Store).</em>
<a name="107" href="#107">107</a> <em class="jxr_javadoccomment"> *</em>
<a name="108" href="#108">108</a> <em class="jxr_javadoccomment"> * &lt;p&gt;Locking and transactions are handled at a higher level.  This API should</em>
<a name="109" href="#109">109</a> <em class="jxr_javadoccomment"> * not be called directly but by an HRegion manager.</em>
<a name="110" href="#110">110</a> <em class="jxr_javadoccomment"> */</em>
<a name="111" href="#111">111</a> <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">Store</a> <strong class="jxr_keyword">extends</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/metrics/SchemaConfigured.html">SchemaConfigured</a> implements <a href="../../../../../org/apache/hadoop/hbase/io/HeapSize.html">HeapSize</a> {
<a name="112" href="#112">112</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> Log LOG = LogFactory.getLog(Store.<strong class="jxr_keyword">class</strong>);
<a name="113" href="#113">113</a> 
<a name="114" href="#114">114</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/MemStore.html">MemStore</a> memstore;
<a name="115" href="#115">115</a>   <em class="jxr_comment">// This stores directory in the filesystem.</em>
<a name="116" href="#116">116</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> Path homedir;
<a name="117" href="#117">117</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> region;
<a name="118" href="#118">118</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> family;
<a name="119" href="#119">119</a>   <strong class="jxr_keyword">final</strong> FileSystem fs;
<a name="120" href="#120">120</a>   <strong class="jxr_keyword">final</strong> Configuration conf;
<a name="121" href="#121">121</a>   <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a> cacheConf;
<a name="122" href="#122">122</a>   <em class="jxr_comment">// ttl in milliseconds.</em>
<a name="123" href="#123">123</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> ttl;
<a name="124" href="#124">124</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> minFilesToCompact;
<a name="125" href="#125">125</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> maxFilesToCompact;
<a name="126" href="#126">126</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> minCompactSize;
<a name="127" href="#127">127</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> maxCompactSize;
<a name="128" href="#128">128</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> lastCompactSize = 0;
<a name="129" href="#129">129</a>   <strong class="jxr_keyword">volatile</strong> <strong class="jxr_keyword">boolean</strong> forceMajor = false;
<a name="130" href="#130">130</a>   <em class="jxr_comment">/*<em class="jxr_comment"> how many bytes to write between status checks */</em></em>
<a name="131" href="#131">131</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">int</strong> closeCheckInterval = 0;
<a name="132" href="#132">132</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> blockingStoreFileCount;
<a name="133" href="#133">133</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">volatile</strong> <strong class="jxr_keyword">long</strong> storeSize = 0L;
<a name="134" href="#134">134</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">volatile</strong> <strong class="jxr_keyword">long</strong> totalUncompressedBytes = 0L;
<a name="135" href="#135">135</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> Object flushLock = <strong class="jxr_keyword">new</strong> Object();
<a name="136" href="#136">136</a>   <strong class="jxr_keyword">final</strong> ReentrantReadWriteLock lock = <strong class="jxr_keyword">new</strong> ReentrantReadWriteLock();
<a name="137" href="#137">137</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">boolean</strong> verifyBulkLoads;
<a name="138" href="#138">138</a> 
<a name="139" href="#139">139</a>   <em class="jxr_comment">/*<em class="jxr_comment"> The default priority for user-specified compaction requests.</em></em>
<a name="140" href="#140">140</a> <em class="jxr_comment">   * The user gets top priority unless we have blocking compactions. (Pri &lt;= 0)</em>
<a name="141" href="#141">141</a> <em class="jxr_comment">   */</em>
<a name="142" href="#142">142</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> PRIORITY_USER = 1;
<a name="143" href="#143">143</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> NO_PRIORITY = Integer.MIN_VALUE;
<a name="144" href="#144">144</a> 
<a name="145" href="#145">145</a>   <em class="jxr_comment">// not private for testing</em>
<a name="146" href="#146">146</a>   <em class="jxr_comment">/*<em class="jxr_comment"> package */</em><a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a> scanInfo;</em>
<a name="147" href="#147">147</a>   <em class="jxr_comment">/*</em>
<a name="148" href="#148">148</a> <em class="jxr_comment">   * List of store files inside this store. This is an immutable list that</em>
<a name="149" href="#149">149</a> <em class="jxr_comment">   * is atomically replaced when its contents change.</em>
<a name="150" href="#150">150</a> <em class="jxr_comment">   */</em>
<a name="151" href="#151">151</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">volatile</strong> ImmutableList&lt;StoreFile&gt; storefiles = <strong class="jxr_keyword">null</strong>;
<a name="152" href="#152">152</a> 
<a name="153" href="#153">153</a>   List&lt;StoreFile&gt; filesCompacting = Lists.newArrayList();
<a name="154" href="#154">154</a> 
<a name="155" href="#155">155</a>   <em class="jxr_comment">// All access must be synchronized.</em>
<a name="156" href="#156">156</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> CopyOnWriteArraySet&lt;ChangedReadersObserver&gt; changedReaderObservers =
<a name="157" href="#157">157</a>     <strong class="jxr_keyword">new</strong> CopyOnWriteArraySet&lt;ChangedReadersObserver&gt;();
<a name="158" href="#158">158</a> 
<a name="159" href="#159">159</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> blocksize;
<a name="160" href="#160">160</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.html">HFileDataBlockEncoder</a> dataBlockEncoder;
<a name="161" href="#161">161</a> 
<a name="162" href="#162">162</a>   <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> Checksum configuration */</em>
<a name="163" href="#163">163</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/util/ChecksumType.html">ChecksumType</a> checksumType;
<a name="164" href="#164">164</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">int</strong> bytesPerChecksum;
<a name="165" href="#165">165</a> 
<a name="166" href="#166">166</a>   <em class="jxr_comment">// Comparing KeyValues</em>
<a name="167" href="#167">167</a>   <strong class="jxr_keyword">final</strong> KeyValue.KVComparator comparator;
<a name="168" href="#168">168</a> 
<a name="169" href="#169">169</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Compactor.html">Compactor</a> compactor;
<a name="170" href="#170">170</a> 
<a name="171" href="#171">171</a>   <em class="jxr_javadoccomment">/**</em>
<a name="172" href="#172">172</a> <em class="jxr_javadoccomment">   * Constructor</em>
<a name="173" href="#173">173</a> <em class="jxr_javadoccomment">   * @param basedir qualified path under which the region directory lives;</em>
<a name="174" href="#174">174</a> <em class="jxr_javadoccomment">   * generally the table subdirectory</em>
<a name="175" href="#175">175</a> <em class="jxr_javadoccomment">   * @param region</em>
<a name="176" href="#176">176</a> <em class="jxr_javadoccomment">   * @param family HColumnDescriptor for this column</em>
<a name="177" href="#177">177</a> <em class="jxr_javadoccomment">   * @param fs file system object</em>
<a name="178" href="#178">178</a> <em class="jxr_javadoccomment">   * @param confParam configuration object</em>
<a name="179" href="#179">179</a> <em class="jxr_javadoccomment">   * failed.  Can be null.</em>
<a name="180" href="#180">180</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="181" href="#181">181</a> <em class="jxr_javadoccomment">   */</em>
<a name="182" href="#182">182</a>   <strong class="jxr_keyword">protected</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">Store</a>(Path basedir, <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> region, <a href="../../../../../org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> family,
<a name="183" href="#183">183</a>     FileSystem fs, Configuration conf)
<a name="184" href="#184">184</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="185" href="#185">185</a>     <strong class="jxr_keyword">super</strong>(conf, region.getRegionInfo().getTableNameAsString(),
<a name="186" href="#186">186</a>         Bytes.toString(family.getName()));
<a name="187" href="#187">187</a>     <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> info = region.getRegionInfo();
<a name="188" href="#188">188</a>     <strong class="jxr_keyword">this</strong>.fs = fs;
<a name="189" href="#189">189</a>     Path p = getStoreHomedir(basedir, info.getEncodedName(), family.getName());
<a name="190" href="#190">190</a>     <strong class="jxr_keyword">this</strong>.homedir = createStoreHomeDir(<strong class="jxr_keyword">this</strong>.fs, p);
<a name="191" href="#191">191</a>     <strong class="jxr_keyword">this</strong>.region = region;
<a name="192" href="#192">192</a>     <strong class="jxr_keyword">this</strong>.family = family;
<a name="193" href="#193">193</a>     <strong class="jxr_keyword">this</strong>.conf = conf;
<a name="194" href="#194">194</a>     <strong class="jxr_keyword">this</strong>.blocksize = family.getBlocksize();
<a name="195" href="#195">195</a> 
<a name="196" href="#196">196</a>     <strong class="jxr_keyword">this</strong>.dataBlockEncoder =
<a name="197" href="#197">197</a>         <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoderImpl.html">HFileDataBlockEncoderImpl</a>(family.getDataBlockEncodingOnDisk(),
<a name="198" href="#198">198</a>             family.getDataBlockEncoding());
<a name="199" href="#199">199</a> 
<a name="200" href="#200">200</a>     <strong class="jxr_keyword">this</strong>.comparator = info.getComparator();
<a name="201" href="#201">201</a>     <em class="jxr_comment">// getTimeToLive returns ttl in seconds.  Convert to milliseconds.</em>
<a name="202" href="#202">202</a>     <strong class="jxr_keyword">this</strong>.ttl = family.getTimeToLive();
<a name="203" href="#203">203</a>     <strong class="jxr_keyword">if</strong> (ttl == HConstants.FOREVER) {
<a name="204" href="#204">204</a>       <em class="jxr_comment">// default is unlimited ttl.</em>
<a name="205" href="#205">205</a>       ttl = Long.MAX_VALUE;
<a name="206" href="#206">206</a>     } <strong class="jxr_keyword">else</strong> <strong class="jxr_keyword">if</strong> (ttl == -1) {
<a name="207" href="#207">207</a>       ttl = Long.MAX_VALUE;
<a name="208" href="#208">208</a>     } <strong class="jxr_keyword">else</strong> {
<a name="209" href="#209">209</a>       <em class="jxr_comment">// second -&gt; ms adjust for user data</em>
<a name="210" href="#210">210</a>       <strong class="jxr_keyword">this</strong>.ttl *= 1000;
<a name="211" href="#211">211</a>     }
<a name="212" href="#212">212</a>     <em class="jxr_comment">// used by ScanQueryMatcher</em>
<a name="213" href="#213">213</a>     <strong class="jxr_keyword">long</strong> timeToPurgeDeletes =
<a name="214" href="#214">214</a>         Math.max(conf.getLong(<span class="jxr_string">"hbase.hstore.time.to.purge.deletes"</span>, 0), 0);
<a name="215" href="#215">215</a>     LOG.info(<span class="jxr_string">"time to purge deletes set to "</span> + timeToPurgeDeletes +
<a name="216" href="#216">216</a>         <span class="jxr_string">"ms in store "</span> + <strong class="jxr_keyword">this</strong>);
<a name="217" href="#217">217</a>     scanInfo = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a>(family, ttl, timeToPurgeDeletes, <strong class="jxr_keyword">this</strong>.comparator);
<a name="218" href="#218">218</a>     <strong class="jxr_keyword">this</strong>.memstore = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/MemStore.html">MemStore</a>(conf, <strong class="jxr_keyword">this</strong>.comparator);
<a name="219" href="#219">219</a> 
<a name="220" href="#220">220</a>     <em class="jxr_comment">// By default, compact if storefile.count &gt;= minFilesToCompact</em>
<a name="221" href="#221">221</a>     <strong class="jxr_keyword">this</strong>.minFilesToCompact = Math.max(2,
<a name="222" href="#222">222</a>       conf.getInt(<span class="jxr_string">"hbase.hstore.compaction.min"</span>,
<a name="223" href="#223">223</a>         <em class="jxr_comment">/*<em class="jxr_comment">old name*/</em> conf.getInt(<span class="jxr_string">"hbase.hstore.compactionThreshold"</span>, 3)));</em>
<a name="224" href="#224">224</a> 
<a name="225" href="#225">225</a>     <em class="jxr_comment">// Setting up cache configuration for this family</em>
<a name="226" href="#226">226</a>     <strong class="jxr_keyword">this</strong>.cacheConf = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a>(conf, family);
<a name="227" href="#227">227</a>     <strong class="jxr_keyword">this</strong>.blockingStoreFileCount =
<a name="228" href="#228">228</a>       conf.getInt(<span class="jxr_string">"hbase.hstore.blockingStoreFiles"</span>, 7);
<a name="229" href="#229">229</a> 
<a name="230" href="#230">230</a>     <strong class="jxr_keyword">this</strong>.maxFilesToCompact = conf.getInt(<span class="jxr_string">"hbase.hstore.compaction.max"</span>, 10);
<a name="231" href="#231">231</a>     <strong class="jxr_keyword">this</strong>.minCompactSize = conf.getLong(<span class="jxr_string">"hbase.hstore.compaction.min.size"</span>,
<a name="232" href="#232">232</a>       <strong class="jxr_keyword">this</strong>.region.memstoreFlushSize);
<a name="233" href="#233">233</a>     <strong class="jxr_keyword">this</strong>.maxCompactSize
<a name="234" href="#234">234</a>       = conf.getLong(<span class="jxr_string">"hbase.hstore.compaction.max.size"</span>, Long.MAX_VALUE);
<a name="235" href="#235">235</a> 
<a name="236" href="#236">236</a>     <strong class="jxr_keyword">this</strong>.verifyBulkLoads = conf.getBoolean(<span class="jxr_string">"hbase.hstore.bulkload.verify"</span>, false);
<a name="237" href="#237">237</a> 
<a name="238" href="#238">238</a>     <strong class="jxr_keyword">if</strong> (Store.closeCheckInterval == 0) {
<a name="239" href="#239">239</a>       Store.closeCheckInterval = conf.getInt(
<a name="240" href="#240">240</a>           <span class="jxr_string">"hbase.hstore.close.check.interval"</span>, 10*1000*1000 <em class="jxr_comment">/*<em class="jxr_comment"> 10 MB */</em>);</em>
<a name="241" href="#241">241</a>     }
<a name="242" href="#242">242</a>     <strong class="jxr_keyword">this</strong>.storefiles = sortAndClone(loadStoreFiles());
<a name="243" href="#243">243</a> 
<a name="244" href="#244">244</a>     <em class="jxr_comment">// Initialize checksum type from name. The names are CRC32, CRC32C, etc.</em>
<a name="245" href="#245">245</a>     <strong class="jxr_keyword">this</strong>.checksumType = getChecksumType(conf);
<a name="246" href="#246">246</a>     <em class="jxr_comment">// initilize bytes per checksum</em>
<a name="247" href="#247">247</a>     <strong class="jxr_keyword">this</strong>.bytesPerChecksum = getBytesPerChecksum(conf);
<a name="248" href="#248">248</a>     <em class="jxr_comment">// Create a compaction tool instance</em>
<a name="249" href="#249">249</a>     <strong class="jxr_keyword">this</strong>.compactor = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Compactor.html">Compactor</a>(<strong class="jxr_keyword">this</strong>.conf);
<a name="250" href="#250">250</a>   }
<a name="251" href="#251">251</a> 
<a name="252" href="#252">252</a>   <em class="jxr_javadoccomment">/**</em>
<a name="253" href="#253">253</a> <em class="jxr_javadoccomment">   * @param family</em>
<a name="254" href="#254">254</a> <em class="jxr_javadoccomment">   * @return</em>
<a name="255" href="#255">255</a> <em class="jxr_javadoccomment">   */</em>
<a name="256" href="#256">256</a>   <strong class="jxr_keyword">long</strong> getTTL(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> family) {
<a name="257" href="#257">257</a>     <em class="jxr_comment">// HCD.getTimeToLive returns ttl in seconds.  Convert to milliseconds.</em>
<a name="258" href="#258">258</a>     <strong class="jxr_keyword">long</strong> ttl = family.getTimeToLive();
<a name="259" href="#259">259</a>     <strong class="jxr_keyword">if</strong> (ttl == HConstants.FOREVER) {
<a name="260" href="#260">260</a>       <em class="jxr_comment">// Default is unlimited ttl.</em>
<a name="261" href="#261">261</a>       ttl = Long.MAX_VALUE;
<a name="262" href="#262">262</a>     } <strong class="jxr_keyword">else</strong> <strong class="jxr_keyword">if</strong> (ttl == -1) {
<a name="263" href="#263">263</a>       ttl = Long.MAX_VALUE;
<a name="264" href="#264">264</a>     } <strong class="jxr_keyword">else</strong> {
<a name="265" href="#265">265</a>       <em class="jxr_comment">// Second -&gt; ms adjust for user data</em>
<a name="266" href="#266">266</a>       ttl *= 1000;
<a name="267" href="#267">267</a>     }
<a name="268" href="#268">268</a>     <strong class="jxr_keyword">return</strong> ttl;
<a name="269" href="#269">269</a>   }
<a name="270" href="#270">270</a> 
<a name="271" href="#271">271</a>   <em class="jxr_javadoccomment">/**</em>
<a name="272" href="#272">272</a> <em class="jxr_javadoccomment">   * Create this store's homedir</em>
<a name="273" href="#273">273</a> <em class="jxr_javadoccomment">   * @param fs</em>
<a name="274" href="#274">274</a> <em class="jxr_javadoccomment">   * @param homedir</em>
<a name="275" href="#275">275</a> <em class="jxr_javadoccomment">   * @return Return &lt;code&gt;homedir&lt;/code&gt;</em>
<a name="276" href="#276">276</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="277" href="#277">277</a> <em class="jxr_javadoccomment">   */</em>
<a name="278" href="#278">278</a>   Path createStoreHomeDir(<strong class="jxr_keyword">final</strong> FileSystem fs,
<a name="279" href="#279">279</a>       <strong class="jxr_keyword">final</strong> Path homedir) <strong class="jxr_keyword">throws</strong> IOException {
<a name="280" href="#280">280</a>     <strong class="jxr_keyword">if</strong> (!fs.exists(homedir) &amp;&amp; !HBaseFileSystem.makeDirOnFileSystem(fs, homedir)) {
<a name="281" href="#281">281</a>         <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed create of: "</span> + homedir.toString());
<a name="282" href="#282">282</a>     }
<a name="283" href="#283">283</a>     <strong class="jxr_keyword">return</strong> homedir;
<a name="284" href="#284">284</a>   }
<a name="285" href="#285">285</a> 
<a name="286" href="#286">286</a>   FileSystem getFileSystem() {
<a name="287" href="#287">287</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.fs;
<a name="288" href="#288">288</a>   }
<a name="289" href="#289">289</a> 
<a name="290" href="#290">290</a>   <em class="jxr_javadoccomment">/**</em>
<a name="291" href="#291">291</a> <em class="jxr_javadoccomment">   * Returns the configured bytesPerChecksum value.</em>
<a name="292" href="#292">292</a> <em class="jxr_javadoccomment">   * @param conf The configuration</em>
<a name="293" href="#293">293</a> <em class="jxr_javadoccomment">   * @return The bytesPerChecksum that is set in the configuration</em>
<a name="294" href="#294">294</a> <em class="jxr_javadoccomment">   */</em>
<a name="295" href="#295">295</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">int</strong> getBytesPerChecksum(Configuration conf) {
<a name="296" href="#296">296</a>     <strong class="jxr_keyword">return</strong> conf.getInt(HConstants.BYTES_PER_CHECKSUM,
<a name="297" href="#297">297</a>                        HFile.DEFAULT_BYTES_PER_CHECKSUM);
<a name="298" href="#298">298</a>   }
<a name="299" href="#299">299</a> 
<a name="300" href="#300">300</a>   <em class="jxr_javadoccomment">/**</em>
<a name="301" href="#301">301</a> <em class="jxr_javadoccomment">   * Returns the configured checksum algorithm.</em>
<a name="302" href="#302">302</a> <em class="jxr_javadoccomment">   * @param conf The configuration</em>
<a name="303" href="#303">303</a> <em class="jxr_javadoccomment">   * @return The checksum algorithm that is set in the configuration</em>
<a name="304" href="#304">304</a> <em class="jxr_javadoccomment">   */</em>
<a name="305" href="#305">305</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <a href="../../../../../org/apache/hadoop/hbase/util/ChecksumType.html">ChecksumType</a> getChecksumType(Configuration conf) {
<a name="306" href="#306">306</a>     String checksumName = conf.get(HConstants.CHECKSUM_TYPE_NAME);
<a name="307" href="#307">307</a>     <strong class="jxr_keyword">if</strong> (checksumName == <strong class="jxr_keyword">null</strong>) {
<a name="308" href="#308">308</a>       <strong class="jxr_keyword">return</strong> HFile.DEFAULT_CHECKSUM_TYPE;
<a name="309" href="#309">309</a>     } <strong class="jxr_keyword">else</strong> {
<a name="310" href="#310">310</a>       <strong class="jxr_keyword">return</strong> ChecksumType.nameToType(checksumName);
<a name="311" href="#311">311</a>     }
<a name="312" href="#312">312</a>   }
<a name="313" href="#313">313</a> 
<a name="314" href="#314">314</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> getFamily() {
<a name="315" href="#315">315</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.family;
<a name="316" href="#316">316</a>   }
<a name="317" href="#317">317</a> 
<a name="318" href="#318">318</a>   <em class="jxr_javadoccomment">/**</em>
<a name="319" href="#319">319</a> <em class="jxr_javadoccomment">   * @return The maximum sequence id in all store files.</em>
<a name="320" href="#320">320</a> <em class="jxr_javadoccomment">   */</em>
<a name="321" href="#321">321</a>   <strong class="jxr_keyword">long</strong> getMaxSequenceId() {
<a name="322" href="#322">322</a>     <strong class="jxr_keyword">return</strong> StoreFile.getMaxSequenceIdInList(<strong class="jxr_keyword">this</strong>.getStorefiles());
<a name="323" href="#323">323</a>   }
<a name="324" href="#324">324</a> 
<a name="325" href="#325">325</a>   <em class="jxr_javadoccomment">/**</em>
<a name="326" href="#326">326</a> <em class="jxr_javadoccomment">   * @return The maximum memstoreTS in all store files.</em>
<a name="327" href="#327">327</a> <em class="jxr_javadoccomment">   */</em>
<a name="328" href="#328">328</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getMaxMemstoreTS() {
<a name="329" href="#329">329</a>     <strong class="jxr_keyword">return</strong> StoreFile.getMaxMemstoreTSInList(<strong class="jxr_keyword">this</strong>.getStorefiles());
<a name="330" href="#330">330</a>   }
<a name="331" href="#331">331</a> 
<a name="332" href="#332">332</a>   <em class="jxr_javadoccomment">/**</em>
<a name="333" href="#333">333</a> <em class="jxr_javadoccomment">   * @param tabledir</em>
<a name="334" href="#334">334</a> <em class="jxr_javadoccomment">   * @param encodedName Encoded region name.</em>
<a name="335" href="#335">335</a> <em class="jxr_javadoccomment">   * @param family</em>
<a name="336" href="#336">336</a> <em class="jxr_javadoccomment">   * @return Path to family/Store home directory.</em>
<a name="337" href="#337">337</a> <em class="jxr_javadoccomment">   */</em>
<a name="338" href="#338">338</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> Path getStoreHomedir(<strong class="jxr_keyword">final</strong> Path tabledir,
<a name="339" href="#339">339</a>       <strong class="jxr_keyword">final</strong> String encodedName, <strong class="jxr_keyword">final</strong> byte [] family) {
<a name="340" href="#340">340</a>      <strong class="jxr_keyword">return</strong> getStoreHomedir(tabledir, encodedName, Bytes.toString(family));
<a name="341" href="#341">341</a>    }
<a name="342" href="#342">342</a> 
<a name="343" href="#343">343</a>   <em class="jxr_javadoccomment">/**</em>
<a name="344" href="#344">344</a> <em class="jxr_javadoccomment">   * @param tabledir</em>
<a name="345" href="#345">345</a> <em class="jxr_javadoccomment">   * @param encodedName Encoded region name.</em>
<a name="346" href="#346">346</a> <em class="jxr_javadoccomment">   * @param family</em>
<a name="347" href="#347">347</a> <em class="jxr_javadoccomment">   * @return Path to family/Store home directory.</em>
<a name="348" href="#348">348</a> <em class="jxr_javadoccomment">   */</em>
<a name="349" href="#349">349</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> Path getStoreHomedir(<strong class="jxr_keyword">final</strong> Path tabledir,
<a name="350" href="#350">350</a>       <strong class="jxr_keyword">final</strong> String encodedName, <strong class="jxr_keyword">final</strong> String family) {
<a name="351" href="#351">351</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> Path(tabledir, <strong class="jxr_keyword">new</strong> Path(encodedName, <strong class="jxr_keyword">new</strong> Path(family)));
<a name="352" href="#352">352</a>   }
<a name="353" href="#353">353</a> 
<a name="354" href="#354">354</a>   <em class="jxr_javadoccomment">/**</em>
<a name="355" href="#355">355</a> <em class="jxr_javadoccomment">   * @param parentRegionDirectory directory for the parent region</em>
<a name="356" href="#356">356</a> <em class="jxr_javadoccomment">   * @param family family name of this store</em>
<a name="357" href="#357">357</a> <em class="jxr_javadoccomment">   * @return Path to the family/Store home directory</em>
<a name="358" href="#358">358</a> <em class="jxr_javadoccomment">   */</em>
<a name="359" href="#359">359</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> Path getStoreHomedir(<strong class="jxr_keyword">final</strong> Path parentRegionDirectory, <strong class="jxr_keyword">final</strong> byte[] family) {
<a name="360" href="#360">360</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> Path(parentRegionDirectory, <strong class="jxr_keyword">new</strong> Path(Bytes.toString(family)));
<a name="361" href="#361">361</a>   }
<a name="362" href="#362">362</a> 
<a name="363" href="#363">363</a>   <em class="jxr_javadoccomment">/**</em>
<a name="364" href="#364">364</a> <em class="jxr_javadoccomment">   * Return the directory in which this store stores its</em>
<a name="365" href="#365">365</a> <em class="jxr_javadoccomment">   * StoreFiles</em>
<a name="366" href="#366">366</a> <em class="jxr_javadoccomment">   */</em>
<a name="367" href="#367">367</a>   Path getHomedir() {
<a name="368" href="#368">368</a>     <strong class="jxr_keyword">return</strong> homedir;
<a name="369" href="#369">369</a>   }
<a name="370" href="#370">370</a> 
<a name="371" href="#371">371</a>   <em class="jxr_javadoccomment">/**</em>
<a name="372" href="#372">372</a> <em class="jxr_javadoccomment">   * @return the data block encoder</em>
<a name="373" href="#373">373</a> <em class="jxr_javadoccomment">   */</em>
<a name="374" href="#374">374</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.html">HFileDataBlockEncoder</a> getDataBlockEncoder() {
<a name="375" href="#375">375</a>     <strong class="jxr_keyword">return</strong> dataBlockEncoder;
<a name="376" href="#376">376</a>   }
<a name="377" href="#377">377</a> 
<a name="378" href="#378">378</a>   <em class="jxr_javadoccomment">/**</em>
<a name="379" href="#379">379</a> <em class="jxr_javadoccomment">   * Should be used only in tests.</em>
<a name="380" href="#380">380</a> <em class="jxr_javadoccomment">   * @param blockEncoder the block delta encoder to use</em>
<a name="381" href="#381">381</a> <em class="jxr_javadoccomment">   */</em>
<a name="382" href="#382">382</a>   <strong class="jxr_keyword">void</strong> setDataBlockEncoderInTest(<a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileDataBlockEncoder.html">HFileDataBlockEncoder</a> blockEncoder) {
<a name="383" href="#383">383</a>     <strong class="jxr_keyword">this</strong>.dataBlockEncoder = blockEncoder;
<a name="384" href="#384">384</a>   }
<a name="385" href="#385">385</a> 
<a name="386" href="#386">386</a>   FileStatus [] getStoreFiles() <strong class="jxr_keyword">throws</strong> IOException {
<a name="387" href="#387">387</a>     <strong class="jxr_keyword">return</strong> FSUtils.listStatus(<strong class="jxr_keyword">this</strong>.fs, <strong class="jxr_keyword">this</strong>.homedir, <strong class="jxr_keyword">null</strong>);
<a name="388" href="#388">388</a>   }
<a name="389" href="#389">389</a> 
<a name="390" href="#390">390</a>   <em class="jxr_javadoccomment">/**</em>
<a name="391" href="#391">391</a> <em class="jxr_javadoccomment">   * Creates an unsorted list of StoreFile loaded in parallel</em>
<a name="392" href="#392">392</a> <em class="jxr_javadoccomment">   * from the given directory.</em>
<a name="393" href="#393">393</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="394" href="#394">394</a> <em class="jxr_javadoccomment">   */</em>
<a name="395" href="#395">395</a>   <strong class="jxr_keyword">private</strong> List&lt;StoreFile&gt; loadStoreFiles() <strong class="jxr_keyword">throws</strong> IOException {
<a name="396" href="#396">396</a>     ArrayList&lt;StoreFile&gt; results = <strong class="jxr_keyword">new</strong> ArrayList&lt;StoreFile&gt;();
<a name="397" href="#397">397</a>     FileStatus files[] = getStoreFiles();
<a name="398" href="#398">398</a> 
<a name="399" href="#399">399</a>     <strong class="jxr_keyword">if</strong> (files == <strong class="jxr_keyword">null</strong> || files.length == 0) {
<a name="400" href="#400">400</a>       <strong class="jxr_keyword">return</strong> results;
<a name="401" href="#401">401</a>     }
<a name="402" href="#402">402</a>     <em class="jxr_comment">// initialize the thread pool for opening store files in parallel..</em>
<a name="403" href="#403">403</a>     ThreadPoolExecutor storeFileOpenerThreadPool =
<a name="404" href="#404">404</a>       <strong class="jxr_keyword">this</strong>.region.getStoreFileOpenAndCloseThreadPool(<span class="jxr_string">"StoreFileOpenerThread-"</span> +
<a name="405" href="#405">405</a>           <strong class="jxr_keyword">this</strong>.family.getNameAsString());
<a name="406" href="#406">406</a>     CompletionService&lt;StoreFile&gt; completionService =
<a name="407" href="#407">407</a>       <strong class="jxr_keyword">new</strong> ExecutorCompletionService&lt;StoreFile&gt;(storeFileOpenerThreadPool);
<a name="408" href="#408">408</a> 
<a name="409" href="#409">409</a>     <strong class="jxr_keyword">int</strong> totalValidStoreFile = 0;
<a name="410" href="#410">410</a>     <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; files.length; i++) {
<a name="411" href="#411">411</a>       <em class="jxr_comment">// Skip directories.</em>
<a name="412" href="#412">412</a>       <strong class="jxr_keyword">if</strong> (files[i].isDir()) {
<a name="413" href="#413">413</a>         <strong class="jxr_keyword">continue</strong>;
<a name="414" href="#414">414</a>       }
<a name="415" href="#415">415</a>       <strong class="jxr_keyword">final</strong> Path p = files[i].getPath();
<a name="416" href="#416">416</a>       <em class="jxr_comment">// Check for empty hfile. Should never be the case but can happen</em>
<a name="417" href="#417">417</a>       <em class="jxr_comment">// after data loss in hdfs for whatever reason (upgrade, etc.): HBASE-646</em>
<a name="418" href="#418">418</a>       <em class="jxr_comment">// NOTE: that the HFileLink is just a name, so it's an empty file.</em>
<a name="419" href="#419">419</a>       <strong class="jxr_keyword">if</strong> (!HFileLink.isHFileLink(p) &amp;&amp; <strong class="jxr_keyword">this</strong>.fs.getFileStatus(p).getLen() &lt;= 0) {
<a name="420" href="#420">420</a>         LOG.warn(<span class="jxr_string">"Skipping "</span> + p + <span class="jxr_string">" because its empty. HBASE-646 DATA LOSS?"</span>);
<a name="421" href="#421">421</a>         <strong class="jxr_keyword">continue</strong>;
<a name="422" href="#422">422</a>       }
<a name="423" href="#423">423</a> 
<a name="424" href="#424">424</a>       <em class="jxr_comment">// open each store file in parallel</em>
<a name="425" href="#425">425</a>       completionService.submit(<strong class="jxr_keyword">new</strong> Callable&lt;StoreFile&gt;() {
<a name="426" href="#426">426</a>         <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> call() <strong class="jxr_keyword">throws</strong> IOException {
<a name="427" href="#427">427</a>           <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> storeFile = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(fs, p, conf, cacheConf,
<a name="428" href="#428">428</a>               family.getBloomFilterType(), dataBlockEncoder);
<a name="429" href="#429">429</a>           passSchemaMetricsTo(storeFile);
<a name="430" href="#430">430</a>           storeFile.createReader();
<a name="431" href="#431">431</a>           <strong class="jxr_keyword">return</strong> storeFile;
<a name="432" href="#432">432</a>         }
<a name="433" href="#433">433</a>       });
<a name="434" href="#434">434</a>       totalValidStoreFile++;
<a name="435" href="#435">435</a>     }
<a name="436" href="#436">436</a> 
<a name="437" href="#437">437</a>     IOException ioe = <strong class="jxr_keyword">null</strong>;
<a name="438" href="#438">438</a>     <strong class="jxr_keyword">try</strong> {
<a name="439" href="#439">439</a>       <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; totalValidStoreFile; i++) {
<a name="440" href="#440">440</a>         <strong class="jxr_keyword">try</strong> {
<a name="441" href="#441">441</a>           Future&lt;StoreFile&gt; future = completionService.take();
<a name="442" href="#442">442</a>           <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> storeFile = future.get();
<a name="443" href="#443">443</a>           <strong class="jxr_keyword">long</strong> length = storeFile.getReader().length();
<a name="444" href="#444">444</a>           <strong class="jxr_keyword">this</strong>.storeSize += length;
<a name="445" href="#445">445</a>           <strong class="jxr_keyword">this</strong>.totalUncompressedBytes +=
<a name="446" href="#446">446</a>               storeFile.getReader().getTotalUncompressedBytes();
<a name="447" href="#447">447</a>           <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="448" href="#448">448</a>             LOG.debug(<span class="jxr_string">"loaded "</span> + storeFile.toStringDetailed());
<a name="449" href="#449">449</a>           }
<a name="450" href="#450">450</a>           results.add(storeFile);
<a name="451" href="#451">451</a>         } <strong class="jxr_keyword">catch</strong> (InterruptedException e) {
<a name="452" href="#452">452</a>           <strong class="jxr_keyword">if</strong> (ioe == <strong class="jxr_keyword">null</strong>) ioe = <strong class="jxr_keyword">new</strong> InterruptedIOException(e.getMessage());
<a name="453" href="#453">453</a>         } <strong class="jxr_keyword">catch</strong> (ExecutionException e) {
<a name="454" href="#454">454</a>           <strong class="jxr_keyword">if</strong> (ioe == <strong class="jxr_keyword">null</strong>) ioe = <strong class="jxr_keyword">new</strong> IOException(e.getCause());
<a name="455" href="#455">455</a>         } 
<a name="456" href="#456">456</a>       } 
<a name="457" href="#457">457</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="458" href="#458">458</a>       storeFileOpenerThreadPool.shutdownNow();
<a name="459" href="#459">459</a>     }
<a name="460" href="#460">460</a>     <strong class="jxr_keyword">if</strong> (ioe != <strong class="jxr_keyword">null</strong>) {
<a name="461" href="#461">461</a>       <em class="jxr_comment">// close StoreFile readers</em>
<a name="462" href="#462">462</a>       <strong class="jxr_keyword">try</strong> {
<a name="463" href="#463">463</a>         <strong class="jxr_keyword">for</strong> (StoreFile file : results) {
<a name="464" href="#464">464</a>           <strong class="jxr_keyword">if</strong> (file != <strong class="jxr_keyword">null</strong>) file.closeReader(<strong class="jxr_keyword">true</strong>);
<a name="465" href="#465">465</a>         }
<a name="466" href="#466">466</a>       } <strong class="jxr_keyword">catch</strong> (IOException e) { }
<a name="467" href="#467">467</a>       <strong class="jxr_keyword">throw</strong> ioe;
<a name="468" href="#468">468</a>     }
<a name="469" href="#469">469</a> 
<a name="470" href="#470">470</a>     <strong class="jxr_keyword">return</strong> results;
<a name="471" href="#471">471</a>   }
<a name="472" href="#472">472</a> 
<a name="473" href="#473">473</a>   <em class="jxr_javadoccomment">/**</em>
<a name="474" href="#474">474</a> <em class="jxr_javadoccomment">   * Adds a value to the memstore</em>
<a name="475" href="#475">475</a> <em class="jxr_javadoccomment">   *</em>
<a name="476" href="#476">476</a> <em class="jxr_javadoccomment">   * @param kv</em>
<a name="477" href="#477">477</a> <em class="jxr_javadoccomment">   * @return memstore size delta</em>
<a name="478" href="#478">478</a> <em class="jxr_javadoccomment">   */</em>
<a name="479" href="#479">479</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">long</strong> add(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv) {
<a name="480" href="#480">480</a>     lock.readLock().lock();
<a name="481" href="#481">481</a>     <strong class="jxr_keyword">try</strong> {
<a name="482" href="#482">482</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.memstore.add(kv);
<a name="483" href="#483">483</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="484" href="#484">484</a>       lock.readLock().unlock();
<a name="485" href="#485">485</a>     }
<a name="486" href="#486">486</a>   }
<a name="487" href="#487">487</a> 
<a name="488" href="#488">488</a>   <em class="jxr_javadoccomment">/**</em>
<a name="489" href="#489">489</a> <em class="jxr_javadoccomment">   * Adds a value to the memstore</em>
<a name="490" href="#490">490</a> <em class="jxr_javadoccomment">   *</em>
<a name="491" href="#491">491</a> <em class="jxr_javadoccomment">   * @param kv</em>
<a name="492" href="#492">492</a> <em class="jxr_javadoccomment">   * @return memstore size delta</em>
<a name="493" href="#493">493</a> <em class="jxr_javadoccomment">   */</em>
<a name="494" href="#494">494</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">long</strong> delete(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv) {
<a name="495" href="#495">495</a>     lock.readLock().lock();
<a name="496" href="#496">496</a>     <strong class="jxr_keyword">try</strong> {
<a name="497" href="#497">497</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.memstore.delete(kv);
<a name="498" href="#498">498</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="499" href="#499">499</a>       lock.readLock().unlock();
<a name="500" href="#500">500</a>     }
<a name="501" href="#501">501</a>   }
<a name="502" href="#502">502</a> 
<a name="503" href="#503">503</a>   <em class="jxr_javadoccomment">/**</em>
<a name="504" href="#504">504</a> <em class="jxr_javadoccomment">   * Removes a kv from the memstore. The KeyValue is removed only</em>
<a name="505" href="#505">505</a> <em class="jxr_javadoccomment">   * if its key &amp; memstoreTS matches the key &amp; memstoreTS value of the</em>
<a name="506" href="#506">506</a> <em class="jxr_javadoccomment">   * kv parameter.</em>
<a name="507" href="#507">507</a> <em class="jxr_javadoccomment">   *</em>
<a name="508" href="#508">508</a> <em class="jxr_javadoccomment">   * @param kv</em>
<a name="509" href="#509">509</a> <em class="jxr_javadoccomment">   */</em>
<a name="510" href="#510">510</a>   <strong class="jxr_keyword">protected</strong> <strong class="jxr_keyword">void</strong> rollback(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv) {
<a name="511" href="#511">511</a>     lock.readLock().lock();
<a name="512" href="#512">512</a>     <strong class="jxr_keyword">try</strong> {
<a name="513" href="#513">513</a>       <strong class="jxr_keyword">this</strong>.memstore.rollback(kv);
<a name="514" href="#514">514</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="515" href="#515">515</a>       lock.readLock().unlock();
<a name="516" href="#516">516</a>     }
<a name="517" href="#517">517</a>   }
<a name="518" href="#518">518</a> 
<a name="519" href="#519">519</a>   <em class="jxr_javadoccomment">/**</em>
<a name="520" href="#520">520</a> <em class="jxr_javadoccomment">   * @return All store files.</em>
<a name="521" href="#521">521</a> <em class="jxr_javadoccomment">   */</em>
<a name="522" href="#522">522</a>   <strong class="jxr_keyword">public</strong> List&lt;StoreFile&gt; getStorefiles() {
<a name="523" href="#523">523</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.storefiles;
<a name="524" href="#524">524</a>   }
<a name="525" href="#525">525</a> 
<a name="526" href="#526">526</a>   <em class="jxr_javadoccomment">/**</em>
<a name="527" href="#527">527</a> <em class="jxr_javadoccomment">   * This throws a WrongRegionException if the HFile does not fit in this</em>
<a name="528" href="#528">528</a> <em class="jxr_javadoccomment">   * region, or an InvalidHFileException if the HFile is not valid.</em>
<a name="529" href="#529">529</a> <em class="jxr_javadoccomment">   */</em>
<a name="530" href="#530">530</a>   <strong class="jxr_keyword">void</strong> assertBulkLoadHFileOk(Path srcPath) <strong class="jxr_keyword">throws</strong> IOException {
<a name="531" href="#531">531</a>     HFile.Reader reader  = <strong class="jxr_keyword">null</strong>;
<a name="532" href="#532">532</a>     <strong class="jxr_keyword">try</strong> {
<a name="533" href="#533">533</a>       LOG.info(<span class="jxr_string">"Validating hfile at "</span> + srcPath + <span class="jxr_string">" for inclusion in "</span>
<a name="534" href="#534">534</a>           + <span class="jxr_string">"store "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">" region "</span> + <strong class="jxr_keyword">this</strong>.region);
<a name="535" href="#535">535</a>       reader = HFile.createReader(srcPath.getFileSystem(conf),
<a name="536" href="#536">536</a>           srcPath, cacheConf);
<a name="537" href="#537">537</a>       reader.loadFileInfo();
<a name="538" href="#538">538</a> 
<a name="539" href="#539">539</a>       byte[] firstKey = reader.getFirstRowKey();
<a name="540" href="#540">540</a>       byte[] lk = reader.getLastKey();
<a name="541" href="#541">541</a>       byte[] lastKey =
<a name="542" href="#542">542</a>           (lk == <strong class="jxr_keyword">null</strong>) ? <strong class="jxr_keyword">null</strong> :
<a name="543" href="#543">543</a>               KeyValue.createKeyValueFromKey(lk).getRow();
<a name="544" href="#544">544</a> 
<a name="545" href="#545">545</a>       LOG.debug(<span class="jxr_string">"HFile bounds: first="</span> + Bytes.toStringBinary(firstKey) +
<a name="546" href="#546">546</a>           <span class="jxr_string">" last="</span> + Bytes.toStringBinary(lastKey));
<a name="547" href="#547">547</a>       LOG.debug(<span class="jxr_string">"Region bounds: first="</span> +
<a name="548" href="#548">548</a>           Bytes.toStringBinary(region.getStartKey()) +
<a name="549" href="#549">549</a>           <span class="jxr_string">" last="</span> + Bytes.toStringBinary(region.getEndKey()));
<a name="550" href="#550">550</a> 
<a name="551" href="#551">551</a>       <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> hri = region.getRegionInfo();
<a name="552" href="#552">552</a>       <strong class="jxr_keyword">if</strong> (!hri.containsRange(firstKey, lastKey)) {
<a name="553" href="#553">553</a>         <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/WrongRegionException.html">WrongRegionException</a>(
<a name="554" href="#554">554</a>             <span class="jxr_string">"Bulk load file "</span> + srcPath.toString() + <span class="jxr_string">" does not fit inside region "</span>
<a name="555" href="#555">555</a>             + <strong class="jxr_keyword">this</strong>.region);
<a name="556" href="#556">556</a>       }
<a name="557" href="#557">557</a> 
<a name="558" href="#558">558</a>       <strong class="jxr_keyword">if</strong> (verifyBulkLoads) {
<a name="559" href="#559">559</a>         <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> prevKV = <strong class="jxr_keyword">null</strong>;
<a name="560" href="#560">560</a>         <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileScanner.html">HFileScanner</a> scanner = reader.getScanner(false, false, false);
<a name="561" href="#561">561</a>         scanner.seekTo();
<a name="562" href="#562">562</a>         <strong class="jxr_keyword">do</strong> {
<a name="563" href="#563">563</a>           <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv = scanner.getKeyValue();
<a name="564" href="#564">564</a>           <strong class="jxr_keyword">if</strong> (prevKV != <strong class="jxr_keyword">null</strong>) {
<a name="565" href="#565">565</a>             <strong class="jxr_keyword">if</strong> (Bytes.compareTo(prevKV.getBuffer(), prevKV.getRowOffset(),
<a name="566" href="#566">566</a>                 prevKV.getRowLength(), kv.getBuffer(), kv.getRowOffset(),
<a name="567" href="#567">567</a>                 kv.getRowLength()) &gt; 0) {
<a name="568" href="#568">568</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/InvalidHFileException.html">InvalidHFileException</a>(<span class="jxr_string">"Previous row is greater than"</span>
<a name="569" href="#569">569</a>                   + <span class="jxr_string">" current row: path="</span> + srcPath + <span class="jxr_string">" previous="</span>
<a name="570" href="#570">570</a>                   + Bytes.toStringBinary(prevKV.getKey()) + <span class="jxr_string">" current="</span>
<a name="571" href="#571">571</a>                   + Bytes.toStringBinary(kv.getKey()));
<a name="572" href="#572">572</a>             }
<a name="573" href="#573">573</a>             <strong class="jxr_keyword">if</strong> (Bytes.compareTo(prevKV.getBuffer(), prevKV.getFamilyOffset(),
<a name="574" href="#574">574</a>                 prevKV.getFamilyLength(), kv.getBuffer(), kv.getFamilyOffset(),
<a name="575" href="#575">575</a>                 kv.getFamilyLength()) != 0) {
<a name="576" href="#576">576</a>               <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/InvalidHFileException.html">InvalidHFileException</a>(<span class="jxr_string">"Previous key had different"</span>
<a name="577" href="#577">577</a>                   + <span class="jxr_string">" family compared to current key: path="</span> + srcPath
<a name="578" href="#578">578</a>                   + <span class="jxr_string">" previous="</span> + Bytes.toStringBinary(prevKV.getFamily())
<a name="579" href="#579">579</a>                   + <span class="jxr_string">" current="</span> + Bytes.toStringBinary(kv.getFamily()));
<a name="580" href="#580">580</a>             }
<a name="581" href="#581">581</a>           }
<a name="582" href="#582">582</a>           prevKV = kv;
<a name="583" href="#583">583</a>         } <strong class="jxr_keyword">while</strong> (scanner.next());
<a name="584" href="#584">584</a>       }
<a name="585" href="#585">585</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="586" href="#586">586</a>       <strong class="jxr_keyword">if</strong> (reader != <strong class="jxr_keyword">null</strong>) reader.close();
<a name="587" href="#587">587</a>     }
<a name="588" href="#588">588</a>   }
<a name="589" href="#589">589</a> 
<a name="590" href="#590">590</a>   <em class="jxr_javadoccomment">/**</em>
<a name="591" href="#591">591</a> <em class="jxr_javadoccomment">   * This method should only be called from HRegion.  It is assumed that the</em>
<a name="592" href="#592">592</a> <em class="jxr_javadoccomment">   * ranges of values in the HFile fit within the stores assigned region.</em>
<a name="593" href="#593">593</a> <em class="jxr_javadoccomment">   * (assertBulkLoadHFileOk checks this)</em>
<a name="594" href="#594">594</a> <em class="jxr_javadoccomment">   */</em>
<a name="595" href="#595">595</a>   <strong class="jxr_keyword">void</strong> bulkLoadHFile(String srcPathStr) <strong class="jxr_keyword">throws</strong> IOException {
<a name="596" href="#596">596</a>     Path srcPath = <strong class="jxr_keyword">new</strong> Path(srcPathStr);
<a name="597" href="#597">597</a> 
<a name="598" href="#598">598</a>     <em class="jxr_comment">// Move the file if it's on another filesystem</em>
<a name="599" href="#599">599</a>     FileSystem srcFs = srcPath.getFileSystem(conf);
<a name="600" href="#600">600</a>     FileSystem desFs = fs instanceof <a href="../../../../../org/apache/hadoop/hbase/fs/HFileSystem.html">HFileSystem</a> ? ((HFileSystem)fs).getBackingFs() : fs;
<a name="601" href="#601">601</a>     <em class="jxr_comment">//We can't compare FileSystem instances as</em>
<a name="602" href="#602">602</a>     <em class="jxr_comment">//equals() includes UGI instance as part of the comparison</em>
<a name="603" href="#603">603</a>     <em class="jxr_comment">//and won't work when doing SecureBulkLoad</em>
<a name="604" href="#604">604</a>     <em class="jxr_comment">//TODO deal with viewFS</em>
<a name="605" href="#605">605</a>     <strong class="jxr_keyword">if</strong> (!srcFs.getUri().equals(desFs.getUri())) {
<a name="606" href="#606">606</a>       LOG.info(<span class="jxr_string">"File "</span> + srcPath + <span class="jxr_string">" on different filesystem than "</span> +
<a name="607" href="#607">607</a>           <span class="jxr_string">"destination store - moving to this filesystem."</span>);
<a name="608" href="#608">608</a>       Path tmpPath = getTmpPath();
<a name="609" href="#609">609</a>       FileUtil.copy(srcFs, srcPath, fs, tmpPath, false, conf);
<a name="610" href="#610">610</a>       LOG.info(<span class="jxr_string">"Copied to temporary path on dst filesystem: "</span> + tmpPath);
<a name="611" href="#611">611</a>       srcPath = tmpPath;
<a name="612" href="#612">612</a>     }
<a name="613" href="#613">613</a> 
<a name="614" href="#614">614</a>     Path dstPath = StoreFile.getRandomFilename(fs, homedir);
<a name="615" href="#615">615</a>     LOG.debug(<span class="jxr_string">"Renaming bulk load file "</span> + srcPath + <span class="jxr_string">" to "</span> + dstPath);
<a name="616" href="#616">616</a>     StoreFile.rename(fs, srcPath, dstPath);
<a name="617" href="#617">617</a> 
<a name="618" href="#618">618</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(fs, dstPath, <strong class="jxr_keyword">this</strong>.conf, <strong class="jxr_keyword">this</strong>.cacheConf,
<a name="619" href="#619">619</a>         <strong class="jxr_keyword">this</strong>.family.getBloomFilterType(), <strong class="jxr_keyword">this</strong>.dataBlockEncoder);
<a name="620" href="#620">620</a>     passSchemaMetricsTo(sf);
<a name="621" href="#621">621</a> 
<a name="622" href="#622">622</a>     StoreFile.Reader r = sf.createReader();
<a name="623" href="#623">623</a>     <strong class="jxr_keyword">this</strong>.storeSize += r.length();
<a name="624" href="#624">624</a>     <strong class="jxr_keyword">this</strong>.totalUncompressedBytes += r.getTotalUncompressedBytes();
<a name="625" href="#625">625</a> 
<a name="626" href="#626">626</a>     LOG.info(<span class="jxr_string">"Moved hfile "</span> + srcPath + <span class="jxr_string">" into store directory "</span> +
<a name="627" href="#627">627</a>         homedir + <span class="jxr_string">" - updating store file list."</span>);
<a name="628" href="#628">628</a> 
<a name="629" href="#629">629</a>     <em class="jxr_comment">// Append the new storefile into the list</em>
<a name="630" href="#630">630</a>     <strong class="jxr_keyword">this</strong>.lock.writeLock().lock();
<a name="631" href="#631">631</a>     <strong class="jxr_keyword">try</strong> {
<a name="632" href="#632">632</a>       ArrayList&lt;StoreFile&gt; newFiles = <strong class="jxr_keyword">new</strong> ArrayList&lt;StoreFile&gt;(storefiles);
<a name="633" href="#633">633</a>       newFiles.add(sf);
<a name="634" href="#634">634</a>       <strong class="jxr_keyword">this</strong>.storefiles = sortAndClone(newFiles);
<a name="635" href="#635">635</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="636" href="#636">636</a>       <em class="jxr_comment">// We need the lock, as long as we are updating the storefiles</em>
<a name="637" href="#637">637</a>       <em class="jxr_comment">// or changing the memstore. Let us release it before calling</em>
<a name="638" href="#638">638</a>       <em class="jxr_comment">// notifyChangeReadersObservers. See HBASE-4485 for a possible</em>
<a name="639" href="#639">639</a>       <em class="jxr_comment">// deadlock scenario that could have happened if continue to hold</em>
<a name="640" href="#640">640</a>       <em class="jxr_comment">// the lock.</em>
<a name="641" href="#641">641</a>       <strong class="jxr_keyword">this</strong>.lock.writeLock().unlock();
<a name="642" href="#642">642</a>     }
<a name="643" href="#643">643</a>     notifyChangedReadersObservers();
<a name="644" href="#644">644</a>     LOG.info(<span class="jxr_string">"Successfully loaded store file "</span> + srcPath
<a name="645" href="#645">645</a>         + <span class="jxr_string">" into store "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">" (new location: "</span> + dstPath + <span class="jxr_string">")"</span>);
<a name="646" href="#646">646</a>   }
<a name="647" href="#647">647</a> 
<a name="648" href="#648">648</a>   <em class="jxr_javadoccomment">/**</em>
<a name="649" href="#649">649</a> <em class="jxr_javadoccomment">   * Get a temporary path in this region. These temporary files</em>
<a name="650" href="#650">650</a> <em class="jxr_javadoccomment">   * will get cleaned up when the region is re-opened if they are</em>
<a name="651" href="#651">651</a> <em class="jxr_javadoccomment">   * still around.</em>
<a name="652" href="#652">652</a> <em class="jxr_javadoccomment">   */</em>
<a name="653" href="#653">653</a>   <strong class="jxr_keyword">private</strong> Path getTmpPath() <strong class="jxr_keyword">throws</strong> IOException {
<a name="654" href="#654">654</a>     <strong class="jxr_keyword">return</strong> StoreFile.getRandomFilename(
<a name="655" href="#655">655</a>         fs, region.getTmpDir());
<a name="656" href="#656">656</a>   }
<a name="657" href="#657">657</a> 
<a name="658" href="#658">658</a>   <em class="jxr_javadoccomment">/**</em>
<a name="659" href="#659">659</a> <em class="jxr_javadoccomment">   * Close all the readers</em>
<a name="660" href="#660">660</a> <em class="jxr_javadoccomment">   *</em>
<a name="661" href="#661">661</a> <em class="jxr_javadoccomment">   * We don't need to worry about subsequent requests because the HRegion holds</em>
<a name="662" href="#662">662</a> <em class="jxr_javadoccomment">   * a write lock that will prevent any more reads or writes.</em>
<a name="663" href="#663">663</a> <em class="jxr_javadoccomment">   *</em>
<a name="664" href="#664">664</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="665" href="#665">665</a> <em class="jxr_javadoccomment">   */</em>
<a name="666" href="#666">666</a>   ImmutableList&lt;StoreFile&gt; close() <strong class="jxr_keyword">throws</strong> IOException {
<a name="667" href="#667">667</a>     <strong class="jxr_keyword">this</strong>.lock.writeLock().lock();
<a name="668" href="#668">668</a>     <strong class="jxr_keyword">try</strong> {
<a name="669" href="#669">669</a>       ImmutableList&lt;StoreFile&gt; result = storefiles;
<a name="670" href="#670">670</a> 
<a name="671" href="#671">671</a>       <em class="jxr_comment">// Clear so metrics doesn't find them.</em>
<a name="672" href="#672">672</a>       storefiles = ImmutableList.of();
<a name="673" href="#673">673</a> 
<a name="674" href="#674">674</a>       <strong class="jxr_keyword">if</strong> (!result.isEmpty()) {
<a name="675" href="#675">675</a>         <em class="jxr_comment">// initialize the thread pool for closing store files in parallel.</em>
<a name="676" href="#676">676</a>         ThreadPoolExecutor storeFileCloserThreadPool = <strong class="jxr_keyword">this</strong>.region
<a name="677" href="#677">677</a>             .getStoreFileOpenAndCloseThreadPool(<span class="jxr_string">"StoreFileCloserThread-"</span>
<a name="678" href="#678">678</a>                 + <strong class="jxr_keyword">this</strong>.family.getNameAsString());
<a name="679" href="#679">679</a> 
<a name="680" href="#680">680</a>         <em class="jxr_comment">// close each store file in parallel</em>
<a name="681" href="#681">681</a>         CompletionService&lt;Void&gt; completionService =
<a name="682" href="#682">682</a>           <strong class="jxr_keyword">new</strong> ExecutorCompletionService&lt;Void&gt;(storeFileCloserThreadPool);
<a name="683" href="#683">683</a>         <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">final</strong> StoreFile f : result) {
<a name="684" href="#684">684</a>           completionService.submit(<strong class="jxr_keyword">new</strong> Callable&lt;Void&gt;() {
<a name="685" href="#685">685</a>             <strong class="jxr_keyword">public</strong> Void call() <strong class="jxr_keyword">throws</strong> IOException {
<a name="686" href="#686">686</a>               f.closeReader(<strong class="jxr_keyword">true</strong>);
<a name="687" href="#687">687</a>               <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="688" href="#688">688</a>             }
<a name="689" href="#689">689</a>           });
<a name="690" href="#690">690</a>         }
<a name="691" href="#691">691</a> 
<a name="692" href="#692">692</a>         IOException ioe = <strong class="jxr_keyword">null</strong>;
<a name="693" href="#693">693</a>         <strong class="jxr_keyword">try</strong> {
<a name="694" href="#694">694</a>           <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; result.size(); i++) {
<a name="695" href="#695">695</a>             <strong class="jxr_keyword">try</strong> {
<a name="696" href="#696">696</a>               Future&lt;Void&gt; future = completionService.take();
<a name="697" href="#697">697</a>               future.get();
<a name="698" href="#698">698</a>             } <strong class="jxr_keyword">catch</strong> (InterruptedException e) {
<a name="699" href="#699">699</a>               <strong class="jxr_keyword">if</strong> (ioe == <strong class="jxr_keyword">null</strong>) {
<a name="700" href="#700">700</a>                 ioe = <strong class="jxr_keyword">new</strong> InterruptedIOException();
<a name="701" href="#701">701</a>                 ioe.initCause(e);
<a name="702" href="#702">702</a>               }
<a name="703" href="#703">703</a>             } <strong class="jxr_keyword">catch</strong> (ExecutionException e) {
<a name="704" href="#704">704</a>               <strong class="jxr_keyword">if</strong> (ioe == <strong class="jxr_keyword">null</strong>) ioe = <strong class="jxr_keyword">new</strong> IOException(e.getCause());
<a name="705" href="#705">705</a>             }
<a name="706" href="#706">706</a>           }
<a name="707" href="#707">707</a>         } <strong class="jxr_keyword">finally</strong> {
<a name="708" href="#708">708</a>           storeFileCloserThreadPool.shutdownNow();
<a name="709" href="#709">709</a>         }
<a name="710" href="#710">710</a>         <strong class="jxr_keyword">if</strong> (ioe != <strong class="jxr_keyword">null</strong>) <strong class="jxr_keyword">throw</strong> ioe;
<a name="711" href="#711">711</a>       }
<a name="712" href="#712">712</a>       LOG.info(<span class="jxr_string">"Closed "</span> + <strong class="jxr_keyword">this</strong>);
<a name="713" href="#713">713</a>       <strong class="jxr_keyword">return</strong> result;
<a name="714" href="#714">714</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="715" href="#715">715</a>       <strong class="jxr_keyword">this</strong>.lock.writeLock().unlock();
<a name="716" href="#716">716</a>     }
<a name="717" href="#717">717</a>   }
<a name="718" href="#718">718</a> 
<a name="719" href="#719">719</a>   <em class="jxr_javadoccomment">/**</em>
<a name="720" href="#720">720</a> <em class="jxr_javadoccomment">   * Snapshot this stores memstore.  Call before running</em>
<a name="721" href="#721">721</a> <em class="jxr_javadoccomment">   * {@link #flushCache(long, SortedSet&lt;KeyValue&gt;)} so it has some work to do.</em>
<a name="722" href="#722">722</a> <em class="jxr_javadoccomment">   */</em>
<a name="723" href="#723">723</a>   <strong class="jxr_keyword">void</strong> snapshot() {
<a name="724" href="#724">724</a>     <strong class="jxr_keyword">this</strong>.memstore.snapshot();
<a name="725" href="#725">725</a>   }
<a name="726" href="#726">726</a> 
<a name="727" href="#727">727</a>   <em class="jxr_javadoccomment">/**</em>
<a name="728" href="#728">728</a> <em class="jxr_javadoccomment">   * Write out current snapshot.  Presumes {@link #snapshot()} has been called</em>
<a name="729" href="#729">729</a> <em class="jxr_javadoccomment">   * previously.</em>
<a name="730" href="#730">730</a> <em class="jxr_javadoccomment">   * @param logCacheFlushId flush sequence number</em>
<a name="731" href="#731">731</a> <em class="jxr_javadoccomment">   * @param snapshot</em>
<a name="732" href="#732">732</a> <em class="jxr_javadoccomment">   * @param snapshotTimeRangeTracker</em>
<a name="733" href="#733">733</a> <em class="jxr_javadoccomment">   * @param flushedSize The number of bytes flushed</em>
<a name="734" href="#734">734</a> <em class="jxr_javadoccomment">   * @param status</em>
<a name="735" href="#735">735</a> <em class="jxr_javadoccomment">   * @return Path The path name of the tmp file to which the store was flushed</em>
<a name="736" href="#736">736</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="737" href="#737">737</a> <em class="jxr_javadoccomment">   */</em>
<a name="738" href="#738">738</a>   <strong class="jxr_keyword">protected</strong> Path flushCache(<strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> logCacheFlushId,
<a name="739" href="#739">739</a>       SortedSet&lt;KeyValue&gt; snapshot,
<a name="740" href="#740">740</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/TimeRangeTracker.html">TimeRangeTracker</a> snapshotTimeRangeTracker,
<a name="741" href="#741">741</a>       AtomicLong flushedSize,
<a name="742" href="#742">742</a>       <a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status) <strong class="jxr_keyword">throws</strong> IOException {
<a name="743" href="#743">743</a>     <em class="jxr_comment">// If an exception happens flushing, we let it out without clearing</em>
<a name="744" href="#744">744</a>     <em class="jxr_comment">// the memstore snapshot.  The old snapshot will be returned when we say</em>
<a name="745" href="#745">745</a>     <em class="jxr_comment">// 'snapshot', the next time flush comes around.</em>
<a name="746" href="#746">746</a>     <strong class="jxr_keyword">return</strong> internalFlushCache(
<a name="747" href="#747">747</a>         snapshot, logCacheFlushId, snapshotTimeRangeTracker, flushedSize, status);
<a name="748" href="#748">748</a>   }
<a name="749" href="#749">749</a> 
<a name="750" href="#750">750</a>   <em class="jxr_comment">/*</em>
<a name="751" href="#751">751</a> <em class="jxr_comment">   * @param cache</em>
<a name="752" href="#752">752</a> <em class="jxr_comment">   * @param logCacheFlushId</em>
<a name="753" href="#753">753</a> <em class="jxr_comment">   * @param snapshotTimeRangeTracker</em>
<a name="754" href="#754">754</a> <em class="jxr_comment">   * @param flushedSize The number of bytes flushed</em>
<a name="755" href="#755">755</a> <em class="jxr_comment">   * @return Path The path name of the tmp file to which the store was flushed</em>
<a name="756" href="#756">756</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="757" href="#757">757</a> <em class="jxr_comment">   */</em>
<a name="758" href="#758">758</a>   <strong class="jxr_keyword">private</strong> Path internalFlushCache(<strong class="jxr_keyword">final</strong> SortedSet&lt;KeyValue&gt; set,
<a name="759" href="#759">759</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> logCacheFlushId,
<a name="760" href="#760">760</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/TimeRangeTracker.html">TimeRangeTracker</a> snapshotTimeRangeTracker,
<a name="761" href="#761">761</a>       AtomicLong flushedSize,
<a name="762" href="#762">762</a>       <a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status)
<a name="763" href="#763">763</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="764" href="#764">764</a>     StoreFile.Writer writer;
<a name="765" href="#765">765</a>     <em class="jxr_comment">// Find the smallest read point across all the Scanners.</em>
<a name="766" href="#766">766</a>     <strong class="jxr_keyword">long</strong> smallestReadPoint = region.getSmallestReadPoint();
<a name="767" href="#767">767</a>     <strong class="jxr_keyword">long</strong> flushed = 0;
<a name="768" href="#768">768</a>     Path pathName;
<a name="769" href="#769">769</a>     <em class="jxr_comment">// Don't flush if there are no entries.</em>
<a name="770" href="#770">770</a>     <strong class="jxr_keyword">if</strong> (set.size() == 0) {
<a name="771" href="#771">771</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="772" href="#772">772</a>     }
<a name="773" href="#773">773</a>     <em class="jxr_comment">// Use a store scanner to find which rows to flush.</em>
<a name="774" href="#774">774</a>     <em class="jxr_comment">// Note that we need to retain deletes, hence</em>
<a name="775" href="#775">775</a>     <em class="jxr_comment">// treat this as a minor compaction.</em>
<a name="776" href="#776">776</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/InternalScanner.html">InternalScanner</a> scanner = <strong class="jxr_keyword">null</strong>;
<a name="777" href="#777">777</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/KeyValueScanner.html">KeyValueScanner</a> memstoreScanner = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/util/CollectionBackedScanner.html">CollectionBackedScanner</a>(set, <strong class="jxr_keyword">this</strong>.comparator);
<a name="778" href="#778">778</a>     <strong class="jxr_keyword">if</strong> (getHRegion().getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="779" href="#779">779</a>       scanner = getHRegion().getCoprocessorHost().preFlushScannerOpen(<strong class="jxr_keyword">this</strong>, memstoreScanner);
<a name="780" href="#780">780</a>     }
<a name="781" href="#781">781</a>     <strong class="jxr_keyword">if</strong> (scanner == <strong class="jxr_keyword">null</strong>) {
<a name="782" href="#782">782</a>       <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a>();
<a name="783" href="#783">783</a>       scan.setMaxVersions(scanInfo.getMaxVersions());
<a name="784" href="#784">784</a>       scanner = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreScanner.html">StoreScanner</a>(<strong class="jxr_keyword">this</strong>, scanInfo, scan,
<a name="785" href="#785">785</a>           Collections.singletonList(memstoreScanner), ScanType.MINOR_COMPACT,
<a name="786" href="#786">786</a>           <strong class="jxr_keyword">this</strong>.region.getSmallestReadPoint(), HConstants.OLDEST_TIMESTAMP);
<a name="787" href="#787">787</a>     }
<a name="788" href="#788">788</a>     <strong class="jxr_keyword">if</strong> (getHRegion().getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="789" href="#789">789</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/InternalScanner.html">InternalScanner</a> cpScanner =
<a name="790" href="#790">790</a>         getHRegion().getCoprocessorHost().preFlush(<strong class="jxr_keyword">this</strong>, scanner);
<a name="791" href="#791">791</a>       <em class="jxr_comment">// NULL scanner returned from coprocessor hooks means skip normal processing</em>
<a name="792" href="#792">792</a>       <strong class="jxr_keyword">if</strong> (cpScanner == <strong class="jxr_keyword">null</strong>) {
<a name="793" href="#793">793</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="794" href="#794">794</a>       }
<a name="795" href="#795">795</a>       scanner = cpScanner;
<a name="796" href="#796">796</a>     }
<a name="797" href="#797">797</a>     <strong class="jxr_keyword">try</strong> {
<a name="798" href="#798">798</a>       <strong class="jxr_keyword">int</strong> compactionKVMax = conf.getInt(HConstants.COMPACTION_KV_MAX, 10);
<a name="799" href="#799">799</a>       <em class="jxr_comment">// TODO:  We can fail in the below block before we complete adding this</em>
<a name="800" href="#800">800</a>       <em class="jxr_comment">// flush to list of store files.  Add cleanup of anything put on filesystem</em>
<a name="801" href="#801">801</a>       <em class="jxr_comment">// if we fail.</em>
<a name="802" href="#802">802</a>       <strong class="jxr_keyword">synchronized</strong> (flushLock) {
<a name="803" href="#803">803</a>         status.setStatus(<span class="jxr_string">"Flushing "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": creating writer"</span>);
<a name="804" href="#804">804</a>         <em class="jxr_comment">// A. Write the map out to the disk</em>
<a name="805" href="#805">805</a>         writer = createWriterInTmp(set.size());
<a name="806" href="#806">806</a>         writer.setTimeRangeTracker(snapshotTimeRangeTracker);
<a name="807" href="#807">807</a>         pathName = writer.getPath();
<a name="808" href="#808">808</a>         <strong class="jxr_keyword">try</strong> {
<a name="809" href="#809">809</a>           List&lt;KeyValue&gt; kvs = <strong class="jxr_keyword">new</strong> ArrayList&lt;KeyValue&gt;();
<a name="810" href="#810">810</a>           <strong class="jxr_keyword">boolean</strong> hasMore;
<a name="811" href="#811">811</a>           <strong class="jxr_keyword">do</strong> {
<a name="812" href="#812">812</a>             hasMore = scanner.next(kvs, compactionKVMax);
<a name="813" href="#813">813</a>             <strong class="jxr_keyword">if</strong> (!kvs.isEmpty()) {
<a name="814" href="#814">814</a>               <strong class="jxr_keyword">for</strong> (KeyValue kv : kvs) {
<a name="815" href="#815">815</a>                 <em class="jxr_comment">// If we know that this KV is going to be included always, then let us</em>
<a name="816" href="#816">816</a>                 <em class="jxr_comment">// set its memstoreTS to 0. This will help us save space when writing to disk.</em>
<a name="817" href="#817">817</a>                 <strong class="jxr_keyword">if</strong> (kv.getMemstoreTS() &lt;= smallestReadPoint) {
<a name="818" href="#818">818</a>                   <em class="jxr_comment">// let us not change the original KV. It could be in the memstore</em>
<a name="819" href="#819">819</a>                   <em class="jxr_comment">// changing its memstoreTS could affect other threads/scanners.</em>
<a name="820" href="#820">820</a>                   kv = kv.shallowCopy();
<a name="821" href="#821">821</a>                   kv.setMemstoreTS(0);
<a name="822" href="#822">822</a>                 }
<a name="823" href="#823">823</a>                 writer.append(kv);
<a name="824" href="#824">824</a>                 flushed += <strong class="jxr_keyword">this</strong>.memstore.heapSizeChange(kv, <strong class="jxr_keyword">true</strong>);
<a name="825" href="#825">825</a>               }
<a name="826" href="#826">826</a>               kvs.clear();
<a name="827" href="#827">827</a>             }
<a name="828" href="#828">828</a>           } <strong class="jxr_keyword">while</strong> (hasMore);
<a name="829" href="#829">829</a>         } <strong class="jxr_keyword">finally</strong> {
<a name="830" href="#830">830</a>           <em class="jxr_comment">// Write out the log sequence number that corresponds to this output</em>
<a name="831" href="#831">831</a>           <em class="jxr_comment">// hfile.  The hfile is current up to and including logCacheFlushId.</em>
<a name="832" href="#832">832</a>           status.setStatus(<span class="jxr_string">"Flushing "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": appending metadata"</span>);
<a name="833" href="#833">833</a>           writer.appendMetadata(logCacheFlushId, false);
<a name="834" href="#834">834</a>           status.setStatus(<span class="jxr_string">"Flushing "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": closing flushed file"</span>);
<a name="835" href="#835">835</a>           writer.close();
<a name="836" href="#836">836</a>         }
<a name="837" href="#837">837</a>       }
<a name="838" href="#838">838</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="839" href="#839">839</a>       flushedSize.set(flushed);
<a name="840" href="#840">840</a>       scanner.close();
<a name="841" href="#841">841</a>     }
<a name="842" href="#842">842</a>     <strong class="jxr_keyword">if</strong> (LOG.isInfoEnabled()) {
<a name="843" href="#843">843</a>       LOG.info(<span class="jxr_string">"Flushed "</span> +
<a name="844" href="#844">844</a>                <span class="jxr_string">", sequenceid="</span> + logCacheFlushId +
<a name="845" href="#845">845</a>                <span class="jxr_string">", memsize="</span> + StringUtils.humanReadableInt(flushed) +
<a name="846" href="#846">846</a>                <span class="jxr_string">", into tmp file "</span> + pathName);
<a name="847" href="#847">847</a>     }
<a name="848" href="#848">848</a>     <strong class="jxr_keyword">return</strong> pathName;
<a name="849" href="#849">849</a>   }
<a name="850" href="#850">850</a> 
<a name="851" href="#851">851</a>   <em class="jxr_comment">/*</em>
<a name="852" href="#852">852</a> <em class="jxr_comment">   * @param path The pathname of the tmp file into which the store was flushed</em>
<a name="853" href="#853">853</a> <em class="jxr_comment">   * @param logCacheFlushId</em>
<a name="854" href="#854">854</a> <em class="jxr_comment">   * @return StoreFile created.</em>
<a name="855" href="#855">855</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="856" href="#856">856</a> <em class="jxr_comment">   */</em>
<a name="857" href="#857">857</a>   <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> commitFile(<strong class="jxr_keyword">final</strong> Path path,
<a name="858" href="#858">858</a>       <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> logCacheFlushId,
<a name="859" href="#859">859</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/TimeRangeTracker.html">TimeRangeTracker</a> snapshotTimeRangeTracker,
<a name="860" href="#860">860</a>       AtomicLong flushedSize,
<a name="861" href="#861">861</a>       <a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status)
<a name="862" href="#862">862</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="863" href="#863">863</a>     <em class="jxr_comment">// Write-out finished successfully, move into the right spot</em>
<a name="864" href="#864">864</a>     String fileName = path.getName();
<a name="865" href="#865">865</a>     Path dstPath = <strong class="jxr_keyword">new</strong> Path(homedir, fileName);
<a name="866" href="#866">866</a>     validateStoreFile(path);
<a name="867" href="#867">867</a>     String msg = <span class="jxr_string">"Renaming flushed file at "</span> + path + <span class="jxr_string">" to "</span> + dstPath;
<a name="868" href="#868">868</a>     LOG.debug(msg);
<a name="869" href="#869">869</a>     status.setStatus(<span class="jxr_string">"Flushing "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": "</span> + msg);
<a name="870" href="#870">870</a>     <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, path, dstPath)) {
<a name="871" href="#871">871</a>       LOG.warn(<span class="jxr_string">"Unable to rename "</span> + path + <span class="jxr_string">" to "</span> + dstPath);
<a name="872" href="#872">872</a>     }
<a name="873" href="#873">873</a> 
<a name="874" href="#874">874</a>     status.setStatus(<span class="jxr_string">"Flushing "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": reopening flushed file"</span>);
<a name="875" href="#875">875</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(<strong class="jxr_keyword">this</strong>.fs, dstPath, <strong class="jxr_keyword">this</strong>.conf, <strong class="jxr_keyword">this</strong>.cacheConf,
<a name="876" href="#876">876</a>         <strong class="jxr_keyword">this</strong>.family.getBloomFilterType(), <strong class="jxr_keyword">this</strong>.dataBlockEncoder);
<a name="877" href="#877">877</a>     passSchemaMetricsTo(sf);
<a name="878" href="#878">878</a> 
<a name="879" href="#879">879</a>     StoreFile.Reader r = sf.createReader();
<a name="880" href="#880">880</a>     <strong class="jxr_keyword">this</strong>.storeSize += r.length();
<a name="881" href="#881">881</a>     <strong class="jxr_keyword">this</strong>.totalUncompressedBytes += r.getTotalUncompressedBytes();
<a name="882" href="#882">882</a> 
<a name="883" href="#883">883</a>     <em class="jxr_comment">// This increments the metrics associated with total flushed bytes for this</em>
<a name="884" href="#884">884</a>     <em class="jxr_comment">// family. The overall flush count is stored in the static metrics and</em>
<a name="885" href="#885">885</a>     <em class="jxr_comment">// retrieved from HRegion.recentFlushes, which is set within</em>
<a name="886" href="#886">886</a>     <em class="jxr_comment">// HRegion.internalFlushcache, which indirectly calls this to actually do</em>
<a name="887" href="#887">887</a>     <em class="jxr_comment">// the flushing through the StoreFlusherImpl class</em>
<a name="888" href="#888">888</a>     getSchemaMetrics().updatePersistentStoreMetric(
<a name="889" href="#889">889</a>         SchemaMetrics.StoreMetricType.FLUSH_SIZE, flushedSize.longValue());
<a name="890" href="#890">890</a>     <strong class="jxr_keyword">if</strong> (LOG.isInfoEnabled()) {
<a name="891" href="#891">891</a>       LOG.info(<span class="jxr_string">"Added "</span> + sf + <span class="jxr_string">", entries="</span> + r.getEntries() +
<a name="892" href="#892">892</a>         <span class="jxr_string">", sequenceid="</span> + logCacheFlushId +
<a name="893" href="#893">893</a>         <span class="jxr_string">", filesize="</span> + StringUtils.humanReadableInt(r.length()));
<a name="894" href="#894">894</a>     }
<a name="895" href="#895">895</a>     <strong class="jxr_keyword">return</strong> sf;
<a name="896" href="#896">896</a>   }
<a name="897" href="#897">897</a> 
<a name="898" href="#898">898</a>   <em class="jxr_comment">/*</em>
<a name="899" href="#899">899</a> <em class="jxr_comment">   * @param maxKeyCount</em>
<a name="900" href="#900">900</a> <em class="jxr_comment">   * @return Writer for a new StoreFile in the tmp dir.</em>
<a name="901" href="#901">901</a> <em class="jxr_comment">   */</em>
<a name="902" href="#902">902</a>   <strong class="jxr_keyword">private</strong> StoreFile.Writer createWriterInTmp(<strong class="jxr_keyword">int</strong> maxKeyCount)
<a name="903" href="#903">903</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="904" href="#904">904</a>     <strong class="jxr_keyword">return</strong> createWriterInTmp(maxKeyCount, <strong class="jxr_keyword">this</strong>.family.getCompression(), false);
<a name="905" href="#905">905</a>   }
<a name="906" href="#906">906</a> 
<a name="907" href="#907">907</a>   <em class="jxr_comment">/*</em>
<a name="908" href="#908">908</a> <em class="jxr_comment">   * @param maxKeyCount</em>
<a name="909" href="#909">909</a> <em class="jxr_comment">   * @param compression Compression algorithm to use</em>
<a name="910" href="#910">910</a> <em class="jxr_comment">   * @param isCompaction whether we are creating a new file in a compaction</em>
<a name="911" href="#911">911</a> <em class="jxr_comment">   * @return Writer for a new StoreFile in the tmp dir.</em>
<a name="912" href="#912">912</a> <em class="jxr_comment">   */</em>
<a name="913" href="#913">913</a>   <strong class="jxr_keyword">public</strong> StoreFile.Writer createWriterInTmp(<strong class="jxr_keyword">int</strong> maxKeyCount,
<a name="914" href="#914">914</a>     Compression.Algorithm compression, <strong class="jxr_keyword">boolean</strong> isCompaction)
<a name="915" href="#915">915</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="916" href="#916">916</a>     <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a> writerCacheConf;
<a name="917" href="#917">917</a>     <strong class="jxr_keyword">if</strong> (isCompaction) {
<a name="918" href="#918">918</a>       <em class="jxr_comment">// Don't cache data on write on compactions.</em>
<a name="919" href="#919">919</a>       writerCacheConf = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a>(cacheConf);
<a name="920" href="#920">920</a>       writerCacheConf.setCacheDataOnWrite(false);
<a name="921" href="#921">921</a>     } <strong class="jxr_keyword">else</strong> {
<a name="922" href="#922">922</a>       writerCacheConf = cacheConf;
<a name="923" href="#923">923</a>     }
<a name="924" href="#924">924</a>     StoreFile.Writer w = <strong class="jxr_keyword">new</strong> StoreFile.WriterBuilder(conf, writerCacheConf,
<a name="925" href="#925">925</a>         fs, blocksize)
<a name="926" href="#926">926</a>             .withOutputDir(region.getTmpDir())
<a name="927" href="#927">927</a>             .withDataBlockEncoder(dataBlockEncoder)
<a name="928" href="#928">928</a>             .withComparator(comparator)
<a name="929" href="#929">929</a>             .withBloomType(family.getBloomFilterType())
<a name="930" href="#930">930</a>             .withMaxKeyCount(maxKeyCount)
<a name="931" href="#931">931</a>             .withChecksumType(checksumType)
<a name="932" href="#932">932</a>             .withBytesPerChecksum(bytesPerChecksum)
<a name="933" href="#933">933</a>             .withCompression(compression)
<a name="934" href="#934">934</a>             .build();
<a name="935" href="#935">935</a>     <em class="jxr_comment">// The store file writer's path does not include the CF name, so we need</em>
<a name="936" href="#936">936</a>     <em class="jxr_comment">// to configure the HFile writer directly.</em>
<a name="937" href="#937">937</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/metrics/SchemaConfigured.html">SchemaConfigured</a> sc = (SchemaConfigured) w.writer;
<a name="938" href="#938">938</a>     SchemaConfigured.resetSchemaMetricsConf(sc);
<a name="939" href="#939">939</a>     passSchemaMetricsTo(sc);
<a name="940" href="#940">940</a>     <strong class="jxr_keyword">return</strong> w;
<a name="941" href="#941">941</a>   }
<a name="942" href="#942">942</a> 
<a name="943" href="#943">943</a>   <em class="jxr_comment">/*</em>
<a name="944" href="#944">944</a> <em class="jxr_comment">   * Change storefiles adding into place the Reader produced by this new flush.</em>
<a name="945" href="#945">945</a> <em class="jxr_comment">   * @param sf</em>
<a name="946" href="#946">946</a> <em class="jxr_comment">   * @param set That was used to make the passed file &lt;code&gt;p&lt;/code&gt;.</em>
<a name="947" href="#947">947</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="948" href="#948">948</a> <em class="jxr_comment">   * @return Whether compaction is required.</em>
<a name="949" href="#949">949</a> <em class="jxr_comment">   */</em>
<a name="950" href="#950">950</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> updateStorefiles(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf,
<a name="951" href="#951">951</a>                                    <strong class="jxr_keyword">final</strong> SortedSet&lt;KeyValue&gt; set)
<a name="952" href="#952">952</a>   <strong class="jxr_keyword">throws</strong> IOException {
<a name="953" href="#953">953</a>     <strong class="jxr_keyword">this</strong>.lock.writeLock().lock();
<a name="954" href="#954">954</a>     <strong class="jxr_keyword">try</strong> {
<a name="955" href="#955">955</a>       ArrayList&lt;StoreFile&gt; newList = <strong class="jxr_keyword">new</strong> ArrayList&lt;StoreFile&gt;(storefiles);
<a name="956" href="#956">956</a>       newList.add(sf);
<a name="957" href="#957">957</a>       storefiles = sortAndClone(newList);
<a name="958" href="#958">958</a> 
<a name="959" href="#959">959</a>       <strong class="jxr_keyword">this</strong>.memstore.clearSnapshot(set);
<a name="960" href="#960">960</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="961" href="#961">961</a>       <em class="jxr_comment">// We need the lock, as long as we are updating the storefiles</em>
<a name="962" href="#962">962</a>       <em class="jxr_comment">// or changing the memstore. Let us release it before calling</em>
<a name="963" href="#963">963</a>       <em class="jxr_comment">// notifyChangeReadersObservers. See HBASE-4485 for a possible</em>
<a name="964" href="#964">964</a>       <em class="jxr_comment">// deadlock scenario that could have happened if continue to hold</em>
<a name="965" href="#965">965</a>       <em class="jxr_comment">// the lock.</em>
<a name="966" href="#966">966</a>       <strong class="jxr_keyword">this</strong>.lock.writeLock().unlock();
<a name="967" href="#967">967</a>     }
<a name="968" href="#968">968</a> 
<a name="969" href="#969">969</a>     <em class="jxr_comment">// Tell listeners of the change in readers.</em>
<a name="970" href="#970">970</a>     notifyChangedReadersObservers();
<a name="971" href="#971">971</a> 
<a name="972" href="#972">972</a>     <strong class="jxr_keyword">return</strong> needsCompaction();
<a name="973" href="#973">973</a>   }
<a name="974" href="#974">974</a> 
<a name="975" href="#975">975</a>   <em class="jxr_comment">/*</em>
<a name="976" href="#976">976</a> <em class="jxr_comment">   * Notify all observers that set of Readers has changed.</em>
<a name="977" href="#977">977</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="978" href="#978">978</a> <em class="jxr_comment">   */</em>
<a name="979" href="#979">979</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> notifyChangedReadersObservers() <strong class="jxr_keyword">throws</strong> IOException {
<a name="980" href="#980">980</a>     <strong class="jxr_keyword">for</strong> (ChangedReadersObserver o: <strong class="jxr_keyword">this</strong>.changedReaderObservers) {
<a name="981" href="#981">981</a>       o.updateReaders();
<a name="982" href="#982">982</a>     }
<a name="983" href="#983">983</a>   }
<a name="984" href="#984">984</a> 
<a name="985" href="#985">985</a>   <em class="jxr_javadoccomment">/**</em>
<a name="986" href="#986">986</a> <em class="jxr_javadoccomment">   * Get all scanners with no filtering based on TTL (that happens further down</em>
<a name="987" href="#987">987</a> <em class="jxr_javadoccomment">   * the line).</em>
<a name="988" href="#988">988</a> <em class="jxr_javadoccomment">   * @return all scanners for this store</em>
<a name="989" href="#989">989</a> <em class="jxr_javadoccomment">   */</em>
<a name="990" href="#990">990</a>   <strong class="jxr_keyword">protected</strong> List&lt;KeyValueScanner&gt; getScanners(<strong class="jxr_keyword">boolean</strong> cacheBlocks,
<a name="991" href="#991">991</a>       <strong class="jxr_keyword">boolean</strong> isGet,
<a name="992" href="#992">992</a>       <strong class="jxr_keyword">boolean</strong> isCompaction,
<a name="993" href="#993">993</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.html">ScanQueryMatcher</a> matcher) <strong class="jxr_keyword">throws</strong> IOException {
<a name="994" href="#994">994</a>     List&lt;StoreFile&gt; storeFiles;
<a name="995" href="#995">995</a>     List&lt;KeyValueScanner&gt; memStoreScanners;
<a name="996" href="#996">996</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="997" href="#997">997</a>     <strong class="jxr_keyword">try</strong> {
<a name="998" href="#998">998</a>       storeFiles = <strong class="jxr_keyword">this</strong>.getStorefiles();
<a name="999" href="#999">999</a>       memStoreScanners = <strong class="jxr_keyword">this</strong>.memstore.getScanners();
<a name="1000" href="#1000">1000</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1001" href="#1001">1001</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1002" href="#1002">1002</a>     }
<a name="1003" href="#1003">1003</a> 
<a name="1004" href="#1004">1004</a>     <em class="jxr_comment">// First the store file scanners</em>
<a name="1005" href="#1005">1005</a> 
<a name="1006" href="#1006">1006</a>     <em class="jxr_comment">// TODO this used to get the store files in descending order,</em>
<a name="1007" href="#1007">1007</a>     <em class="jxr_comment">// but now we get them in ascending order, which I think is</em>
<a name="1008" href="#1008">1008</a>     <em class="jxr_comment">// actually more correct, since memstore get put at the end.</em>
<a name="1009" href="#1009">1009</a>     List&lt;StoreFileScanner&gt; sfScanners = <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFileScanner.html">StoreFileScanner</a>
<a name="1010" href="#1010">1010</a>       .getScannersForStoreFiles(storeFiles, cacheBlocks, isGet, isCompaction, matcher);
<a name="1011" href="#1011">1011</a>     List&lt;KeyValueScanner&gt; scanners =
<a name="1012" href="#1012">1012</a>       <strong class="jxr_keyword">new</strong> ArrayList&lt;KeyValueScanner&gt;(sfScanners.size()+1);
<a name="1013" href="#1013">1013</a>     scanners.addAll(sfScanners);
<a name="1014" href="#1014">1014</a>     <em class="jxr_comment">// Then the memstore scanners</em>
<a name="1015" href="#1015">1015</a>     scanners.addAll(memStoreScanners);
<a name="1016" href="#1016">1016</a>     <strong class="jxr_keyword">return</strong> scanners;
<a name="1017" href="#1017">1017</a>   }
<a name="1018" href="#1018">1018</a> 
<a name="1019" href="#1019">1019</a>   <em class="jxr_comment">/*</em>
<a name="1020" href="#1020">1020</a> <em class="jxr_comment">   * @param o Observer who wants to know about changes in set of Readers</em>
<a name="1021" href="#1021">1021</a> <em class="jxr_comment">   */</em>
<a name="1022" href="#1022">1022</a>   <strong class="jxr_keyword">void</strong> addChangedReaderObserver(<a href="../../../../../org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.html">ChangedReadersObserver</a> o) {
<a name="1023" href="#1023">1023</a>     <strong class="jxr_keyword">this</strong>.changedReaderObservers.add(o);
<a name="1024" href="#1024">1024</a>   }
<a name="1025" href="#1025">1025</a> 
<a name="1026" href="#1026">1026</a>   <em class="jxr_comment">/*</em>
<a name="1027" href="#1027">1027</a> <em class="jxr_comment">   * @param o Observer no longer interested in changes in set of Readers.</em>
<a name="1028" href="#1028">1028</a> <em class="jxr_comment">   */</em>
<a name="1029" href="#1029">1029</a>   <strong class="jxr_keyword">void</strong> deleteChangedReaderObserver(<a href="../../../../../org/apache/hadoop/hbase/regionserver/ChangedReadersObserver.html">ChangedReadersObserver</a> o) {
<a name="1030" href="#1030">1030</a>     <em class="jxr_comment">// We don't check if observer present; it may not be (legitimately)</em>
<a name="1031" href="#1031">1031</a>     <strong class="jxr_keyword">this</strong>.changedReaderObservers.remove(o);
<a name="1032" href="#1032">1032</a>   }
<a name="1033" href="#1033">1033</a> 
<a name="1034" href="#1034">1034</a>   <em class="jxr_comment">//////////////////////////////////////////////////////////////////////////////</em>
<a name="1035" href="#1035">1035</a>   <em class="jxr_comment">// Compaction</em>
<a name="1036" href="#1036">1036</a>   <em class="jxr_comment">//////////////////////////////////////////////////////////////////////////////</em>
<a name="1037" href="#1037">1037</a> 
<a name="1038" href="#1038">1038</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1039" href="#1039">1039</a> <em class="jxr_javadoccomment">   * Compact the StoreFiles.  This method may take some time, so the calling</em>
<a name="1040" href="#1040">1040</a> <em class="jxr_javadoccomment">   * thread must be able to block for long periods.</em>
<a name="1041" href="#1041">1041</a> <em class="jxr_javadoccomment">   *</em>
<a name="1042" href="#1042">1042</a> <em class="jxr_javadoccomment">   * &lt;p&gt;During this time, the Store can work as usual, getting values from</em>
<a name="1043" href="#1043">1043</a> <em class="jxr_javadoccomment">   * StoreFiles and writing new StoreFiles from the memstore.</em>
<a name="1044" href="#1044">1044</a> <em class="jxr_javadoccomment">   *</em>
<a name="1045" href="#1045">1045</a> <em class="jxr_javadoccomment">   * Existing StoreFiles are not destroyed until the new compacted StoreFile is</em>
<a name="1046" href="#1046">1046</a> <em class="jxr_javadoccomment">   * completely written-out to disk.</em>
<a name="1047" href="#1047">1047</a> <em class="jxr_javadoccomment">   *</em>
<a name="1048" href="#1048">1048</a> <em class="jxr_javadoccomment">   * &lt;p&gt;The compactLock prevents multiple simultaneous compactions.</em>
<a name="1049" href="#1049">1049</a> <em class="jxr_javadoccomment">   * The structureLock prevents us from interfering with other write operations.</em>
<a name="1050" href="#1050">1050</a> <em class="jxr_javadoccomment">   *</em>
<a name="1051" href="#1051">1051</a> <em class="jxr_javadoccomment">   * &lt;p&gt;We don't want to hold the structureLock for the whole time, as a compact()</em>
<a name="1052" href="#1052">1052</a> <em class="jxr_javadoccomment">   * can be lengthy and we want to allow cache-flushes during this period.</em>
<a name="1053" href="#1053">1053</a> <em class="jxr_javadoccomment">   *</em>
<a name="1054" href="#1054">1054</a> <em class="jxr_javadoccomment">   * @param cr</em>
<a name="1055" href="#1055">1055</a> <em class="jxr_javadoccomment">   *          compaction details obtained from requestCompaction()</em>
<a name="1056" href="#1056">1056</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="1057" href="#1057">1057</a> <em class="jxr_javadoccomment">   * @return Storefile we compacted into or null if we failed or opted out early.</em>
<a name="1058" href="#1058">1058</a> <em class="jxr_javadoccomment">   */</em>
<a name="1059" href="#1059">1059</a>   <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> compact(<a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a> cr) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1060" href="#1060">1060</a>     <strong class="jxr_keyword">if</strong> (cr == <strong class="jxr_keyword">null</strong> || cr.getFiles().isEmpty()) <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1061" href="#1061">1061</a>     Preconditions.checkArgument(cr.getStore().toString().equals(<strong class="jxr_keyword">this</strong>.toString()));
<a name="1062" href="#1062">1062</a>     List&lt;StoreFile&gt; filesToCompact = cr.getFiles();
<a name="1063" href="#1063">1063</a>     <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1064" href="#1064">1064</a>       <em class="jxr_comment">// sanity check: we're compacting files that this store knows about</em>
<a name="1065" href="#1065">1065</a>       <em class="jxr_comment">// TODO: change this to LOG.error() after more debugging</em>
<a name="1066" href="#1066">1066</a>       Preconditions.checkArgument(filesCompacting.containsAll(filesToCompact));
<a name="1067" href="#1067">1067</a>     }
<a name="1068" href="#1068">1068</a> 
<a name="1069" href="#1069">1069</a>     <em class="jxr_comment">// Max-sequenceID is the last key in the files we're compacting</em>
<a name="1070" href="#1070">1070</a>     <strong class="jxr_keyword">long</strong> maxId = StoreFile.getMaxSequenceIdInList(filesToCompact);
<a name="1071" href="#1071">1071</a> 
<a name="1072" href="#1072">1072</a>     <em class="jxr_comment">// Ready to go. Have list of files to compact.</em>
<a name="1073" href="#1073">1073</a>     LOG.info(<span class="jxr_string">"Starting compaction of "</span> + filesToCompact.size() + <span class="jxr_string">" file(s) in "</span>
<a name="1074" href="#1074">1074</a>         + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">" of "</span>
<a name="1075" href="#1075">1075</a>         + <strong class="jxr_keyword">this</strong>.region.getRegionInfo().getRegionNameAsString()
<a name="1076" href="#1076">1076</a>         + <span class="jxr_string">" into tmpdir="</span> + region.getTmpDir() + <span class="jxr_string">", seqid="</span> + maxId + <span class="jxr_string">", totalSize="</span>
<a name="1077" href="#1077">1077</a>         + StringUtils.humanReadableInt(cr.getSize()));
<a name="1078" href="#1078">1078</a> 
<a name="1079" href="#1079">1079</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf = <strong class="jxr_keyword">null</strong>;
<a name="1080" href="#1080">1080</a>     <strong class="jxr_keyword">try</strong> {
<a name="1081" href="#1081">1081</a>       StoreFile.Writer writer = <strong class="jxr_keyword">this</strong>.compactor.compact(cr, maxId);
<a name="1082" href="#1082">1082</a>       <em class="jxr_comment">// Move the compaction into place.</em>
<a name="1083" href="#1083">1083</a>       <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.conf.getBoolean(<span class="jxr_string">"hbase.hstore.compaction.complete"</span>, <strong class="jxr_keyword">true</strong>)) {
<a name="1084" href="#1084">1084</a>         sf = completeCompaction(filesToCompact, writer);
<a name="1085" href="#1085">1085</a>         <strong class="jxr_keyword">if</strong> (region.getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="1086" href="#1086">1086</a>           region.getCoprocessorHost().postCompact(<strong class="jxr_keyword">this</strong>, sf, cr);
<a name="1087" href="#1087">1087</a>         }
<a name="1088" href="#1088">1088</a>       } <strong class="jxr_keyword">else</strong> {
<a name="1089" href="#1089">1089</a>         <em class="jxr_comment">// Create storefile around what we wrote with a reader on it.</em>
<a name="1090" href="#1090">1090</a>         sf = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(<strong class="jxr_keyword">this</strong>.fs, writer.getPath(), <strong class="jxr_keyword">this</strong>.conf, <strong class="jxr_keyword">this</strong>.cacheConf,
<a name="1091" href="#1091">1091</a>           <strong class="jxr_keyword">this</strong>.family.getBloomFilterType(), <strong class="jxr_keyword">this</strong>.dataBlockEncoder);
<a name="1092" href="#1092">1092</a>         sf.createReader();
<a name="1093" href="#1093">1093</a>       }
<a name="1094" href="#1094">1094</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1095" href="#1095">1095</a>       <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1096" href="#1096">1096</a>         filesCompacting.removeAll(filesToCompact);
<a name="1097" href="#1097">1097</a>       }
<a name="1098" href="#1098">1098</a>     }
<a name="1099" href="#1099">1099</a> 
<a name="1100" href="#1100">1100</a>     LOG.info(<span class="jxr_string">"Completed"</span> + (cr.isMajor() ? <span class="jxr_string">" major "</span> : <span class="jxr_string">" "</span>) + <span class="jxr_string">"compaction of "</span>
<a name="1101" href="#1101">1101</a>         + filesToCompact.size() + <span class="jxr_string">" file(s) in "</span> + <strong class="jxr_keyword">this</strong> + <span class="jxr_string">" of "</span>
<a name="1102" href="#1102">1102</a>         + <strong class="jxr_keyword">this</strong>.region.getRegionInfo().getRegionNameAsString()
<a name="1103" href="#1103">1103</a>         + <span class="jxr_string">" into "</span> +
<a name="1104" href="#1104">1104</a>         (sf == <strong class="jxr_keyword">null</strong> ? <span class="jxr_string">"none"</span> : sf.getPath().getName()) +
<a name="1105" href="#1105">1105</a>         <span class="jxr_string">", size="</span> + (sf == <strong class="jxr_keyword">null</strong> ? <span class="jxr_string">"none"</span> :
<a name="1106" href="#1106">1106</a>           StringUtils.humanReadableInt(sf.getReader().length()))
<a name="1107" href="#1107">1107</a>         + <span class="jxr_string">"; total size for store is "</span>
<a name="1108" href="#1108">1108</a>         + StringUtils.humanReadableInt(storeSize));
<a name="1109" href="#1109">1109</a>     <strong class="jxr_keyword">return</strong> sf;
<a name="1110" href="#1110">1110</a>   }
<a name="1111" href="#1111">1111</a> 
<a name="1112" href="#1112">1112</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1113" href="#1113">1113</a> <em class="jxr_javadoccomment">   * Compact the most recent N files. Used in testing.</em>
<a name="1114" href="#1114">1114</a> <em class="jxr_javadoccomment">   */</em>
<a name="1115" href="#1115">1115</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> compactRecentForTesting(<strong class="jxr_keyword">int</strong> N) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1116" href="#1116">1116</a>     List&lt;StoreFile&gt; filesToCompact;
<a name="1117" href="#1117">1117</a>     <strong class="jxr_keyword">long</strong> maxId;
<a name="1118" href="#1118">1118</a>     <strong class="jxr_keyword">boolean</strong> isMajor;
<a name="1119" href="#1119">1119</a> 
<a name="1120" href="#1120">1120</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="1121" href="#1121">1121</a>     <strong class="jxr_keyword">try</strong> {
<a name="1122" href="#1122">1122</a>       <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1123" href="#1123">1123</a>         filesToCompact = Lists.newArrayList(storefiles);
<a name="1124" href="#1124">1124</a>         <strong class="jxr_keyword">if</strong> (!filesCompacting.isEmpty()) {
<a name="1125" href="#1125">1125</a>           <em class="jxr_comment">// exclude all files older than the newest file we're currently</em>
<a name="1126" href="#1126">1126</a>           <em class="jxr_comment">// compacting. this allows us to preserve contiguity (HBASE-2856)</em>
<a name="1127" href="#1127">1127</a>           <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> last = filesCompacting.get(filesCompacting.size() - 1);
<a name="1128" href="#1128">1128</a>           <strong class="jxr_keyword">int</strong> idx = filesToCompact.indexOf(last);
<a name="1129" href="#1129">1129</a>           Preconditions.checkArgument(idx != -1);
<a name="1130" href="#1130">1130</a>           filesToCompact.subList(0, idx + 1).clear();
<a name="1131" href="#1131">1131</a>         }
<a name="1132" href="#1132">1132</a>         <strong class="jxr_keyword">int</strong> count = filesToCompact.size();
<a name="1133" href="#1133">1133</a>         <strong class="jxr_keyword">if</strong> (N &gt; count) {
<a name="1134" href="#1134">1134</a>           <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> RuntimeException(<span class="jxr_string">"Not enough files"</span>);
<a name="1135" href="#1135">1135</a>         }
<a name="1136" href="#1136">1136</a> 
<a name="1137" href="#1137">1137</a>         filesToCompact = filesToCompact.subList(count - N, count);
<a name="1138" href="#1138">1138</a>         maxId = StoreFile.getMaxSequenceIdInList(filesToCompact);
<a name="1139" href="#1139">1139</a>         isMajor = (filesToCompact.size() == storefiles.size());
<a name="1140" href="#1140">1140</a>         filesCompacting.addAll(filesToCompact);
<a name="1141" href="#1141">1141</a>         Collections.sort(filesCompacting, StoreFile.Comparators.FLUSH_TIME);
<a name="1142" href="#1142">1142</a>       }
<a name="1143" href="#1143">1143</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1144" href="#1144">1144</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1145" href="#1145">1145</a>     }
<a name="1146" href="#1146">1146</a> 
<a name="1147" href="#1147">1147</a>     <strong class="jxr_keyword">try</strong> {
<a name="1148" href="#1148">1148</a>       <em class="jxr_comment">// Ready to go. Have list of files to compact.</em>
<a name="1149" href="#1149">1149</a>       StoreFile.Writer writer = <strong class="jxr_keyword">this</strong>.compactor.compactForTesting(<strong class="jxr_keyword">this</strong>, conf, filesToCompact,
<a name="1150" href="#1150">1150</a>         isMajor, maxId);
<a name="1151" href="#1151">1151</a>       <em class="jxr_comment">// Move the compaction into place.</em>
<a name="1152" href="#1152">1152</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf = completeCompaction(filesToCompact, writer);
<a name="1153" href="#1153">1153</a>       <strong class="jxr_keyword">if</strong> (region.getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="1154" href="#1154">1154</a>         region.getCoprocessorHost().postCompact(<strong class="jxr_keyword">this</strong>, sf, <strong class="jxr_keyword">null</strong>);
<a name="1155" href="#1155">1155</a>       }
<a name="1156" href="#1156">1156</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1157" href="#1157">1157</a>       <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1158" href="#1158">1158</a>         filesCompacting.removeAll(filesToCompact);
<a name="1159" href="#1159">1159</a>       }
<a name="1160" href="#1160">1160</a>     }
<a name="1161" href="#1161">1161</a>   }
<a name="1162" href="#1162">1162</a> 
<a name="1163" href="#1163">1163</a>   <strong class="jxr_keyword">boolean</strong> hasReferences() {
<a name="1164" href="#1164">1164</a>     <strong class="jxr_keyword">return</strong> hasReferences(<strong class="jxr_keyword">this</strong>.storefiles);
<a name="1165" href="#1165">1165</a>   }
<a name="1166" href="#1166">1166</a> 
<a name="1167" href="#1167">1167</a>   <em class="jxr_comment">/*</em>
<a name="1168" href="#1168">1168</a> <em class="jxr_comment">   * @param files</em>
<a name="1169" href="#1169">1169</a> <em class="jxr_comment">   * @return True if any of the files in &lt;code&gt;files&lt;/code&gt; are References.</em>
<a name="1170" href="#1170">1170</a> <em class="jxr_comment">   */</em>
<a name="1171" href="#1171">1171</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> hasReferences(Collection&lt;StoreFile&gt; files) {
<a name="1172" href="#1172">1172</a>     <strong class="jxr_keyword">if</strong> (files != <strong class="jxr_keyword">null</strong> &amp;&amp; files.size() &gt; 0) {
<a name="1173" href="#1173">1173</a>       <strong class="jxr_keyword">for</strong> (StoreFile hsf: files) {
<a name="1174" href="#1174">1174</a>         <strong class="jxr_keyword">if</strong> (hsf.isReference()) {
<a name="1175" href="#1175">1175</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">true</strong>;
<a name="1176" href="#1176">1176</a>         }
<a name="1177" href="#1177">1177</a>       }
<a name="1178" href="#1178">1178</a>     }
<a name="1179" href="#1179">1179</a>     <strong class="jxr_keyword">return</strong> false;
<a name="1180" href="#1180">1180</a>   }
<a name="1181" href="#1181">1181</a> 
<a name="1182" href="#1182">1182</a>   <em class="jxr_comment">/*</em>
<a name="1183" href="#1183">1183</a> <em class="jxr_comment">   * Gets lowest timestamp from candidate StoreFiles</em>
<a name="1184" href="#1184">1184</a> <em class="jxr_comment">   *</em>
<a name="1185" href="#1185">1185</a> <em class="jxr_comment">   * @param fs</em>
<a name="1186" href="#1186">1186</a> <em class="jxr_comment">   * @param dir</em>
<a name="1187" href="#1187">1187</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="1188" href="#1188">1188</a> <em class="jxr_comment">   */</em>
<a name="1189" href="#1189">1189</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">long</strong> getLowestTimestamp(<strong class="jxr_keyword">final</strong> List&lt;StoreFile&gt; candidates)
<a name="1190" href="#1190">1190</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1191" href="#1191">1191</a>     <strong class="jxr_keyword">long</strong> minTs = Long.MAX_VALUE;
<a name="1192" href="#1192">1192</a>     <strong class="jxr_keyword">for</strong> (StoreFile storeFile : candidates) {
<a name="1193" href="#1193">1193</a>       minTs = Math.min(minTs, storeFile.getModificationTimeStamp());
<a name="1194" href="#1194">1194</a>     }
<a name="1195" href="#1195">1195</a>     <strong class="jxr_keyword">return</strong> minTs;
<a name="1196" href="#1196">1196</a>   }
<a name="1197" href="#1197">1197</a> 
<a name="1198" href="#1198">1198</a>   <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> getter for CompactionProgress object</em>
<a name="1199" href="#1199">1199</a> <em class="jxr_javadoccomment">   * @return CompactionProgress object; can be null</em>
<a name="1200" href="#1200">1200</a> <em class="jxr_javadoccomment">   */</em>
<a name="1201" href="#1201">1201</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionProgress.html">CompactionProgress</a> getCompactionProgress() {
<a name="1202" href="#1202">1202</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.compactor.getProgress();
<a name="1203" href="#1203">1203</a>   }
<a name="1204" href="#1204">1204</a> 
<a name="1205" href="#1205">1205</a>   <em class="jxr_comment">/*</em>
<a name="1206" href="#1206">1206</a> <em class="jxr_comment">   * @return True if we should run a major compaction.</em>
<a name="1207" href="#1207">1207</a> <em class="jxr_comment">   */</em>
<a name="1208" href="#1208">1208</a>   <strong class="jxr_keyword">boolean</strong> isMajorCompaction() <strong class="jxr_keyword">throws</strong> IOException {
<a name="1209" href="#1209">1209</a>     <strong class="jxr_keyword">for</strong> (StoreFile sf : <strong class="jxr_keyword">this</strong>.storefiles) {
<a name="1210" href="#1210">1210</a>       <strong class="jxr_keyword">if</strong> (sf.getReader() == <strong class="jxr_keyword">null</strong>) {
<a name="1211" href="#1211">1211</a>         LOG.debug(<span class="jxr_string">"StoreFile "</span> + sf + <span class="jxr_string">" has null Reader"</span>);
<a name="1212" href="#1212">1212</a>         <strong class="jxr_keyword">return</strong> false;
<a name="1213" href="#1213">1213</a>       }
<a name="1214" href="#1214">1214</a>     }
<a name="1215" href="#1215">1215</a> 
<a name="1216" href="#1216">1216</a>     List&lt;StoreFile&gt; candidates = <strong class="jxr_keyword">new</strong> ArrayList&lt;StoreFile&gt;(<strong class="jxr_keyword">this</strong>.storefiles);
<a name="1217" href="#1217">1217</a> 
<a name="1218" href="#1218">1218</a>     <em class="jxr_comment">// exclude files above the max compaction threshold</em>
<a name="1219" href="#1219">1219</a>     <em class="jxr_comment">// except: save all references. we MUST compact them</em>
<a name="1220" href="#1220">1220</a>     <strong class="jxr_keyword">int</strong> pos = 0;
<a name="1221" href="#1221">1221</a>     <strong class="jxr_keyword">while</strong> (pos &lt; candidates.size() &amp;&amp;
<a name="1222" href="#1222">1222</a>            candidates.get(pos).getReader().length() &gt; <strong class="jxr_keyword">this</strong>.maxCompactSize &amp;&amp;
<a name="1223" href="#1223">1223</a>            !candidates.get(pos).isReference()) ++pos;
<a name="1224" href="#1224">1224</a>     candidates.subList(0, pos).clear();
<a name="1225" href="#1225">1225</a> 
<a name="1226" href="#1226">1226</a>     <strong class="jxr_keyword">return</strong> isMajorCompaction(candidates);
<a name="1227" href="#1227">1227</a>   }
<a name="1228" href="#1228">1228</a> 
<a name="1229" href="#1229">1229</a>   <em class="jxr_comment">/*</em>
<a name="1230" href="#1230">1230</a> <em class="jxr_comment">   * @param filesToCompact Files to compact. Can be null.</em>
<a name="1231" href="#1231">1231</a> <em class="jxr_comment">   * @return True if we should run a major compaction.</em>
<a name="1232" href="#1232">1232</a> <em class="jxr_comment">   */</em>
<a name="1233" href="#1233">1233</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> isMajorCompaction(<strong class="jxr_keyword">final</strong> List&lt;StoreFile&gt; filesToCompact) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1234" href="#1234">1234</a>     <strong class="jxr_keyword">boolean</strong> result = false;
<a name="1235" href="#1235">1235</a>     <strong class="jxr_keyword">long</strong> mcTime = getNextMajorCompactTime();
<a name="1236" href="#1236">1236</a>     <strong class="jxr_keyword">if</strong> (filesToCompact == <strong class="jxr_keyword">null</strong> || filesToCompact.isEmpty() || mcTime == 0) {
<a name="1237" href="#1237">1237</a>       <strong class="jxr_keyword">return</strong> result;
<a name="1238" href="#1238">1238</a>     }
<a name="1239" href="#1239">1239</a>     <em class="jxr_comment">// TODO: Use better method for determining stamp of last major (HBASE-2990)</em>
<a name="1240" href="#1240">1240</a>     <strong class="jxr_keyword">long</strong> lowTimestamp = getLowestTimestamp(filesToCompact);
<a name="1241" href="#1241">1241</a>     <strong class="jxr_keyword">long</strong> now = System.currentTimeMillis();
<a name="1242" href="#1242">1242</a>     <strong class="jxr_keyword">if</strong> (lowTimestamp &gt; 0l &amp;&amp; lowTimestamp &lt; (now - mcTime)) {
<a name="1243" href="#1243">1243</a>       <em class="jxr_comment">// Major compaction time has elapsed.</em>
<a name="1244" href="#1244">1244</a>       <strong class="jxr_keyword">if</strong> (filesToCompact.size() == 1) {
<a name="1245" href="#1245">1245</a>         <em class="jxr_comment">// Single file</em>
<a name="1246" href="#1246">1246</a>         <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> sf = filesToCompact.get(0);
<a name="1247" href="#1247">1247</a>         <strong class="jxr_keyword">long</strong> oldest =
<a name="1248" href="#1248">1248</a>             (sf.getReader().timeRangeTracker == <strong class="jxr_keyword">null</strong>) ?
<a name="1249" href="#1249">1249</a>                 Long.MIN_VALUE :
<a name="1250" href="#1250">1250</a>                 now - sf.getReader().timeRangeTracker.minimumTimestamp;
<a name="1251" href="#1251">1251</a>         <strong class="jxr_keyword">if</strong> (sf.isMajorCompaction() &amp;&amp;
<a name="1252" href="#1252">1252</a>             (<strong class="jxr_keyword">this</strong>.ttl == HConstants.FOREVER || oldest &lt; <strong class="jxr_keyword">this</strong>.ttl)) {
<a name="1253" href="#1253">1253</a>           <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="1254" href="#1254">1254</a>             LOG.debug(<span class="jxr_string">"Skipping major compaction of "</span> + <strong class="jxr_keyword">this</strong> +
<a name="1255" href="#1255">1255</a>                 <span class="jxr_string">" because one (major) compacted file only and oldestTime "</span> +
<a name="1256" href="#1256">1256</a>                 oldest + <span class="jxr_string">"ms is &lt; ttl="</span> + <strong class="jxr_keyword">this</strong>.ttl);
<a name="1257" href="#1257">1257</a>           }
<a name="1258" href="#1258">1258</a>         } <strong class="jxr_keyword">else</strong> <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.ttl != HConstants.FOREVER &amp;&amp; oldest &gt; <strong class="jxr_keyword">this</strong>.ttl) {
<a name="1259" href="#1259">1259</a>           LOG.debug(<span class="jxr_string">"Major compaction triggered on store "</span> + <strong class="jxr_keyword">this</strong> +
<a name="1260" href="#1260">1260</a>             <span class="jxr_string">", because keyvalues outdated; time since last major compaction "</span> +
<a name="1261" href="#1261">1261</a>             (now - lowTimestamp) + <span class="jxr_string">"ms"</span>);
<a name="1262" href="#1262">1262</a>           result = <strong class="jxr_keyword">true</strong>;
<a name="1263" href="#1263">1263</a>         }
<a name="1264" href="#1264">1264</a>       } <strong class="jxr_keyword">else</strong> {
<a name="1265" href="#1265">1265</a>         <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="1266" href="#1266">1266</a>           LOG.debug(<span class="jxr_string">"Major compaction triggered on store "</span> + <strong class="jxr_keyword">this</strong> +
<a name="1267" href="#1267">1267</a>               <span class="jxr_string">"; time since last major compaction "</span> + (now - lowTimestamp) + <span class="jxr_string">"ms"</span>);
<a name="1268" href="#1268">1268</a>         }
<a name="1269" href="#1269">1269</a>         result = <strong class="jxr_keyword">true</strong>;
<a name="1270" href="#1270">1270</a>       }
<a name="1271" href="#1271">1271</a>     }
<a name="1272" href="#1272">1272</a>     <strong class="jxr_keyword">return</strong> result;
<a name="1273" href="#1273">1273</a>   }
<a name="1274" href="#1274">1274</a> 
<a name="1275" href="#1275">1275</a>   <strong class="jxr_keyword">long</strong> getNextMajorCompactTime() {
<a name="1276" href="#1276">1276</a>     <em class="jxr_comment">// default = 24hrs</em>
<a name="1277" href="#1277">1277</a>     <strong class="jxr_keyword">long</strong> ret = conf.getLong(HConstants.MAJOR_COMPACTION_PERIOD, 1000*60*60*24);
<a name="1278" href="#1278">1278</a>     <strong class="jxr_keyword">if</strong> (family.getValue(HConstants.MAJOR_COMPACTION_PERIOD) != <strong class="jxr_keyword">null</strong>) {
<a name="1279" href="#1279">1279</a>       String strCompactionTime =
<a name="1280" href="#1280">1280</a>         family.getValue(HConstants.MAJOR_COMPACTION_PERIOD);
<a name="1281" href="#1281">1281</a>       ret = (<strong class="jxr_keyword">new</strong> Long(strCompactionTime)).longValue();
<a name="1282" href="#1282">1282</a>     }
<a name="1283" href="#1283">1283</a> 
<a name="1284" href="#1284">1284</a>     <strong class="jxr_keyword">if</strong> (ret &gt; 0) {
<a name="1285" href="#1285">1285</a>       <em class="jxr_comment">// default = 20% = +/- 4.8 hrs</em>
<a name="1286" href="#1286">1286</a>       <strong class="jxr_keyword">double</strong> jitterPct =  conf.getFloat(<span class="jxr_string">"hbase.hregion.majorcompaction.jitter"</span>,
<a name="1287" href="#1287">1287</a>           0.20F);
<a name="1288" href="#1288">1288</a>       <strong class="jxr_keyword">if</strong> (jitterPct &gt; 0) {
<a name="1289" href="#1289">1289</a>         <strong class="jxr_keyword">long</strong> jitter = Math.round(ret * jitterPct);
<a name="1290" href="#1290">1290</a>         <em class="jxr_comment">// deterministic jitter avoids a major compaction storm on restart</em>
<a name="1291" href="#1291">1291</a>         ImmutableList&lt;StoreFile&gt; snapshot = storefiles;
<a name="1292" href="#1292">1292</a>         <strong class="jxr_keyword">if</strong> (snapshot != <strong class="jxr_keyword">null</strong> &amp;&amp; !snapshot.isEmpty()) {
<a name="1293" href="#1293">1293</a>           String seed = snapshot.get(0).getPath().getName();
<a name="1294" href="#1294">1294</a>           <strong class="jxr_keyword">double</strong> curRand = <strong class="jxr_keyword">new</strong> Random(seed.hashCode()).nextDouble();
<a name="1295" href="#1295">1295</a>           ret += jitter - Math.round(2L * jitter * curRand);
<a name="1296" href="#1296">1296</a>         } <strong class="jxr_keyword">else</strong> {
<a name="1297" href="#1297">1297</a>           ret = 0; <em class="jxr_comment">// no storefiles == no major compaction</em>
<a name="1298" href="#1298">1298</a>         }
<a name="1299" href="#1299">1299</a>       }
<a name="1300" href="#1300">1300</a>     }
<a name="1301" href="#1301">1301</a>     <strong class="jxr_keyword">return</strong> ret;
<a name="1302" href="#1302">1302</a>   }
<a name="1303" href="#1303">1303</a> 
<a name="1304" href="#1304">1304</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a> requestCompaction() <strong class="jxr_keyword">throws</strong> IOException {
<a name="1305" href="#1305">1305</a>     <strong class="jxr_keyword">return</strong> requestCompaction(NO_PRIORITY, <strong class="jxr_keyword">null</strong>);
<a name="1306" href="#1306">1306</a>   }
<a name="1307" href="#1307">1307</a> 
<a name="1308" href="#1308">1308</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a> requestCompaction(<strong class="jxr_keyword">int</strong> priority, <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a> request)
<a name="1309" href="#1309">1309</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1310" href="#1310">1310</a>     <em class="jxr_comment">// don't even select for compaction if writes are disabled</em>
<a name="1311" href="#1311">1311</a>     <strong class="jxr_keyword">if</strong> (!<strong class="jxr_keyword">this</strong>.region.areWritesEnabled()) {
<a name="1312" href="#1312">1312</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1313" href="#1313">1313</a>     }
<a name="1314" href="#1314">1314</a> 
<a name="1315" href="#1315">1315</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="1316" href="#1316">1316</a>     <strong class="jxr_keyword">try</strong> {
<a name="1317" href="#1317">1317</a>       <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1318" href="#1318">1318</a>         <em class="jxr_comment">// candidates = all storefiles not already in compaction queue</em>
<a name="1319" href="#1319">1319</a>         List&lt;StoreFile&gt; candidates = Lists.newArrayList(storefiles);
<a name="1320" href="#1320">1320</a>         <strong class="jxr_keyword">if</strong> (!filesCompacting.isEmpty()) {
<a name="1321" href="#1321">1321</a>           <em class="jxr_comment">// exclude all files older than the newest file we're currently</em>
<a name="1322" href="#1322">1322</a>           <em class="jxr_comment">// compacting. this allows us to preserve contiguity (HBASE-2856)</em>
<a name="1323" href="#1323">1323</a>           <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> last = filesCompacting.get(filesCompacting.size() - 1);
<a name="1324" href="#1324">1324</a>           <strong class="jxr_keyword">int</strong> idx = candidates.indexOf(last);
<a name="1325" href="#1325">1325</a>           Preconditions.checkArgument(idx != -1);
<a name="1326" href="#1326">1326</a>           candidates.subList(0, idx + 1).clear();
<a name="1327" href="#1327">1327</a>         }
<a name="1328" href="#1328">1328</a> 
<a name="1329" href="#1329">1329</a>         <strong class="jxr_keyword">boolean</strong> override = false;
<a name="1330" href="#1330">1330</a>         <strong class="jxr_keyword">if</strong> (region.getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="1331" href="#1331">1331</a>           override = region.getCoprocessorHost().preCompactSelection(<strong class="jxr_keyword">this</strong>, candidates, request);
<a name="1332" href="#1332">1332</a>         }
<a name="1333" href="#1333">1333</a>         <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a> filesToCompact;
<a name="1334" href="#1334">1334</a>         <strong class="jxr_keyword">if</strong> (override) {
<a name="1335" href="#1335">1335</a>           <em class="jxr_comment">// coprocessor is overriding normal file selection</em>
<a name="1336" href="#1336">1336</a>           filesToCompact = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a>(conf, candidates);
<a name="1337" href="#1337">1337</a>         } <strong class="jxr_keyword">else</strong> {
<a name="1338" href="#1338">1338</a>           filesToCompact = compactSelection(candidates, priority);
<a name="1339" href="#1339">1339</a>         }
<a name="1340" href="#1340">1340</a> 
<a name="1341" href="#1341">1341</a>         <strong class="jxr_keyword">if</strong> (region.getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="1342" href="#1342">1342</a>           region.getCoprocessorHost().postCompactSelection(<strong class="jxr_keyword">this</strong>,
<a name="1343" href="#1343">1343</a>             ImmutableList.copyOf(filesToCompact.getFilesToCompact()), request);
<a name="1344" href="#1344">1344</a>         }
<a name="1345" href="#1345">1345</a> 
<a name="1346" href="#1346">1346</a>         <em class="jxr_comment">// no files to compact</em>
<a name="1347" href="#1347">1347</a>         <strong class="jxr_keyword">if</strong> (filesToCompact.getFilesToCompact().isEmpty()) {
<a name="1348" href="#1348">1348</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1349" href="#1349">1349</a>         }
<a name="1350" href="#1350">1350</a> 
<a name="1351" href="#1351">1351</a>         <em class="jxr_comment">// basic sanity check: do not try to compact the same StoreFile twice.</em>
<a name="1352" href="#1352">1352</a>         <strong class="jxr_keyword">if</strong> (!Collections.disjoint(filesCompacting, filesToCompact.getFilesToCompact())) {
<a name="1353" href="#1353">1353</a>           <em class="jxr_comment">// TODO: change this from an IAE to LOG.error after sufficient testing</em>
<a name="1354" href="#1354">1354</a>           Preconditions.checkArgument(false, <span class="jxr_string">"%s overlaps with %s"</span>,
<a name="1355" href="#1355">1355</a>               filesToCompact, filesCompacting);
<a name="1356" href="#1356">1356</a>         }
<a name="1357" href="#1357">1357</a>         filesCompacting.addAll(filesToCompact.getFilesToCompact());
<a name="1358" href="#1358">1358</a>         Collections.sort(filesCompacting, StoreFile.Comparators.FLUSH_TIME);
<a name="1359" href="#1359">1359</a> 
<a name="1360" href="#1360">1360</a>         <em class="jxr_comment">// major compaction iff all StoreFiles are included</em>
<a name="1361" href="#1361">1361</a>         <strong class="jxr_keyword">boolean</strong> isMajor = (filesToCompact.getFilesToCompact().size() == <strong class="jxr_keyword">this</strong>.storefiles.size());
<a name="1362" href="#1362">1362</a>         <strong class="jxr_keyword">if</strong> (isMajor) {
<a name="1363" href="#1363">1363</a>           <em class="jxr_comment">// since we're enqueuing a major, update the compaction wait interval</em>
<a name="1364" href="#1364">1364</a>           <strong class="jxr_keyword">this</strong>.forceMajor = false;
<a name="1365" href="#1365">1365</a>         }
<a name="1366" href="#1366">1366</a> 
<a name="1367" href="#1367">1367</a>         <em class="jxr_comment">// everything went better than expected. create a compaction request</em>
<a name="1368" href="#1368">1368</a>         <strong class="jxr_keyword">int</strong> pri = getCompactPriority(priority);
<a name="1369" href="#1369">1369</a>         <em class="jxr_comment">//not a special compaction request, so we need to make one</em>
<a name="1370" href="#1370">1370</a>         <strong class="jxr_keyword">if</strong>(request == <strong class="jxr_keyword">null</strong>){
<a name="1371" href="#1371">1371</a>           request = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a>(region, <strong class="jxr_keyword">this</strong>, filesToCompact, isMajor, pri);
<a name="1372" href="#1372">1372</a>         } <strong class="jxr_keyword">else</strong> {
<a name="1373" href="#1373">1373</a>           <em class="jxr_comment">// update the request with what the system thinks the request should be</em>
<a name="1374" href="#1374">1374</a>           <em class="jxr_comment">// its up to the request if it wants to listen</em>
<a name="1375" href="#1375">1375</a>           request.setSelection(filesToCompact);
<a name="1376" href="#1376">1376</a>           request.setIsMajor(isMajor);
<a name="1377" href="#1377">1377</a>           request.setPriority(pri);
<a name="1378" href="#1378">1378</a>         }
<a name="1379" href="#1379">1379</a>       }
<a name="1380" href="#1380">1380</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1381" href="#1381">1381</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1382" href="#1382">1382</a>     }
<a name="1383" href="#1383">1383</a>     <strong class="jxr_keyword">if</strong> (request != <strong class="jxr_keyword">null</strong>) {
<a name="1384" href="#1384">1384</a>       CompactionRequest.preRequest(request);
<a name="1385" href="#1385">1385</a>     }
<a name="1386" href="#1386">1386</a>     <strong class="jxr_keyword">return</strong> request;
<a name="1387" href="#1387">1387</a>   }
<a name="1388" href="#1388">1388</a> 
<a name="1389" href="#1389">1389</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> finishRequest(<a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.html">CompactionRequest</a> cr) {
<a name="1390" href="#1390">1390</a>     CompactionRequest.postRequest(cr);
<a name="1391" href="#1391">1391</a>     cr.finishRequest();
<a name="1392" href="#1392">1392</a>     <strong class="jxr_keyword">synchronized</strong> (filesCompacting) {
<a name="1393" href="#1393">1393</a>       filesCompacting.removeAll(cr.getFiles());
<a name="1394" href="#1394">1394</a>     }
<a name="1395" href="#1395">1395</a>   }
<a name="1396" href="#1396">1396</a> 
<a name="1397" href="#1397">1397</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1398" href="#1398">1398</a> <em class="jxr_javadoccomment">   * Algorithm to choose which files to compact, see {@link #compactSelection(java.util.List, int)}</em>
<a name="1399" href="#1399">1399</a> <em class="jxr_javadoccomment">   * @param candidates</em>
<a name="1400" href="#1400">1400</a> <em class="jxr_javadoccomment">   * @return</em>
<a name="1401" href="#1401">1401</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="1402" href="#1402">1402</a> <em class="jxr_javadoccomment">   */</em>
<a name="1403" href="#1403">1403</a>   <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a> compactSelection(List&lt;StoreFile&gt; candidates) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1404" href="#1404">1404</a>     <strong class="jxr_keyword">return</strong> compactSelection(candidates,NO_PRIORITY);
<a name="1405" href="#1405">1405</a>   }
<a name="1406" href="#1406">1406</a> 
<a name="1407" href="#1407">1407</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1408" href="#1408">1408</a> <em class="jxr_javadoccomment">   * Algorithm to choose which files to compact</em>
<a name="1409" href="#1409">1409</a> <em class="jxr_javadoccomment">   *</em>
<a name="1410" href="#1410">1410</a> <em class="jxr_javadoccomment">   * Configuration knobs:</em>
<a name="1411" href="#1411">1411</a> <em class="jxr_javadoccomment">   *  "hbase.hstore.compaction.ratio"</em>
<a name="1412" href="#1412">1412</a> <em class="jxr_javadoccomment">   *    normal case: minor compact when file &lt;= sum(smaller_files) * ratio</em>
<a name="1413" href="#1413">1413</a> <em class="jxr_javadoccomment">   *  "hbase.hstore.compaction.min.size"</em>
<a name="1414" href="#1414">1414</a> <em class="jxr_javadoccomment">   *    unconditionally compact individual files below this size</em>
<a name="1415" href="#1415">1415</a> <em class="jxr_javadoccomment">   *  "hbase.hstore.compaction.max.size"</em>
<a name="1416" href="#1416">1416</a> <em class="jxr_javadoccomment">   *    never compact individual files above this size (unless splitting)</em>
<a name="1417" href="#1417">1417</a> <em class="jxr_javadoccomment">   *  "hbase.hstore.compaction.min"</em>
<a name="1418" href="#1418">1418</a> <em class="jxr_javadoccomment">   *    min files needed to minor compact</em>
<a name="1419" href="#1419">1419</a> <em class="jxr_javadoccomment">   *  "hbase.hstore.compaction.max"</em>
<a name="1420" href="#1420">1420</a> <em class="jxr_javadoccomment">   *    max files to compact at once (avoids OOM)</em>
<a name="1421" href="#1421">1421</a> <em class="jxr_javadoccomment">   *</em>
<a name="1422" href="#1422">1422</a> <em class="jxr_javadoccomment">   * @param candidates candidate files, ordered from oldest to newest</em>
<a name="1423" href="#1423">1423</a> <em class="jxr_javadoccomment">   * @return subset copy of candidate list that meets compaction criteria</em>
<a name="1424" href="#1424">1424</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="1425" href="#1425">1425</a> <em class="jxr_javadoccomment">   */</em>
<a name="1426" href="#1426">1426</a>   <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a> compactSelection(List&lt;StoreFile&gt; candidates, <strong class="jxr_keyword">int</strong> priority)
<a name="1427" href="#1427">1427</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1428" href="#1428">1428</a>     <em class="jxr_comment">// ASSUMPTION!!! filesCompacting is locked when calling this function</em>
<a name="1429" href="#1429">1429</a> 
<a name="1430" href="#1430">1430</a>     <em class="jxr_comment">/*<em class="jxr_comment"> normal skew:</em></em>
<a name="1431" href="#1431">1431</a> <em class="jxr_comment">     *</em>
<a name="1432" href="#1432">1432</a> <em class="jxr_comment">     *         older ----&gt; newer</em>
<a name="1433" href="#1433">1433</a> <em class="jxr_comment">     *     _</em>
<a name="1434" href="#1434">1434</a> <em class="jxr_comment">     *    | |   _</em>
<a name="1435" href="#1435">1435</a> <em class="jxr_comment">     *    | |  | |   _</em>
<a name="1436" href="#1436">1436</a> <em class="jxr_comment">     *  --|-|- |-|- |-|---_-------_-------  minCompactSize</em>
<a name="1437" href="#1437">1437</a> <em class="jxr_comment">     *    | |  | |  | |  | |  _  | |</em>
<a name="1438" href="#1438">1438</a> <em class="jxr_comment">     *    | |  | |  | |  | | | | | |</em>
<a name="1439" href="#1439">1439</a> <em class="jxr_comment">     *    | |  | |  | |  | | | | | |</em>
<a name="1440" href="#1440">1440</a> <em class="jxr_comment">     */</em>
<a name="1441" href="#1441">1441</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a> compactSelection = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a>(conf, candidates);
<a name="1442" href="#1442">1442</a> 
<a name="1443" href="#1443">1443</a>     <strong class="jxr_keyword">boolean</strong> forcemajor = <strong class="jxr_keyword">this</strong>.forceMajor &amp;&amp; filesCompacting.isEmpty();
<a name="1444" href="#1444">1444</a>     <strong class="jxr_keyword">if</strong> (!forcemajor) {
<a name="1445" href="#1445">1445</a>       <em class="jxr_comment">// Delete the expired store files before the compaction selection.</em>
<a name="1446" href="#1446">1446</a>       <strong class="jxr_keyword">if</strong> (conf.getBoolean(<span class="jxr_string">"hbase.store.delete.expired.storefile"</span>, <strong class="jxr_keyword">true</strong>)
<a name="1447" href="#1447">1447</a>           &amp;&amp; (ttl != Long.MAX_VALUE) &amp;&amp; (<strong class="jxr_keyword">this</strong>.scanInfo.minVersions == 0)) {
<a name="1448" href="#1448">1448</a>         <a href="../../../../../org/apache/hadoop/hbase/regionserver/compactions/CompactSelection.html">CompactSelection</a> expiredSelection = compactSelection
<a name="1449" href="#1449">1449</a>             .selectExpiredStoreFilesToCompact(
<a name="1450" href="#1450">1450</a>                 EnvironmentEdgeManager.currentTimeMillis() - <strong class="jxr_keyword">this</strong>.ttl);
<a name="1451" href="#1451">1451</a> 
<a name="1452" href="#1452">1452</a>         <em class="jxr_comment">// If there is any expired store files, delete them  by compaction.</em>
<a name="1453" href="#1453">1453</a>         <strong class="jxr_keyword">if</strong> (expiredSelection != <strong class="jxr_keyword">null</strong>) {
<a name="1454" href="#1454">1454</a>           <strong class="jxr_keyword">return</strong> expiredSelection;
<a name="1455" href="#1455">1455</a>         }
<a name="1456" href="#1456">1456</a>       }
<a name="1457" href="#1457">1457</a>       <em class="jxr_comment">// do not compact old files above a configurable threshold</em>
<a name="1458" href="#1458">1458</a>       <em class="jxr_comment">// save all references. we MUST compact them</em>
<a name="1459" href="#1459">1459</a>       <strong class="jxr_keyword">int</strong> pos = 0;
<a name="1460" href="#1460">1460</a>       <strong class="jxr_keyword">while</strong> (pos &lt; compactSelection.getFilesToCompact().size() &amp;&amp;
<a name="1461" href="#1461">1461</a>              compactSelection.getFilesToCompact().get(pos).getReader().length()
<a name="1462" href="#1462">1462</a>                &gt; maxCompactSize &amp;&amp;
<a name="1463" href="#1463">1463</a>              !compactSelection.getFilesToCompact().get(pos).isReference()) ++pos;
<a name="1464" href="#1464">1464</a>       <strong class="jxr_keyword">if</strong> (pos != 0) compactSelection.clearSubList(0, pos);
<a name="1465" href="#1465">1465</a>     }
<a name="1466" href="#1466">1466</a> 
<a name="1467" href="#1467">1467</a>     <strong class="jxr_keyword">if</strong> (compactSelection.getFilesToCompact().isEmpty()) {
<a name="1468" href="#1468">1468</a>       LOG.debug(<strong class="jxr_keyword">this</strong>.getHRegionInfo().getEncodedName() + <span class="jxr_string">" - "</span> +
<a name="1469" href="#1469">1469</a>         <strong class="jxr_keyword">this</strong> + <span class="jxr_string">": no store files to compact"</span>);
<a name="1470" href="#1470">1470</a>       compactSelection.emptyFileList();
<a name="1471" href="#1471">1471</a>       <strong class="jxr_keyword">return</strong> compactSelection;
<a name="1472" href="#1472">1472</a>     }
<a name="1473" href="#1473">1473</a> 
<a name="1474" href="#1474">1474</a>     <em class="jxr_comment">// Force a major compaction if this is a user-requested major compaction,</em>
<a name="1475" href="#1475">1475</a>     <em class="jxr_comment">// or if we do not have too many files to compact and this was requested</em>
<a name="1476" href="#1476">1476</a>     <em class="jxr_comment">// as a major compaction</em>
<a name="1477" href="#1477">1477</a>     <strong class="jxr_keyword">boolean</strong> majorcompaction = (forcemajor &amp;&amp; priority == PRIORITY_USER) ||
<a name="1478" href="#1478">1478</a>       (forcemajor || isMajorCompaction(compactSelection.getFilesToCompact())) &amp;&amp;
<a name="1479" href="#1479">1479</a>       (compactSelection.getFilesToCompact().size() &lt; <strong class="jxr_keyword">this</strong>.maxFilesToCompact
<a name="1480" href="#1480">1480</a>     );
<a name="1481" href="#1481">1481</a>     LOG.debug(<strong class="jxr_keyword">this</strong>.getHRegionInfo().getEncodedName() + <span class="jxr_string">" - "</span> +
<a name="1482" href="#1482">1482</a>       <strong class="jxr_keyword">this</strong>.getColumnFamilyName() + <span class="jxr_string">": Initiating "</span> +
<a name="1483" href="#1483">1483</a>       (majorcompaction ? <span class="jxr_string">"major"</span> : <span class="jxr_string">"minor"</span>) + <span class="jxr_string">"compaction"</span>);
<a name="1484" href="#1484">1484</a> 
<a name="1485" href="#1485">1485</a>     <strong class="jxr_keyword">if</strong> (!majorcompaction &amp;&amp;
<a name="1486" href="#1486">1486</a>         !hasReferences(compactSelection.getFilesToCompact())) {
<a name="1487" href="#1487">1487</a>       <em class="jxr_comment">// we're doing a minor compaction, let's see what files are applicable</em>
<a name="1488" href="#1488">1488</a>       <strong class="jxr_keyword">int</strong> start = 0;
<a name="1489" href="#1489">1489</a>       <strong class="jxr_keyword">double</strong> r = compactSelection.getCompactSelectionRatio();
<a name="1490" href="#1490">1490</a> 
<a name="1491" href="#1491">1491</a>       <em class="jxr_comment">// remove bulk import files that request to be excluded from minors</em>
<a name="1492" href="#1492">1492</a>       compactSelection.getFilesToCompact().removeAll(Collections2.filter(
<a name="1493" href="#1493">1493</a>           compactSelection.getFilesToCompact(),
<a name="1494" href="#1494">1494</a>           <strong class="jxr_keyword">new</strong> Predicate&lt;StoreFile&gt;() {
<a name="1495" href="#1495">1495</a>             <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> apply(<a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> input) {
<a name="1496" href="#1496">1496</a>               <strong class="jxr_keyword">return</strong> input.excludeFromMinorCompaction();
<a name="1497" href="#1497">1497</a>             }
<a name="1498" href="#1498">1498</a>           }));
<a name="1499" href="#1499">1499</a> 
<a name="1500" href="#1500">1500</a>       <em class="jxr_comment">// skip selection algorithm if we don't have enough files</em>
<a name="1501" href="#1501">1501</a>       <strong class="jxr_keyword">if</strong> (compactSelection.getFilesToCompact().size() &lt; <strong class="jxr_keyword">this</strong>.minFilesToCompact) {
<a name="1502" href="#1502">1502</a>         <strong class="jxr_keyword">if</strong>(LOG.isDebugEnabled()) {
<a name="1503" href="#1503">1503</a>           LOG.debug(<span class="jxr_string">"Not compacting files because we only have "</span> +
<a name="1504" href="#1504">1504</a>             compactSelection.getFilesToCompact().size() +
<a name="1505" href="#1505">1505</a>             <span class="jxr_string">" files ready for compaction.  Need "</span> + <strong class="jxr_keyword">this</strong>.minFilesToCompact + <span class="jxr_string">" to initiate."</span>);
<a name="1506" href="#1506">1506</a>         }
<a name="1507" href="#1507">1507</a>         compactSelection.emptyFileList();
<a name="1508" href="#1508">1508</a>         <strong class="jxr_keyword">return</strong> compactSelection;
<a name="1509" href="#1509">1509</a>       }
<a name="1510" href="#1510">1510</a> 
<a name="1511" href="#1511">1511</a>       <em class="jxr_comment">/*<em class="jxr_comment"> TODO: add sorting + unit test back in when HBASE-2856 is fixed</em></em>
<a name="1512" href="#1512">1512</a> <em class="jxr_comment">      // Sort files by size to correct when normal skew is altered by bulk load.</em>
<a name="1513" href="#1513">1513</a> <em class="jxr_comment">      Collections.sort(filesToCompact, StoreFile.Comparators.FILE_SIZE);</em>
<a name="1514" href="#1514">1514</a> <em class="jxr_comment">       */</em>
<a name="1515" href="#1515">1515</a> 
<a name="1516" href="#1516">1516</a>       <em class="jxr_comment">// get store file sizes for incremental compacting selection.</em>
<a name="1517" href="#1517">1517</a>       <strong class="jxr_keyword">int</strong> countOfFiles = compactSelection.getFilesToCompact().size();
<a name="1518" href="#1518">1518</a>       <strong class="jxr_keyword">long</strong> [] fileSizes = <strong class="jxr_keyword">new</strong> <strong class="jxr_keyword">long</strong>[countOfFiles];
<a name="1519" href="#1519">1519</a>       <strong class="jxr_keyword">long</strong> [] sumSize = <strong class="jxr_keyword">new</strong> <strong class="jxr_keyword">long</strong>[countOfFiles];
<a name="1520" href="#1520">1520</a>       <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = countOfFiles-1; i &gt;= 0; --i) {
<a name="1521" href="#1521">1521</a>         <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> file = compactSelection.getFilesToCompact().get(i);
<a name="1522" href="#1522">1522</a>         fileSizes[i] = file.getReader().length();
<a name="1523" href="#1523">1523</a>         <em class="jxr_comment">// calculate the sum of fileSizes[i,i+maxFilesToCompact-1) for algo</em>
<a name="1524" href="#1524">1524</a>         <strong class="jxr_keyword">int</strong> tooFar = i + <strong class="jxr_keyword">this</strong>.maxFilesToCompact - 1;
<a name="1525" href="#1525">1525</a>         sumSize[i] = fileSizes[i]
<a name="1526" href="#1526">1526</a>                    + ((i+1    &lt; countOfFiles) ? sumSize[i+1]      : 0)
<a name="1527" href="#1527">1527</a>                    - ((tooFar &lt; countOfFiles) ? fileSizes[tooFar] : 0);
<a name="1528" href="#1528">1528</a>       }
<a name="1529" href="#1529">1529</a> 
<a name="1530" href="#1530">1530</a>       <em class="jxr_comment">/*<em class="jxr_comment"> Start at the oldest file and stop when you find the first file that</em></em>
<a name="1531" href="#1531">1531</a> <em class="jxr_comment">       * meets compaction criteria:</em>
<a name="1532" href="#1532">1532</a> <em class="jxr_comment">       *   (1) a recently-flushed, small file (i.e. &lt;= minCompactSize)</em>
<a name="1533" href="#1533">1533</a> <em class="jxr_comment">       *      OR</em>
<a name="1534" href="#1534">1534</a> <em class="jxr_comment">       *   (2) within the compactRatio of sum(newer_files)</em>
<a name="1535" href="#1535">1535</a> <em class="jxr_comment">       * Given normal skew, any newer files will also meet this criteria</em>
<a name="1536" href="#1536">1536</a> <em class="jxr_comment">       *</em>
<a name="1537" href="#1537">1537</a> <em class="jxr_comment">       * Additional Note:</em>
<a name="1538" href="#1538">1538</a> <em class="jxr_comment">       * If fileSizes.size() &gt;&gt; maxFilesToCompact, we will recurse on</em>
<a name="1539" href="#1539">1539</a> <em class="jxr_comment">       * compact().  Consider the oldest files first to avoid a</em>
<a name="1540" href="#1540">1540</a> <em class="jxr_comment">       * situation where we always compact [end-threshold,end).  Then, the</em>
<a name="1541" href="#1541">1541</a> <em class="jxr_comment">       * last file becomes an aggregate of the previous compactions.</em>
<a name="1542" href="#1542">1542</a> <em class="jxr_comment">       */</em>
<a name="1543" href="#1543">1543</a>       <strong class="jxr_keyword">while</strong>(countOfFiles - start &gt;= <strong class="jxr_keyword">this</strong>.minFilesToCompact &amp;&amp;
<a name="1544" href="#1544">1544</a>             fileSizes[start] &gt;
<a name="1545" href="#1545">1545</a>               Math.max(minCompactSize, (<strong class="jxr_keyword">long</strong>)(sumSize[start+1] * r))) {
<a name="1546" href="#1546">1546</a>         ++start;
<a name="1547" href="#1547">1547</a>       }
<a name="1548" href="#1548">1548</a>       <strong class="jxr_keyword">int</strong> end = Math.min(countOfFiles, start + <strong class="jxr_keyword">this</strong>.maxFilesToCompact);
<a name="1549" href="#1549">1549</a>       <strong class="jxr_keyword">long</strong> totalSize = fileSizes[start]
<a name="1550" href="#1550">1550</a>                      + ((start+1 &lt; countOfFiles) ? sumSize[start+1] : 0);
<a name="1551" href="#1551">1551</a>       compactSelection = compactSelection.getSubList(start, end);
<a name="1552" href="#1552">1552</a> 
<a name="1553" href="#1553">1553</a>       <em class="jxr_comment">// if we don't have enough files to compact, just wait</em>
<a name="1554" href="#1554">1554</a>       <strong class="jxr_keyword">if</strong> (compactSelection.getFilesToCompact().size() &lt; <strong class="jxr_keyword">this</strong>.minFilesToCompact) {
<a name="1555" href="#1555">1555</a>         <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="1556" href="#1556">1556</a>           LOG.debug(<span class="jxr_string">"Skipped compaction of "</span> + <strong class="jxr_keyword">this</strong>
<a name="1557" href="#1557">1557</a>             + <span class="jxr_string">".  Only "</span> + (end - start) + <span class="jxr_string">" file(s) of size "</span>
<a name="1558" href="#1558">1558</a>             + StringUtils.humanReadableInt(totalSize)
<a name="1559" href="#1559">1559</a>             + <span class="jxr_string">" have met compaction criteria."</span>);
<a name="1560" href="#1560">1560</a>         }
<a name="1561" href="#1561">1561</a>         compactSelection.emptyFileList();
<a name="1562" href="#1562">1562</a>         <strong class="jxr_keyword">return</strong> compactSelection;
<a name="1563" href="#1563">1563</a>       }
<a name="1564" href="#1564">1564</a>     } <strong class="jxr_keyword">else</strong> {
<a name="1565" href="#1565">1565</a>       <strong class="jxr_keyword">if</strong>(majorcompaction) {
<a name="1566" href="#1566">1566</a>         <strong class="jxr_keyword">if</strong> (compactSelection.getFilesToCompact().size() &gt; <strong class="jxr_keyword">this</strong>.maxFilesToCompact) {
<a name="1567" href="#1567">1567</a>           LOG.debug(<span class="jxr_string">"Warning, compacting more than "</span> + <strong class="jxr_keyword">this</strong>.maxFilesToCompact +
<a name="1568" href="#1568">1568</a>             <span class="jxr_string">" files, probably because of a user-requested major compaction"</span>);
<a name="1569" href="#1569">1569</a>           <strong class="jxr_keyword">if</strong>(priority != PRIORITY_USER) {
<a name="1570" href="#1570">1570</a>             LOG.error(<span class="jxr_string">"Compacting more than max files on a non user-requested compaction"</span>);
<a name="1571" href="#1571">1571</a>           }
<a name="1572" href="#1572">1572</a>         }
<a name="1573" href="#1573">1573</a>       } <strong class="jxr_keyword">else</strong> <strong class="jxr_keyword">if</strong> (compactSelection.getFilesToCompact().size() &gt; <strong class="jxr_keyword">this</strong>.maxFilesToCompact) {
<a name="1574" href="#1574">1574</a>         <em class="jxr_comment">// all files included in this compaction, up to max</em>
<a name="1575" href="#1575">1575</a>         <strong class="jxr_keyword">int</strong> pastMax = compactSelection.getFilesToCompact().size() - <strong class="jxr_keyword">this</strong>.maxFilesToCompact;
<a name="1576" href="#1576">1576</a>         compactSelection.getFilesToCompact().subList(0, pastMax).clear();
<a name="1577" href="#1577">1577</a>       }
<a name="1578" href="#1578">1578</a>     }
<a name="1579" href="#1579">1579</a>     <strong class="jxr_keyword">return</strong> compactSelection;
<a name="1580" href="#1580">1580</a>   }
<a name="1581" href="#1581">1581</a> 
<a name="1582" href="#1582">1582</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1583" href="#1583">1583</a> <em class="jxr_javadoccomment">   * Validates a store file by opening and closing it. In HFileV2 this should</em>
<a name="1584" href="#1584">1584</a> <em class="jxr_javadoccomment">   * not be an expensive operation.</em>
<a name="1585" href="#1585">1585</a> <em class="jxr_javadoccomment">   *</em>
<a name="1586" href="#1586">1586</a> <em class="jxr_javadoccomment">   * @param path the path to the store file</em>
<a name="1587" href="#1587">1587</a> <em class="jxr_javadoccomment">   */</em>
<a name="1588" href="#1588">1588</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> validateStoreFile(Path path)
<a name="1589" href="#1589">1589</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1590" href="#1590">1590</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> storeFile = <strong class="jxr_keyword">null</strong>;
<a name="1591" href="#1591">1591</a>     <strong class="jxr_keyword">try</strong> {
<a name="1592" href="#1592">1592</a>       storeFile = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(<strong class="jxr_keyword">this</strong>.fs, path, <strong class="jxr_keyword">this</strong>.conf,
<a name="1593" href="#1593">1593</a>           <strong class="jxr_keyword">this</strong>.cacheConf, <strong class="jxr_keyword">this</strong>.family.getBloomFilterType(),
<a name="1594" href="#1594">1594</a>           NoOpDataBlockEncoder.INSTANCE);
<a name="1595" href="#1595">1595</a>       passSchemaMetricsTo(storeFile);
<a name="1596" href="#1596">1596</a>       storeFile.createReader();
<a name="1597" href="#1597">1597</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="1598" href="#1598">1598</a>       LOG.error(<span class="jxr_string">"Failed to open store file : "</span> + path
<a name="1599" href="#1599">1599</a>           + <span class="jxr_string">", keeping it in tmp location"</span>, e);
<a name="1600" href="#1600">1600</a>       <strong class="jxr_keyword">throw</strong> e;
<a name="1601" href="#1601">1601</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1602" href="#1602">1602</a>       <strong class="jxr_keyword">if</strong> (storeFile != <strong class="jxr_keyword">null</strong>) {
<a name="1603" href="#1603">1603</a>         storeFile.closeReader(false);
<a name="1604" href="#1604">1604</a>       }
<a name="1605" href="#1605">1605</a>     }
<a name="1606" href="#1606">1606</a>   }
<a name="1607" href="#1607">1607</a> 
<a name="1608" href="#1608">1608</a>   <em class="jxr_comment">/*</em>
<a name="1609" href="#1609">1609</a> <em class="jxr_comment">   * &lt;p&gt;It works by processing a compaction that's been written to disk.</em>
<a name="1610" href="#1610">1610</a> <em class="jxr_comment">   *</em>
<a name="1611" href="#1611">1611</a> <em class="jxr_comment">   * &lt;p&gt;It is usually invoked at the end of a compaction, but might also be</em>
<a name="1612" href="#1612">1612</a> <em class="jxr_comment">   * invoked at HStore startup, if the prior execution died midway through.</em>
<a name="1613" href="#1613">1613</a> <em class="jxr_comment">   *</em>
<a name="1614" href="#1614">1614</a> <em class="jxr_comment">   * &lt;p&gt;Moving the compacted TreeMap into place means:</em>
<a name="1615" href="#1615">1615</a> <em class="jxr_comment">   * &lt;pre&gt;</em>
<a name="1616" href="#1616">1616</a> <em class="jxr_comment">   * 1) Moving the new compacted StoreFile into place</em>
<a name="1617" href="#1617">1617</a> <em class="jxr_comment">   * 2) Unload all replaced StoreFile, close and collect list to delete.</em>
<a name="1618" href="#1618">1618</a> <em class="jxr_comment">   * 3) Loading the new TreeMap.</em>
<a name="1619" href="#1619">1619</a> <em class="jxr_comment">   * 4) Compute new store size</em>
<a name="1620" href="#1620">1620</a> <em class="jxr_comment">   * &lt;/pre&gt;</em>
<a name="1621" href="#1621">1621</a> <em class="jxr_comment">   *</em>
<a name="1622" href="#1622">1622</a> <em class="jxr_comment">   * @param compactedFiles list of files that were compacted</em>
<a name="1623" href="#1623">1623</a> <em class="jxr_comment">   * @param compactedFile StoreFile that is the result of the compaction</em>
<a name="1624" href="#1624">1624</a> <em class="jxr_comment">   * @return StoreFile created. May be null.</em>
<a name="1625" href="#1625">1625</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="1626" href="#1626">1626</a> <em class="jxr_comment">   */</em>
<a name="1627" href="#1627">1627</a>   <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> completeCompaction(<strong class="jxr_keyword">final</strong> Collection&lt;StoreFile&gt; compactedFiles,
<a name="1628" href="#1628">1628</a>                                        <strong class="jxr_keyword">final</strong> StoreFile.Writer compactedFile)
<a name="1629" href="#1629">1629</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1630" href="#1630">1630</a>     <em class="jxr_comment">// 1. Moving the new files into place -- if there is a new file (may not</em>
<a name="1631" href="#1631">1631</a>     <em class="jxr_comment">// be if all cells were expired or deleted).</em>
<a name="1632" href="#1632">1632</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> result = <strong class="jxr_keyword">null</strong>;
<a name="1633" href="#1633">1633</a>     <strong class="jxr_keyword">if</strong> (compactedFile != <strong class="jxr_keyword">null</strong>) {
<a name="1634" href="#1634">1634</a>       validateStoreFile(compactedFile.getPath());
<a name="1635" href="#1635">1635</a>       <em class="jxr_comment">// Move the file into the right spot</em>
<a name="1636" href="#1636">1636</a>       Path origPath = compactedFile.getPath();
<a name="1637" href="#1637">1637</a>       Path destPath = <strong class="jxr_keyword">new</strong> Path(homedir, origPath.getName());
<a name="1638" href="#1638">1638</a>       LOG.info(<span class="jxr_string">"Renaming compacted file at "</span> + origPath + <span class="jxr_string">" to "</span> + destPath);
<a name="1639" href="#1639">1639</a>       <strong class="jxr_keyword">if</strong> (!HBaseFileSystem.renameDirForFileSystem(fs, origPath, destPath)) {
<a name="1640" href="#1640">1640</a>         LOG.error(<span class="jxr_string">"Failed move of compacted file "</span> + origPath + <span class="jxr_string">" to "</span> +
<a name="1641" href="#1641">1641</a>             destPath);
<a name="1642" href="#1642">1642</a>         <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed move of compacted file "</span> + origPath +
<a name="1643" href="#1643">1643</a>             <span class="jxr_string">" to "</span> + destPath);
<a name="1644" href="#1644">1644</a>       }
<a name="1645" href="#1645">1645</a>       result = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a>(<strong class="jxr_keyword">this</strong>.fs, destPath, <strong class="jxr_keyword">this</strong>.conf, <strong class="jxr_keyword">this</strong>.cacheConf,
<a name="1646" href="#1646">1646</a>           <strong class="jxr_keyword">this</strong>.family.getBloomFilterType(), <strong class="jxr_keyword">this</strong>.dataBlockEncoder);
<a name="1647" href="#1647">1647</a>       passSchemaMetricsTo(result);
<a name="1648" href="#1648">1648</a>       result.createReader();
<a name="1649" href="#1649">1649</a>     }
<a name="1650" href="#1650">1650</a>     <strong class="jxr_keyword">try</strong> {
<a name="1651" href="#1651">1651</a>       <strong class="jxr_keyword">this</strong>.lock.writeLock().lock();
<a name="1652" href="#1652">1652</a>       <strong class="jxr_keyword">try</strong> {
<a name="1653" href="#1653">1653</a>         <em class="jxr_comment">// Change this.storefiles so it reflects new state but do not</em>
<a name="1654" href="#1654">1654</a>         <em class="jxr_comment">// delete old store files until we have sent out notification of</em>
<a name="1655" href="#1655">1655</a>         <em class="jxr_comment">// change in case old files are still being accessed by outstanding</em>
<a name="1656" href="#1656">1656</a>         <em class="jxr_comment">// scanners.</em>
<a name="1657" href="#1657">1657</a>         ArrayList&lt;StoreFile&gt; newStoreFiles = Lists.newArrayList(storefiles);
<a name="1658" href="#1658">1658</a>         newStoreFiles.removeAll(compactedFiles);
<a name="1659" href="#1659">1659</a>         filesCompacting.removeAll(compactedFiles); <em class="jxr_comment">// safe bc: lock.writeLock()</em>
<a name="1660" href="#1660">1660</a> 
<a name="1661" href="#1661">1661</a>         <em class="jxr_comment">// If a StoreFile result, move it into place.  May be null.</em>
<a name="1662" href="#1662">1662</a>         <strong class="jxr_keyword">if</strong> (result != <strong class="jxr_keyword">null</strong>) {
<a name="1663" href="#1663">1663</a>           newStoreFiles.add(result);
<a name="1664" href="#1664">1664</a>         }
<a name="1665" href="#1665">1665</a> 
<a name="1666" href="#1666">1666</a>         <strong class="jxr_keyword">this</strong>.storefiles = sortAndClone(newStoreFiles);
<a name="1667" href="#1667">1667</a>       } <strong class="jxr_keyword">finally</strong> {
<a name="1668" href="#1668">1668</a>         <em class="jxr_comment">// We need the lock, as long as we are updating the storefiles</em>
<a name="1669" href="#1669">1669</a>         <em class="jxr_comment">// or changing the memstore. Let us release it before calling</em>
<a name="1670" href="#1670">1670</a>         <em class="jxr_comment">// notifyChangeReadersObservers. See HBASE-4485 for a possible</em>
<a name="1671" href="#1671">1671</a>         <em class="jxr_comment">// deadlock scenario that could have happened if continue to hold</em>
<a name="1672" href="#1672">1672</a>         <em class="jxr_comment">// the lock.</em>
<a name="1673" href="#1673">1673</a>         <strong class="jxr_keyword">this</strong>.lock.writeLock().unlock();
<a name="1674" href="#1674">1674</a>       }
<a name="1675" href="#1675">1675</a> 
<a name="1676" href="#1676">1676</a>       <em class="jxr_comment">// Tell observers that list of StoreFiles has changed.</em>
<a name="1677" href="#1677">1677</a>       notifyChangedReadersObservers();
<a name="1678" href="#1678">1678</a> 
<a name="1679" href="#1679">1679</a>       <em class="jxr_comment">// let the archive util decide if we should archive or delete the files</em>
<a name="1680" href="#1680">1680</a>       LOG.debug(<span class="jxr_string">"Removing store files after compaction..."</span>);
<a name="1681" href="#1681">1681</a>       HFileArchiver.archiveStoreFiles(<strong class="jxr_keyword">this</strong>.conf, <strong class="jxr_keyword">this</strong>.fs, <strong class="jxr_keyword">this</strong>.region, <strong class="jxr_keyword">this</strong>.family.getName(),
<a name="1682" href="#1682">1682</a>         compactedFiles);
<a name="1683" href="#1683">1683</a> 
<a name="1684" href="#1684">1684</a>     } <strong class="jxr_keyword">catch</strong> (IOException e) {
<a name="1685" href="#1685">1685</a>       e = RemoteExceptionHandler.checkIOException(e);
<a name="1686" href="#1686">1686</a>       LOG.error(<span class="jxr_string">"Failed replacing compacted files in "</span> + <strong class="jxr_keyword">this</strong> +
<a name="1687" href="#1687">1687</a>         <span class="jxr_string">". Compacted file is "</span> + (result == <strong class="jxr_keyword">null</strong>? <span class="jxr_string">"none"</span>: result.toString()) +
<a name="1688" href="#1688">1688</a>         <span class="jxr_string">".  Files replaced "</span> + compactedFiles.toString() +
<a name="1689" href="#1689">1689</a>         <span class="jxr_string">" some of which may have been already removed"</span>, e);
<a name="1690" href="#1690">1690</a>     }
<a name="1691" href="#1691">1691</a> 
<a name="1692" href="#1692">1692</a>     <em class="jxr_comment">// 4. Compute new store size</em>
<a name="1693" href="#1693">1693</a>     <strong class="jxr_keyword">this</strong>.storeSize = 0L;
<a name="1694" href="#1694">1694</a>     <strong class="jxr_keyword">this</strong>.totalUncompressedBytes = 0L;
<a name="1695" href="#1695">1695</a>     <strong class="jxr_keyword">for</strong> (StoreFile hsf : <strong class="jxr_keyword">this</strong>.storefiles) {
<a name="1696" href="#1696">1696</a>       StoreFile.Reader r = hsf.getReader();
<a name="1697" href="#1697">1697</a>       <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="1698" href="#1698">1698</a>         LOG.warn(<span class="jxr_string">"StoreFile "</span> + hsf + <span class="jxr_string">" has a null Reader"</span>);
<a name="1699" href="#1699">1699</a>         <strong class="jxr_keyword">continue</strong>;
<a name="1700" href="#1700">1700</a>       }
<a name="1701" href="#1701">1701</a>       <strong class="jxr_keyword">this</strong>.storeSize += r.length();
<a name="1702" href="#1702">1702</a>       <strong class="jxr_keyword">this</strong>.totalUncompressedBytes += r.getTotalUncompressedBytes();
<a name="1703" href="#1703">1703</a>     }
<a name="1704" href="#1704">1704</a>     <strong class="jxr_keyword">return</strong> result;
<a name="1705" href="#1705">1705</a>   }
<a name="1706" href="#1706">1706</a> 
<a name="1707" href="#1707">1707</a>   <strong class="jxr_keyword">public</strong> ImmutableList&lt;StoreFile&gt; sortAndClone(List&lt;StoreFile&gt; storeFiles) {
<a name="1708" href="#1708">1708</a>     Collections.sort(storeFiles, StoreFile.Comparators.FLUSH_TIME);
<a name="1709" href="#1709">1709</a>     ImmutableList&lt;StoreFile&gt; newList = ImmutableList.copyOf(storeFiles);
<a name="1710" href="#1710">1710</a>     <strong class="jxr_keyword">return</strong> newList;
<a name="1711" href="#1711">1711</a>   }
<a name="1712" href="#1712">1712</a> 
<a name="1713" href="#1713">1713</a>   <em class="jxr_comment">// ////////////////////////////////////////////////////////////////////////////</em>
<a name="1714" href="#1714">1714</a>   <em class="jxr_comment">// Accessors.</em>
<a name="1715" href="#1715">1715</a>   <em class="jxr_comment">// (This is the only section that is directly useful!)</em>
<a name="1716" href="#1716">1716</a>   <em class="jxr_comment">//////////////////////////////////////////////////////////////////////////////</em>
<a name="1717" href="#1717">1717</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1718" href="#1718">1718</a> <em class="jxr_javadoccomment">   * @return the number of files in this store</em>
<a name="1719" href="#1719">1719</a> <em class="jxr_javadoccomment">   */</em>
<a name="1720" href="#1720">1720</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getNumberOfStoreFiles() {
<a name="1721" href="#1721">1721</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.storefiles.size();
<a name="1722" href="#1722">1722</a>   }
<a name="1723" href="#1723">1723</a> 
<a name="1724" href="#1724">1724</a>   <em class="jxr_comment">/*</em>
<a name="1725" href="#1725">1725</a> <em class="jxr_comment">   * @param wantedVersions How many versions were asked for.</em>
<a name="1726" href="#1726">1726</a> <em class="jxr_comment">   * @return wantedVersions or this families' {@link HConstants#VERSIONS}.</em>
<a name="1727" href="#1727">1727</a> <em class="jxr_comment">   */</em>
<a name="1728" href="#1728">1728</a>   <strong class="jxr_keyword">int</strong> versionsToReturn(<strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">int</strong> wantedVersions) {
<a name="1729" href="#1729">1729</a>     <strong class="jxr_keyword">if</strong> (wantedVersions &lt;= 0) {
<a name="1730" href="#1730">1730</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IllegalArgumentException(<span class="jxr_string">"Number of versions must be &gt; 0"</span>);
<a name="1731" href="#1731">1731</a>     }
<a name="1732" href="#1732">1732</a>     <em class="jxr_comment">// Make sure we do not return more than maximum versions for this store.</em>
<a name="1733" href="#1733">1733</a>     <strong class="jxr_keyword">int</strong> maxVersions = <strong class="jxr_keyword">this</strong>.family.getMaxVersions();
<a name="1734" href="#1734">1734</a>     <strong class="jxr_keyword">return</strong> wantedVersions &gt; maxVersions ? maxVersions: wantedVersions;
<a name="1735" href="#1735">1735</a>   }
<a name="1736" href="#1736">1736</a> 
<a name="1737" href="#1737">1737</a>   <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">boolean</strong> isExpired(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> key, <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> oldestTimestamp) {
<a name="1738" href="#1738">1738</a>     <strong class="jxr_keyword">return</strong> key.getTimestamp() &lt; oldestTimestamp;
<a name="1739" href="#1739">1739</a>   }
<a name="1740" href="#1740">1740</a> 
<a name="1741" href="#1741">1741</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1742" href="#1742">1742</a> <em class="jxr_javadoccomment">   * Find the key that matches &lt;i&gt;row&lt;/i&gt; exactly, or the one that immediately</em>
<a name="1743" href="#1743">1743</a> <em class="jxr_javadoccomment">   * precedes it. WARNING: Only use this method on a table where writes occur</em>
<a name="1744" href="#1744">1744</a> <em class="jxr_javadoccomment">   * with strictly increasing timestamps. This method assumes this pattern of</em>
<a name="1745" href="#1745">1745</a> <em class="jxr_javadoccomment">   * writes in order to make it reasonably performant.  Also our search is</em>
<a name="1746" href="#1746">1746</a> <em class="jxr_javadoccomment">   * dependent on the axiom that deletes are for cells that are in the container</em>
<a name="1747" href="#1747">1747</a> <em class="jxr_javadoccomment">   * that follows whether a memstore snapshot or a storefile, not for the</em>
<a name="1748" href="#1748">1748</a> <em class="jxr_javadoccomment">   * current container: i.e. we'll see deletes before we come across cells we</em>
<a name="1749" href="#1749">1749</a> <em class="jxr_javadoccomment">   * are to delete. Presumption is that the memstore#kvset is processed before</em>
<a name="1750" href="#1750">1750</a> <em class="jxr_javadoccomment">   * memstore#snapshot and so on.</em>
<a name="1751" href="#1751">1751</a> <em class="jxr_javadoccomment">   * @param row The row key of the targeted row.</em>
<a name="1752" href="#1752">1752</a> <em class="jxr_javadoccomment">   * @return Found keyvalue or null if none found.</em>
<a name="1753" href="#1753">1753</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="1754" href="#1754">1754</a> <em class="jxr_javadoccomment">   */</em>
<a name="1755" href="#1755">1755</a>   <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> getRowKeyAtOrBefore(<strong class="jxr_keyword">final</strong> byte[] row) <strong class="jxr_keyword">throws</strong> IOException {
<a name="1756" href="#1756">1756</a>     <em class="jxr_comment">// If minVersions is set, we will not ignore expired KVs.</em>
<a name="1757" href="#1757">1757</a>     <em class="jxr_comment">// As we're only looking for the latest matches, that should be OK.</em>
<a name="1758" href="#1758">1758</a>     <em class="jxr_comment">// With minVersions &gt; 0 we guarantee that any KV that has any version</em>
<a name="1759" href="#1759">1759</a>     <em class="jxr_comment">// at all (expired or not) has at least one version that will not expire.</em>
<a name="1760" href="#1760">1760</a>     <em class="jxr_comment">// Note that this method used to take a KeyValue as arguments. KeyValue</em>
<a name="1761" href="#1761">1761</a>     <em class="jxr_comment">// can be back-dated, a row key cannot.</em>
<a name="1762" href="#1762">1762</a>     <strong class="jxr_keyword">long</strong> ttlToUse = scanInfo.getMinVersions() &gt; 0 ? Long.MAX_VALUE : <strong class="jxr_keyword">this</strong>.ttl;
<a name="1763" href="#1763">1763</a> 
<a name="1764" href="#1764">1764</a>     <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a>(row, HConstants.LATEST_TIMESTAMP);
<a name="1765" href="#1765">1765</a> 
<a name="1766" href="#1766">1766</a>     <a href="../../../../../org/apache/hadoop/hbase/regionserver/GetClosestRowBeforeTracker.html">GetClosestRowBeforeTracker</a> state = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/GetClosestRowBeforeTracker.html">GetClosestRowBeforeTracker</a>(
<a name="1767" href="#1767">1767</a>       <strong class="jxr_keyword">this</strong>.comparator, kv, ttlToUse, <strong class="jxr_keyword">this</strong>.region.getRegionInfo().isMetaRegion());
<a name="1768" href="#1768">1768</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="1769" href="#1769">1769</a>     <strong class="jxr_keyword">try</strong> {
<a name="1770" href="#1770">1770</a>       <em class="jxr_comment">// First go to the memstore.  Pick up deletes and candidates.</em>
<a name="1771" href="#1771">1771</a>       <strong class="jxr_keyword">this</strong>.memstore.getRowKeyAtOrBefore(state);
<a name="1772" href="#1772">1772</a>       <em class="jxr_comment">// Check if match, if we got a candidate on the asked for 'kv' row.</em>
<a name="1773" href="#1773">1773</a>       <em class="jxr_comment">// Process each store file. Run through from newest to oldest.</em>
<a name="1774" href="#1774">1774</a>       <strong class="jxr_keyword">for</strong> (StoreFile sf : Lists.reverse(storefiles)) {
<a name="1775" href="#1775">1775</a>         <em class="jxr_comment">// Update the candidate keys from the current map file</em>
<a name="1776" href="#1776">1776</a>         rowAtOrBeforeFromStoreFile(sf, state);
<a name="1777" href="#1777">1777</a>       }
<a name="1778" href="#1778">1778</a>       <strong class="jxr_keyword">return</strong> state.getCandidate();
<a name="1779" href="#1779">1779</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1780" href="#1780">1780</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1781" href="#1781">1781</a>     }
<a name="1782" href="#1782">1782</a>   }
<a name="1783" href="#1783">1783</a> 
<a name="1784" href="#1784">1784</a>   <em class="jxr_comment">/*</em>
<a name="1785" href="#1785">1785</a> <em class="jxr_comment">   * Check an individual MapFile for the row at or before a given row.</em>
<a name="1786" href="#1786">1786</a> <em class="jxr_comment">   * @param f</em>
<a name="1787" href="#1787">1787</a> <em class="jxr_comment">   * @param state</em>
<a name="1788" href="#1788">1788</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="1789" href="#1789">1789</a> <em class="jxr_comment">   */</em>
<a name="1790" href="#1790">1790</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> rowAtOrBeforeFromStoreFile(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> f,
<a name="1791" href="#1791">1791</a>                                           <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/GetClosestRowBeforeTracker.html">GetClosestRowBeforeTracker</a> state)
<a name="1792" href="#1792">1792</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1793" href="#1793">1793</a>     StoreFile.Reader r = f.getReader();
<a name="1794" href="#1794">1794</a>     <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="1795" href="#1795">1795</a>       LOG.warn(<span class="jxr_string">"StoreFile "</span> + f + <span class="jxr_string">" has a null Reader"</span>);
<a name="1796" href="#1796">1796</a>       <strong class="jxr_keyword">return</strong>;
<a name="1797" href="#1797">1797</a>     }
<a name="1798" href="#1798">1798</a>     <em class="jxr_comment">// TODO: Cache these keys rather than make each time?</em>
<a name="1799" href="#1799">1799</a>     byte [] fk = r.getFirstKey();
<a name="1800" href="#1800">1800</a>     <strong class="jxr_keyword">if</strong> (fk == <strong class="jxr_keyword">null</strong>) <strong class="jxr_keyword">return</strong>;
<a name="1801" href="#1801">1801</a>     <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstKV = KeyValue.createKeyValueFromKey(fk, 0, fk.length);
<a name="1802" href="#1802">1802</a>     byte [] lk = r.getLastKey();
<a name="1803" href="#1803">1803</a>     <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> lastKV = KeyValue.createKeyValueFromKey(lk, 0, lk.length);
<a name="1804" href="#1804">1804</a>     <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstOnRow = state.getTargetKey();
<a name="1805" href="#1805">1805</a>     <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.comparator.compareRows(lastKV, firstOnRow) &lt; 0) {
<a name="1806" href="#1806">1806</a>       <em class="jxr_comment">// If last key in file is not of the target table, no candidates in this</em>
<a name="1807" href="#1807">1807</a>       <em class="jxr_comment">// file.  Return.</em>
<a name="1808" href="#1808">1808</a>       <strong class="jxr_keyword">if</strong> (!state.isTargetTable(lastKV)) <strong class="jxr_keyword">return</strong>;
<a name="1809" href="#1809">1809</a>       <em class="jxr_comment">// If the row we're looking for is past the end of file, set search key to</em>
<a name="1810" href="#1810">1810</a>       <em class="jxr_comment">// last key. TODO: Cache last and first key rather than make each time.</em>
<a name="1811" href="#1811">1811</a>       firstOnRow = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a>(lastKV.getRow(), HConstants.LATEST_TIMESTAMP);
<a name="1812" href="#1812">1812</a>     }
<a name="1813" href="#1813">1813</a>     <em class="jxr_comment">// Get a scanner that caches blocks and that uses pread.</em>
<a name="1814" href="#1814">1814</a>     <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileScanner.html">HFileScanner</a> scanner = r.getScanner(<strong class="jxr_keyword">true</strong>, <strong class="jxr_keyword">true</strong>, false);
<a name="1815" href="#1815">1815</a>     <em class="jxr_comment">// Seek scanner.  If can't seek it, return.</em>
<a name="1816" href="#1816">1816</a>     <strong class="jxr_keyword">if</strong> (!seekToScanner(scanner, firstOnRow, firstKV)) <strong class="jxr_keyword">return</strong>;
<a name="1817" href="#1817">1817</a>     <em class="jxr_comment">// If we found candidate on firstOnRow, just return. THIS WILL NEVER HAPPEN!</em>
<a name="1818" href="#1818">1818</a>     <em class="jxr_comment">// Unlikely that there'll be an instance of actual first row in table.</em>
<a name="1819" href="#1819">1819</a>     <strong class="jxr_keyword">if</strong> (walkForwardInSingleRow(scanner, firstOnRow, state)) <strong class="jxr_keyword">return</strong>;
<a name="1820" href="#1820">1820</a>     <em class="jxr_comment">// If here, need to start backing up.</em>
<a name="1821" href="#1821">1821</a>     <strong class="jxr_keyword">while</strong> (scanner.seekBefore(firstOnRow.getBuffer(), firstOnRow.getKeyOffset(),
<a name="1822" href="#1822">1822</a>        firstOnRow.getKeyLength())) {
<a name="1823" href="#1823">1823</a>       <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv = scanner.getKeyValue();
<a name="1824" href="#1824">1824</a>       <strong class="jxr_keyword">if</strong> (!state.isTargetTable(kv)) <strong class="jxr_keyword">break</strong>;
<a name="1825" href="#1825">1825</a>       <strong class="jxr_keyword">if</strong> (!state.isBetterCandidate(kv)) <strong class="jxr_keyword">break</strong>;
<a name="1826" href="#1826">1826</a>       <em class="jxr_comment">// Make new first on row.</em>
<a name="1827" href="#1827">1827</a>       firstOnRow = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a>(kv.getRow(), HConstants.LATEST_TIMESTAMP);
<a name="1828" href="#1828">1828</a>       <em class="jxr_comment">// Seek scanner.  If can't seek it, break.</em>
<a name="1829" href="#1829">1829</a>       <strong class="jxr_keyword">if</strong> (!seekToScanner(scanner, firstOnRow, firstKV)) <strong class="jxr_keyword">break</strong>;
<a name="1830" href="#1830">1830</a>       <em class="jxr_comment">// If we find something, break;</em>
<a name="1831" href="#1831">1831</a>       <strong class="jxr_keyword">if</strong> (walkForwardInSingleRow(scanner, firstOnRow, state)) <strong class="jxr_keyword">break</strong>;
<a name="1832" href="#1832">1832</a>     }
<a name="1833" href="#1833">1833</a>   }
<a name="1834" href="#1834">1834</a> 
<a name="1835" href="#1835">1835</a>   <em class="jxr_comment">/*</em>
<a name="1836" href="#1836">1836</a> <em class="jxr_comment">   * Seek the file scanner to firstOnRow or first entry in file.</em>
<a name="1837" href="#1837">1837</a> <em class="jxr_comment">   * @param scanner</em>
<a name="1838" href="#1838">1838</a> <em class="jxr_comment">   * @param firstOnRow</em>
<a name="1839" href="#1839">1839</a> <em class="jxr_comment">   * @param firstKV</em>
<a name="1840" href="#1840">1840</a> <em class="jxr_comment">   * @return True if we successfully seeked scanner.</em>
<a name="1841" href="#1841">1841</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="1842" href="#1842">1842</a> <em class="jxr_comment">   */</em>
<a name="1843" href="#1843">1843</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> seekToScanner(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileScanner.html">HFileScanner</a> scanner,
<a name="1844" href="#1844">1844</a>                                 <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstOnRow,
<a name="1845" href="#1845">1845</a>                                 <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstKV)
<a name="1846" href="#1846">1846</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1847" href="#1847">1847</a>     <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv = firstOnRow;
<a name="1848" href="#1848">1848</a>     <em class="jxr_comment">// If firstOnRow &lt; firstKV, set to firstKV</em>
<a name="1849" href="#1849">1849</a>     <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.comparator.compareRows(firstKV, firstOnRow) == 0) kv = firstKV;
<a name="1850" href="#1850">1850</a>     <strong class="jxr_keyword">int</strong> result = scanner.seekTo(kv.getBuffer(), kv.getKeyOffset(),
<a name="1851" href="#1851">1851</a>       kv.getKeyLength());
<a name="1852" href="#1852">1852</a>     <strong class="jxr_keyword">return</strong> result &gt;= 0;
<a name="1853" href="#1853">1853</a>   }
<a name="1854" href="#1854">1854</a> 
<a name="1855" href="#1855">1855</a>   <em class="jxr_comment">/*</em>
<a name="1856" href="#1856">1856</a> <em class="jxr_comment">   * When we come in here, we are probably at the kv just before we break into</em>
<a name="1857" href="#1857">1857</a> <em class="jxr_comment">   * the row that firstOnRow is on.  Usually need to increment one time to get</em>
<a name="1858" href="#1858">1858</a> <em class="jxr_comment">   * on to the row we are interested in.</em>
<a name="1859" href="#1859">1859</a> <em class="jxr_comment">   * @param scanner</em>
<a name="1860" href="#1860">1860</a> <em class="jxr_comment">   * @param firstOnRow</em>
<a name="1861" href="#1861">1861</a> <em class="jxr_comment">   * @param state</em>
<a name="1862" href="#1862">1862</a> <em class="jxr_comment">   * @return True we found a candidate.</em>
<a name="1863" href="#1863">1863</a> <em class="jxr_comment">   * @throws IOException</em>
<a name="1864" href="#1864">1864</a> <em class="jxr_comment">   */</em>
<a name="1865" href="#1865">1865</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> walkForwardInSingleRow(<strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/HFileScanner.html">HFileScanner</a> scanner,
<a name="1866" href="#1866">1866</a>                                          <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstOnRow,
<a name="1867" href="#1867">1867</a>                                          <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/GetClosestRowBeforeTracker.html">GetClosestRowBeforeTracker</a> state)
<a name="1868" href="#1868">1868</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="1869" href="#1869">1869</a>     <strong class="jxr_keyword">boolean</strong> foundCandidate = false;
<a name="1870" href="#1870">1870</a>     <strong class="jxr_keyword">do</strong> {
<a name="1871" href="#1871">1871</a>       <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> kv = scanner.getKeyValue();
<a name="1872" href="#1872">1872</a>       <em class="jxr_comment">// If we are not in the row, skip.</em>
<a name="1873" href="#1873">1873</a>       <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.comparator.compareRows(kv, firstOnRow) &lt; 0) <strong class="jxr_keyword">continue</strong>;
<a name="1874" href="#1874">1874</a>       <em class="jxr_comment">// Did we go beyond the target row? If so break.</em>
<a name="1875" href="#1875">1875</a>       <strong class="jxr_keyword">if</strong> (state.isTooFar(kv, firstOnRow)) <strong class="jxr_keyword">break</strong>;
<a name="1876" href="#1876">1876</a>       <strong class="jxr_keyword">if</strong> (state.isExpired(kv)) {
<a name="1877" href="#1877">1877</a>         <strong class="jxr_keyword">continue</strong>;
<a name="1878" href="#1878">1878</a>       }
<a name="1879" href="#1879">1879</a>       <em class="jxr_comment">// If we added something, this row is a contender. break.</em>
<a name="1880" href="#1880">1880</a>       <strong class="jxr_keyword">if</strong> (state.handle(kv)) {
<a name="1881" href="#1881">1881</a>         foundCandidate = <strong class="jxr_keyword">true</strong>;
<a name="1882" href="#1882">1882</a>         <strong class="jxr_keyword">break</strong>;
<a name="1883" href="#1883">1883</a>       }
<a name="1884" href="#1884">1884</a>     } <strong class="jxr_keyword">while</strong>(scanner.next());
<a name="1885" href="#1885">1885</a>     <strong class="jxr_keyword">return</strong> foundCandidate;
<a name="1886" href="#1886">1886</a>   }
<a name="1887" href="#1887">1887</a> 
<a name="1888" href="#1888">1888</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> canSplit() {
<a name="1889" href="#1889">1889</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="1890" href="#1890">1890</a>     <strong class="jxr_keyword">try</strong> {
<a name="1891" href="#1891">1891</a>       <em class="jxr_comment">// Not splitable if we find a reference store file present in the store.</em>
<a name="1892" href="#1892">1892</a>       <strong class="jxr_keyword">for</strong> (StoreFile sf : storefiles) {
<a name="1893" href="#1893">1893</a>         <strong class="jxr_keyword">if</strong> (sf.isReference()) {
<a name="1894" href="#1894">1894</a>           <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="1895" href="#1895">1895</a>             LOG.debug(sf + <span class="jxr_string">" is not splittable"</span>);
<a name="1896" href="#1896">1896</a>           }
<a name="1897" href="#1897">1897</a>           <strong class="jxr_keyword">return</strong> false;
<a name="1898" href="#1898">1898</a>         }
<a name="1899" href="#1899">1899</a>       }
<a name="1900" href="#1900">1900</a> 
<a name="1901" href="#1901">1901</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">true</strong>;
<a name="1902" href="#1902">1902</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1903" href="#1903">1903</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1904" href="#1904">1904</a>     }
<a name="1905" href="#1905">1905</a>   }
<a name="1906" href="#1906">1906</a>   <em class="jxr_javadoccomment">/**</em>
<a name="1907" href="#1907">1907</a> <em class="jxr_javadoccomment">   * Determines if Store should be split</em>
<a name="1908" href="#1908">1908</a> <em class="jxr_javadoccomment">   * @return byte[] if store should be split, null otherwise.</em>
<a name="1909" href="#1909">1909</a> <em class="jxr_javadoccomment">   */</em>
<a name="1910" href="#1910">1910</a>   <strong class="jxr_keyword">public</strong> byte[] getSplitPoint() {
<a name="1911" href="#1911">1911</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="1912" href="#1912">1912</a>     <strong class="jxr_keyword">try</strong> {
<a name="1913" href="#1913">1913</a>       <em class="jxr_comment">// sanity checks</em>
<a name="1914" href="#1914">1914</a>       <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.storefiles.isEmpty()) {
<a name="1915" href="#1915">1915</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1916" href="#1916">1916</a>       }
<a name="1917" href="#1917">1917</a>       <em class="jxr_comment">// Should already be enforced by the split policy!</em>
<a name="1918" href="#1918">1918</a>       assert !<strong class="jxr_keyword">this</strong>.region.getRegionInfo().isMetaRegion();
<a name="1919" href="#1919">1919</a> 
<a name="1920" href="#1920">1920</a>       <em class="jxr_comment">// Not splitable if we find a reference store file present in the store.</em>
<a name="1921" href="#1921">1921</a>       <strong class="jxr_keyword">long</strong> maxSize = 0L;
<a name="1922" href="#1922">1922</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> largestSf = <strong class="jxr_keyword">null</strong>;
<a name="1923" href="#1923">1923</a>       <strong class="jxr_keyword">for</strong> (StoreFile sf : storefiles) {
<a name="1924" href="#1924">1924</a>         <strong class="jxr_keyword">if</strong> (sf.isReference()) {
<a name="1925" href="#1925">1925</a>           <em class="jxr_comment">// Should already be enforced since we return false in this case</em>
<a name="1926" href="#1926">1926</a>           assert false : <span class="jxr_string">"getSplitPoint() called on a region that can't split!"</span>;
<a name="1927" href="#1927">1927</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1928" href="#1928">1928</a>         }
<a name="1929" href="#1929">1929</a> 
<a name="1930" href="#1930">1930</a>         StoreFile.Reader r = sf.getReader();
<a name="1931" href="#1931">1931</a>         <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="1932" href="#1932">1932</a>           LOG.warn(<span class="jxr_string">"Storefile "</span> + sf + <span class="jxr_string">" Reader is null"</span>);
<a name="1933" href="#1933">1933</a>           <strong class="jxr_keyword">continue</strong>;
<a name="1934" href="#1934">1934</a>         }
<a name="1935" href="#1935">1935</a> 
<a name="1936" href="#1936">1936</a>         <strong class="jxr_keyword">long</strong> size = r.length();
<a name="1937" href="#1937">1937</a>         <strong class="jxr_keyword">if</strong> (size &gt; maxSize) {
<a name="1938" href="#1938">1938</a>           <em class="jxr_comment">// This is the largest one so far</em>
<a name="1939" href="#1939">1939</a>           maxSize = size;
<a name="1940" href="#1940">1940</a>           largestSf = sf;
<a name="1941" href="#1941">1941</a>         }
<a name="1942" href="#1942">1942</a>       }
<a name="1943" href="#1943">1943</a> 
<a name="1944" href="#1944">1944</a>       StoreFile.Reader r = largestSf.getReader();
<a name="1945" href="#1945">1945</a>       <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="1946" href="#1946">1946</a>         LOG.warn(<span class="jxr_string">"Storefile "</span> + largestSf + <span class="jxr_string">" Reader is null"</span>);
<a name="1947" href="#1947">1947</a>         <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1948" href="#1948">1948</a>       }
<a name="1949" href="#1949">1949</a>       <em class="jxr_comment">// Get first, last, and mid keys.  Midkey is the key that starts block</em>
<a name="1950" href="#1950">1950</a>       <em class="jxr_comment">// in middle of hfile.  Has column and timestamp.  Need to return just</em>
<a name="1951" href="#1951">1951</a>       <em class="jxr_comment">// the row we want to split on as midkey.</em>
<a name="1952" href="#1952">1952</a>       byte [] midkey = r.midkey();
<a name="1953" href="#1953">1953</a>       <strong class="jxr_keyword">if</strong> (midkey != <strong class="jxr_keyword">null</strong>) {
<a name="1954" href="#1954">1954</a>         <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> mk = KeyValue.createKeyValueFromKey(midkey, 0, midkey.length);
<a name="1955" href="#1955">1955</a>         byte [] fk = r.getFirstKey();
<a name="1956" href="#1956">1956</a>         <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> firstKey = KeyValue.createKeyValueFromKey(fk, 0, fk.length);
<a name="1957" href="#1957">1957</a>         byte [] lk = r.getLastKey();
<a name="1958" href="#1958">1958</a>         <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KeyValue</a> lastKey = KeyValue.createKeyValueFromKey(lk, 0, lk.length);
<a name="1959" href="#1959">1959</a>         <em class="jxr_comment">// if the midkey is the same as the first or last keys, then we cannot</em>
<a name="1960" href="#1960">1960</a>         <em class="jxr_comment">// (ever) split this region.</em>
<a name="1961" href="#1961">1961</a>         <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.comparator.compareRows(mk, firstKey) == 0 ||
<a name="1962" href="#1962">1962</a>             <strong class="jxr_keyword">this</strong>.comparator.compareRows(mk, lastKey) == 0) {
<a name="1963" href="#1963">1963</a>           <strong class="jxr_keyword">if</strong> (LOG.isDebugEnabled()) {
<a name="1964" href="#1964">1964</a>             LOG.debug(<span class="jxr_string">"cannot split because midkey is the same as first or "</span> +
<a name="1965" href="#1965">1965</a>               <span class="jxr_string">"last row"</span>);
<a name="1966" href="#1966">1966</a>           }
<a name="1967" href="#1967">1967</a>           <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1968" href="#1968">1968</a>         }
<a name="1969" href="#1969">1969</a>         <strong class="jxr_keyword">return</strong> mk.getRow();
<a name="1970" href="#1970">1970</a>       }
<a name="1971" href="#1971">1971</a>     } <strong class="jxr_keyword">catch</strong>(IOException e) {
<a name="1972" href="#1972">1972</a>       LOG.warn(<span class="jxr_string">"Failed getting store size for "</span> + <strong class="jxr_keyword">this</strong>, e);
<a name="1973" href="#1973">1973</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="1974" href="#1974">1974</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="1975" href="#1975">1975</a>     }
<a name="1976" href="#1976">1976</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">null</strong>;
<a name="1977" href="#1977">1977</a>   }
<a name="1978" href="#1978">1978</a> 
<a name="1979" href="#1979">1979</a>   <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> @return aggregate size of all HStores used in the last compaction */</em>
<a name="1980" href="#1980">1980</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getLastCompactSize() {
<a name="1981" href="#1981">1981</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.lastCompactSize;
<a name="1982" href="#1982">1982</a>   }
<a name="1983" href="#1983">1983</a> 
<a name="1984" href="#1984">1984</a>   <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> @return aggregate size of HStore */</em>
<a name="1985" href="#1985">1985</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getSize() {
<a name="1986" href="#1986">1986</a>     <strong class="jxr_keyword">return</strong> storeSize;
<a name="1987" href="#1987">1987</a>   }
<a name="1988" href="#1988">1988</a> 
<a name="1989" href="#1989">1989</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> triggerMajorCompaction() {
<a name="1990" href="#1990">1990</a>     <strong class="jxr_keyword">this</strong>.forceMajor = <strong class="jxr_keyword">true</strong>;
<a name="1991" href="#1991">1991</a>   }
<a name="1992" href="#1992">1992</a> 
<a name="1993" href="#1993">1993</a>   <strong class="jxr_keyword">boolean</strong> getForceMajorCompaction() {
<a name="1994" href="#1994">1994</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.forceMajor;
<a name="1995" href="#1995">1995</a>   }
<a name="1996" href="#1996">1996</a> 
<a name="1997" href="#1997">1997</a>   <em class="jxr_comment">//////////////////////////////////////////////////////////////////////////////</em>
<a name="1998" href="#1998">1998</a>   <em class="jxr_comment">// File administration</em>
<a name="1999" href="#1999">1999</a>   <em class="jxr_comment">//////////////////////////////////////////////////////////////////////////////</em>
<a name="2000" href="#2000">2000</a> 
<a name="2001" href="#2001">2001</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2002" href="#2002">2002</a> <em class="jxr_javadoccomment">   * Return a scanner for both the memstore and the HStore files. Assumes we</em>
<a name="2003" href="#2003">2003</a> <em class="jxr_javadoccomment">   * are not in a compaction.</em>
<a name="2004" href="#2004">2004</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="2005" href="#2005">2005</a> <em class="jxr_javadoccomment">   */</em>
<a name="2006" href="#2006">2006</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/KeyValueScanner.html">KeyValueScanner</a> getScanner(<a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan,
<a name="2007" href="#2007">2007</a>       <strong class="jxr_keyword">final</strong> NavigableSet&lt;byte []&gt; targetCols) <strong class="jxr_keyword">throws</strong> IOException {
<a name="2008" href="#2008">2008</a>     lock.readLock().lock();
<a name="2009" href="#2009">2009</a>     <strong class="jxr_keyword">try</strong> {
<a name="2010" href="#2010">2010</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/KeyValueScanner.html">KeyValueScanner</a> scanner = <strong class="jxr_keyword">null</strong>;
<a name="2011" href="#2011">2011</a>       <strong class="jxr_keyword">if</strong> (getHRegion().getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="2012" href="#2012">2012</a>         scanner = getHRegion().getCoprocessorHost().preStoreScannerOpen(<strong class="jxr_keyword">this</strong>, scan, targetCols);
<a name="2013" href="#2013">2013</a>       }
<a name="2014" href="#2014">2014</a>       <strong class="jxr_keyword">if</strong> (scanner == <strong class="jxr_keyword">null</strong>) {
<a name="2015" href="#2015">2015</a>         scanner = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreScanner.html">StoreScanner</a>(<strong class="jxr_keyword">this</strong>, getScanInfo(), scan, targetCols);
<a name="2016" href="#2016">2016</a>       }
<a name="2017" href="#2017">2017</a>       <strong class="jxr_keyword">return</strong> scanner;
<a name="2018" href="#2018">2018</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="2019" href="#2019">2019</a>       lock.readLock().unlock();
<a name="2020" href="#2020">2020</a>     }
<a name="2021" href="#2021">2021</a>   }
<a name="2022" href="#2022">2022</a> 
<a name="2023" href="#2023">2023</a>   @Override
<a name="2024" href="#2024">2024</a>   <strong class="jxr_keyword">public</strong> String toString() {
<a name="2025" href="#2025">2025</a>     <strong class="jxr_keyword">return</strong> getColumnFamilyName();
<a name="2026" href="#2026">2026</a>   }
<a name="2027" href="#2027">2027</a> 
<a name="2028" href="#2028">2028</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2029" href="#2029">2029</a> <em class="jxr_javadoccomment">   * @return Count of store files</em>
<a name="2030" href="#2030">2030</a> <em class="jxr_javadoccomment">   */</em>
<a name="2031" href="#2031">2031</a>   <strong class="jxr_keyword">int</strong> getStorefilesCount() {
<a name="2032" href="#2032">2032</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.storefiles.size();
<a name="2033" href="#2033">2033</a>   }
<a name="2034" href="#2034">2034</a> 
<a name="2035" href="#2035">2035</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2036" href="#2036">2036</a> <em class="jxr_javadoccomment">   * @return The size of the store files, in bytes, uncompressed.</em>
<a name="2037" href="#2037">2037</a> <em class="jxr_javadoccomment">   */</em>
<a name="2038" href="#2038">2038</a>   <strong class="jxr_keyword">long</strong> getStoreSizeUncompressed() {
<a name="2039" href="#2039">2039</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.totalUncompressedBytes;
<a name="2040" href="#2040">2040</a>   }
<a name="2041" href="#2041">2041</a> 
<a name="2042" href="#2042">2042</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2043" href="#2043">2043</a> <em class="jxr_javadoccomment">   * @return The size of the store files, in bytes.</em>
<a name="2044" href="#2044">2044</a> <em class="jxr_javadoccomment">   */</em>
<a name="2045" href="#2045">2045</a>   <strong class="jxr_keyword">long</strong> getStorefilesSize() {
<a name="2046" href="#2046">2046</a>     <strong class="jxr_keyword">long</strong> size = 0;
<a name="2047" href="#2047">2047</a>     <strong class="jxr_keyword">for</strong> (StoreFile s: storefiles) {
<a name="2048" href="#2048">2048</a>       StoreFile.Reader r = s.getReader();
<a name="2049" href="#2049">2049</a>       <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="2050" href="#2050">2050</a>         LOG.warn(<span class="jxr_string">"StoreFile "</span> + s + <span class="jxr_string">" has a null Reader"</span>);
<a name="2051" href="#2051">2051</a>         <strong class="jxr_keyword">continue</strong>;
<a name="2052" href="#2052">2052</a>       }
<a name="2053" href="#2053">2053</a>       size += r.length();
<a name="2054" href="#2054">2054</a>     }
<a name="2055" href="#2055">2055</a>     <strong class="jxr_keyword">return</strong> size;
<a name="2056" href="#2056">2056</a>   }
<a name="2057" href="#2057">2057</a> 
<a name="2058" href="#2058">2058</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2059" href="#2059">2059</a> <em class="jxr_javadoccomment">   * @return The size of the store file indexes, in bytes.</em>
<a name="2060" href="#2060">2060</a> <em class="jxr_javadoccomment">   */</em>
<a name="2061" href="#2061">2061</a>   <strong class="jxr_keyword">long</strong> getStorefilesIndexSize() {
<a name="2062" href="#2062">2062</a>     <strong class="jxr_keyword">long</strong> size = 0;
<a name="2063" href="#2063">2063</a>     <strong class="jxr_keyword">for</strong> (StoreFile s: storefiles) {
<a name="2064" href="#2064">2064</a>       StoreFile.Reader r = s.getReader();
<a name="2065" href="#2065">2065</a>       <strong class="jxr_keyword">if</strong> (r == <strong class="jxr_keyword">null</strong>) {
<a name="2066" href="#2066">2066</a>         LOG.warn(<span class="jxr_string">"StoreFile "</span> + s + <span class="jxr_string">" has a null Reader"</span>);
<a name="2067" href="#2067">2067</a>         <strong class="jxr_keyword">continue</strong>;
<a name="2068" href="#2068">2068</a>       }
<a name="2069" href="#2069">2069</a>       size += r.indexSize();
<a name="2070" href="#2070">2070</a>     }
<a name="2071" href="#2071">2071</a>     <strong class="jxr_keyword">return</strong> size;
<a name="2072" href="#2072">2072</a>   }
<a name="2073" href="#2073">2073</a> 
<a name="2074" href="#2074">2074</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2075" href="#2075">2075</a> <em class="jxr_javadoccomment">   * Returns the total size of all index blocks in the data block indexes,</em>
<a name="2076" href="#2076">2076</a> <em class="jxr_javadoccomment">   * including the root level, intermediate levels, and the leaf level for</em>
<a name="2077" href="#2077">2077</a> <em class="jxr_javadoccomment">   * multi-level indexes, or just the root level for single-level indexes.</em>
<a name="2078" href="#2078">2078</a> <em class="jxr_javadoccomment">   *</em>
<a name="2079" href="#2079">2079</a> <em class="jxr_javadoccomment">   * @return the total size of block indexes in the store</em>
<a name="2080" href="#2080">2080</a> <em class="jxr_javadoccomment">   */</em>
<a name="2081" href="#2081">2081</a>   <strong class="jxr_keyword">long</strong> getTotalStaticIndexSize() {
<a name="2082" href="#2082">2082</a>     <strong class="jxr_keyword">long</strong> size = 0;
<a name="2083" href="#2083">2083</a>     <strong class="jxr_keyword">for</strong> (StoreFile s : storefiles) {
<a name="2084" href="#2084">2084</a>       size += s.getReader().getUncompressedDataIndexSize();
<a name="2085" href="#2085">2085</a>     }
<a name="2086" href="#2086">2086</a>     <strong class="jxr_keyword">return</strong> size;
<a name="2087" href="#2087">2087</a>   }
<a name="2088" href="#2088">2088</a> 
<a name="2089" href="#2089">2089</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2090" href="#2090">2090</a> <em class="jxr_javadoccomment">   * Returns the total byte size of all Bloom filter bit arrays. For compound</em>
<a name="2091" href="#2091">2091</a> <em class="jxr_javadoccomment">   * Bloom filters even the Bloom blocks currently not loaded into the block</em>
<a name="2092" href="#2092">2092</a> <em class="jxr_javadoccomment">   * cache are counted.</em>
<a name="2093" href="#2093">2093</a> <em class="jxr_javadoccomment">   *</em>
<a name="2094" href="#2094">2094</a> <em class="jxr_javadoccomment">   * @return the total size of all Bloom filters in the store</em>
<a name="2095" href="#2095">2095</a> <em class="jxr_javadoccomment">   */</em>
<a name="2096" href="#2096">2096</a>   <strong class="jxr_keyword">long</strong> getTotalStaticBloomSize() {
<a name="2097" href="#2097">2097</a>     <strong class="jxr_keyword">long</strong> size = 0;
<a name="2098" href="#2098">2098</a>     <strong class="jxr_keyword">for</strong> (StoreFile s : storefiles) {
<a name="2099" href="#2099">2099</a>       StoreFile.Reader r = s.getReader();
<a name="2100" href="#2100">2100</a>       size += r.getTotalBloomSize();
<a name="2101" href="#2101">2101</a>     }
<a name="2102" href="#2102">2102</a>     <strong class="jxr_keyword">return</strong> size;
<a name="2103" href="#2103">2103</a>   }
<a name="2104" href="#2104">2104</a> 
<a name="2105" href="#2105">2105</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2106" href="#2106">2106</a> <em class="jxr_javadoccomment">   * @return The size of this store's memstore, in bytes</em>
<a name="2107" href="#2107">2107</a> <em class="jxr_javadoccomment">   */</em>
<a name="2108" href="#2108">2108</a>   <strong class="jxr_keyword">long</strong> getMemStoreSize() {
<a name="2109" href="#2109">2109</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.memstore.heapSize();
<a name="2110" href="#2110">2110</a>   }
<a name="2111" href="#2111">2111</a> 
<a name="2112" href="#2112">2112</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getCompactPriority() {
<a name="2113" href="#2113">2113</a>     <strong class="jxr_keyword">return</strong> getCompactPriority(NO_PRIORITY);
<a name="2114" href="#2114">2114</a>   }
<a name="2115" href="#2115">2115</a> 
<a name="2116" href="#2116">2116</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2117" href="#2117">2117</a> <em class="jxr_javadoccomment">   * @return The priority that this store should have in the compaction queue</em>
<a name="2118" href="#2118">2118</a> <em class="jxr_javadoccomment">   * @param priority</em>
<a name="2119" href="#2119">2119</a> <em class="jxr_javadoccomment">   */</em>
<a name="2120" href="#2120">2120</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getCompactPriority(<strong class="jxr_keyword">int</strong> priority) {
<a name="2121" href="#2121">2121</a>     <em class="jxr_comment">// If this is a user-requested compaction, leave this at the highest priority</em>
<a name="2122" href="#2122">2122</a>     <strong class="jxr_keyword">if</strong>(priority == PRIORITY_USER) {
<a name="2123" href="#2123">2123</a>       <strong class="jxr_keyword">return</strong> PRIORITY_USER;
<a name="2124" href="#2124">2124</a>     } <strong class="jxr_keyword">else</strong> {
<a name="2125" href="#2125">2125</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.blockingStoreFileCount - <strong class="jxr_keyword">this</strong>.storefiles.size();
<a name="2126" href="#2126">2126</a>     }
<a name="2127" href="#2127">2127</a>   }
<a name="2128" href="#2128">2128</a> 
<a name="2129" href="#2129">2129</a>   <strong class="jxr_keyword">boolean</strong> throttleCompaction(<strong class="jxr_keyword">long</strong> compactionSize) {
<a name="2130" href="#2130">2130</a>     <strong class="jxr_keyword">long</strong> throttlePoint = conf.getLong(
<a name="2131" href="#2131">2131</a>         <span class="jxr_string">"hbase.regionserver.thread.compaction.throttle"</span>,
<a name="2132" href="#2132">2132</a>         2 * <strong class="jxr_keyword">this</strong>.minFilesToCompact * <strong class="jxr_keyword">this</strong>.region.memstoreFlushSize);
<a name="2133" href="#2133">2133</a>     <strong class="jxr_keyword">return</strong> compactionSize &gt; throttlePoint;
<a name="2134" href="#2134">2134</a>   }
<a name="2135" href="#2135">2135</a> 
<a name="2136" href="#2136">2136</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> getHRegion() {
<a name="2137" href="#2137">2137</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.region;
<a name="2138" href="#2138">2138</a>   }
<a name="2139" href="#2139">2139</a> 
<a name="2140" href="#2140">2140</a>   <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> getHRegionInfo() {
<a name="2141" href="#2141">2141</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.region.getRegionInfo();
<a name="2142" href="#2142">2142</a>   }
<a name="2143" href="#2143">2143</a> 
<a name="2144" href="#2144">2144</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2145" href="#2145">2145</a> <em class="jxr_javadoccomment">   * Increments the value for the given row/family/qualifier.</em>
<a name="2146" href="#2146">2146</a> <em class="jxr_javadoccomment">   *</em>
<a name="2147" href="#2147">2147</a> <em class="jxr_javadoccomment">   * This function will always be seen as atomic by other readers</em>
<a name="2148" href="#2148">2148</a> <em class="jxr_javadoccomment">   * because it only puts a single KV to memstore. Thus no</em>
<a name="2149" href="#2149">2149</a> <em class="jxr_javadoccomment">   * read/write control necessary.</em>
<a name="2150" href="#2150">2150</a> <em class="jxr_javadoccomment">   *</em>
<a name="2151" href="#2151">2151</a> <em class="jxr_javadoccomment">   * @param row</em>
<a name="2152" href="#2152">2152</a> <em class="jxr_javadoccomment">   * @param f</em>
<a name="2153" href="#2153">2153</a> <em class="jxr_javadoccomment">   * @param qualifier</em>
<a name="2154" href="#2154">2154</a> <em class="jxr_javadoccomment">   * @param newValue the new value to set into memstore</em>
<a name="2155" href="#2155">2155</a> <em class="jxr_javadoccomment">   * @return memstore size delta</em>
<a name="2156" href="#2156">2156</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="2157" href="#2157">2157</a> <em class="jxr_javadoccomment">   */</em>
<a name="2158" href="#2158">2158</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> updateColumnValue(byte [] row, byte [] f,
<a name="2159" href="#2159">2159</a>                                 byte [] qualifier, <strong class="jxr_keyword">long</strong> newValue)
<a name="2160" href="#2160">2160</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="2161" href="#2161">2161</a> 
<a name="2162" href="#2162">2162</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="2163" href="#2163">2163</a>     <strong class="jxr_keyword">try</strong> {
<a name="2164" href="#2164">2164</a>       <strong class="jxr_keyword">long</strong> now = EnvironmentEdgeManager.currentTimeMillis();
<a name="2165" href="#2165">2165</a> 
<a name="2166" href="#2166">2166</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.memstore.updateColumnValue(row,
<a name="2167" href="#2167">2167</a>           f,
<a name="2168" href="#2168">2168</a>           qualifier,
<a name="2169" href="#2169">2169</a>           newValue,
<a name="2170" href="#2170">2170</a>           now);
<a name="2171" href="#2171">2171</a> 
<a name="2172" href="#2172">2172</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="2173" href="#2173">2173</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="2174" href="#2174">2174</a>     }
<a name="2175" href="#2175">2175</a>   }
<a name="2176" href="#2176">2176</a> 
<a name="2177" href="#2177">2177</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2178" href="#2178">2178</a> <em class="jxr_javadoccomment">   * Adds or replaces the specified KeyValues.</em>
<a name="2179" href="#2179">2179</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="2180" href="#2180">2180</a> <em class="jxr_javadoccomment">   * For each KeyValue specified, if a cell with the same row, family, and</em>
<a name="2181" href="#2181">2181</a> <em class="jxr_javadoccomment">   * qualifier exists in MemStore, it will be replaced.  Otherwise, it will just</em>
<a name="2182" href="#2182">2182</a> <em class="jxr_javadoccomment">   * be inserted to MemStore.</em>
<a name="2183" href="#2183">2183</a> <em class="jxr_javadoccomment">   * &lt;p&gt;</em>
<a name="2184" href="#2184">2184</a> <em class="jxr_javadoccomment">   * This operation is atomic on each KeyValue (row/family/qualifier) but not</em>
<a name="2185" href="#2185">2185</a> <em class="jxr_javadoccomment">   * necessarily atomic across all of them.</em>
<a name="2186" href="#2186">2186</a> <em class="jxr_javadoccomment">   * @param kvs</em>
<a name="2187" href="#2187">2187</a> <em class="jxr_javadoccomment">   * @return memstore size delta</em>
<a name="2188" href="#2188">2188</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="2189" href="#2189">2189</a> <em class="jxr_javadoccomment">   */</em>
<a name="2190" href="#2190">2190</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> upsert(List&lt;KeyValue&gt; kvs)
<a name="2191" href="#2191">2191</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="2192" href="#2192">2192</a>     <strong class="jxr_keyword">this</strong>.lock.readLock().lock();
<a name="2193" href="#2193">2193</a>     <strong class="jxr_keyword">try</strong> {
<a name="2194" href="#2194">2194</a>       <em class="jxr_comment">// TODO: Make this operation atomic w/ MVCC</em>
<a name="2195" href="#2195">2195</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.memstore.upsert(kvs);
<a name="2196" href="#2196">2196</a>     } <strong class="jxr_keyword">finally</strong> {
<a name="2197" href="#2197">2197</a>       <strong class="jxr_keyword">this</strong>.lock.readLock().unlock();
<a name="2198" href="#2198">2198</a>     }
<a name="2199" href="#2199">2199</a>   }
<a name="2200" href="#2200">2200</a> 
<a name="2201" href="#2201">2201</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFlusher.html">StoreFlusher</a> getStoreFlusher(<strong class="jxr_keyword">long</strong> cacheFlushId) {
<a name="2202" href="#2202">2202</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">StoreFlusherImpl</a>(cacheFlushId);
<a name="2203" href="#2203">2203</a>   }
<a name="2204" href="#2204">2204</a> 
<a name="2205" href="#2205">2205</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">StoreFlusherImpl</a> implements <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFlusher.html">StoreFlusher</a> {
<a name="2206" href="#2206">2206</a> 
<a name="2207" href="#2207">2207</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> cacheFlushId;
<a name="2208" href="#2208">2208</a>     <strong class="jxr_keyword">private</strong> SortedSet&lt;KeyValue&gt; snapshot;
<a name="2209" href="#2209">2209</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/StoreFile.html">StoreFile</a> storeFile;
<a name="2210" href="#2210">2210</a>     <strong class="jxr_keyword">private</strong> Path storeFilePath;
<a name="2211" href="#2211">2211</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/TimeRangeTracker.html">TimeRangeTracker</a> snapshotTimeRangeTracker;
<a name="2212" href="#2212">2212</a>     <strong class="jxr_keyword">private</strong> AtomicLong flushedSize;
<a name="2213" href="#2213">2213</a> 
<a name="2214" href="#2214">2214</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">StoreFlusherImpl</a>(<strong class="jxr_keyword">long</strong> cacheFlushId) {
<a name="2215" href="#2215">2215</a>       <strong class="jxr_keyword">this</strong>.cacheFlushId = cacheFlushId;
<a name="2216" href="#2216">2216</a>       <strong class="jxr_keyword">this</strong>.flushedSize = <strong class="jxr_keyword">new</strong> AtomicLong();
<a name="2217" href="#2217">2217</a>     }
<a name="2218" href="#2218">2218</a> 
<a name="2219" href="#2219">2219</a>     @Override
<a name="2220" href="#2220">2220</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> prepare() {
<a name="2221" href="#2221">2221</a>       memstore.snapshot();
<a name="2222" href="#2222">2222</a>       <strong class="jxr_keyword">this</strong>.snapshot = memstore.getSnapshot();
<a name="2223" href="#2223">2223</a>       <strong class="jxr_keyword">this</strong>.snapshotTimeRangeTracker = memstore.getSnapshotTimeRangeTracker();
<a name="2224" href="#2224">2224</a>     }
<a name="2225" href="#2225">2225</a> 
<a name="2226" href="#2226">2226</a>     @Override
<a name="2227" href="#2227">2227</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> flushCache(<a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status) <strong class="jxr_keyword">throws</strong> IOException {
<a name="2228" href="#2228">2228</a>       storeFilePath = Store.<strong class="jxr_keyword">this</strong>.flushCache(
<a name="2229" href="#2229">2229</a>         cacheFlushId, snapshot, snapshotTimeRangeTracker, flushedSize, status);
<a name="2230" href="#2230">2230</a>     }
<a name="2231" href="#2231">2231</a> 
<a name="2232" href="#2232">2232</a>     @Override
<a name="2233" href="#2233">2233</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> commit(<a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status) <strong class="jxr_keyword">throws</strong> IOException {
<a name="2234" href="#2234">2234</a>       <strong class="jxr_keyword">if</strong> (storeFilePath == <strong class="jxr_keyword">null</strong>) {
<a name="2235" href="#2235">2235</a>         <strong class="jxr_keyword">return</strong> false;
<a name="2236" href="#2236">2236</a>       }
<a name="2237" href="#2237">2237</a>       storeFile = Store.<strong class="jxr_keyword">this</strong>.commitFile(storeFilePath, cacheFlushId,
<a name="2238" href="#2238">2238</a>                                snapshotTimeRangeTracker, flushedSize, status);
<a name="2239" href="#2239">2239</a>       <strong class="jxr_keyword">if</strong> (Store.<strong class="jxr_keyword">this</strong>.getHRegion().getCoprocessorHost() != <strong class="jxr_keyword">null</strong>) {
<a name="2240" href="#2240">2240</a>         Store.<strong class="jxr_keyword">this</strong>.getHRegion()
<a name="2241" href="#2241">2241</a>             .getCoprocessorHost()
<a name="2242" href="#2242">2242</a>             .postFlush(Store.<strong class="jxr_keyword">this</strong>, storeFile);
<a name="2243" href="#2243">2243</a>       }
<a name="2244" href="#2244">2244</a> 
<a name="2245" href="#2245">2245</a>       <em class="jxr_comment">// Add new file to store files.  Clear snapshot too while we have</em>
<a name="2246" href="#2246">2246</a>       <em class="jxr_comment">// the Store write lock.</em>
<a name="2247" href="#2247">2247</a>       <strong class="jxr_keyword">return</strong> Store.<strong class="jxr_keyword">this</strong>.updateStorefiles(storeFile, snapshot);
<a name="2248" href="#2248">2248</a>     }
<a name="2249" href="#2249">2249</a>   }
<a name="2250" href="#2250">2250</a> 
<a name="2251" href="#2251">2251</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2252" href="#2252">2252</a> <em class="jxr_javadoccomment">   * See if there's too much store files in this store</em>
<a name="2253" href="#2253">2253</a> <em class="jxr_javadoccomment">   * @return true if number of store files is greater than</em>
<a name="2254" href="#2254">2254</a> <em class="jxr_javadoccomment">   *  the number defined in minFilesToCompact</em>
<a name="2255" href="#2255">2255</a> <em class="jxr_javadoccomment">   */</em>
<a name="2256" href="#2256">2256</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> needsCompaction() {
<a name="2257" href="#2257">2257</a>     <strong class="jxr_keyword">return</strong> (storefiles.size() - filesCompacting.size()) &gt; minFilesToCompact;
<a name="2258" href="#2258">2258</a>   }
<a name="2259" href="#2259">2259</a> 
<a name="2260" href="#2260">2260</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2261" href="#2261">2261</a> <em class="jxr_javadoccomment">   * Used for tests. Get the cache configuration for this Store.</em>
<a name="2262" href="#2262">2262</a> <em class="jxr_javadoccomment">   */</em>
<a name="2263" href="#2263">2263</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a> getCacheConfig() {
<a name="2264" href="#2264">2264</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">this</strong>.cacheConf;
<a name="2265" href="#2265">2265</a>   }
<a name="2266" href="#2266">2266</a> 
<a name="2267" href="#2267">2267</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> FIXED_OVERHEAD =
<a name="2268" href="#2268">2268</a>       ClassSize.align(SchemaConfigured.SCHEMA_CONFIGURED_UNALIGNED_HEAP_SIZE +
<a name="2269" href="#2269">2269</a>           + (17 * ClassSize.REFERENCE) + (6 * Bytes.SIZEOF_LONG)
<a name="2270" href="#2270">2270</a>           + (5 * Bytes.SIZEOF_INT) + Bytes.SIZEOF_BOOLEAN);
<a name="2271" href="#2271">2271</a> 
<a name="2272" href="#2272">2272</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> DEEP_OVERHEAD = ClassSize.align(FIXED_OVERHEAD
<a name="2273" href="#2273">2273</a>       + ClassSize.OBJECT + ClassSize.REENTRANT_LOCK
<a name="2274" href="#2274">2274</a>       + ClassSize.CONCURRENT_SKIPLISTMAP
<a name="2275" href="#2275">2275</a>       + ClassSize.CONCURRENT_SKIPLISTMAP_ENTRY + ClassSize.OBJECT
<a name="2276" href="#2276">2276</a>       + ScanInfo.FIXED_OVERHEAD);
<a name="2277" href="#2277">2277</a> 
<a name="2278" href="#2278">2278</a>   @Override
<a name="2279" href="#2279">2279</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> heapSize() {
<a name="2280" href="#2280">2280</a>     <strong class="jxr_keyword">return</strong> DEEP_OVERHEAD + <strong class="jxr_keyword">this</strong>.memstore.heapSize();
<a name="2281" href="#2281">2281</a>   }
<a name="2282" href="#2282">2282</a> 
<a name="2283" href="#2283">2283</a>   <strong class="jxr_keyword">public</strong> KeyValue.KVComparator getComparator() {
<a name="2284" href="#2284">2284</a>     <strong class="jxr_keyword">return</strong> comparator;
<a name="2285" href="#2285">2285</a>   }
<a name="2286" href="#2286">2286</a> 
<a name="2287" href="#2287">2287</a>   <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a> getScanInfo() {
<a name="2288" href="#2288">2288</a>     <strong class="jxr_keyword">return</strong> scanInfo;
<a name="2289" href="#2289">2289</a>   }
<a name="2290" href="#2290">2290</a> 
<a name="2291" href="#2291">2291</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2292" href="#2292">2292</a> <em class="jxr_javadoccomment">   * Immutable information for scans over a store.</em>
<a name="2293" href="#2293">2293</a> <em class="jxr_javadoccomment">   */</em>
<a name="2294" href="#2294">2294</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a> {
<a name="2295" href="#2295">2295</a>     <strong class="jxr_keyword">private</strong> byte[] family;
<a name="2296" href="#2296">2296</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">int</strong> minVersions;
<a name="2297" href="#2297">2297</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">int</strong> maxVersions;
<a name="2298" href="#2298">2298</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> ttl;
<a name="2299" href="#2299">2299</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> keepDeletedCells;
<a name="2300" href="#2300">2300</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">long</strong> timeToPurgeDeletes;
<a name="2301" href="#2301">2301</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KVComparator</a> comparator;
<a name="2302" href="#2302">2302</a> 
<a name="2303" href="#2303">2303</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">long</strong> FIXED_OVERHEAD = ClassSize.align(ClassSize.OBJECT
<a name="2304" href="#2304">2304</a>         + (2 * ClassSize.REFERENCE) + (2 * Bytes.SIZEOF_INT)
<a name="2305" href="#2305">2305</a>         + Bytes.SIZEOF_LONG + Bytes.SIZEOF_BOOLEAN);
<a name="2306" href="#2306">2306</a> 
<a name="2307" href="#2307">2307</a>     <em class="jxr_javadoccomment">/**</em>
<a name="2308" href="#2308">2308</a> <em class="jxr_javadoccomment">     * @param family {@link HColumnDescriptor} describing the column family</em>
<a name="2309" href="#2309">2309</a> <em class="jxr_javadoccomment">     * @param ttl Store's TTL (in ms)</em>
<a name="2310" href="#2310">2310</a> <em class="jxr_javadoccomment">     * @param timeToPurgeDeletes duration in ms after which a delete marker can</em>
<a name="2311" href="#2311">2311</a> <em class="jxr_javadoccomment">     *        be purged during a major compaction.</em>
<a name="2312" href="#2312">2312</a> <em class="jxr_javadoccomment">     * @param comparator The store's comparator</em>
<a name="2313" href="#2313">2313</a> <em class="jxr_javadoccomment">     */</em>
<a name="2314" href="#2314">2314</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a>(<a href="../../../../../org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> family, <strong class="jxr_keyword">long</strong> ttl, <strong class="jxr_keyword">long</strong> timeToPurgeDeletes, <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KVComparator</a> comparator) {
<a name="2315" href="#2315">2315</a>       <strong class="jxr_keyword">this</strong>(family.getName(), family.getMinVersions(), family.getMaxVersions(), ttl, family
<a name="2316" href="#2316">2316</a>           .getKeepDeletedCells(), timeToPurgeDeletes, comparator);
<a name="2317" href="#2317">2317</a>     }
<a name="2318" href="#2318">2318</a>     <em class="jxr_javadoccomment">/**</em>
<a name="2319" href="#2319">2319</a> <em class="jxr_javadoccomment">     * @param family Name of this store's column family</em>
<a name="2320" href="#2320">2320</a> <em class="jxr_javadoccomment">     * @param minVersions Store's MIN_VERSIONS setting</em>
<a name="2321" href="#2321">2321</a> <em class="jxr_javadoccomment">     * @param maxVersions Store's VERSIONS setting</em>
<a name="2322" href="#2322">2322</a> <em class="jxr_javadoccomment">     * @param ttl Store's TTL (in ms)</em>
<a name="2323" href="#2323">2323</a> <em class="jxr_javadoccomment">     * @param timeToPurgeDeletes duration in ms after which a delete marker can</em>
<a name="2324" href="#2324">2324</a> <em class="jxr_javadoccomment">     *        be purged during a major compaction.</em>
<a name="2325" href="#2325">2325</a> <em class="jxr_javadoccomment">     * @param keepDeletedCells Store's keepDeletedCells setting</em>
<a name="2326" href="#2326">2326</a> <em class="jxr_javadoccomment">     * @param comparator The store's comparator</em>
<a name="2327" href="#2327">2327</a> <em class="jxr_javadoccomment">     */</em>
<a name="2328" href="#2328">2328</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/Store.html">ScanInfo</a>(byte[] family, <strong class="jxr_keyword">int</strong> minVersions, <strong class="jxr_keyword">int</strong> maxVersions, <strong class="jxr_keyword">long</strong> ttl,
<a name="2329" href="#2329">2329</a>         <strong class="jxr_keyword">boolean</strong> keepDeletedCells, <strong class="jxr_keyword">long</strong> timeToPurgeDeletes,
<a name="2330" href="#2330">2330</a>         <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KVComparator</a> comparator) {
<a name="2331" href="#2331">2331</a> 
<a name="2332" href="#2332">2332</a>       <strong class="jxr_keyword">this</strong>.family = family;
<a name="2333" href="#2333">2333</a>       <strong class="jxr_keyword">this</strong>.minVersions = minVersions;
<a name="2334" href="#2334">2334</a>       <strong class="jxr_keyword">this</strong>.maxVersions = maxVersions;
<a name="2335" href="#2335">2335</a>       <strong class="jxr_keyword">this</strong>.ttl = ttl;
<a name="2336" href="#2336">2336</a>       <strong class="jxr_keyword">this</strong>.keepDeletedCells = keepDeletedCells;
<a name="2337" href="#2337">2337</a>       <strong class="jxr_keyword">this</strong>.timeToPurgeDeletes = timeToPurgeDeletes;
<a name="2338" href="#2338">2338</a>       <strong class="jxr_keyword">this</strong>.comparator = comparator;
<a name="2339" href="#2339">2339</a>     }
<a name="2340" href="#2340">2340</a> 
<a name="2341" href="#2341">2341</a>     <strong class="jxr_keyword">public</strong> byte[] getFamily() {
<a name="2342" href="#2342">2342</a>       <strong class="jxr_keyword">return</strong> family;
<a name="2343" href="#2343">2343</a>     }
<a name="2344" href="#2344">2344</a> 
<a name="2345" href="#2345">2345</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getMinVersions() {
<a name="2346" href="#2346">2346</a>       <strong class="jxr_keyword">return</strong> minVersions;
<a name="2347" href="#2347">2347</a>     }
<a name="2348" href="#2348">2348</a> 
<a name="2349" href="#2349">2349</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">int</strong> getMaxVersions() {
<a name="2350" href="#2350">2350</a>       <strong class="jxr_keyword">return</strong> maxVersions;
<a name="2351" href="#2351">2351</a>     }
<a name="2352" href="#2352">2352</a> 
<a name="2353" href="#2353">2353</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getTtl() {
<a name="2354" href="#2354">2354</a>       <strong class="jxr_keyword">return</strong> ttl;
<a name="2355" href="#2355">2355</a>     }
<a name="2356" href="#2356">2356</a> 
<a name="2357" href="#2357">2357</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> getKeepDeletedCells() {
<a name="2358" href="#2358">2358</a>       <strong class="jxr_keyword">return</strong> keepDeletedCells;
<a name="2359" href="#2359">2359</a>     }
<a name="2360" href="#2360">2360</a> 
<a name="2361" href="#2361">2361</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getTimeToPurgeDeletes() {
<a name="2362" href="#2362">2362</a>       <strong class="jxr_keyword">return</strong> timeToPurgeDeletes;
<a name="2363" href="#2363">2363</a>     }
<a name="2364" href="#2364">2364</a> 
<a name="2365" href="#2365">2365</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/KeyValue.html">KVComparator</a> getComparator() {
<a name="2366" href="#2366">2366</a>       <strong class="jxr_keyword">return</strong> comparator;
<a name="2367" href="#2367">2367</a>     }
<a name="2368" href="#2368">2368</a>   }
<a name="2369" href="#2369">2369</a> 
<a name="2370" href="#2370">2370</a> }
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

