<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- Generated by Apache Maven Doxia at Jan 7, 2014 -->
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Llama, Testing with</title>
    <style type="text/css" media="all">
      @import url("./css/maven-base.css");
      @import url("./css/maven-theme.css");
      @import url("./css/site.css");
    </style>
    <link rel="stylesheet" href="./css/print.css" type="text/css" media="print" />
        <meta name="Date-Revision-yyyymmdd" content="20140107" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      </head>
  <body class="composite">
    <div id="banner">
                  <span id="bannerLeft">
                Llama
                </span>
                    <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="breadcrumbs">
            
                                <div class="xleft">
        Last Published: 2014-01-07
                  &nbsp;| Version: 1.0.0-cdh5.0.0-SNAPSHOT
                      </div>
            <div class="xright">            <a href="http://www.cloudera.com/" class="externalLink">Cloudera Inc.</a>
              
                      </div>
      <div class="clear">
        <hr/>
      </div>
    </div>
    <div id="leftColumn">
      <div id="navcolumn">
             
                                                <h5>Llama</h5>
                  <ul>
                  <li class="none">
                  <a href="index.html">Overview</a>
            </li>
                  <li class="none">
                  <a href="Llama.thrift">Thrift Definition</a>
            </li>
                  <li class="none">
                  <a href="ThriftInterfaceBehavior.html">Thrift Interface Behavior</a>
            </li>
                  <li class="none">
            <strong>Testing with Llama</strong>
          </li>
                  <li class="none">
                  <a href="RunningLlama.html">Running Llama</a>
            </li>
                  <li class="none">
                  <a href="llama-site.html">LlamaAM Configuration</a>
            </li>
          </ul>
                                 <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
          <img alt="Built by Maven" src="./images/logos/maven-feather.png"/>
        </a>
                       
                            </div>
    </div>
    <div id="bodyColumn">
      <div id="contentBox">
        <!-- Licensed under the Apache License, Version 2.0 (the "License"); --><!-- you may not use this file except in compliance with the License. --><!-- You may obtain a copy of the License at --><!--  --><!-- http://www.apache.org/licenses/LICENSE-2.0 --><!--  --><!-- Unless required by applicable law or agreed to in writing, software --><!-- distributed under the License is distributed on an "AS IS" BASIS, --><!-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. --><!-- See the License for the specific language governing permissions and --><!-- limitations under the License. --><div class="section"><h2>Testing with Llama<a name="Testing_with_Llama"></a></h2><ul><li><a href="#Using_MiniLlama_from_within_Java_Testcases">Using MiniLlama from within Java Testcases</a><ul><li><a href="#Testcase_boiler_plate_code:">Testcase boiler plate code:</a></li></ul></li><li><a href="#Using_MiniLlama_from_the_Command-Line">Using MiniLlama from the Command-Line</a><ul><li><a href="#Install_MiniLlama">Install MiniLlama</a></li><li><a href="#Configure_MiniLlama">Configure MiniLlama</a></li><li><a href="#Run_MiniLlama">Run MiniLlama</a><ul><li><a href="#When_Running_MiniLlama_in_cluster_Mode">When Running MiniLlama in cluster Mode</a></li><li><a href="#When_Running_MiniLlama_in_minicluster_Mode">When Running MiniLlama in minicluster Mode</a></li></ul></li></ul></li><li><a href="#Using_the_LlamaClient_Command-Line_Tool">Using the LlamaClient Command-Line Tool</a><ul><li><a href="#Run_LlamaClient">Run LlamaClient</a></li></ul></li></ul><div class="section"><h3>Using MiniLlama from within Java Testcases<a name="Using_MiniLlama_from_within_Java_Testcases"></a></h3><p>Add the following dependency in your project</p><div class="source"><pre>    &lt;dependency&gt;
      &lt;groupId&gt;com.cloudera.llama&lt;/groupId&gt;
      &lt;artifactId&gt;mini-llama&lt;/artifactId&gt;
      &lt;version&gt;1.0.0-cdh5.0.0-SNAPSHOT&lt;/version&gt;
      &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;</pre></div><p>The Maven repository where SNAPSHOT artifacts are currently deployed is <tt><a class="externalLink" href="https://repository.cloudera.com/artifactory/libs-snapshot-local">https://repository.cloudera.com/artifactory/libs-snapshot-local</a></tt></p><p><b>IMPORTANT:</b> By default, MiniLlama uses an ephemeral port bound to <tt>localhost</tt> only.</p><div class="section"><h4>Testcase boiler plate code:<a name="Testcase_boiler_plate_code:"></a></h4><p>Using MiniLlama will also start a Hadoop HDFS/Yarn minicluster. You need to specify how many nodes (number of DataNodes and NodeManagers) for the Hadoop HDFS/Yarn minicluster.</p><p>You must have in your classpath (in a directory, not in a JAR) a <tt>fair-scheduler.xml</tt> file defining the FairScheduler queue configuration.</p><p>For example:</p><div class="source"><pre>public class TestUsingMiniLlama {

  private Configuration createMiniLlamaConfiguration() {
    URL url = Thread.currentThread().getContextClassLoader().getResource(
        &quot;fair-scheduler.xml&quot;);
    String fsallocationFile = url.toExternalForm();
    fsallocationFile = fsallocationFile.substring(&quot;file://&quot;.length());
    Configuration conf = MiniLlama.createMiniClusterConf(1);
    conf.set(&quot;yarn.scheduler.fair.allocation.file&quot;, fsallocationFile);
    conf.set(LlamaAM.INITIAL_QUEUES_KEY, &quot;default&quot;);
    return conf;
  }
  
  @Test
  public void testMiniLlama() throws Exception {
    Configuration conf = createMiniLlamaConfiguration();
    try {
      server.start();
      
      String serverHost = server.getAddressHost();
      String serverPort = server.getAddressPort();
      
      TTransport transport = new TSocket(server.getAddressHost(),
          server.getAddressPort());
      transport.open();
      TProtocol protocol = new TBinaryProtocol(transport);
      LlamaAMService.Client client = new LlamaAMService.Client(protocol);
      ....
    } finally {
      server.stop();
    }   
  }
}</pre></div><p>Example of a minimal <tt>fair-scheduler.xml</tt> configuration file defining 3 queues:</p><div class="source"><pre>&lt;allocations&gt;
  &lt;queue name=&quot;queue1&quot;&gt;
  &lt;/queue&gt;
  &lt;queue name=&quot;queue2&quot;&gt;
  &lt;/queue&gt;
  &lt;queue name=&quot;queue3&quot;&gt;
  &lt;/queue&gt;
&lt;/allocations&gt;</pre></div></div></div><div class="section"><h3>Using MiniLlama from the Command-Line<a name="Using_MiniLlama_from_the_Command-Line"></a></h3><p><b>IMPORTANT:</b> MiniLlama from the command-line is available from the mini-llama tarball, it is not available in the llama-dist tarball.</p><p>MiniLlama requires a local Hadoop cluster installation to pick up the Hadoop JAR files. The <tt>HADOOP_HOME</tt> environment variable must be defined.</p><div class="section"><h4>Install MiniLlama<a name="Install_MiniLlama"></a></h4><p>Expand the <tt>mini-llama-1.0.0-cdh5.0.0-SNAPSHOT.tar.gz</tt>.</p></div><div class="section"><h4>Configure MiniLlama<a name="Configure_MiniLlama"></a></h4><p>MiniLlama uses the following 2 configuration files from the installation directory:</p><ul><li><tt>conf/llama-site.xml</tt></li><li><tt>conf/llama-log4j.properties</tt></li></ul></div><div class="section"><h4>Run MiniLlama<a name="Run_MiniLlama"></a></h4><p>To run MiniLlama use the <tt>minillama</tt> script.</p><p>The <tt>minillama</tt> script supports the following commands and options:</p><div class="source"><pre>usage:

      minillama help : display usage for all commands or specified command

      minillama minicluster &lt;OPTIONS&gt; : start embedded mini HDFS/Yarn cluster

                            -hdfsnoformat          don't format mini HDFS
                            -hdfswriteconf &lt;arg&gt;   file to write mini HDFS configuration
                            -nodes &lt;arg&gt;           number of nodes (default: 1)

      minillama cluster : use external HDFS/Yarn cluster</pre></div><p>If MiniLlama is started with the <tt>minicluster</tt> sub-command, MiniLlama will bootstrap a HDFS/Yarn minicluster.</p><p>If MiniLlama is started with the <tt>cluster</tt> sub-command, it will use an existing HDFS/Yarn pseudo cluster.</p><div class="section"><h5>When Running MiniLlama in <tt>cluster</tt> Mode<a name="When_Running_MiniLlama_in_cluster_Mode"></a></h5><ul><li>The pseudo cluster may have several DataNodes and NodeManagers, but all have to be running in the same host.</li><li>All DataNodes and NodeManagers must be running at the time MiniLlama starts.</li><li>If the DataNodes or NodeManagers are restarted while MiniLlama is running they should come up in the same port they were running before.</li></ul></div><div class="section"><h5>When Running MiniLlama in <tt>minicluster</tt> Mode<a name="When_Running_MiniLlama_in_minicluster_Mode"></a></h5><ul><li>Hadoop core or hdfs configuration files must define the <tt>fs.defaultFS</tt> property.</li><li>The Yarn configuration must define the scheduler configuration and it should not include Map-Reduce's <tt>ShuffleHandler</tt> auxiliary service to avoid port conflicts.</li><li>The <tt>-nodes</tt> option indicates how many DataNodes and NodeManagers the minicluster will have have.</li><li>The <tt>-hdfsnoformat</tt> option it does not reformat MiniHDFS on startup.</li><li>The <tt>-hdfswriteconf FILE</tt> option writes out MiniHDFS configuration to the specified <b>FILE</b>.</li></ul></div></div></div><div class="section"><h3>Using the LlamaClient Command-Line Tool<a name="Using_the_LlamaClient_Command-Line_Tool"></a></h3><p>The LlamaClient command-line tool allows to interact with a Llama AM running from a proper installation or from MiniLlama.</p><p>LlamaClient can run a client callback server listening for notifications and support all Llama AM Thrift API operations: <tt>Register</tt>, <tt>Unregister</tt>, <tt>GetNodes</tt>, <tt>Reserve</tt> and <tt>Release</tt>.</p><p><b>IMPORTANT:</b> LlamaClient command-line line is available from the mini-llama tarball, it is not available in the llama-dist tarball.</p><p>Follow the steps to install and configure MiniLlama.</p><div class="section"><h4>Run LlamaClient<a name="Run_LlamaClient"></a></h4><p>The LlamaClient supports the following sub-command options:</p><div class="source"><pre>      llamaclient help : display usage for all commands or specified command

      llamaclient uuid : generate an UUID

      llamaclient register &lt;OPTIONS&gt; : register client

                           -callback &lt;arg&gt;   &lt;HOST&gt;:&lt;PORT&gt; of client's callback server
                           -clientid &lt;arg&gt;   client ID
                           -llama &lt;arg&gt;      &lt;HOST&gt;:&lt;PORT&gt; of llama
                           -nolog            no logging
                           -secure           uses kerberos

      llamaclient unregister &lt;OPTIONS&gt; : unregister client

                             -handle &lt;arg&gt;   &lt;UUID&gt; from registration
                             -llama &lt;arg&gt;    &lt;HOST&gt;:&lt;PORT&gt; of llama
                             -nolog          no logging
                             -secure         uses kerberos

      llamaclient getnodes &lt;OPTIONS&gt; : get cluster nodes

                           -handle &lt;arg&gt;   &lt;UUID&gt; from registration
                           -llama &lt;arg&gt;    &lt;HOST&gt;:&lt;PORT&gt; of llama
                           -nolog          no logging
                           -secure         uses kerberos

      llamaclient reserve &lt;OPTIONS&gt; : make a reservation

                          -cpus &lt;arg&gt;        cpus required per location of reservation
                          -handle &lt;arg&gt;      &lt;UUID&gt; from registration
                          -llama &lt;arg&gt;       &lt;HOST&gt;:&lt;PORT&gt; of llama
                          -locations &lt;arg&gt;   locations of reservation, comma separated
                          -memory &lt;arg&gt;      memory (MB) required per location of reservation
                          -nogang            no gang reservation
                          -nolog             no logging
                          -queue &lt;arg&gt;       queue of reservation
                          -relaxlocality     relax locality
                          -secure            uses kerberos

      llamaclient release &lt;OPTIONS&gt; : release a reservation

                          -handle &lt;arg&gt;        &lt;UUID&gt; from registration
                          -llama &lt;arg&gt;         &lt;HOST&gt;:&lt;PORT&gt; of llama
                          -nolog               no logging
                          -reservation &lt;arg&gt;   &lt;UUID&gt; from reservation
                          -secure              uses kerberos

      llamaclient callbackserver &lt;OPTIONS&gt; : run callback server

                                 -nolog        no logging
                                 -port &lt;arg&gt;   &lt;PORT&gt; of callback server
                                 -secure       uses kerberos

      llamaclient load &lt;OPTIONS&gt; : run a load

                       -allocationtimeout &lt;arg&gt;   allocation timeout, millisecs (default 10000)
                       -callback &lt;arg&gt;            &lt;HOST&gt;:&lt;PORT&gt; of client's callback server
                       -clients &lt;arg&gt;             number of clients
                       -cpus &lt;arg&gt;                cpus required per location of reservation
                       -holdtime &lt;arg&gt;            time to hold a reservation once allocated (-1 to
                                                  not wait for allocation and release immediately),
                                                  millisecs
                       -llama &lt;arg&gt;               &lt;HOST&gt;:&lt;PORT&gt; of llama
                       -locations &lt;arg&gt;           locations of reservation, comma separated
                       -memory &lt;arg&gt;              memory (MB) required per location of reservation
                       -nogang                    no gang reservation
                       -nolog                     no logging
                       -queue &lt;arg&gt;               queue of reservation
                       -relaxlocality             relax locality
                       -rounds &lt;arg&gt;              reservations per client
                       -sleeptime &lt;arg&gt;           time to sleep between  reservations, millisecs

*** Load Testing

  The &lt;&lt;&lt;llamaclient&gt;&gt;&gt; '&lt;&lt;&lt;load&gt;&gt;&gt;' sub-command allows to simulate basic load
  in Llama. The main motivation for this load testing is to stress Llama and
  and find out contention points and critical paths in Llama code.

  For example, a run using 100 clients doing 1000 reservations/releases without
  waiting for the allocation notification (&lt;&lt;&lt;-holdtime -1&gt;&gt;&gt;) and no sleep time
  between reservations is:
</pre></div></div></div></div><div class="section"><h2>$ bin/llamaclient load -llama localhost:15000 -callback localhost:20000 <br />-clients 100 -rounds 1000 -holdtime 0 -sleeptime 0 -locations node1,node2 <br />-cpus 1 -memory 1024 -queue queue1 -nolog<a name="a_binllamaclient_load_-llama_localhost:15000_-callback_localhost:20000_-clients_100_-rounds_1000_-holdtime_0_-sleeptime_0_-locations_node1node2_-cpus_1_-memory_1024_-queue_queue1_-nolog"></a></h2></div><div class="section"><h2>Llama load run:<a name="Llama_load_run:"></a></h2><p>Number of clients : 100 Reservations per client : 1000 Hold allocations for : 0 ms Sleep between reservations: 0 ms Allocation timeout : 10000 ms</p><p>Wall time : 31220 ms</p><p>Timed out allocations : 14</p><p>Reservation rate : 3204.743738595719 per sec</p><p>Register time (mean) : 6.87 ms Reserve time (mean) : 0.5457198443579767 ms Allocate time (mean) : 23.180933852140075 ms Release time (mean) : 0.48540856031128404 ms Unregister time (mean) : 82.76 ms</p></div><div class="section"><h2>$ +---+<a name="a_---"></a></h2><p>If <tt>-holdtime</tt> is set to <tt>-1</tt>, the Llama client will not wait for the allocation callback, it will immediately release the reservation. This can be use to add significantly more stress to Llama data structures and their synchronization.</p></div>
      </div>
    </div>
    <div class="clear">
      <hr/>
    </div>
    <div id="footer">
      <div class="xright">&#169;            2014
              Cloudera Inc
            
                       - <a href="http://maven.apache.org/privacy-policy.html">Privacy Policy</a></div>
      <div class="clear">
        <hr/>
      </div>
    </div>
  </body>
</html>
