From 591a8f9f0f3a9b58e199fc5cc669ab01afe7ffd2 Mon Sep 17 00:00:00 2001
From: Alexander Alten-Lorenz <alexander@cloudera.com>
Date: Tue, 15 Jan 2013 11:44:47 +0100
Subject: [PATCH 170/196] HBASE-6372 Add scanner batching to Export job

Description: When a single row is too large for the RS heap then an OOME can take out the entire RS. Setting scanner batching in custom scans helps avoiding this scenario, but for the supplied Export job this is not set.
Reason: Customer request
Author: Alexander Alten-Lorenz
Ref: CDH-7016
---
 .../org/apache/hadoop/hbase/mapreduce/Export.java  |   16 ++++++++++++++--
 1 files changed, 14 insertions(+), 2 deletions(-)

diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/Export.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/Export.java
index 2c53f6d..7de90e7 100644
--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/Export.java
+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/Export.java
@@ -48,7 +48,8 @@ import org.apache.commons.logging.LogFactory;
 public class Export {
   private static final Log LOG = LogFactory.getLog(Export.class);
   final static String NAME = "export";
-  final static String RAW_SCAN="hbase.mapreduce.include.deleted.rows";
+  final static String RAW_SCAN = "hbase.mapreduce.include.deleted.rows";
+  final static String EXPORT_BATCHING = "hbase.export.scanner.batch";
 
   /**
    * Mapper.
@@ -130,6 +131,15 @@ public class Export {
         LOG.info("Setting Scan Filter for Export.");
       s.setFilter(exportFilter);
     }
+
+    int batching = conf.getInt(EXPORT_BATCHING, -1);
+    if (batching !=  -1){
+      try{
+        s.setBatch(batching);
+	} catch (RuntimeException e) {
+	    LOG.error("Batching could not be set", e);
+      }
+    }
     LOG.info("versions=" + versions + ", starttime=" + startTime +
       ", endtime=" + endTime + ", keepDeletedCells=" + raw);
     return s;
@@ -170,6 +180,8 @@ public class Export {
         + "   -Dhbase.client.scanner.caching=100\n"
         + "   -Dmapred.map.tasks.speculative.execution=false\n"
         + "   -Dmapred.reduce.tasks.speculative.execution=false");
+    System.err.println("For tables with very wide rows consider setting the batch size as below:\n"
+        + "   -D" + EXPORT_BATCHING + "=10");
   }
 
   /**
@@ -188,4 +200,4 @@ public class Export {
     Job job = createSubmittableJob(conf, otherArgs);
     System.exit(job.waitForCompletion(true)? 0 : 1);
   }
-}
\ No newline at end of file
+}
-- 
1.7.0.4

