<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title></title><link rel="stylesheet" type="text/css" href="css/freebsd_docbook.css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.76.1"><meta name="description" content="This is the official book of Apache HBase, a distributed, versioned, column-oriented database built on top of Apache Hadoop and Apache ZooKeeper."></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="book"><div class="titlepage"><div><div><h1 class="title"><a name="d0e2"></a><a class="link" href="http://www.hbase.org" target="_top">
           <span class="inlinemediaobject"><img src="images/hbase_logo.png" align="middle"></span>
       </a>
    </h1></div><div><p class="copyright">Copyright &copy; 2011 Apache Software Foundation</p></div><div><div class="revhistory"><table border="1" width="100%" summary="Revision history"><tr><th align="left" valign="top" colspan="2"><b>Revision History</b></th></tr><tr><td align="left">Revision 
          0.92.0-cdh4b1
        </td><td align="left"></td></tr><tr><td align="left" colspan="2">HBase version</td></tr></table></div></div><div><div class="abstract" title="Abstract"><p class="title"><b>Abstract</b></p><p>This is the official book of
    <a class="link" href="http://www.hbase.org" target="_top">Apache HBase</a>,
    a distributed, versioned, column-oriented database built on top of
    <a class="link" href="http://hadoop.apache.org/" target="_top">Apache Hadoop</a> and
    <a class="link" href="http://zookeeper.apache.org/" target="_top">Apache ZooKeeper</a>.
      </p></div></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="preface"><a href="#preface">Preface</a></span></dt><dt><span class="chapter"><a href="#getting_started">1. Getting Started</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e75">1.1. Introduction</a></span></dt><dt><span class="section"><a href="#quickstart">1.2. Quick Start</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e91">1.2.1. Download and unpack the latest stable release.</a></span></dt><dt><span class="section"><a href="#start_hbase">1.2.2. Start HBase</a></span></dt><dt><span class="section"><a href="#shell_exercises">1.2.3. Shell Exercises</a></span></dt><dt><span class="section"><a href="#stopping">1.2.4. Stopping HBase</a></span></dt><dt><span class="section"><a href="#d0e248">1.2.5. Where to go next</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#configuration">2. Configuration</a></span></dt><dd><dl><dt><span class="section"><a href="#java">2.1. Java</a></span></dt><dt><span class="section"><a href="#os">2.2. Operating System</a></span></dt><dd><dl><dt><span class="section"><a href="#ssh">2.2.1. ssh</a></span></dt><dt><span class="section"><a href="#dns">2.2.2. DNS</a></span></dt><dt><span class="section"><a href="#ntp">2.2.3. NTP</a></span></dt><dt><span class="section"><a href="#ulimit">2.2.4. 
          <code class="varname">ulimit</code>
            and
          <code class="varname">nproc</code>
        </a></span></dt><dt><span class="section"><a href="#windows">2.2.5. Windows</a></span></dt></dl></dd><dt><span class="section"><a href="#hadoop">2.3. Hadoop</a></span></dt><dd><dl><dt><span class="section"><a href="#hadoop.security">2.3.1. Hadoop Security</a></span></dt><dt><span class="section"><a href="#dfs.datanode.max.xcievers">2.3.2. <code class="varname">dfs.datanode.max.xcievers</code></a></span></dt></dl></dd><dt><span class="section"><a href="#standalone_dist">2.4. HBase run modes: Standalone and Distributed</a></span></dt><dd><dl><dt><span class="section"><a href="#standalone">2.4.1. Standalone HBase</a></span></dt><dt><span class="section"><a href="#distributed">2.4.2. Distributed</a></span></dt><dt><span class="section"><a href="#confirm">2.4.3. Running and Confirming Your Installation</a></span></dt></dl></dd><dt><span class="section"><a href="#zookeeper">2.5. ZooKeeper</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e925">2.5.1. Using existing ZooKeeper ensemble</a></span></dt></dl></dd><dt><span class="section"><a href="#config.files">2.6. Configuration Files</a></span></dt><dd><dl><dt><span class="section"><a href="#hbase.site">2.6.1. <code class="filename">hbase-site.xml</code> and <code class="filename">hbase-default.xml</code></a></span></dt><dt><span class="section"><a href="#hbase.env.sh">2.6.2. <code class="filename">hbase-env.sh</code></a></span></dt><dt><span class="section"><a href="#log4j">2.6.3. <code class="filename">log4j.properties</code></a></span></dt><dt><span class="section"><a href="#client_dependencies">2.6.4. Client configuration and dependencies connecting to an HBase cluster</a></span></dt></dl></dd><dt><span class="section"><a href="#example_config">2.7. Example Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2081">2.7.1. Basic Distributed HBase Install</a></span></dt></dl></dd><dt><span class="section"><a href="#important_configurations">2.8. The Important Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#required_configuration">2.8.1. Required Configurations</a></span></dt><dt><span class="section"><a href="#recommended_configurations">2.8.2. Recommended Configuations</a></span></dt><dt><span class="section"><a href="#other_configuration">2.8.3. Other Configurations</a></span></dt></dl></dd><dt><span class="section"><a href="#config.bloom">2.9. Bloom Filter Configuration</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2317">2.9.1. <code class="varname">io.hfile.bloom.enabled</code> global kill
        switch</a></span></dt><dt><span class="section"><a href="#d0e2332">2.9.2. <code class="varname">io.hfile.bloom.error.rate</code></a></span></dt><dt><span class="section"><a href="#d0e2340">2.9.3. <code class="varname">io.hfile.bloom.max.fold</code></a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#upgrading">3. Upgrading</a></span></dt><dd><dl><dt><span class="section"><a href="#upgrade0.90">3.1. Upgrading to HBase 0.90.x from 0.20.x or 0.89.x</a></span></dt></dl></dd><dt><span class="chapter"><a href="#shell">4. The HBase Shell</a></span></dt><dd><dl><dt><span class="section"><a href="#scripting">4.1. Scripting</a></span></dt><dt><span class="section"><a href="#shell_tricks">4.2. Shell Tricks</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2456">4.2.1. <code class="filename">irbrc</code></a></span></dt><dt><span class="section"><a href="#d0e2474">4.2.2. LOG data to timestamp</a></span></dt><dt><span class="section"><a href="#d0e2492">4.2.3. Debug</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#datamodel">5. Data Model</a></span></dt><dd><dl><dt><span class="section"><a href="#conceptual.view">5.1. Conceptual View</a></span></dt><dt><span class="section"><a href="#physical.view">5.2. Physical View</a></span></dt><dt><span class="section"><a href="#table">5.3. Table</a></span></dt><dt><span class="section"><a href="#row">5.4. Row</a></span></dt><dt><span class="section"><a href="#columnfamily">5.5. Column Family</a></span></dt><dt><span class="section"><a href="#cells">5.6. Cells</a></span></dt><dt><span class="section"><a href="#data_model_operations">5.7. Data Model Operations</a></span></dt><dd><dl><dt><span class="section"><a href="#get">5.7.1. Get</a></span></dt><dt><span class="section"><a href="#put">5.7.2. Put</a></span></dt><dt><span class="section"><a href="#scan">5.7.3. Scans</a></span></dt><dt><span class="section"><a href="#delete">5.7.4. Delete</a></span></dt></dl></dd><dt><span class="section"><a href="#versions">5.8. Versions</a></span></dt><dd><dl><dt><span class="section"><a href="#versions.ops">5.8.1. Versions and HBase Operations</a></span></dt><dt><span class="section"><a href="#d0e3063">5.8.2. Current Limitations</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#schema">6. HBase and Schema Design</a></span></dt><dd><dl><dt><span class="section"><a href="#schema.creation">6.1. 
      Schema Creation
  </a></span></dt><dt><span class="section"><a href="#number.of.cfs">6.2. 
      On the number of column families
  </a></span></dt><dd><dl><dt><span class="section"><a href="#number.of.cfs.card">6.2.1. Cardinality of ColumnFamilies</a></span></dt></dl></dd><dt><span class="section"><a href="#rowkey.design">6.3. Rowkey Design</a></span></dt><dd><dl><dt><span class="section"><a href="#timeseries">6.3.1. 
    Monotonically Increasing Row Keys/Timeseries Data
    </a></span></dt><dt><span class="section"><a href="#keysize">6.3.2. Try to minimize row and column sizes</a></span></dt><dt><span class="section"><a href="#reverse.timestamp">6.3.3. Reverse Timestamps</a></span></dt><dt><span class="section"><a href="#rowkey.scope">6.3.4. Rowkeys and ColumnFamilies</a></span></dt><dt><span class="section"><a href="#changing.rowkeys">6.3.5. Immutability of Rowkeys</a></span></dt></dl></dd><dt><span class="section"><a href="#schema.versions">6.4. 
  Number of Versions
  </a></span></dt><dd><dl><dt><span class="section"><a href="#schema.versions.max">6.4.1. Maximum Number of Versions</a></span></dt><dt><span class="section"><a href="#schema.minversions">6.4.2. 
    Minimum Number of Versions
    </a></span></dt></dl></dd><dt><span class="section"><a href="#supported.datatypes">6.5. 
  Supported Datatypes
  </a></span></dt><dd><dl><dt><span class="section"><a href="#counters">6.5.1. Counters</a></span></dt></dl></dd><dt><span class="section"><a href="#ttl">6.6. Time To Live (TTL)</a></span></dt><dt><span class="section"><a href="#cf.keep.deleted">6.7. 
  Keeping Deleted Cells
  </a></span></dt><dt><span class="section"><a href="#secondary.indexes">6.8. 
  Secondary Indexes and Alternate Query Paths
  </a></span></dt><dd><dl><dt><span class="section"><a href="#secondary.indexes.filter">6.8.1. 
       Filter Query
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.periodic">6.8.2. 
       Periodic-Update Secondary Index
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.dualwrite">6.8.3. 
       Dual-Write Secondary Index
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.summary">6.8.4. 
       Summary Tables
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.coproc">6.8.5. 
       Coprocessor Secondary Index
      </a></span></dt></dl></dd><dt><span class="section"><a href="#schema.smackdown">6.9. Schema Design Smackdown</a></span></dt><dd><dl><dt><span class="section"><a href="#schema.smackdown.rowsversions">6.9.1. Rows vs. Versions</a></span></dt><dt><span class="section"><a href="#schema.smackdown.rowscols">6.9.2. Rows vs. Columns</a></span></dt></dl></dd><dt><span class="section"><a href="#schema.ops">6.10. Operational and Performance Configuration Options</a></span></dt></dl></dd><dt><span class="chapter"><a href="#mapreduce">7. HBase and MapReduce</a></span></dt><dd><dl><dt><span class="section"><a href="#splitter">7.1. Map-Task Spitting</a></span></dt><dd><dl><dt><span class="section"><a href="#splitter.default">7.1.1. The Default HBase MapReduce Splitter</a></span></dt><dt><span class="section"><a href="#splitter.custom">7.1.2. Custom Splitters</a></span></dt></dl></dd><dt><span class="section"><a href="#mapreduce.example">7.2. HBase MapReduce Examples</a></span></dt><dd><dl><dt><span class="section"><a href="#mapreduce.example.read">7.2.1. HBase MapReduce Read Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.readwrite">7.2.2. HBase MapReduce Read/Write Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.readwrite.multi">7.2.3. HBase MapReduce Read/Write Example With Multi-Table Output</a></span></dt><dt><span class="section"><a href="#mapreduce.example.summary">7.2.4. HBase MapReduce Summary Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.summary.file">7.2.5. HBase MapReduce Summary to File Example</a></span></dt></dl></dd><dt><span class="section"><a href="#mapreduce.htable.access">7.3. Accessing Other HBase Tables in a MapReduce Job</a></span></dt><dt><span class="section"><a href="#mapreduce.specex">7.4. Speculative Execution</a></span></dt></dl></dd><dt><span class="chapter"><a href="#architecture">8. Architecture</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.catalog">8.1. Catalog Tables</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.catalog.root">8.1.1. ROOT</a></span></dt><dt><span class="section"><a href="#arch.catalog.meta">8.1.2. META</a></span></dt><dt><span class="section"><a href="#arch.catalog.startup">8.1.3. Startup Sequencing</a></span></dt></dl></dd><dt><span class="section"><a href="#client">8.2. Client</a></span></dt><dd><dl><dt><span class="section"><a href="#client.connections">8.2.1. Connections</a></span></dt><dt><span class="section"><a href="#client.writebuffer">8.2.2. WriteBuffer and Batch Methods</a></span></dt><dt><span class="section"><a href="#client.external">8.2.3. External Clients</a></span></dt></dl></dd><dt><span class="section"><a href="#client.filter">8.3. Client Filters</a></span></dt><dd><dl><dt><span class="section"><a href="#client.filter.structural">8.3.1. Structural</a></span></dt><dt><span class="section"><a href="#client.filter.cv">8.3.2. Column Value</a></span></dt><dt><span class="section"><a href="#client.filter.cvp">8.3.3. Column Value Comparators</a></span></dt><dt><span class="section"><a href="#client.filter.kvm">8.3.4. KeyValue Metadata</a></span></dt><dt><span class="section"><a href="#client.filter.row">8.3.5. RowKey</a></span></dt><dt><span class="section"><a href="#client.filter.utility">8.3.6. Utility</a></span></dt></dl></dd><dt><span class="section"><a href="#master">8.4. Master</a></span></dt><dd><dl><dt><span class="section"><a href="#master.startup">8.4.1. Startup Behavior</a></span></dt><dt><span class="section"><a href="#master.api">8.4.2. Interface</a></span></dt><dt><span class="section"><a href="#master.processes">8.4.3. Processes</a></span></dt></dl></dd><dt><span class="section"><a href="#regionserver.arch">8.5. RegionServer</a></span></dt><dd><dl><dt><span class="section"><a href="#regionserver.arch.api">8.5.1. Interface</a></span></dt><dt><span class="section"><a href="#regionserver.arch.processes">8.5.2. Processes</a></span></dt><dt><span class="section"><a href="#block.cache">8.5.3. Block Cache</a></span></dt><dt><span class="section"><a href="#wal">8.5.4. Write Ahead Log (WAL)</a></span></dt></dl></dd><dt><span class="section"><a href="#regions.arch">8.6. Regions</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.regions.size">8.6.1. Region Size</a></span></dt><dt><span class="section"><a href="#d0e4152">8.6.2. Region Splits</a></span></dt><dt><span class="section"><a href="#regions.arch.balancer">8.6.3. Region Load Balancing</a></span></dt><dt><span class="section"><a href="#store">8.6.4. Store</a></span></dt><dt><span class="section"><a href="#blooms">8.6.5. Bloom Filters</a></span></dt></dl></dd><dt><span class="section"><a href="#arch.hdfs">8.7. HDFS</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.hdfs.nn">8.7.1. NameNode</a></span></dt><dt><span class="section"><a href="#arch.hdfs.dn">8.7.2. DataNode</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#external_apis">9. External APIs</a></span></dt><dd><dl><dt><span class="section"><a href="#nonjava.jvm">9.1. Non-Java Languages Talking to the JVM</a></span></dt><dt><span class="section"><a href="#rest">9.2. REST</a></span></dt><dt><span class="section"><a href="#thrift">9.3. Thrift</a></span></dt><dd><dl><dt><span class="section"><a href="#thrift.filter-language">9.3.1. Filter Language</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#performance">10. Performance Tuning</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.os">10.1. Operating System</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.os.ram">10.1.1. Memory</a></span></dt><dt><span class="section"><a href="#perf.os.64">10.1.2. 64-bit</a></span></dt><dt><span class="section"><a href="#perf.os.swap">10.1.3. Swapping</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.network">10.2. Network</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.network.1switch">10.2.1. Single Switch</a></span></dt><dt><span class="section"><a href="#perf.network.2switch">10.2.2. Multiple Switches</a></span></dt><dt><span class="section"><a href="#perf.network.multirack">10.2.3. Multiple Racks</a></span></dt></dl></dd><dt><span class="section"><a href="#jvm">10.3. Java</a></span></dt><dd><dl><dt><span class="section"><a href="#gc">10.3.1. The Garbage Collector and HBase</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.configurations">10.4. HBase Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.number.of.regions">10.4.1. Number of Regions</a></span></dt><dt><span class="section"><a href="#perf.compactions.and.splits">10.4.2. Managing Compactions</a></span></dt><dt><span class="section"><a href="#perf.handlers">10.4.3. <code class="varname">hbase.regionserver.handler.count</code></a></span></dt><dt><span class="section"><a href="#perf.hfile.block.cache.size">10.4.4. <code class="varname">hfile.block.cache.size</code></a></span></dt><dt><span class="section"><a href="#perf.rs.memstore.upperlimit">10.4.5. <code class="varname">hbase.regionserver.global.memstore.upperLimit</code></a></span></dt><dt><span class="section"><a href="#perf.rs.memstore.lowerlimit">10.4.6. <code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></a></span></dt><dt><span class="section"><a href="#perf.hstore.blockingstorefiles">10.4.7. <code class="varname">hbase.hstore.blockingStoreFiles</code></a></span></dt><dt><span class="section"><a href="#perf.hregion.memstore.block.multiplier">10.4.8. <code class="varname">hbase.hregion.memstore.block.multiplier</code></a></span></dt></dl></dd><dt><span class="section"><a href="#perf.schema">10.5. Schema Design</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.number.of.cfs">10.5.1. Number of Column Families</a></span></dt><dt><span class="section"><a href="#perf.schema.keys">10.5.2. Key and Attribute Lengths</a></span></dt><dt><span class="section"><a href="#schema.regionsize">10.5.3. Table RegionSize</a></span></dt><dt><span class="section"><a href="#schema.bloom">10.5.4. Bloom Filters</a></span></dt><dt><span class="section"><a href="#schema.cf.blocksize">10.5.5. ColumnFamily BlockSize</a></span></dt><dt><span class="section"><a href="#cf.in.memory">10.5.6. In-Memory ColumnFamilies</a></span></dt><dt><span class="section"><a href="#perf.compression">10.5.7. Compression</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.writing">10.6. Writing to HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.batch.loading">10.6.1. Batch Loading</a></span></dt><dt><span class="section"><a href="#precreate.regions">10.6.2. 
    Table Creation: Pre-Creating Regions
    </a></span></dt><dt><span class="section"><a href="#def.log.flush">10.6.3. 
    Table Creation: Deferred Log Flush
    </a></span></dt><dt><span class="section"><a href="#perf.hbase.client.autoflush">10.6.4. HBase Client:  AutoFlush</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.putwal">10.6.5. HBase Client:  Turn off WAL on Puts</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.regiongroup">10.6.6. HBase Client: Group Puts by RegionServer</a></span></dt><dt><span class="section"><a href="#perf.hbase.write.mr.reducer">10.6.7. MapReduce:  Skip The Reducer</a></span></dt><dt><span class="section"><a href="#perf.one.region">10.6.8. Anti-Pattern:  One Hot Region</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.reading">10.7. Reading from HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.hbase.client.caching">10.7.1. Scan Caching</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.selection">10.7.2. Scan Attribute Selection</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.scannerclose">10.7.3. Close ResultScanners</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.blockcache">10.7.4. Block Cache</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.rowkeyonly">10.7.5. Optimal Loading of Row Keys</a></span></dt><dt><span class="section"><a href="#perf.hbase.read.dist">10.7.6. Concurrency:  Monitor Data Spread</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.deleting">10.8. Deleting from HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.deleting.queue">10.8.1. Using HBase Tables as Queues</a></span></dt><dt><span class="section"><a href="#perf.deleting.rpc">10.8.2. Delete RPC Behavior</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.hdfs">10.9. HDFS</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.hdfs.curr">10.9.1. Current Issues With Low-Latency Reads</a></span></dt><dt><span class="section"><a href="#perf.hdfs.comp">10.9.2. Performance Comparisons of HBase vs. HDFS</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.ec2">10.10. Amazon EC2</a></span></dt></dl></dd><dt><span class="chapter"><a href="#trouble">11. Troubleshooting and Debugging HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.general">11.1. General Guidelines</a></span></dt><dt><span class="section"><a href="#trouble.log">11.2. Logs</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.log.locations">11.2.1. Log Locations</a></span></dt><dt><span class="section"><a href="#trouble.log.levels">11.2.2. Log Levels</a></span></dt><dt><span class="section"><a href="#trouble.log.gc">11.2.3. JVM Garbage Collection Logs</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.tools">11.3. Tools</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.tools.builtin">11.3.1. Builtin Tools</a></span></dt><dt><span class="section"><a href="#trouble.tools.external">11.3.2. External Tools</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.client">11.4. Client</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.client.scantimeout">11.4.1. ScannerTimeoutException or UnknownScannerException</a></span></dt><dt><span class="section"><a href="#trouble.client.scarylogs">11.4.2. Shell or client application throws lots of scary exceptions during normal operation</a></span></dt><dt><span class="section"><a href="#trouble.client.longpauseswithcompression">11.4.3. Long Client Pauses With Compression</a></span></dt><dt><span class="section"><a href="#trouble.client.zookeeper">11.4.4. ZooKeeper Client Connection Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.namenode">11.5. NameNode</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.namenode.disk">11.5.1. HDFS Utilization of Tables and Regions</a></span></dt><dt><span class="section"><a href="#trouble.namenode.hbase.objects">11.5.2. Browsing HDFS for HBase Objects</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.rs">11.6. RegionServer</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.rs.startup">11.6.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.rs.runtime">11.6.2. Runtime Errors</a></span></dt><dt><span class="section"><a href="#trouble.rs.shutdown">11.6.3. Shutdown Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.master">11.7. Master</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.master.startup">11.7.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.master.shutdown">11.7.2. Shutdown Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.zookeeper">11.8. ZooKeeper</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.zookeeper.startup">11.8.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.zookeeper.general">11.8.2. ZooKeeper, The Cluster Canary</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.ec2">11.9. Amazon EC2</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.ec2.zookeeper">11.9.1. ZooKeeper does not seem to work on Amazon EC2</a></span></dt><dt><span class="section"><a href="#trouble.ec2.instability">11.9.2. Instability on Amazon EC2</a></span></dt><dt><span class="section"><a href="#trouble.ec2.connection">11.9.3. Remote Java Connection into EC2 Cluster Not Working</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#ops_mgt">12. HBase Operational Management</a></span></dt><dd><dl><dt><span class="section"><a href="#tools">12.1. HBase Tools and Utilities</a></span></dt><dd><dl><dt><span class="section"><a href="#hbck">12.1.1. HBase <span class="application">hbck</span></a></span></dt><dt><span class="section"><a href="#hfile_tool2">12.1.2. HFile Tool</a></span></dt><dt><span class="section"><a href="#wal_tools">12.1.3. WAL Tools</a></span></dt><dt><span class="section"><a href="#compression.tool">12.1.4. Compression Tool</a></span></dt><dt><span class="section"><a href="#copytable">12.1.5. CopyTable</a></span></dt><dt><span class="section"><a href="#export">12.1.6. Export</a></span></dt><dt><span class="section"><a href="#import">12.1.7. Import</a></span></dt><dt><span class="section"><a href="#rowcounter">12.1.8. RowCounter</a></span></dt></dl></dd><dt><span class="section"><a href="#node.management">12.2. Node Management</a></span></dt><dd><dl><dt><span class="section"><a href="#decommission">12.2.1. Node Decommission</a></span></dt><dt><span class="section"><a href="#rolling">12.2.2. Rolling Restart</a></span></dt></dl></dd><dt><span class="section"><a href="#hbase_metrics">12.3. Metrics</a></span></dt><dd><dl><dt><span class="section"><a href="#metric_setup">12.3.1. Metric Setup</a></span></dt><dt><span class="section"><a href="#rs_metrics">12.3.2. RegionServer Metrics</a></span></dt></dl></dd><dt><span class="section"><a href="#ops.monitoring">12.4. HBase Monitoring</a></span></dt><dt><span class="section"><a href="#cluster_replication">12.5. Cluster Replication</a></span></dt><dt><span class="section"><a href="#ops.backup">12.6. HBase Backup</a></span></dt><dd><dl><dt><span class="section"><a href="#ops.backup.fullshutdown">12.6.1. Full Shutdown Backup</a></span></dt><dt><span class="section"><a href="#ops.backup.live.replication">12.6.2. Live Cluster Backup - Replication</a></span></dt><dt><span class="section"><a href="#ops.backup.live.copytable">12.6.3. Live Cluster Backup - CopyTable</a></span></dt><dt><span class="section"><a href="#ops.backup.live.export">12.6.4. Live Cluster Backup - Export</a></span></dt></dl></dd><dt><span class="section"><a href="#ops.capacity">12.7. Capacity Planning</a></span></dt><dd><dl><dt><span class="section"><a href="#ops.capacity.storage">12.7.1. Storage</a></span></dt><dt><span class="section"><a href="#ops.capacity.regions">12.7.2. Regions</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#developer">13. Building and Developing HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#repos">13.1. HBase Repositories</a></span></dt><dd><dl><dt><span class="section"><a href="#svn">13.1.1. SVN</a></span></dt><dt><span class="section"><a href="#git">13.1.2. Git</a></span></dt></dl></dd><dt><span class="section"><a href="#ides">13.2. IDEs</a></span></dt><dd><dl><dt><span class="section"><a href="#eclipse">13.2.1. Eclipse</a></span></dt></dl></dd><dt><span class="section"><a href="#build">13.3. Building HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#build.snappy">13.3.1. Building in snappy compression support</a></span></dt><dt><span class="section"><a href="#mvn_repo">13.3.2. Adding an HBase release to Apache's Maven Repository</a></span></dt></dl></dd><dt><span class="section"><a href="#maven.build.commands">13.4. Maven Build Commands</a></span></dt><dd><dl><dt><span class="section"><a href="#maven.build.commands.compile">13.4.1. Compile</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unitall">13.4.2. Run all Unit Tests</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit">13.4.3. Run a Single Unit Test</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit2">13.4.4. Run a Few Unit Tests</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit.package">13.4.5. Run all Unit Tests for a Package</a></span></dt><dt><span class="section"><a href="#maven.build.commanas.integration.tests">13.4.6. Integration Tests</a></span></dt></dl></dd><dt><span class="section"><a href="#getting.involved">13.5. Getting Involved</a></span></dt><dd><dl><dt><span class="section"><a href="#mailing.list">13.5.1. Mailing Lists</a></span></dt><dt><span class="section"><a href="#jira">13.5.2. Jira</a></span></dt></dl></dd><dt><span class="section"><a href="#developing">13.6. Developing</a></span></dt><dd><dl><dt><span class="section"><a href="#codelines">13.6.1. Codelines</a></span></dt><dt><span class="section"><a href="#unit.tests">13.6.2. Unit Tests</a></span></dt></dl></dd><dt><span class="section"><a href="#submitting.patches">13.7. Submitting Patches</a></span></dt><dd><dl><dt><span class="section"><a href="#submitting.patches.create">13.7.1. Create Patch</a></span></dt><dt><span class="section"><a href="#submitting.patches.naming">13.7.2. Patch File Naming</a></span></dt><dt><span class="section"><a href="#submitting.patches.tests">13.7.3. Unit Tests</a></span></dt><dt><span class="section"><a href="#submitting.patches.jira">13.7.4. Attach Patch to Jira</a></span></dt><dt><span class="section"><a href="#common.patch.feedback">13.7.5. Common Patch Feedback</a></span></dt><dt><span class="section"><a href="#reviewboard">13.7.6. ReviewBoard</a></span></dt><dt><span class="section"><a href="#committing.patches">13.7.7. Committing Patches</a></span></dt></dl></dd></dl></dd><dt><span class="appendix"><a href="#compression">A. Compression In HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#compression.test">A.1. CompressionTest Tool</a></span></dt><dt><span class="section"><a href="#hbase.regionserver.codecs">A.2. 
    <code class="varname">
    hbase.regionserver.codecs
    </code>
    </a></span></dt><dt><span class="section"><a href="#lzo.compression">A.3. 
    LZO
    </a></span></dt><dt><span class="section"><a href="#gzip.compression">A.4. 
    GZIP
    </a></span></dt><dt><span class="section"><a href="#snappy.compression">A.5. 
    SNAPPY
    </a></span></dt></dl></dd><dt><span class="appendix"><a href="#faq">B. FAQ</a></span></dt><dt><span class="appendix"><a href="#d0e7678">C. YCSB: The Yahoo! Cloud Serving Benchmark and HBase</a></span></dt><dt><span class="appendix"><a href="#hfilev2">D. HFile format version 2</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e7695">D.1. Motivation </a></span></dt><dt><span class="section"><a href="#d0e7706">D.2. HFile format version 1 overview </a></span></dt><dd><dl><dt><span class="section"><a href="#d0e7728">D.2.1.  Block index format in version 1 </a></span></dt></dl></dd><dt><span class="section"><a href="#d0e7752">D.3. 
      HBase file format with inline blocks (version 2)
      </a></span></dt><dd><dl><dt><span class="section"><a href="#d0e7755">D.3.1.  Overview</a></span></dt><dt><span class="section"><a href="#d0e7770">D.3.2. Unified version 2 block format</a></span></dt><dt><span class="section"><a href="#d0e7839">D.3.3.  Block index in version 2</a></span></dt><dt><span class="section"><a href="#d0e7864">D.3.4. 
      Root block index format in version 2</a></span></dt><dt><span class="section"><a href="#d0e7917">D.3.5. 
      Non-root block index format in version 2</a></span></dt><dt><span class="section"><a href="#d0e7942">D.3.6. 
      Bloom filters in version 2</a></span></dt><dt><span class="section"><a href="#d0e7979">D.3.7. File Info format in versions 1 and 2</a></span></dt><dt><span class="section"><a href="#d0e8025">D.3.8. 
      Fixed file trailer format differences between versions 1 and 2</a></span></dt></dl></dd></dl></dd><dt><span class="appendix"><a href="#asf">E. HBase and the Apache Software Foundation</a></span></dt><dt><span class="index"><a href="#book_index">Index</a></span></dt></dl></div><div class="list-of-tables"><p><b>List of Tables</b></p><dl><dt>5.1. <a href="#d0e2574">Table <code class="varname">webtable</code></a></dt><dt>5.2. <a href="#d0e2658">ColumnFamily <code class="varname">anchor</code></a></dt><dt>5.3. <a href="#d0e2697">ColumnFamily <code class="varname">contents</code></a></dt></dl></div><div class="preface" title="Preface"><div class="titlepage"><div><div><h2 class="title"><a name="preface"></a>Preface</h2></div></div></div><p>This book aims to be the official guide for the <a class="link" href="http://hbase.apache.org/" target="_top">HBase</a> version it ships with.
  This document describes HBase version <span class="emphasis"><em>0.92.0-cdh4b1</em></span>.
  Herein you will find either the definitive documentation on an HBase topic
  as of its standing when the referenced HBase version shipped, or this book
  will point to the location in <a class="link" href="http://hbase.apache.org/docs/current/api/index.html" target="_top">javadoc</a>,
  <a class="link" href="https://issues.apache.org/jira/browse/HBASE" target="_top">JIRA</a>
  or <a class="link" href="http://wiki.apache.org/hadoop/Hbase" target="_top">wiki</a> where
  the pertinent information can be found.</p><p>This book is a work in progress.  Feel free to add to this book by adding
  a patch to an issue up in the HBase <a class="link" href="https://issues.apache.org/jira/browse/HBASE" target="_top">JIRA</a>.</p><div class="note" title="Heads-up" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a name="headsup"></a>Heads-up</h3><p>
          If this is your first foray into the wonderful world of
          Distributed Computing, then you are in for
          some interesting times.  First off, distributed systems are
          hard; making a distributed system hum requires a disparate
          skillset that needs span systems (hardware and software) and
          networking.  Your cluster' operation can hiccup because of any
          of a myriad set of reasons from bugs in HBase itself through misconfigurations
          -- misconfiguration of HBase but also operating system misconfigurations --
          through to hardware problems whether it be a bug in your network card
          drivers or an underprovisioned RAM bus (to mention two recent
          examples of hardware issues that manifested as "HBase is slow").
          You will also need to do a recalibration if up to this your
          computing has been bound to a single box.  Here is one good
          starting point:
          <a class="link" href="http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing" target="_top">Fallacies of Distributed Computing</a>.
      </p></div></div><div class="chapter" title="Chapter&nbsp;1.&nbsp;Getting Started"><div class="titlepage"><div><div><h2 class="title"><a name="getting_started"></a>Chapter&nbsp;1.&nbsp;Getting Started</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#d0e75">1.1. Introduction</a></span></dt><dt><span class="section"><a href="#quickstart">1.2. Quick Start</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e91">1.2.1. Download and unpack the latest stable release.</a></span></dt><dt><span class="section"><a href="#start_hbase">1.2.2. Start HBase</a></span></dt><dt><span class="section"><a href="#shell_exercises">1.2.3. Shell Exercises</a></span></dt><dt><span class="section"><a href="#stopping">1.2.4. Stopping HBase</a></span></dt><dt><span class="section"><a href="#d0e248">1.2.5. Where to go next</a></span></dt></dl></dd></dl></div><div class="section" title="1.1.&nbsp;Introduction"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e75"></a>1.1.&nbsp;Introduction</h2></div></div></div><p><a class="xref" href="#quickstart" title="1.2.&nbsp;Quick Start">Section&nbsp;1.2, &#8220;Quick Start&#8221;</a> will get you up and
    running on a single-node instance of HBase using the local filesystem. 
    <a class="xref" href="#configuration" title="Chapter&nbsp;2.&nbsp;Configuration">Chapter&nbsp;2, <i>Configuration</i></a> describes setup
    of HBase in distributed mode running on top of HDFS.</p></div><div class="section" title="1.2.&nbsp;Quick Start"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="quickstart"></a>1.2.&nbsp;Quick Start</h2></div></div></div><p>This guide describes setup of a standalone HBase instance that uses
    the local filesystem. It leads you through creating a table, inserting
    rows via the HBase <span class="command"><strong>shell</strong></span>, and then cleaning
    up and shutting down your standalone HBase instance. The below exercise
    should take no more than ten minutes (not including download time).</p><div class="section" title="1.2.1.&nbsp;Download and unpack the latest stable release."><div class="titlepage"><div><div><h3 class="title"><a name="d0e91"></a>1.2.1.&nbsp;Download and unpack the latest stable release.</h3></div></div></div><p>Choose a download site from this list of <a class="link" href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_top">Apache Download
      Mirrors</a>. Click on suggested top link. This will take you to a
      mirror of <span class="emphasis"><em>HBase Releases</em></span>. Click on the folder named
      <code class="filename">stable</code> and then download the file that ends in
      <code class="filename">.tar.gz</code> to your local filesystem; e.g.
      <code class="filename">hbase-0.92.0-cdh4b1.tar.gz</code>.</p><p>Decompress and untar your download and then change into the
      unpacked directory.</p><pre class="programlisting">$ tar xfz hbase-0.92.0-cdh4b1.tar.gz
$ cd hbase-0.92.0-cdh4b1
</pre><p>At this point, you are ready to start HBase. But before starting
      it, you might want to edit <code class="filename">conf/hbase-site.xml</code> and
      set the directory you want HBase to write to,
      <code class="varname">hbase.rootdir</code>. </p><pre class="programlisting">

&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;file:///DIRECTORY/hbase&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

</pre><p> Replace <code class="varname">DIRECTORY</code> in the above with a
      path to a directory where you want HBase to store its data. By default,
      <code class="varname">hbase.rootdir</code> is set to
      <code class="filename">/tmp/hbase-${user.name}</code> which means you'll lose all
      your data whenever your server reboots (Most operating systems clear
      <code class="filename">/tmp</code> on restart).</p></div><div class="section" title="1.2.2.&nbsp;Start HBase"><div class="titlepage"><div><div><h3 class="title"><a name="start_hbase"></a>1.2.2.&nbsp;Start HBase</h3></div></div></div><p>Now start HBase:</p><pre class="programlisting">$ ./bin/start-hbase.sh
starting Master, logging to logs/hbase-user-master-example.org.out</pre><p>You should now have a running standalone HBase instance. In
      standalone mode, HBase runs all daemons in the the one JVM; i.e. both
      the HBase and ZooKeeper daemons. HBase logs can be found in the
      <code class="filename">logs</code> subdirectory. Check them out especially if
      HBase had trouble starting.</p><div class="note" title="Is java installed?" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Is <span class="application">java</span> installed?</h3><p>All of the above presumes a 1.6 version of Oracle
        <span class="application">java</span> is installed on your machine and
        available on your path; i.e. when you type
        <span class="application">java</span>, you see output that describes the
        options the java program takes (HBase requires java 6). If this is not
        the case, HBase will not start. Install java, edit
        <code class="filename">conf/hbase-env.sh</code>, uncommenting the
        <code class="envar">JAVA_HOME</code> line pointing it to your java install. Then,
        retry the steps above.</p></div></div><div class="section" title="1.2.3.&nbsp;Shell Exercises"><div class="titlepage"><div><div><h3 class="title"><a name="shell_exercises"></a>1.2.3.&nbsp;Shell Exercises</h3></div></div></div><p>Connect to your running HBase via the <span class="command"><strong>shell</strong></span>.</p><pre class="programlisting">$ ./bin/hbase shell
HBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.
Type "exit&lt;RETURN&gt;" to leave the HBase Shell
Version: 0.90.0, r1001068, Fri Sep 24 13:55:42 PDT 2010

hbase(main):001:0&gt; </pre><p>Type <span class="command"><strong>help</strong></span> and then
      <span class="command"><strong>&lt;RETURN&gt;</strong></span> to see a listing of shell commands and
      options. Browse at least the paragraphs at the end of the help emission
      for the gist of how variables and command arguments are entered into the
      HBase shell; in particular note how table names, rows, and columns,
      etc., must be quoted.</p><p>Create a table named <code class="varname">test</code> with a single column family named <code class="varname">cf</code>.
      Verify its creation by listing all tables and then insert some
      values.</p><pre class="programlisting">hbase(main):003:0&gt; create 'test', 'cf'
0 row(s) in 1.2200 seconds
hbase(main):003:0&gt; list 'table'
test
1 row(s) in 0.0550 seconds
hbase(main):004:0&gt; put 'test', 'row1', 'cf:a', 'value1'
0 row(s) in 0.0560 seconds
hbase(main):005:0&gt; put 'test', 'row2', 'cf:b', 'value2'
0 row(s) in 0.0370 seconds
hbase(main):006:0&gt; put 'test', 'row3', 'cf:c', 'value3'
0 row(s) in 0.0450 seconds</pre><p>Above we inserted 3 values, one at a time. The first insert is at
      <code class="varname">row1</code>, column <code class="varname">cf:a</code> with a value of
      <code class="varname">value1</code>. Columns in HBase are comprised of a column family prefix --
      <code class="varname">cf</code> in this example -- followed by a colon and then a
      column qualifier suffix (<code class="varname">a</code> in this case).</p><p>Verify the data insert.</p><p>Run a scan of the table by doing the following</p><pre class="programlisting">hbase(main):007:0&gt; scan 'test'
ROW        COLUMN+CELL
row1       column=cf:a, timestamp=1288380727188, value=value1
row2       column=cf:b, timestamp=1288380738440, value=value2
row3       column=cf:c, timestamp=1288380747365, value=value3
3 row(s) in 0.0590 seconds</pre><p>Get a single row as follows</p><pre class="programlisting">hbase(main):008:0&gt; get 'test', 'row1'
COLUMN      CELL
cf:a        timestamp=1288380727188, value=value1
1 row(s) in 0.0400 seconds</pre><p>Now, disable and drop your table. This will clean up all done
      above.</p><pre class="programlisting">hbase(main):012:0&gt; disable 'test'
0 row(s) in 1.0930 seconds
hbase(main):013:0&gt; drop 'test'
0 row(s) in 0.0770 seconds </pre><p>Exit the shell by typing exit.</p><pre class="programlisting">hbase(main):014:0&gt; exit</pre></div><div class="section" title="1.2.4.&nbsp;Stopping HBase"><div class="titlepage"><div><div><h3 class="title"><a name="stopping"></a>1.2.4.&nbsp;Stopping HBase</h3></div></div></div><p>Stop your hbase instance by running the stop script.</p><pre class="programlisting">$ ./bin/stop-hbase.sh
stopping hbase...............</pre></div><div class="section" title="1.2.5.&nbsp;Where to go next"><div class="titlepage"><div><div><h3 class="title"><a name="d0e248"></a>1.2.5.&nbsp;Where to go next</h3></div></div></div><p>The above described standalone setup is good for testing and
          experiments only. Next move on to <a class="xref" href="#configuration" title="Chapter&nbsp;2.&nbsp;Configuration">Chapter&nbsp;2, <i>Configuration</i></a> where we'll go into
      depth on the different HBase run modes, requirements and critical
      configurations needed setting up a distributed HBase deploy.</p></div></div></div><div class="chapter" title="Chapter&nbsp;2.&nbsp;Configuration"><div class="titlepage"><div><div><h2 class="title"><a name="configuration"></a>Chapter&nbsp;2.&nbsp;Configuration</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#java">2.1. Java</a></span></dt><dt><span class="section"><a href="#os">2.2. Operating System</a></span></dt><dd><dl><dt><span class="section"><a href="#ssh">2.2.1. ssh</a></span></dt><dt><span class="section"><a href="#dns">2.2.2. DNS</a></span></dt><dt><span class="section"><a href="#ntp">2.2.3. NTP</a></span></dt><dt><span class="section"><a href="#ulimit">2.2.4. 
          <code class="varname">ulimit</code>
            and
          <code class="varname">nproc</code>
        </a></span></dt><dt><span class="section"><a href="#windows">2.2.5. Windows</a></span></dt></dl></dd><dt><span class="section"><a href="#hadoop">2.3. Hadoop</a></span></dt><dd><dl><dt><span class="section"><a href="#hadoop.security">2.3.1. Hadoop Security</a></span></dt><dt><span class="section"><a href="#dfs.datanode.max.xcievers">2.3.2. <code class="varname">dfs.datanode.max.xcievers</code></a></span></dt></dl></dd><dt><span class="section"><a href="#standalone_dist">2.4. HBase run modes: Standalone and Distributed</a></span></dt><dd><dl><dt><span class="section"><a href="#standalone">2.4.1. Standalone HBase</a></span></dt><dt><span class="section"><a href="#distributed">2.4.2. Distributed</a></span></dt><dt><span class="section"><a href="#confirm">2.4.3. Running and Confirming Your Installation</a></span></dt></dl></dd><dt><span class="section"><a href="#zookeeper">2.5. ZooKeeper</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e925">2.5.1. Using existing ZooKeeper ensemble</a></span></dt></dl></dd><dt><span class="section"><a href="#config.files">2.6. Configuration Files</a></span></dt><dd><dl><dt><span class="section"><a href="#hbase.site">2.6.1. <code class="filename">hbase-site.xml</code> and <code class="filename">hbase-default.xml</code></a></span></dt><dt><span class="section"><a href="#hbase.env.sh">2.6.2. <code class="filename">hbase-env.sh</code></a></span></dt><dt><span class="section"><a href="#log4j">2.6.3. <code class="filename">log4j.properties</code></a></span></dt><dt><span class="section"><a href="#client_dependencies">2.6.4. Client configuration and dependencies connecting to an HBase cluster</a></span></dt></dl></dd><dt><span class="section"><a href="#example_config">2.7. Example Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2081">2.7.1. Basic Distributed HBase Install</a></span></dt></dl></dd><dt><span class="section"><a href="#important_configurations">2.8. The Important Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#required_configuration">2.8.1. Required Configurations</a></span></dt><dt><span class="section"><a href="#recommended_configurations">2.8.2. Recommended Configuations</a></span></dt><dt><span class="section"><a href="#other_configuration">2.8.3. Other Configurations</a></span></dt></dl></dd><dt><span class="section"><a href="#config.bloom">2.9. Bloom Filter Configuration</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2317">2.9.1. <code class="varname">io.hfile.bloom.enabled</code> global kill
        switch</a></span></dt><dt><span class="section"><a href="#d0e2332">2.9.2. <code class="varname">io.hfile.bloom.error.rate</code></a></span></dt><dt><span class="section"><a href="#d0e2340">2.9.3. <code class="varname">io.hfile.bloom.max.fold</code></a></span></dt></dl></dd></dl></div><p>This chapter is the Not-So-Quick start guide to HBase configuration.</p><p>Please read this chapter carefully and ensure that all requirements have 
      been satisfied.  Failure to do so will cause you (and us) grief debugging strange errors
      and/or data loss.</p><p>
        HBase uses the same configuration system as Hadoop.
        To configure a deploy, edit a file of environment variables
        in <code class="filename">conf/hbase-env.sh</code> -- this configuration
        is used mostly by the launcher shell scripts getting the cluster
        off the ground -- and then add configuration to an XML file to
        do things like override HBase defaults, tell HBase what Filesystem to
        use, and the location of the ZooKeeper ensemble
        <sup>[<a name="d0e268" href="#ftn.d0e268" class="footnote">1</a>]</sup>
        .
    </p><p>When running in distributed mode, after you make
    an edit to an HBase configuration, make sure you copy the
    content of the <code class="filename">conf</code> directory to
    all nodes of the cluster.  HBase will not do this for you.
    Use <span class="command"><strong>rsync</strong></span>.</p><div class="section" title="2.1.&nbsp;Java"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="java"></a>2.1.&nbsp;Java</h2></div></div></div><p>Just like Hadoop, HBase requires java 6 from <a class="link" href="http://www.java.com/download/" target="_top">Oracle</a>. Usually
        you'll want to use the latest version available except the problematic
        u18 (u24 is the latest version as of this writing).</p></div><div class="section" title="2.2.&nbsp;Operating System"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="os"></a>2.2.&nbsp;Operating System</h2></div></div></div><div class="section" title="2.2.1.&nbsp;ssh"><div class="titlepage"><div><div><h3 class="title"><a name="ssh"></a>2.2.1.&nbsp;ssh</h3></div></div></div><p><span class="command"><strong>ssh</strong></span> must be installed and
        <span class="command"><strong>sshd</strong></span> must be running to use Hadoop's scripts to
        manage remote Hadoop and HBase daemons. You must be able to ssh to all
        nodes, including your local node, using passwordless login (Google
        "ssh passwordless login").</p></div><div class="section" title="2.2.2.&nbsp;DNS"><div class="titlepage"><div><div><h3 class="title"><a name="dns"></a>2.2.2.&nbsp;DNS</h3></div></div></div><p>HBase uses the local hostname to self-report it's IP address.
        Both forward and reverse DNS resolving should work.</p><p>If your machine has multiple interfaces, HBase will use the
        interface that the primary hostname resolves to.</p><p>If this is insufficient, you can set
        <code class="varname">hbase.regionserver.dns.interface</code> to indicate the
        primary interface. This only works if your cluster configuration is
        consistent and every host has the same network interface
        configuration.</p><p>Another alternative is setting
        <code class="varname">hbase.regionserver.dns.nameserver</code> to choose a
        different nameserver than the system wide default.</p></div><div class="section" title="2.2.3.&nbsp;NTP"><div class="titlepage"><div><div><h3 class="title"><a name="ntp"></a>2.2.3.&nbsp;NTP</h3></div></div></div><p>The clocks on cluster members should be in basic alignments.
        Some skew is tolerable but wild skew could generate odd behaviors. Run
        <a class="link" href="http://en.wikipedia.org/wiki/Network_Time_Protocol" target="_top">NTP</a>
        on your cluster, or an equivalent.</p><p>If you are having problems querying data, or "weird" cluster
        operations, check system time!</p></div><div class="section" title="2.2.4.&nbsp; ulimit and nproc"><div class="titlepage"><div><div><h3 class="title"><a name="ulimit"></a>2.2.4.&nbsp;
          <code class="varname">ulimit</code><a class="indexterm" name="d0e336"></a>
            and
          <code class="varname">nproc</code><a class="indexterm" name="d0e342"></a>
        </h3></div></div></div><p>HBase is a database.  It uses a lot of files all at the same time.
        The default ulimit -n -- i.e. user file limit -- of 1024 on most *nix systems
        is insufficient (On mac os x its 256). Any significant amount of loading will
        lead you to <a class="xref" href="#trouble.rs.runtime.filehandles" title="11.6.2.2.&nbsp;java.io.IOException...(Too many open files)">Section&nbsp;11.6.2.2, &#8220;java.io.IOException...(Too many open files)&#8221;</a>.
        You may also notice errors such as... </p><pre class="programlisting">
      2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Exception increateBlockOutputStream java.io.EOFException
      2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6935524980745310745_1391901
      </pre><p> Do yourself a favor and change the upper bound on the
        number of file descriptors. Set it to north of 10k.  The math runs roughly as follows:  per ColumnFamily
        there is at least one StoreFile and possibly up to 5 or 6 if the region is under load.  Multiply the 
        average number of StoreFiles per ColumnFamily times the number of regions per RegionServer.  For example, assuming
        that a schema had 3 ColumnFamilies per region with an average of 3 StoreFiles per ColumnFamily, 
        and there are 100 regions per RegionServer, the JVM will open 3 * 3 * 100 = 900 file descriptors
        (not counting open jar files, config files, etc.)
        </p><p>You should also up the hbase users'
        <code class="varname">nproc</code> setting; under load, a low-nproc
        setting could manifest as <code class="classname">OutOfMemoryError</code>
        <sup>[<a name="d0e361" href="#ftn.d0e361" class="footnote">2</a>]</sup>
        <sup>[<a name="d0e368" href="#ftn.d0e368" class="footnote">3</a>]</sup>.
       </p><p>To be clear, upping the file descriptors and nproc for the user who is
        running the HBase process is an operating system configuration, not an
        HBase configuration. Also, a common mistake is that administrators
        will up the file descriptors for a particular user but for whatever
        reason, HBase will be running as some one else. HBase prints in its
        logs as the first line the ulimit its seeing. Ensure its correct.
        <sup>[<a name="d0e380" href="#ftn.d0e380" class="footnote">4</a>]</sup></p><div class="section" title="2.2.4.1.&nbsp;ulimit on Ubuntu"><div class="titlepage"><div><div><h4 class="title"><a name="ulimit_ubuntu"></a>2.2.4.1.&nbsp;<code class="varname">ulimit</code> on Ubuntu</h4></div></div></div><p>If you are on Ubuntu you will need to make the following
          changes:</p><p>In the file <code class="filename">/etc/security/limits.conf</code> add
          a line like: </p><pre class="programlisting">hadoop  -       nofile  32768</pre><p>
          Replace <code class="varname">hadoop</code> with whatever user is running
          Hadoop and HBase. If you have separate users, you will need 2
          entries, one for each user.  In the same file set nproc hard and soft
          limits.  For example: </p><pre class="programlisting">hadoop soft/hard nproc 32000</pre><p>.</p><p>In the file <code class="filename">/etc/pam.d/common-session</code> add
          as the last line in the file: </p><pre class="programlisting">session required  pam_limits.so</pre><p>
          Otherwise the changes in <code class="filename">/etc/security/limits.conf</code> won't be
          applied.</p><p>Don't forget to log out and back in again for the changes to
          take effect!</p></div></div><div class="section" title="2.2.5.&nbsp;Windows"><div class="titlepage"><div><div><h3 class="title"><a name="windows"></a>2.2.5.&nbsp;Windows</h3></div></div></div><p>HBase has been little tested running on Windows. Running a
        production install of HBase on top of Windows is not
        recommended.</p><p>If you are running HBase on Windows, you must install <a class="link" href="http://cygwin.com/" target="_top">Cygwin</a> to have a *nix-like
        environment for the shell scripts. The full details are explained in
        the <a class="link" href="http://hbase.apache.org/cygwin.html" target="_top">Windows
        Installation</a> guide. Also 
        <a class="link" href="http://search-hadoop.com/?q=hbase+windows&amp;fc_project=HBase&amp;fc_type=mail+_hash_+dev" target="_top">search our user mailing list</a> to pick
        up latest fixes figured by Windows users.</p></div></div><div class="section" title="2.3.&nbsp;Hadoop"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="hadoop"></a>2.3.&nbsp;<a class="link" href="http://hadoop.apache.org" target="_top">Hadoop</a><a class="indexterm" name="d0e440"></a></h2></div></div></div><p>
              This version of HBase will only run on <a class="link" href="http://hadoop.apache.org/common/releases.html" target="_top">Hadoop
        0.20.x</a>. It will not run on hadoop 0.21.x (but may run on 0.22.x/0.23.x).
        HBase will lose data unless it is running on an HDFS that has a durable
        <code class="code">sync</code>. Hadoop 0.20.2, Hadoop 0.20.203.0, and Hadoop 0.20.204.0
	DO NOT have this attribute.
        Currently only Hadoop versions 0.20.205.x or any release in excess of this
        version has a durable sync.  You have to explicitly enable it though by
        setting <code class="varname">dfs.support.append</code> equal to true on both
        the client side -- in <code class="filename">hbase-site.xml</code> though it should
        be on in your <code class="filename">base-default.xml</code> file -- and on the
        serverside in <code class="filename">hdfs-site.xml</code> (You will have to restart
        your cluster after setting this configuration).  Ignore the chicken-little
        comment you'll find in the <code class="filename">hdfs-site.xml</code> in the
        description for this configuration; it says it is not enabled because there
        are <span class="quote">&#8220;<span class="quote">... bugs in the 'append code' and is not supported in any production
        cluster.</span>&#8221;</span> because it is not true (I'm sure there are bugs but the
        append code has been running in production at large scale deploys and is on
        by default in the offerings of hadoop by commercial vendors)
        <sup>[<a name="d0e469" href="#ftn.d0e469" class="footnote">5</a>]</sup>
    <sup>[<a name="d0e479" href="#ftn.d0e479" class="footnote">6</a>]</sup><sup>[<a name="d0e485" href="#ftn.d0e485" class="footnote">7</a>]</sup>.</p><p>Or use the
    <a class="link" href="http://www.cloudera.com/" target="_top">Cloudera</a> or
    <a class="link" href="http://www.mapr.com/" target="_top">MapR</a> distributions.
    Cloudera' <a class="link" href="http://archive.cloudera.com/docs/" target="_top">CDH3</a>
    is Apache Hadoop 0.20.x plus patches including all of the 
    <a class="link" href="http://svn.apache.org/viewvc/hadoop/common/branches/branch-0.20-append/" target="_top">branch-0.20-append</a>
    additions needed to add a durable sync. Use the released, most recent version of CDH3.</p><p>
    <a class="link" href="http://www.mapr.com/" target="_top">MapR</a>
    includes a commercial, reimplementation of HDFS.
    It has a durable sync as well as some other interesting features that are not
    yet in Apache Hadoop.  Their <a class="link" href="http://www.mapr.com/products/mapr-editions/m3-edition" target="_top">M3</a>
    product is free to use and unlimited.
    </p><p>Because HBase depends on Hadoop, it bundles an instance of the
        Hadoop jar under its <code class="filename">lib</code> directory. The bundled jar is ONLY for use in standalone mode.
        In distributed mode, it is <span class="emphasis"><em>critical</em></span> that the version of Hadoop that is out
        on your cluster match what is under HBase.  Replace the hadoop jar found in the HBase
        <code class="filename">lib</code> directory with the hadoop jar you are running on
        your cluster to avoid version mismatch issues. Make sure you
        replace the jar in HBase everywhere on your cluster.  Hadoop version
        mismatch issues have various manifestations but often all looks like
        its hung up.</p><div class="section" title="2.3.1.&nbsp;Hadoop Security"><div class="titlepage"><div><div><h3 class="title"><a name="hadoop.security"></a>2.3.1.&nbsp;Hadoop Security</h3></div></div></div><p>HBase will run on any Hadoop 0.20.x that incorporates Hadoop
          security features -- e.g. Y! 0.20S or CDH3B3 -- as long as you do as
          suggested above and replace the Hadoop jar that ships with HBase
          with the secure version.</p></div><div class="section" title="2.3.2.&nbsp;dfs.datanode.max.xcievers"><div class="titlepage"><div><div><h3 class="title"><a name="dfs.datanode.max.xcievers"></a>2.3.2.&nbsp;<code class="varname">dfs.datanode.max.xcievers</code><a class="indexterm" name="d0e533"></a></h3></div></div></div><p>An Hadoop HDFS datanode has an upper bound on the number of
        files that it will serve at any one time. The upper bound parameter is
        called <code class="varname">xcievers</code> (yes, this is misspelled). Again,
        before doing any loading, make sure you have configured Hadoop's
        <code class="filename">conf/hdfs-site.xml</code> setting the
        <code class="varname">xceivers</code> value to at least the following:
        </p><pre class="programlisting">
      &lt;property&gt;
        &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
      &lt;/property&gt;
      </pre><p>Be sure to restart your HDFS after making the above
        configuration.</p><p>Not having this configuration in place makes for strange looking
        failures. Eventually you'll see a complain in the datanode logs
        complaining about the xcievers exceeded, but on the run up to this one
        manifestation is complaint about missing blocks. For example:
        <code class="code">10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block
        blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node:
        java.io.IOException: No live nodes contain current block. Will get new
        block locations from namenode and retry...</code>
        <sup>[<a name="d0e556" href="#ftn.d0e556" class="footnote">8</a>]</sup></p></div></div><div class="section" title="2.4.&nbsp;HBase run modes: Standalone and Distributed"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="standalone_dist"></a>2.4.&nbsp;HBase run modes: Standalone and Distributed</h2></div></div></div><p>HBase has two run modes: <a class="xref" href="#standalone" title="2.4.1.&nbsp;Standalone HBase">Section&nbsp;2.4.1, &#8220;Standalone HBase&#8221;</a> and <a class="xref" href="#distributed" title="2.4.2.&nbsp;Distributed">Section&nbsp;2.4.2, &#8220;Distributed&#8221;</a>. Out of the box, HBase runs in
      standalone mode. To set up a distributed deploy, you will need to
      configure HBase by editing files in the HBase <code class="filename">conf</code>
      directory.</p><p>Whatever your mode, you will need to edit
      <code class="code">conf/hbase-env.sh</code> to tell HBase which
      <span class="command"><strong>java</strong></span> to use. In this file you set HBase environment
      variables such as the heapsize and other options for the
      <span class="application">JVM</span>, the preferred location for log files,
      etc. Set <code class="varname">JAVA_HOME</code> to point at the root of your
      <span class="command"><strong>java</strong></span> install.</p><div class="section" title="2.4.1.&nbsp;Standalone HBase"><div class="titlepage"><div><div><h3 class="title"><a name="standalone"></a>2.4.1.&nbsp;Standalone HBase</h3></div></div></div><p>This is the default mode. Standalone mode is what is described
            in the <a class="xref" href="#quickstart" title="1.2.&nbsp;Quick Start">Section&nbsp;1.2, &#8220;Quick Start&#8221;</a> section. In
        standalone mode, HBase does not use HDFS -- it uses the local
        filesystem instead -- and it runs all HBase daemons and a local
        ZooKeeper all up in the same JVM. Zookeeper binds to a well known port
        so clients may talk to HBase.</p></div><div class="section" title="2.4.2.&nbsp;Distributed"><div class="titlepage"><div><div><h3 class="title"><a name="distributed"></a>2.4.2.&nbsp;Distributed</h3></div></div></div><p>Distributed mode can be subdivided into distributed but all
        daemons run on a single node -- a.k.a
        <span class="emphasis"><em>pseudo-distributed</em></span>-- and
        <span class="emphasis"><em>fully-distributed</em></span> where the daemons are spread
        across all nodes in the cluster <sup>[<a name="d0e610" href="#ftn.d0e610" class="footnote">9</a>]</sup>.</p><p>Distributed modes require an instance of the <span class="emphasis"><em>Hadoop
        Distributed File System</em></span> (HDFS). See the Hadoop <a class="link" href="http://hadoop.apache.org/common/docs/current/api/overview-summary.html#overview_description" target="_top">
        requirements and instructions</a> for how to set up a HDFS. Before
        proceeding, ensure you have an appropriate, working HDFS.</p><p>Below we describe the different distributed setups. Starting,
        verification and exploration of your install, whether a
        <span class="emphasis"><em>pseudo-distributed</em></span> or
        <span class="emphasis"><em>fully-distributed</em></span> configuration is described in a
        section that follows, <a class="xref" href="#confirm" title="2.4.3.&nbsp;Running and Confirming Your Installation">Section&nbsp;2.4.3, &#8220;Running and Confirming Your Installation&#8221;</a>. The same verification script applies to both
        deploy types.</p><div class="section" title="2.4.2.1.&nbsp;Pseudo-distributed"><div class="titlepage"><div><div><h4 class="title"><a name="pseudo"></a>2.4.2.1.&nbsp;Pseudo-distributed</h4></div></div></div><p>A pseudo-distributed mode is simply a distributed mode run on
          a single host. Use this configuration testing and prototyping on
          HBase. Do not use this configuration for production nor for
          evaluating HBase performance.</p><p>Once you have confirmed your HDFS setup, edit
          <code class="filename">conf/hbase-site.xml</code>. This is the file into
          which you add local customizations and overrides for
          <span style="color: red">&lt;xreg&gt;&lt;/xreg&gt;</span> and <a class="xref" href="#hdfs_client_conf" title="2.4.2.2.3.&nbsp;HDFS Client Configuration">Section&nbsp;2.4.2.2.3, &#8220;HDFS Client Configuration&#8221;</a>. Point HBase at the running Hadoop HDFS
          instance by setting the <code class="varname">hbase.rootdir</code> property.
          This property points HBase at the Hadoop filesystem instance to use.
          For example, adding the properties below to your
          <code class="filename">hbase-site.xml</code> says that HBase should use the
          <code class="filename">/hbase</code> directory in the HDFS whose namenode is
          at port 8020 on your local machine, and that it should run with one
          replica only (recommended for pseudo-distributed mode):</p><pre class="programlisting">
&lt;configuration&gt;
  ...
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;
    &lt;description&gt;The directory shared by RegionServers.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
    &lt;description&gt;The replication count for HLog and HFile storage. Should not be greater than HDFS datanode count.
    &lt;/description&gt;
  &lt;/property&gt;
  ...
&lt;/configuration&gt;
</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Let HBase create the <code class="varname">hbase.rootdir</code>
            directory. If you don't, you'll get warning saying HBase needs a
            migration run because the directory is missing files expected by
            HBase (it'll create them if you let it).</p></div><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Above we bind to <code class="varname">localhost</code>. This means
            that a remote client cannot connect. Amend accordingly, if you
            want to connect from a remote location.</p></div><p>Now skip to <a class="xref" href="#confirm" title="2.4.3.&nbsp;Running and Confirming Your Installation">Section&nbsp;2.4.3, &#8220;Running and Confirming Your Installation&#8221;</a> for how to start and verify your
          pseudo-distributed install. <sup>[<a name="d0e673" href="#ftn.d0e673" class="footnote">10</a>]</sup></p></div><div class="section" title="2.4.2.2.&nbsp;Fully-distributed"><div class="titlepage"><div><div><h4 class="title"><a name="fully_dist"></a>2.4.2.2.&nbsp;Fully-distributed</h4></div></div></div><p>For running a fully-distributed operation on more than one
          host, make the following configurations. In
          <code class="filename">hbase-site.xml</code>, add the property
          <code class="varname">hbase.cluster.distributed</code> and set it to
          <code class="varname">true</code> and point the HBase
          <code class="varname">hbase.rootdir</code> at the appropriate HDFS NameNode
          and location in HDFS where you would like HBase to write data. For
          example, if you namenode were running at namenode.example.org on
          port 8020 and you wanted to home your HBase in HDFS at
          <code class="filename">/hbase</code>, make the following
          configuration.</p><pre class="programlisting">
&lt;configuration&gt;
  ...
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://namenode.example.org:8020/hbase&lt;/value&gt;
    &lt;description&gt;The directory shared by RegionServers.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    &lt;/description&gt;
  &lt;/property&gt;
  ...
&lt;/configuration&gt;
</pre><div class="section" title="2.4.2.2.1.&nbsp;regionservers"><div class="titlepage"><div><div><h5 class="title"><a name="regionserver"></a>2.4.2.2.1.&nbsp;<code class="filename">regionservers</code></h5></div></div></div><p>In addition, a fully-distributed mode requires that you
            modify <code class="filename">conf/regionservers</code>. The
            <a class="xref" href="#regionservers" title="2.7.1.2.&nbsp;regionservers">Section&nbsp;2.7.1.2, &#8220;<code class="filename">regionservers</code>&#8221;</a> file
            lists all hosts that you would have running
            <span class="application">HRegionServer</span>s, one host per line (This
            file in HBase is like the Hadoop <code class="filename">slaves</code>
            file). All servers listed in this file will be started and stopped
            when HBase cluster start or stop is run.</p></div><div class="section" title="2.4.2.2.2.&nbsp;ZooKeeper and HBase"><div class="titlepage"><div><div><h5 class="title"><a name="hbase.zookeeper"></a>2.4.2.2.2.&nbsp;ZooKeeper and HBase</h5></div></div></div><p>See section <a class="xref" href="#zookeeper" title="2.5.&nbsp;ZooKeeper">Section&nbsp;2.5, &#8220;ZooKeeper&#8221;</a> for ZooKeeper setup for HBase.</p></div><div class="section" title="2.4.2.2.3.&nbsp;HDFS Client Configuration"><div class="titlepage"><div><div><h5 class="title"><a name="hdfs_client_conf"></a>2.4.2.2.3.&nbsp;HDFS Client Configuration</h5></div></div></div><p>Of note, if you have made <span class="emphasis"><em>HDFS client
            configuration</em></span> on your Hadoop cluster -- i.e.
            configuration you want HDFS clients to use as opposed to
            server-side configurations -- HBase will not see this
            configuration unless you do one of the following:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Add a pointer to your <code class="varname">HADOOP_CONF_DIR</code>
                to the <code class="varname">HBASE_CLASSPATH</code> environment variable
                in <code class="filename">hbase-env.sh</code>.</p></li><li class="listitem"><p>Add a copy of <code class="filename">hdfs-site.xml</code> (or
                <code class="filename">hadoop-site.xml</code>) or, better, symlinks,
                under <code class="filename">${HBASE_HOME}/conf</code>, or</p></li><li class="listitem"><p>if only a small set of HDFS client configurations, add
                them to <code class="filename">hbase-site.xml</code>.</p></li></ul></div><p>An example of such an HDFS client configuration is
            <code class="varname">dfs.replication</code>. If for example, you want to
            run with a replication factor of 5, hbase will create files with
            the default of 3 unless you do the above to make the configuration
            available to HBase.</p></div></div></div><div class="section" title="2.4.3.&nbsp;Running and Confirming Your Installation"><div class="titlepage"><div><div><h3 class="title"><a name="confirm"></a>2.4.3.&nbsp;Running and Confirming Your Installation</h3></div></div></div><p>Make sure HDFS is running first. Start and stop the Hadoop HDFS
        daemons by running <code class="filename">bin/start-hdfs.sh</code> over in the
        <code class="varname">HADOOP_HOME</code> directory. You can ensure it started
        properly by testing the <span class="command"><strong>put</strong></span> and
        <span class="command"><strong>get</strong></span> of files into the Hadoop filesystem. HBase does
        not normally use the mapreduce daemons. These do not need to be
        started.</p><p><span class="emphasis"><em>If</em></span> you are managing your own ZooKeeper,
        start it and confirm its running else, HBase will start up ZooKeeper
        for you as part of its start process.</p><p>Start HBase with the following command:</p><pre class="programlisting">bin/start-hbase.sh</pre>

         Run the above from the 

        <code class="varname">HBASE_HOME</code>

         directory. 

        <p>You should now have a running HBase instance. HBase logs can be
        found in the <code class="filename">logs</code> subdirectory. Check them out
        especially if HBase had trouble starting.</p><p>HBase also puts up a UI listing vital attributes. By default its
        deployed on the Master host at port 60010 (HBase RegionServers listen
        on port 60020 by default and put up an informational http server at
        60030). If the Master were running on a host named
        <code class="varname">master.example.org</code> on the default port, to see the
        Master's homepage you'd point your browser at
        <code class="filename">http://master.example.org:60010</code>.</p><p>Once HBase has started, see the <a class="xref" href="#shell_exercises" title="1.2.3.&nbsp;Shell Exercises">Section&nbsp;1.2.3, &#8220;Shell Exercises&#8221;</a> for how to
        create tables, add data, scan your insertions, and finally disable and
        drop your tables.</p><p>To stop HBase after exiting the HBase shell enter
        </p><pre class="programlisting">$ ./bin/stop-hbase.sh
stopping hbase...............</pre><p> Shutdown can take a moment to
        complete. It can take longer if your cluster is comprised of many
        machines. If you are running a distributed operation, be sure to wait
        until HBase has shut down completely before stopping the Hadoop
        daemons.</p></div></div><div class="section" title="2.5.&nbsp;ZooKeeper"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="zookeeper"></a>2.5.&nbsp;ZooKeeper<a class="indexterm" name="d0e824"></a></h2></div></div></div><p>A distributed HBase depends on a running ZooKeeper cluster.
            All participating nodes and clients need to be able to access the
            running ZooKeeper ensemble. HBase by default manages a ZooKeeper
            "cluster" for you. It will start and stop the ZooKeeper ensemble
            as part of the HBase start/stop process. You can also manage the
            ZooKeeper ensemble independent of HBase and just point HBase at
            the cluster it should use. To toggle HBase management of
            ZooKeeper, use the <code class="varname">HBASE_MANAGES_ZK</code> variable in
            <code class="filename">conf/hbase-env.sh</code>. This variable, which
            defaults to <code class="varname">true</code>, tells HBase whether to
            start/stop the ZooKeeper ensemble servers as part of HBase
            start/stop.</p><p>When HBase manages the ZooKeeper ensemble, you can specify
            ZooKeeper configuration using its native
            <code class="filename">zoo.cfg</code> file, or, the easier option is to
            just specify ZooKeeper options directly in
            <code class="filename">conf/hbase-site.xml</code>. A ZooKeeper
            configuration option can be set as a property in the HBase
            <code class="filename">hbase-site.xml</code> XML configuration file by
            prefacing the ZooKeeper option name with
            <code class="varname">hbase.zookeeper.property</code>. For example, the
            <code class="varname">clientPort</code> setting in ZooKeeper can be changed
            by setting the
            <code class="varname">hbase.zookeeper.property.clientPort</code> property.
            For all default values used by HBase, including ZooKeeper
            configuration, see <a class="xref" href="#hbase_default_configurations" title="2.6.1.1.&nbsp;HBase Default Configuration">Section&nbsp;2.6.1.1, &#8220;HBase Default Configuration&#8221;</a>. Look for the
            <code class="varname">hbase.zookeeper.property</code> prefix <sup>[<a name="d0e863" href="#ftn.d0e863" class="footnote">11</a>]</sup></p><p>You must at least list the ensemble servers in
            <code class="filename">hbase-site.xml</code> using the
            <code class="varname">hbase.zookeeper.quorum</code> property. This property
            defaults to a single ensemble member at
            <code class="varname">localhost</code> which is not suitable for a fully
            distributed HBase. (It binds to the local machine only and remote
            clients will not be able to connect). </p><div class="note" title="How many ZooKeepers should I run?" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a name="how_many_zks"></a>How many ZooKeepers should I run?</h3><p>You can run a ZooKeeper ensemble that comprises 1 node
                only but in production it is recommended that you run a
                ZooKeeper ensemble of 3, 5 or 7 machines; the more members an
                ensemble has, the more tolerant the ensemble is of host
                failures. Also, run an odd number of machines. There can be no
                quorum if the number of members is an even number. Give each
                ZooKeeper server around 1GB of RAM, and if possible, its own
                dedicated disk (A dedicated disk is the best thing you can do
                to ensure a performant ZooKeeper ensemble). For very heavily
                loaded clusters, run ZooKeeper servers on separate machines
                from RegionServers (DataNodes and TaskTrackers).</p></div><p>For example, to have HBase manage a ZooKeeper quorum on
            nodes <span class="emphasis"><em>rs{1,2,3,4,5}.example.com</em></span>, bound to
            port 2222 (the default is 2181) ensure
            <code class="varname">HBASE_MANAGE_ZK</code> is commented out or set to
            <code class="varname">true</code> in <code class="filename">conf/hbase-env.sh</code>
            and then edit <code class="filename">conf/hbase-site.xml</code> and set
            <code class="varname">hbase.zookeeper.property.clientPort</code> and
            <code class="varname">hbase.zookeeper.quorum</code>. You should also set
            <code class="varname">hbase.zookeeper.property.dataDir</code> to other than
            the default as the default has ZooKeeper persist data under
            <code class="filename">/tmp</code> which is often cleared on system
            restart. In the example below we have ZooKeeper persist to
            <code class="filename">/user/local/zookeeper</code>. </p><pre class="programlisting">
  &lt;configuration&gt;
    ...
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;
      &lt;value&gt;2222&lt;/value&gt;
      &lt;description&gt;Property from ZooKeeper's config zoo.cfg.
      The port at which the clients will connect.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
      &lt;value&gt;rs1.example.com,rs2.example.com,rs3.example.com,rs4.example.com,rs5.example.com&lt;/value&gt;
      &lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.
      For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".
      By default this is set to localhost for local and pseudo-distributed modes
      of operation. For a fully-distributed setup, this should be set to a full
      list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
      this is the list of servers which we will start/stop ZooKeeper on.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;/usr/local/zookeeper&lt;/value&gt;
      &lt;description&gt;Property from ZooKeeper's config zoo.cfg.
      The directory where the snapshot is stored.
      &lt;/description&gt;
    &lt;/property&gt;
    ...
  &lt;/configuration&gt;</pre><div class="section" title="2.5.1.&nbsp;Using existing ZooKeeper ensemble"><div class="titlepage"><div><div><h3 class="title"><a name="d0e925"></a>2.5.1.&nbsp;Using existing ZooKeeper ensemble</h3></div></div></div><p>To point HBase at an existing ZooKeeper cluster, one that
              is not managed by HBase, set <code class="varname">HBASE_MANAGES_ZK</code>
              in <code class="filename">conf/hbase-env.sh</code> to false
              </p><pre class="programlisting">
  ...
  # Tell HBase whether it should manage it's own instance of Zookeeper or not.
  export HBASE_MANAGES_ZK=false</pre><p> Next set ensemble locations
              and client port, if non-standard, in
              <code class="filename">hbase-site.xml</code>, or add a suitably
              configured <code class="filename">zoo.cfg</code> to HBase's
              <code class="filename">CLASSPATH</code>. HBase will prefer the
              configuration found in <code class="filename">zoo.cfg</code> over any
              settings in <code class="filename">hbase-site.xml</code>.</p><p>When HBase manages ZooKeeper, it will start/stop the
              ZooKeeper servers as a part of the regular start/stop scripts.
              If you would like to run ZooKeeper yourself, independent of
              HBase start/stop, you would do the following</p><pre class="programlisting">
${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper
</pre><p>Note that you can use HBase in this manner to spin up a
              ZooKeeper cluster, unrelated to HBase. Just make sure to set
              <code class="varname">HBASE_MANAGES_ZK</code> to <code class="varname">false</code>
              if you want it to stay up across HBase restarts so that when
              HBase shuts down, it doesn't take ZooKeeper down with it.</p><p>For more information about running a distinct ZooKeeper
              cluster, see the ZooKeeper <a class="link" href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperStarted.html" target="_top">Getting
              Started Guide</a>.  Additionally, see the <a class="link" href="http://wiki.apache.org/hadoop/ZooKeeper/FAQ#A7" target="_top">ZooKeeper Wiki</a> or the 
          <a class="link" href="http://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_zkMulitServerSetup" target="_top">ZooKeeper documentation</a> 
          for more information on ZooKeeper sizing.
            </p></div></div><div class="section" title="2.6.&nbsp;Configuration Files"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="config.files"></a>2.6.&nbsp;Configuration Files</h2></div></div></div><div class="section" title="2.6.1.&nbsp;hbase-site.xml and hbase-default.xml"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.site"></a>2.6.1.&nbsp;<code class="filename">hbase-site.xml</code> and <code class="filename">hbase-default.xml</code></h3></div></div></div><p>Just as in Hadoop where you add site-specific HDFS configuration
    to the <code class="filename">hdfs-site.xml</code> file,
    for HBase, site specific customizations go into
    the file <code class="filename">conf/hbase-site.xml</code>.
    For the list of configurable properties, see
    <a class="xref" href="#hbase_default_configurations" title="2.6.1.1.&nbsp;HBase Default Configuration">Section&nbsp;2.6.1.1, &#8220;HBase Default Configuration&#8221;</a>
    below or view the raw <code class="filename">hbase-default.xml</code>
    source file in the HBase source code at
    <code class="filename">src/main/resources</code>.
    </p><p>
    Not all configuration options make it out to
    <code class="filename">hbase-default.xml</code>.  Configuration
    that it is thought rare anyone would change can exist only
    in code; the only way to turn up such configurations is
    via a reading of the source code itself.
    </p><p>
      Currently, changes here will require a cluster restart for HBase to notice the change.
      </p><div class="section" title="2.6.1.1.&nbsp;HBase Default Configuration"><div class="titlepage"><div><div><h4 class="title"><a name="hbase_default_configurations"></a>2.6.1.1.&nbsp;HBase Default Configuration</h4></div></div></div><p></p><div class="glossary" title="HBase Default Configuration"><div class="titlepage"><div><div><h5 class="title"><a name="hbase.default.configuration"></a>HBase Default Configuration</h5></div></div></div><p>
The documentation below is generated using the default hbase configuration file,
<code class="filename">hbase-default.xml</code>, as source.
</p><dl><dt><a name="hbase.rootdir"></a><code class="varname">hbase.rootdir</code></dt><dd><p>The directory shared by region servers and into
    which HBase persists.  The URL should be 'fully-qualified'
    to include the filesystem scheme.  For example, to specify the
    HDFS directory '/hbase' where the HDFS instance's namenode is
    running at namenode.example.org on port 9000, set this value to:
    hdfs://namenode.example.org:9000/hbase.  By default HBase writes
    into /tmp.  Change this configuration else all data will be lost
    on machine restart.
    </p><p>Default: <code class="varname">file:///tmp/hbase-${user.name}/hbase</code></p></dd><dt><a name="hbase.master.port"></a><code class="varname">hbase.master.port</code></dt><dd><p>The port the HBase Master should bind to.</p><p>Default: <code class="varname">60000</code></p></dd><dt><a name="hbase.cluster.distributed"></a><code class="varname">hbase.cluster.distributed</code></dt><dd><p>The mode the cluster will be in. Possible values are
      false for standalone mode and true for distributed mode.  If
      false, startup will run all HBase and ZooKeeper daemons together
      in the one JVM.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.tmp.dir"></a><code class="varname">hbase.tmp.dir</code></dt><dd><p>Temporary directory on the local filesystem.
    Change this setting to point to a location more permanent
    than '/tmp' (The '/tmp' directory is often cleared on
    machine restart).
    </p><p>Default: <code class="varname">/tmp/hbase-${user.name}</code></p></dd><dt><a name="hbase.master.info.port"></a><code class="varname">hbase.master.info.port</code></dt><dd><p>The port for the HBase Master web UI.
    Set to -1 if you do not want a UI instance run.
    </p><p>Default: <code class="varname">60010</code></p></dd><dt><a name="hbase.master.info.bindAddress"></a><code class="varname">hbase.master.info.bindAddress</code></dt><dd><p>The bind address for the HBase Master web UI
    </p><p>Default: <code class="varname">0.0.0.0</code></p></dd><dt><a name="hbase.client.write.buffer"></a><code class="varname">hbase.client.write.buffer</code></dt><dd><p>Default size of the HTable clien write buffer in bytes.
    A bigger buffer takes more memory -- on both the client and server
    side since server instantiates the passed write buffer to process
    it -- but a larger buffer size reduces the number of RPCs made.
    For an estimate of server-side memory-used, evaluate
    hbase.client.write.buffer * hbase.regionserver.handler.count
    </p><p>Default: <code class="varname">2097152</code></p></dd><dt><a name="hbase.regionserver.port"></a><code class="varname">hbase.regionserver.port</code></dt><dd><p>The port the HBase RegionServer binds to.
    </p><p>Default: <code class="varname">60020</code></p></dd><dt><a name="hbase.regionserver.info.port"></a><code class="varname">hbase.regionserver.info.port</code></dt><dd><p>The port for the HBase RegionServer web UI
    Set to -1 if you do not want the RegionServer UI to run.
    </p><p>Default: <code class="varname">60030</code></p></dd><dt><a name="hbase.regionserver.info.port.auto"></a><code class="varname">hbase.regionserver.info.port.auto</code></dt><dd><p>Whether or not the Master or RegionServer
    UI should search for a port to bind to. Enables automatic port
    search if hbase.regionserver.info.port is already in use.
    Useful for testing, turned off by default.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.regionserver.info.bindAddress"></a><code class="varname">hbase.regionserver.info.bindAddress</code></dt><dd><p>The address for the HBase RegionServer web UI
    </p><p>Default: <code class="varname">0.0.0.0</code></p></dd><dt><a name="hbase.regionserver.class"></a><code class="varname">hbase.regionserver.class</code></dt><dd><p>The RegionServer interface to use.
    Used by the client opening proxy to remote region server.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.ipc.HRegionInterface</code></p></dd><dt><a name="hbase.client.pause"></a><code class="varname">hbase.client.pause</code></dt><dd><p>General client pause value.  Used mostly as value to wait
    before running a retry of a failed get, region lookup, etc.</p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.client.retries.number"></a><code class="varname">hbase.client.retries.number</code></dt><dd><p>Maximum retries.  Used as maximum for all retryable
    operations such as fetching of the root region from root region
    server, getting a cell's value, starting a row update, etc.
    Default: 10.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.bulkload.retries.number"></a><code class="varname">hbase.bulkload.retries.number</code></dt><dd><p>Maximum retries.  This is maximum number of iterations
    to atomic bulk loads are attempted in the face of splitting operations
    0 means never give up.  Default: 0.
    </p><p>Default: <code class="varname">0</code></p></dd><dt><a name="hbase.client.scanner.caching"></a><code class="varname">hbase.client.scanner.caching</code></dt><dd><p>Number of rows that will be fetched when calling next
    on a scanner if it is not served from (local, client) memory. Higher
    caching values will enable faster scanners but will eat up more memory
    and some calls of next may take longer and longer times when the cache is empty.
    Do not set this value such that the time between invocations is greater
    than the scanner timeout; i.e. hbase.regionserver.lease.period
    </p><p>Default: <code class="varname">1</code></p></dd><dt><a name="hbase.client.keyvalue.maxsize"></a><code class="varname">hbase.client.keyvalue.maxsize</code></dt><dd><p>Specifies the combined maximum allowed size of a KeyValue
    instance. This is to set an upper boundary for a single entry saved in a
    storage file. Since they cannot be split it helps avoiding that a region
    cannot be split any further because the data is too large. It seems wise
    to set this to a fraction of the maximum region size. Setting it to zero
    or less disables the check.
    </p><p>Default: <code class="varname">10485760</code></p></dd><dt><a name="hbase.regionserver.lease.period"></a><code class="varname">hbase.regionserver.lease.period</code></dt><dd><p>HRegion server lease period in milliseconds. Default is
    60 seconds. Clients must report in within this period else they are
    considered dead.</p><p>Default: <code class="varname">60000</code></p></dd><dt><a name="hbase.regionserver.handler.count"></a><code class="varname">hbase.regionserver.handler.count</code></dt><dd><p>Count of RPC Listener instances spun up on RegionServers.
    Same property is used by the Master for count of master handlers.
    Default is 10.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.regionserver.msginterval"></a><code class="varname">hbase.regionserver.msginterval</code></dt><dd><p>Interval between messages from the RegionServer to Master
    in milliseconds.
    </p><p>Default: <code class="varname">3000</code></p></dd><dt><a name="hbase.regionserver.optionallogflushinterval"></a><code class="varname">hbase.regionserver.optionallogflushinterval</code></dt><dd><p>Sync the HLog to the HDFS after this interval if it has not
    accumulated enough entries to trigger a sync. Default 1 second. Units:
    milliseconds.
    </p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.regionserver.regionSplitLimit"></a><code class="varname">hbase.regionserver.regionSplitLimit</code></dt><dd><p>Limit for the number of regions after which no more region
    splitting should take place. This is not a hard limit for the number of
    regions but acts as a guideline for the regionserver to stop splitting after
    a certain limit. Default is set to MAX_INT; i.e. do not block splitting.
    </p><p>Default: <code class="varname">2147483647</code></p></dd><dt><a name="hbase.regionserver.logroll.period"></a><code class="varname">hbase.regionserver.logroll.period</code></dt><dd><p>Period at which we will roll the commit log regardless
    of how many edits it has.</p><p>Default: <code class="varname">3600000</code></p></dd><dt><a name="hbase.regionserver.logroll.errors.tolerated"></a><code class="varname">hbase.regionserver.logroll.errors.tolerated</code></dt><dd><p>The number of consecutive WAL close errors we will allow
    before triggering a server abort.  A setting of 0 will cause the
    region server to abort if closing the current WAL writer fails during
    log rolling.  Even a small value (2 or 3) will allow a region server
    to ride over transient HDFS errors.</p><p>Default: <code class="varname">2</code></p></dd><dt><a name="hbase.regionserver.hlog.reader.impl"></a><code class="varname">hbase.regionserver.hlog.reader.impl</code></dt><dd><p>The HLog file reader implementation.</p><p>Default: <code class="varname">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader</code></p></dd><dt><a name="hbase.regionserver.hlog.writer.impl"></a><code class="varname">hbase.regionserver.hlog.writer.impl</code></dt><dd><p>The HLog file writer implementation.</p><p>Default: <code class="varname">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter</code></p></dd><dt><a name="hbase.regionserver.nbreservationblocks"></a><code class="varname">hbase.regionserver.nbreservationblocks</code></dt><dd><p>The number of resevoir blocks of memory release on
    OOME so we can cleanup properly before server shutdown.
    </p><p>Default: <code class="varname">4</code></p></dd><dt><a name="hbase.zookeeper.dns.interface"></a><code class="varname">hbase.zookeeper.dns.interface</code></dt><dd><p>The name of the Network Interface from which a ZooKeeper server
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.zookeeper.dns.nameserver"></a><code class="varname">hbase.zookeeper.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a ZooKeeper server should use to determine the host name used by the
      master for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.regionserver.dns.interface"></a><code class="varname">hbase.regionserver.dns.interface</code></dt><dd><p>The name of the Network Interface from which a region server
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.regionserver.dns.nameserver"></a><code class="varname">hbase.regionserver.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a region server should use to determine the host name used by the
      master for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.master.dns.interface"></a><code class="varname">hbase.master.dns.interface</code></dt><dd><p>The name of the Network Interface from which a master
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.master.dns.nameserver"></a><code class="varname">hbase.master.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a master should use to determine the host name used
      for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.balancer.period%0A    "></a><code class="varname">hbase.balancer.period
    </code></dt><dd><p>Period at which the region balancer runs in the Master.
    </p><p>Default: <code class="varname">300000</code></p></dd><dt><a name="hbase.regions.slop"></a><code class="varname">hbase.regions.slop</code></dt><dd><p>Rebalance if any regionserver has average + (average * slop) regions.
    Default is 20% slop.
    </p><p>Default: <code class="varname">0.2</code></p></dd><dt><a name="hbase.master.logcleaner.ttl"></a><code class="varname">hbase.master.logcleaner.ttl</code></dt><dd><p>Maximum time a HLog can stay in the .oldlogdir directory,
    after which it will be cleaned by a Master thread.
    </p><p>Default: <code class="varname">600000</code></p></dd><dt><a name="hbase.master.logcleaner.plugins"></a><code class="varname">hbase.master.logcleaner.plugins</code></dt><dd><p>A comma-separated list of LogCleanerDelegate invoked by
    the LogsCleaner service. These WAL/HLog cleaners are called in order,
    so put the HLog cleaner that prunes the most HLog files in front. To
    implement your own LogCleanerDelegate, just put it in HBase's classpath
    and add the fully qualified class name here. Always add the above
    default log cleaners in the list.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.master.TimeToLiveLogCleaner</code></p></dd><dt><a name="hbase.regionserver.global.memstore.upperLimit"></a><code class="varname">hbase.regionserver.global.memstore.upperLimit</code></dt><dd><p>Maximum size of all memstores in a region server before new
      updates are blocked and flushes are forced. Defaults to 40% of heap
    </p><p>Default: <code class="varname">0.4</code></p></dd><dt><a name="hbase.regionserver.global.memstore.lowerLimit"></a><code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></dt><dd><p>When memstores are being forced to flush to make room in
      memory, keep flushing until we hit this mark. Defaults to 35% of heap.
      This value equal to hbase.regionserver.global.memstore.upperLimit causes
      the minimum possible flushing to occur when updates are blocked due to
      memstore limiting.
    </p><p>Default: <code class="varname">0.35</code></p></dd><dt><a name="hbase.server.thread.wakefrequency"></a><code class="varname">hbase.server.thread.wakefrequency</code></dt><dd><p>Time to sleep in between searches for work (in milliseconds).
    Used as sleep interval by service threads such as log roller.
    </p><p>Default: <code class="varname">10000</code></p></dd><dt><a name="hbase.hregion.memstore.flush.size"></a><code class="varname">hbase.hregion.memstore.flush.size</code></dt><dd><p>
    Memstore will be flushed to disk if size of the memstore
    exceeds this number of bytes.  Value is checked by a thread that runs
    every hbase.server.thread.wakefrequency.
    </p><p>Default: <code class="varname">134217728</code></p></dd><dt><a name="hbase.hregion.preclose.flush.size"></a><code class="varname">hbase.hregion.preclose.flush.size</code></dt><dd><p>
      If the memstores in a region are this size or larger when we go
      to close, run a "pre-flush" to clear out memstores before we put up
      the region closed flag and take the region offline.  On close,
      a flush is run under the close flag to empty memory.  During
      this time the region is offline and we are not taking on any writes.
      If the memstore content is large, this flush could take a long time to
      complete.  The preflush is meant to clean out the bulk of the memstore
      before putting up the close flag and taking the region offline so the
      flush that runs under the close flag has little to do.
    </p><p>Default: <code class="varname">5242880</code></p></dd><dt><a name="hbase.hregion.memstore.block.multiplier"></a><code class="varname">hbase.hregion.memstore.block.multiplier</code></dt><dd><p>
    Block updates if memstore has hbase.hregion.block.memstore
    time hbase.hregion.flush.size bytes.  Useful preventing
    runaway memstore during spikes in update traffic.  Without an
    upper-bound, memstore fills such that when it flushes the
    resultant flush files take a long time to compact or split, or
    worse, we OOME.
    </p><p>Default: <code class="varname">2</code></p></dd><dt><a name="hbase.hregion.memstore.mslab.enabled"></a><code class="varname">hbase.hregion.memstore.mslab.enabled</code></dt><dd><p>
      Enables the MemStore-Local Allocation Buffer,
      a feature which works to prevent heap fragmentation under
      heavy write loads. This can reduce the frequency of stop-the-world
      GC pauses on large heaps.
    </p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.hregion.max.filesize"></a><code class="varname">hbase.hregion.max.filesize</code></dt><dd><p>
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.
    Default: 1G.
    </p><p>Default: <code class="varname">1073741824</code></p></dd><dt><a name="hbase.hstore.compactionThreshold"></a><code class="varname">hbase.hstore.compactionThreshold</code></dt><dd><p>
    If more than this number of HStoreFiles in any one HStore
    (one HStoreFile is written per flush of memstore) then a compaction
    is run to rewrite all HStoreFiles files as one.  Larger numbers
    put off compaction but when it runs, it takes longer to complete.
    </p><p>Default: <code class="varname">3</code></p></dd><dt><a name="hbase.hstore.blockingStoreFiles"></a><code class="varname">hbase.hstore.blockingStoreFiles</code></dt><dd><p>
    If more than this number of StoreFiles in any one Store
    (one StoreFile is written per flush of MemStore) then updates are
    blocked for this HRegion until a compaction is completed, or
    until hbase.hstore.blockingWaitTime has been exceeded.
    </p><p>Default: <code class="varname">7</code></p></dd><dt><a name="hbase.hstore.blockingWaitTime"></a><code class="varname">hbase.hstore.blockingWaitTime</code></dt><dd><p>
    The time an HRegion will block updates for after hitting the StoreFile
    limit defined by hbase.hstore.blockingStoreFiles.
    After this time has elapsed, the HRegion will stop blocking updates even
    if a compaction has not been completed.  Default: 90 seconds.
    </p><p>Default: <code class="varname">90000</code></p></dd><dt><a name="hbase.hstore.compaction.max"></a><code class="varname">hbase.hstore.compaction.max</code></dt><dd><p>Max number of HStoreFiles to compact per 'minor' compaction.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.hregion.majorcompaction"></a><code class="varname">hbase.hregion.majorcompaction</code></dt><dd><p>The time (in miliseconds) between 'major' compactions of all
    HStoreFiles in a region.  Default: 1 day.
    Set to 0 to disable automated major compactions.
    </p><p>Default: <code class="varname">86400000</code></p></dd><dt><a name="hbase.mapreduce.hfileoutputformat.blocksize"></a><code class="varname">hbase.mapreduce.hfileoutputformat.blocksize</code></dt><dd><p>The mapreduce HFileOutputFormat writes storefiles/hfiles.
    This is the minimum hfile blocksize to emit.  Usually in hbase, writing
    hfiles, the blocksize is gotten from the table schema (HColumnDescriptor)
    but in the mapreduce outputformat context, we don't have access to the
    schema so get blocksize from Configuation.  The smaller you make
    the blocksize, the bigger your index and the less you fetch on a
    random-access.  Set the blocksize down if you have small cells and want
    faster random-access of individual cells.
    </p><p>Default: <code class="varname">65536</code></p></dd><dt><a name="hfile.block.cache.size"></a><code class="varname">hfile.block.cache.size</code></dt><dd><p>
        Percentage of maximum heap (-Xmx setting) to allocate to block cache
        used by HFile/StoreFile. Default of 0.25 means allocate 25%.
        Set to 0 to disable but it's not recommended.
    </p><p>Default: <code class="varname">0.25</code></p></dd><dt><a name="hbase.hash.type"></a><code class="varname">hbase.hash.type</code></dt><dd><p>The hashing algorithm for use in HashFunction. Two values are
    supported now: murmur (MurmurHash) and jenkins (JenkinsHash).
    Used by bloom filters.
    </p><p>Default: <code class="varname">murmur</code></p></dd><dt><a name="hfile.block.index.cacheonwrite"></a><code class="varname">hfile.block.index.cacheonwrite</code></dt><dd><p>
          This allows to put non-root multi-level index blocks into the block
          cache at the time the index is being written.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hfile.index.block.max.size"></a><code class="varname">hfile.index.block.max.size</code></dt><dd><p>
          When the size of a leaf-level, intermediate-level, or root-level
          index block in a multi-level block index grows to this size, the
          block is written out and a new block is started.
      </p><p>Default: <code class="varname">131072</code></p></dd><dt><a name="hfile.format.version"></a><code class="varname">hfile.format.version</code></dt><dd><p>
          The HFile format version to use for new files. Set this to 1 to test
          backwards-compatibility. The default value of this option should be
          consistent with FixedFileTrailer.MAX_VERSION.
      </p><p>Default: <code class="varname">2</code></p></dd><dt><a name="io.storefile.bloom.block.size"></a><code class="varname">io.storefile.bloom.block.size</code></dt><dd><p>
          The size in bytes of a single block ("chunk") of a compound Bloom
          filter. This size is approximate, because Bloom blocks can only be
          inserted at data block boundaries, and the number of keys per data
          block varies.
      </p><p>Default: <code class="varname">131072</code></p></dd><dt><a name="io.storefile.bloom.cacheonwrite"></a><code class="varname">io.storefile.bloom.cacheonwrite</code></dt><dd><p>
          Enables cache-on-write for inline blocks of a compound Bloom filter.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.rs.cacheblocksonwrite"></a><code class="varname">hbase.rs.cacheblocksonwrite</code></dt><dd><p>
          Whether an HFile block should be added to the block cache when the
          block is finished.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.rpc.engine"></a><code class="varname">hbase.rpc.engine</code></dt><dd><p>Implementation of org.apache.hadoop.hbase.ipc.RpcEngine to be
    used for client / server RPC call marshalling.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.ipc.WritableRpcEngine</code></p></dd><dt><a name="hbase.master.keytab.file"></a><code class="varname">hbase.master.keytab.file</code></dt><dd><p>Full path to the kerberos keytab file to use for logging in
    the configured HMaster server principal.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.master.kerberos.principal"></a><code class="varname">hbase.master.kerberos.principal</code></dt><dd><p>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HMaster process.  The principal name should
    be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the hostname
    portion, it will be replaced with the actual hostname of the running
    instance.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.regionserver.keytab.file"></a><code class="varname">hbase.regionserver.keytab.file</code></dt><dd><p>Full path to the kerberos keytab file to use for logging in
    the configured HRegionServer server principal.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.regionserver.kerberos.principal"></a><code class="varname">hbase.regionserver.kerberos.principal</code></dt><dd><p>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HRegionServer process.  The principal name
    should be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the
    hostname portion, it will be replaced with the actual hostname of the
    running instance.  An entry for this principal must exist in the file
    specified in hbase.regionserver.keytab.file
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hadoop.policy.file"></a><code class="varname">hadoop.policy.file</code></dt><dd><p>The policy configuration file used by RPC servers to make
      authorization decisions on client requests.  Only used when HBase
      security is enabled.
    </p><p>Default: <code class="varname">hbase-policy.xml</code></p></dd><dt><a name="hbase.superuser"></a><code class="varname">hbase.superuser</code></dt><dd><p>List of users or groups (comma-separated), who are allowed
    full privileges, regardless of stored ACLs, across the cluster.
    Only used when HBase security is enabled.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.auth.key.update.interval"></a><code class="varname">hbase.auth.key.update.interval</code></dt><dd><p>The update interval for master key for authentication tokens 
    in servers in milliseconds.  Only used when HBase security is enabled.
    </p><p>Default: <code class="varname">86400000</code></p></dd><dt><a name="hbase.auth.token.max.lifetime"></a><code class="varname">hbase.auth.token.max.lifetime</code></dt><dd><p>The maximum lifetime in milliseconds after which an
    authentication token expires.  Only used when HBase security is enabled.
    </p><p>Default: <code class="varname">604800000</code></p></dd><dt><a name="zookeeper.session.timeout"></a><code class="varname">zookeeper.session.timeout</code></dt><dd><p>ZooKeeper session timeout.
      HBase passes this to the zk quorum as suggested maximum time for a
      session (This setting becomes zookeeper's 'maxSessionTimeout').  See
      http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions
      "The client sends a requested timeout, the server responds with the
      timeout that it can give the client. " In milliseconds.
    </p><p>Default: <code class="varname">180000</code></p></dd><dt><a name="zookeeper.znode.parent"></a><code class="varname">zookeeper.znode.parent</code></dt><dd><p>Root ZNode for HBase in ZooKeeper. All of HBase's ZooKeeper
      files that are configured with a relative path will go under this node.
      By default, all of HBase's ZooKeeper file path are configured with a
      relative path, so they will all go under this directory unless changed.
    </p><p>Default: <code class="varname">/hbase</code></p></dd><dt><a name="zookeeper.znode.rootserver"></a><code class="varname">zookeeper.znode.rootserver</code></dt><dd><p>Path to ZNode holding root region location. This is written by
      the master and read by clients and region servers. If a relative path is
      given, the parent folder will be ${zookeeper.znode.parent}. By default,
      this means the root location is stored at /hbase/root-region-server.
    </p><p>Default: <code class="varname">root-region-server</code></p></dd><dt><a name="zookeeper.znode.acl.parent"></a><code class="varname">zookeeper.znode.acl.parent</code></dt><dd><p>Root ZNode for access control lists.</p><p>Default: <code class="varname">acl</code></p></dd><dt><a name="hbase.coprocessor.region.classes"></a><code class="varname">hbase.coprocessor.region.classes</code></dt><dd><p>A comma-separated list of Coprocessors that are loaded by
    default on all tables. For any override coprocessor method, these classes
    will be called in order. After implementing your own Coprocessor, just put
    it in HBase's classpath and add the fully qualified class name here.
    A coprocessor can also be loaded on demand by setting HTableDescriptor.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.coprocessor.master.classes"></a><code class="varname">hbase.coprocessor.master.classes</code></dt><dd><p>A comma-separated list of
    org.apache.hadoop.hbase.coprocessor.MasterObserver coprocessors that are
    loaded by default on the active HMaster process. For any implemented
    coprocessor methods, the listed classes will be called in order. After
    implementing your own MasterObserver, just put it in HBase's classpath
    and add the fully qualified class name here.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.zookeeper.quorum"></a><code class="varname">hbase.zookeeper.quorum</code></dt><dd><p>Comma separated list of servers in the ZooKeeper Quorum.
    For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".
    By default this is set to localhost for local and pseudo-distributed modes
    of operation. For a fully-distributed setup, this should be set to a full
    list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
    this is the list of servers which we will start/stop ZooKeeper on.
    </p><p>Default: <code class="varname">localhost</code></p></dd><dt><a name="hbase.zookeeper.peerport"></a><code class="varname">hbase.zookeeper.peerport</code></dt><dd><p>Port used by ZooKeeper peers to talk to each other.
    See http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    for more information.
    </p><p>Default: <code class="varname">2888</code></p></dd><dt><a name="hbase.zookeeper.leaderport"></a><code class="varname">hbase.zookeeper.leaderport</code></dt><dd><p>Port used by ZooKeeper for leader election.
    See http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    for more information.
    </p><p>Default: <code class="varname">3888</code></p></dd><dt><a name="hbase.zookeeper.property.initLimit"></a><code class="varname">hbase.zookeeper.property.initLimit</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that the initial synchronization phase can take.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.zookeeper.property.syncLimit"></a><code class="varname">hbase.zookeeper.property.syncLimit</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that can pass between sending a request and getting an
    acknowledgment.
    </p><p>Default: <code class="varname">5</code></p></dd><dt><a name="hbase.zookeeper.property.dataDir"></a><code class="varname">hbase.zookeeper.property.dataDir</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The directory where the snapshot is stored.
    </p><p>Default: <code class="varname">${hbase.tmp.dir}/zookeeper</code></p></dd><dt><a name="hbase.zookeeper.property.clientPort"></a><code class="varname">hbase.zookeeper.property.clientPort</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The port at which the clients will connect.
    </p><p>Default: <code class="varname">2181</code></p></dd><dt><a name="hbase.zookeeper.property.maxClientCnxns"></a><code class="varname">hbase.zookeeper.property.maxClientCnxns</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    Limit on number of concurrent connections (at the socket level) that a
    single client, identified by IP address, may make to a single member of
    the ZooKeeper ensemble. Set high to avoid zk connection issues running
    standalone and pseudo-distributed.
    </p><p>Default: <code class="varname">300</code></p></dd><dt><a name="hbase.rest.port"></a><code class="varname">hbase.rest.port</code></dt><dd><p>The port for the HBase REST server.</p><p>Default: <code class="varname">8080</code></p></dd><dt><a name="hbase.rest.readonly"></a><code class="varname">hbase.rest.readonly</code></dt><dd><p>
    Defines the mode the REST server will be started in. Possible values are:
    false: All HTTP methods are permitted - GET/PUT/POST/DELETE.
    true: Only the GET method is permitted.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.defaults.for.version.skip"></a><code class="varname">hbase.defaults.for.version.skip</code></dt><dd><p>
    Set to true to skip the 'hbase.defaults.for.version' check.
    Setting this to true can be useful in contexts other than
    the other side of a maven generation; i.e. running in an
    ide.  You'll want to set this boolean to true to avoid
    seeing the RuntimException complaint: "hbase-default.xml file
    seems to be for and old version of HBase (@@@VERSION@@@), this
    version is X.X.X-SNAPSHOT"
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.coprocessor.abortonerror"></a><code class="varname">hbase.coprocessor.abortonerror</code></dt><dd><p>
      Set to true to cause the hosting server (master or regionserver) to
      abort if a coprocessor throws a Throwable object that is not IOException or
      a subclass of IOException. Setting it to true might be useful in development
      environments where one wants to terminate the server as soon as possible to
      simplify coprocessor failure analysis.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.online.schema.update.enable"></a><code class="varname">hbase.online.schema.update.enable</code></dt><dd><p>
    Set true to enable online schema changes.  This is an experimental feature.  
    There are known issues modifying table schemas at the same time a region
    split is happening so your table needs to be quiescent or else you have to
    be running with splits disabled.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="dfs.support.append"></a><code class="varname">dfs.support.append</code></dt><dd><p>Does HDFS allow appends to files?
    This is an hdfs config. set in here so the hdfs client will do append support.
    You must ensure that this config. is true serverside too when running hbase
    (You will have to restart your cluster after setting it).
    </p><p>Default: <code class="varname">true</code></p></dd></dl></div></div></div><div class="section" title="2.6.2.&nbsp;hbase-env.sh"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.env.sh"></a>2.6.2.&nbsp;<code class="filename">hbase-env.sh</code></h3></div></div></div><p>Set HBase environment variables in this file.
      Examples include options to pass the JVM on start of
      an HBase daemon such as heap size and garbarge collector configs.
      You can also set configurations for HBase configuration, log directories,
      niceness, ssh options, where to locate process pid files,
      etc. Open the file at
      <code class="filename">conf/hbase-env.sh</code> and peruse its content.
      Each option is fairly well documented.  Add your own environment
      variables here if you want them read by HBase daemons on startup.</p><p>
      Changes here will require a cluster restart for HBase to notice the change.
      </p></div><div class="section" title="2.6.3.&nbsp;log4j.properties"><div class="titlepage"><div><div><h3 class="title"><a name="log4j"></a>2.6.3.&nbsp;<code class="filename">log4j.properties</code></h3></div></div></div><p>Edit this file to change rate at which HBase files
      are rolled and to change the level at which HBase logs messages.
      </p><p>
      Changes here will require a cluster restart for HBase to notice the change
      though log levels can be changed for particular daemons via the HBase UI.
      </p></div><div class="section" title="2.6.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster"><div class="titlepage"><div><div><h3 class="title"><a name="client_dependencies"></a>2.6.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster</h3></div></div></div><p>
          Since the HBase Master may move around, clients bootstrap by looking to ZooKeeper for
          current critical locations.  ZooKeeper is where all these values are kept.  Thus clients
          require the location of the ZooKeeper ensemble information before they can do anything else.
          Usually this the ensemble location is kept out in the <code class="filename">hbase-site.xml</code> and
          is picked up by the client from the <code class="varname">CLASSPATH</code>.</p><p>If you are configuring an IDE to run a HBase client, you should
            include the <code class="filename">conf/</code> directory on your classpath so
            <code class="filename">hbase-site.xml</code> settings can be found (or
            add <code class="filename">src/test/resources</code> to pick up the hbase-site.xml
            used by tests).
      </p><p>
          Minimally, a client of HBase needs the hbase, hadoop, log4j, commons-logging, commons-lang,
          and ZooKeeper jars in its <code class="varname">CLASSPATH</code> connecting to a cluster.
      </p><p>
          An example basic <code class="filename">hbase-site.xml</code> for client only
          might look as follows:
          </p><pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;example1,example2,example3&lt;/value&gt;
    &lt;description&gt;The directory shared by region servers.
    &lt;/description&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre><p>
        </p><div class="section" title="2.6.4.1.&nbsp;Java client configuration"><div class="titlepage"><div><div><h4 class="title"><a name="java.client.config"></a>2.6.4.1.&nbsp;Java client configuration</h4></div></div></div><p>The configuration used by a Java client is kept
        in an <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration" target="_top">HBaseConfiguration</a> instance.
        The factory method on HBaseConfiguration, <code class="code">HBaseConfiguration.create();</code>,
        on invocation, will read in the content of the first <code class="filename">hbase-site.xml</code> found on
        the client's <code class="varname">CLASSPATH</code>, if one is present
        (Invocation will also factor in any <code class="filename">hbase-default.xml</code> found;
        an hbase-default.xml ships inside the <code class="filename">hbase.X.X.X.jar</code>). 
        It is also possible to specify configuration directly without having to read from a
        <code class="filename">hbase-site.xml</code>.  For example, to set the ZooKeeper
        ensemble for the cluster programmatically do as follows:
        </p><pre class="programlisting">Configuration config = HBaseConfiguration.create();
config.set("hbase.zookeeper.quorum", "localhost");  // Here we are running zookeeper locally</pre><p>    
        If multiple ZooKeeper instances make up your ZooKeeper ensemble,
        they may be specified in a comma-separated list (just as in the <code class="filename">hbase-site.xml</code> file).
        This populated <code class="classname">Configuration</code> instance can then be passed to an 
        <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>,
        and so on.
        </p></div></div></div><div class="section" title="2.7.&nbsp;Example Configurations"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="example_config"></a>2.7.&nbsp;Example Configurations</h2></div></div></div><div class="section" title="2.7.1.&nbsp;Basic Distributed HBase Install"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2081"></a>2.7.1.&nbsp;Basic Distributed HBase Install</h3></div></div></div><p>Here is an example basic configuration for a distributed ten
        node cluster. The nodes are named <code class="varname">example0</code>,
        <code class="varname">example1</code>, etc., through node
        <code class="varname">example9</code> in this example. The HBase Master and the
        HDFS namenode are running on the node <code class="varname">example0</code>.
        RegionServers run on nodes
        <code class="varname">example1</code>-<code class="varname">example9</code>. A 3-node
        ZooKeeper ensemble runs on <code class="varname">example1</code>,
        <code class="varname">example2</code>, and <code class="varname">example3</code> on the
        default ports. ZooKeeper data is persisted to the directory
        <code class="filename">/export/zookeeper</code>. Below we show what the main
        configuration files -- <code class="filename">hbase-site.xml</code>,
        <code class="filename">regionservers</code>, and
        <code class="filename">hbase-env.sh</code> -- found in the HBase
        <code class="filename">conf</code> directory might look like.</p><div class="section" title="2.7.1.1.&nbsp;hbase-site.xml"><div class="titlepage"><div><div><h4 class="title"><a name="hbase_site"></a>2.7.1.1.&nbsp;<code class="filename">hbase-site.xml</code></h4></div></div></div><pre class="programlisting">

&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;example1,example2,example3&lt;/value&gt;
    &lt;description&gt;The directory shared by RegionServers.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
    &lt;value&gt;/export/zookeeper&lt;/value&gt;
    &lt;description&gt;Property from ZooKeeper's config zoo.cfg.
    The directory where the snapshot is stored.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://example0:8020/hbase&lt;/value&gt;
    &lt;description&gt;The directory shared by RegionServers.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;description&gt;The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    &lt;/description&gt;
  &lt;/property&gt;
&lt;/configuration&gt;

    </pre></div><div class="section" title="2.7.1.2.&nbsp;regionservers"><div class="titlepage"><div><div><h4 class="title"><a name="regionservers"></a>2.7.1.2.&nbsp;<code class="filename">regionservers</code></h4></div></div></div><p>In this file you list the nodes that will run RegionServers.
          In our case we run RegionServers on all but the head node
          <code class="varname">example1</code> which is carrying the HBase Master and
          the HDFS namenode</p><pre class="programlisting">
    example1
    example3
    example4
    example5
    example6
    example7
    example8
    example9
    </pre></div><div class="section" title="2.7.1.3.&nbsp;hbase-env.sh"><div class="titlepage"><div><div><h4 class="title"><a name="hbase_env"></a>2.7.1.3.&nbsp;<code class="filename">hbase-env.sh</code></h4></div></div></div><p>Below we use a <span class="command"><strong>diff</strong></span> to show the differences
          from default in the <code class="filename">hbase-env.sh</code> file. Here we
          are setting the HBase heap to be 4G instead of the default
          1G.</p><pre class="programlisting">
    
$ git diff hbase-env.sh
diff --git a/conf/hbase-env.sh b/conf/hbase-env.sh
index e70ebc6..96f8c27 100644
--- a/conf/hbase-env.sh
+++ b/conf/hbase-env.sh
@@ -31,7 +31,7 @@ export JAVA_HOME=/usr/lib//jvm/java-6-sun/
 # export HBASE_CLASSPATH=
 
 # The maximum amount of heap to use, in MB. Default is 1000.
-# export HBASE_HEAPSIZE=1000
+export HBASE_HEAPSIZE=4096
 
 # Extra Java runtime options.
 # Below are what we set by default.  May only work with SUN JVM.

    </pre><p>Use <span class="command"><strong>rsync</strong></span> to copy the content of the
          <code class="filename">conf</code> directory to all nodes of the
          cluster.</p></div></div></div><div class="section" title="2.8.&nbsp;The Important Configurations"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="important_configurations"></a>2.8.&nbsp;The Important Configurations</h2></div></div></div><p>Below we list what the <span class="emphasis"><em>important</em></span>
      Configurations.  We've divided this section into
      required configuration and worth-a-look recommended configs.
      </p><div class="section" title="2.8.1.&nbsp;Required Configurations"><div class="titlepage"><div><div><h3 class="title"><a name="required_configuration"></a>2.8.1.&nbsp;Required Configurations</h3></div></div></div><p>Review the <a class="xref" href="#os" title="2.2.&nbsp;Operating System">Section&nbsp;2.2, &#8220;Operating System&#8221;</a> and <a class="xref" href="#hadoop" title="2.3.&nbsp;Hadoop">Section&nbsp;2.3, &#8220;Hadoop&#8221;</a> sections.
      </p></div><div class="section" title="2.8.2.&nbsp;Recommended Configuations"><div class="titlepage"><div><div><h3 class="title"><a name="recommended_configurations"></a>2.8.2.&nbsp;Recommended Configuations</h3></div></div></div><div class="section" title="2.8.2.1.&nbsp;zookeeper.session.timeout"><div class="titlepage"><div><div><h4 class="title"><a name="zookeeper.session.timeout"></a>2.8.2.1.&nbsp;<code class="varname">zookeeper.session.timeout</code></h4></div></div></div><p>The default timeout is three minutes (specified in milliseconds). This means
              that if a server crashes, it will be three minutes before the Master notices
              the crash and starts recovery. You might like to tune the timeout down to
              a minute or even less so the Master notices failures the sooner.
              Before changing this value, be sure you have your JVM garbage collection
              configuration under control otherwise, a long garbage collection that lasts
              beyond the ZooKeeper session timeout will take out
              your RegionServer (You might be fine with this -- you probably want recovery to start
          on the server if a RegionServer has been in GC for a long period of time).</p><p>To change this configuration, edit <code class="filename">hbase-site.xml</code>,
          copy the changed file around the cluster and restart.</p><p>We set this value high to save our having to field noob questions up on the mailing lists asking
              why a RegionServer went down during a massive import.  The usual cause is that their JVM is untuned and
              they are running into long GC pauses.  Our thinking is that
              while users are  getting familiar with HBase, we'd save them having to know all of its
              intricacies.  Later when they've built some confidence, then they can play
              with configuration such as this.
          </p></div><div class="section" title="2.8.2.2.&nbsp;Number of ZooKeeper Instances"><div class="titlepage"><div><div><h4 class="title"><a name="zookeeper.instances"></a>2.8.2.2.&nbsp;Number of ZooKeeper Instances</h4></div></div></div><p>See <a class="xref" href="#zookeeper" title="2.5.&nbsp;ZooKeeper">Section&nbsp;2.5, &#8220;ZooKeeper&#8221;</a>.
          </p></div><div class="section" title="2.8.2.3.&nbsp;hbase.regionserver.handler.count"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.handler.count"></a>2.8.2.3.&nbsp;<code class="varname">hbase.regionserver.handler.count</code></h4></div></div></div><p>
          This setting defines the number of threads that are kept open to answer
          incoming requests to user tables. The default of 10 is rather low in order to
          prevent users from killing their region servers when using large write buffers
          with a high number of concurrent clients. The rule of thumb is to keep this
          number low when the payload per request approaches the MB (big puts, scans using
          a large cache) and high when the payload is small (gets, small puts, ICVs, deletes).
          </p><p>
          It is safe to set that number to the
          maximum number of incoming clients if their payload is small, the typical example
          being a cluster that serves a website since puts aren't typically buffered
          and most of the operations are gets.
          </p><p>
          The reason why it is dangerous to keep this setting high is that the aggregate
          size of all the puts that are currently happening in a region server may impose
          too much pressure on its memory, or even trigger an OutOfMemoryError. A region server
          running on low memory will trigger its JVM's garbage collector to run more frequently
          up to a point where GC pauses become noticeable (the reason being that all the memory
          used to keep all the requests' payloads cannot be trashed, no matter how hard the
          garbage collector tries). After some time, the overall cluster
          throughput is affected since every request that hits that region server will take longer,
          which exacerbates the problem even more.
          </p></div><div class="section" title="2.8.2.4.&nbsp;Configuration for large memory machines"><div class="titlepage"><div><div><h4 class="title"><a name="big_memory"></a>2.8.2.4.&nbsp;Configuration for large memory machines</h4></div></div></div><p>
          HBase ships with a reasonable, conservative configuration that will
          work on nearly all
          machine types that people might want to test with. If you have larger
          machines -- HBase has 8G and larger heap -- you might the following configuration options helpful.
          TODO.
        </p></div><div class="section" title="2.8.2.5.&nbsp;Compression"><div class="titlepage"><div><div><h4 class="title"><a name="config.compression"></a>2.8.2.5.&nbsp;Compression</h4></div></div></div><p>You should consider enabling ColumnFamily compression.  There are several options that are near-frictionless and in most all cases boost
      performance by reducing the size of StoreFiles and thus reducing I/O.
      </p><p>See <a class="xref" href="#compression" title="Appendix&nbsp;A.&nbsp;Compression In HBase">Appendix&nbsp;A, <i>Compression In HBase</i></a> for more information.</p></div><div class="section" title="2.8.2.6.&nbsp;Bigger Regions"><div class="titlepage"><div><div><h4 class="title"><a name="bigger.regions"></a>2.8.2.6.&nbsp;Bigger Regions</h4></div></div></div><p>
      Consider going to larger regions to cut down on the total number of regions
      on your cluster. Generally less Regions to manage makes for a smoother running
      cluster (You can always later manually split the big Regions should one prove
      hot and you want to spread the request load over the cluster).  By default,
      regions are 256MB in size.  You could run with
      1G.  Some run with even larger regions; 4G or even larger.  Adjust
      <code class="code">hbase.hregion.max.filesize</code> in your <code class="filename">hbase-site.xml</code>.
      </p></div><div class="section" title="2.8.2.7.&nbsp;Managed Splitting"><div class="titlepage"><div><div><h4 class="title"><a name="disable.splitting"></a>2.8.2.7.&nbsp;Managed Splitting</h4></div></div></div><p>
      Rather than let HBase auto-split your Regions, manage the splitting manually
      <sup>[<a name="d0e2248" href="#ftn.d0e2248" class="footnote">12</a>]</sup>.
 With growing amounts of data, splits will continually be needed. Since
 you always know exactly what regions you have, long-term debugging and
 profiling is much easier with manual splits. It is hard to trace the logs to
 understand region level problems if it keeps splitting and getting renamed.
 Data offlining bugs + unknown number of split regions == oh crap! If an
 <code class="classname">HLog</code> or <code class="classname">StoreFile</code>
 was mistakenly unprocessed by HBase due to a weird bug and
 you notice it a day or so later, you can be assured that the regions
 specified in these files are the same as the current regions and you have
 less headaches trying to restore/replay your data.
 You can finely tune your compaction algorithm. With roughly uniform data
 growth, it's easy to cause split / compaction storms as the regions all
 roughly hit the same data size at the same time. With manual splits, you can
 let staggered, time-based major compactions spread out your network IO load.
      </p><p>
 How do I turn off automatic splitting? Automatic splitting is determined by the configuration value
 <code class="code">hbase.hregion.max.filesize</code>. It is not recommended that you set this
 to <code class="varname">Long.MAX_VALUE</code> in case you forget about manual splits. A suggested setting
 is 100GB, which would result in &gt; 1hr major compactions if reached.
 </p><p>What's the optimal number of pre-split regions to create?
 Mileage will vary depending upon your application.
 You could start low with 10 pre-split regions / server and watch as data grows
 over time. It's better to err on the side of too little regions and rolling split later.
 A more complicated answer is that this depends upon the largest storefile
 in your region. With a growing data size, this will get larger over time. You
 want the largest region to be just big enough that the <code class="classname">Store</code> compact
 selection algorithm only compacts it due to a timed major. If you don't, your
 cluster can be prone to compaction storms as the algorithm decides to run
 major compactions on a large series of regions all at once. Note that
 compaction storms are due to the uniform data growth, not the manual split
 decision.
 </p><p> If you pre-split your regions too thin, you can increase the major compaction
interval by configuring <code class="varname">HConstants.MAJOR_COMPACTION_PERIOD</code>. If your data size
grows too large, use the (post-0.90.0 HBase) <code class="classname">org.apache.hadoop.hbase.util.RegionSplitter</code>
script to perform a network IO safe rolling split
of all regions.
</p></div><div class="section" title="2.8.2.8.&nbsp;Managed Compactions"><div class="titlepage"><div><div><h4 class="title"><a name="managed.compactions"></a>2.8.2.8.&nbsp;Managed Compactions</h4></div></div></div><p>A common administrative technique is to manage major compactions manually, rather than letting 
      HBase do it.  By default, <code class="varname">HConstants.MAJOR_COMPACTION_PERIOD</code> is one day and major compactions
      may kick in when you least desire it - especially on a busy system.  To "turn off" automatic major compactions set
      the value to <code class="varname">Long.MAX_VALUE</code>. 
      </p><p>It is important to stress that major compactions are absolutely necessary for StoreFile cleanup, the only variant is when
      they occur.  They can be administered through the HBase shell, or via 
      <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html#majorCompact%28java.lang.String%29" target="_top">HBaseAdmin</a>.
      </p></div></div><div class="section" title="2.8.3.&nbsp;Other Configurations"><div class="titlepage"><div><div><h3 class="title"><a name="other_configuration"></a>2.8.3.&nbsp;Other Configurations</h3></div></div></div><div class="section" title="2.8.3.1.&nbsp;Balancer"><div class="titlepage"><div><div><h4 class="title"><a name="balancer_config"></a>2.8.3.1.&nbsp;Balancer</h4></div></div></div><p>The balancer is periodic operation run on the master to redistribute regions on the cluster.  It is configured via
           <code class="varname">hbase.balancer.period</code> and defaults to 300000 (5 minutes). </p><p>See <a class="xref" href="#master.processes.loadbalancer" title="8.4.3.1.&nbsp;LoadBalancer">Section&nbsp;8.4.3.1, &#8220;LoadBalancer&#8221;</a> for more information on the LoadBalancer.
           </p></div></div></div><div class="section" title="2.9.&nbsp;Bloom Filter Configuration"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="config.bloom"></a>2.9.&nbsp;Bloom Filter Configuration</h2></div></div></div><div class="section" title="2.9.1.&nbsp;io.hfile.bloom.enabled global kill switch"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2317"></a>2.9.1.&nbsp;<code class="varname">io.hfile.bloom.enabled</code> global kill
        switch</h3></div></div></div><p><code class="code">io.hfile.bloom.enabled</code> in
        <code class="classname">Configuration</code> serves as the kill switch in case
        something goes wrong. Default = <code class="varname">true</code>.</p></div><div class="section" title="2.9.2.&nbsp;io.hfile.bloom.error.rate"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2332"></a>2.9.2.&nbsp;<code class="varname">io.hfile.bloom.error.rate</code></h3></div></div></div><p><code class="varname">io.hfile.bloom.error.rate</code> = average false
        positive rate. Default = 1%. Decrease rate by &frac12; (e.g. to .5%) == +1
        bit per bloom entry.</p></div><div class="section" title="2.9.3.&nbsp;io.hfile.bloom.max.fold"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2340"></a>2.9.3.&nbsp;<code class="varname">io.hfile.bloom.max.fold</code></h3></div></div></div><p><code class="varname">io.hfile.bloom.max.fold</code> = guaranteed minimum
        fold rate. Most people should leave this alone. Default = 7, or can
        collapse to at least 1/128th of original size. See the
        <span class="emphasis"><em>Development Process</em></span> section of the document <a class="link" href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf" target="_top">BloomFilters
        in HBase</a> for more on what this option means.</p></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e268" href="#d0e268" class="para">1</a>] </sup>
Be careful editing XML.  Make sure you close all elements.
Run your file through <span class="command"><strong>xmllint</strong></span> or similar
to ensure well-formedness of your document after an edit session.
</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e361" href="#d0e361" class="para">2</a>] </sup>See Jack Levin's <a class="link" href="" target="_top">major hdfs issues</a>
                note up on the user list.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e368" href="#d0e368" class="para">3</a>] </sup>The requirement that a database requires upping of system limits
        is not peculiar to HBase.  See for example the section
        <span class="emphasis"><em>Setting Shell Limits for the Oracle User</em></span> in
        <a class="link" href="http://www.akadia.com/services/ora_linux_install_10g.html" target="_top">
        Short Guide to install Oracle 10 on Linux</a>.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e380" href="#d0e380" class="para">4</a>] </sup>A useful read setting config on you hadoop cluster is Aaron
            Kimballs' Configuration
            Parameters: What can you just ignore?</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e469" href="#d0e469" class="para">5</a>] </sup>Until recently only the
        <a class="link" href="http://svn.apache.org/viewvc/hadoop/common/branches/branch-0.20-append/" target="_top">branch-0.20-append</a>
        branch had a working sync but no official release was ever made from this branch.
        You had to build it yourself. Michael Noll wrote a detailed blog,
        <a class="link" href="http://www.michael-noll.com/blog/2011/04/14/building-an-hadoop-0-20-x-version-for-hbase-0-90-2/" target="_top">Building
        an Hadoop 0.20.x version for HBase 0.90.2</a>, on how to build an
    Hadoop from branch-0.20-append.  Recommended.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e479" href="#d0e479" class="para">6</a>] </sup>Praveen Kumar has written
            a complimentary article,
            <a class="link" href="http://praveen.kumar.in/2011/06/20/building-hadoop-and-hbase-for-hbase-maven-application-development/" target="_top">Building Hadoop and HBase for HBase Maven application development</a>.
</p></div><div class="footnote"><code class="varname"><sup>[<a name="ftn.d0e485" href="#d0e485" class="varname">7</a>] </sup>dfs.support.append</code></div><div class="footnote"><p><sup>[<a id="ftn.d0e556" href="#d0e556" class="para">8</a>] </sup>See <a class="link" href="http://ccgtech.blogspot.com/2010/02/hadoop-hdfs-deceived-by-xciever.html" target="_top">Hadoop HDFS: Deceived by Xciever</a> for an informative rant on xceivering.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e610" href="#d0e610" class="para">9</a>] </sup>The pseudo-distributed vs fully-distributed nomenclature
            comes from Hadoop.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e673" href="#d0e673" class="para">10</a>] </sup>See <a class="link" href="http://hbase.apache.org/pseudo-distributed.html" target="_top">Pseudo-distributed
              mode extras</a> for notes on how to start extra Masters and
              RegionServers when running pseudo-distributed.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e863" href="#d0e863" class="para">11</a>] </sup>For the full list of ZooKeeper configurations, see
                ZooKeeper's <code class="filename">zoo.cfg</code>. HBase does not ship
                with a <code class="filename">zoo.cfg</code> so you will need to browse
                the <code class="filename">conf</code> directory in an appropriate
                ZooKeeper download.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e2248" href="#d0e2248" class="para">12</a>] </sup>What follows is taken from the javadoc at the head of
      the <code class="classname">org.apache.hadoop.hbase.util.RegionSplitter</code> tool
      added to HBase post-0.90.0 release.
      </p></div></div></div><div class="chapter" title="Chapter&nbsp;3.&nbsp;Upgrading"><div class="titlepage"><div><div><h2 class="title"><a name="upgrading"></a>Chapter&nbsp;3.&nbsp;Upgrading</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#upgrade0.90">3.1. Upgrading to HBase 0.90.x from 0.20.x or 0.89.x</a></span></dt></dl></div><p>
        Review <a class="xref" href="#configuration" title="Chapter&nbsp;2.&nbsp;Configuration">Chapter&nbsp;2, <i>Configuration</i></a>, in particular the section on Hadoop version.
    </p><div class="section" title="3.1.&nbsp;Upgrading to HBase 0.90.x from 0.20.x or 0.89.x"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="upgrade0.90"></a>3.1.&nbsp;Upgrading to HBase 0.90.x from 0.20.x or 0.89.x</h2></div></div></div><p>This version of 0.90.x HBase can be started on data written by
              HBase 0.20.x or HBase 0.89.x.  There is no need of a migration step.
              HBase 0.89.x and 0.90.x does write out the name of region directories
              differently -- it names them with a md5 hash of the region name rather
              than a jenkins hash -- so this means that once started, there is no
              going back to HBase 0.20.x.
          </p><p>
             Be sure to remove the <code class="filename">hbase-default.xml</code> from
             your <code class="filename">conf</code>
             directory on upgrade.  A 0.20.x version of this file will have
             sub-optimal configurations for 0.90.x HBase.  The
             <code class="filename">hbase-default.xml</code> file is now bundled into the
             HBase jar and read from there.  If you would like to review
             the content of this file, see it in the src tree at
             <code class="filename">src/main/resources/hbase-default.xml</code> or
             see <a class="xref" href="#hbase_default_configurations" title="2.6.1.1.&nbsp;HBase Default Configuration">Section&nbsp;2.6.1.1, &#8220;HBase Default Configuration&#8221;</a>.
          </p><p>
            Finally, if upgrading from 0.20.x, check your 
            <code class="varname">.META.</code> schema in the shell.  In the past we would
            recommend that users run with a 16kb
            <code class="varname">MEMSTORE_FLUSHSIZE</code>.
            Run <code class="code">hbase&gt; scan '-ROOT-'</code> in the shell. This will output
            the current <code class="varname">.META.</code> schema.  Check
            <code class="varname">MEMSTORE_FLUSHSIZE</code> size.  Is it 16kb (16384)?  If so, you will
            need to change this (The 'normal'/default value is 64MB (67108864)).
            Run the script <code class="filename">bin/set_meta_memstore_size.rb</code>.
            This will make the necessary edit to your <code class="varname">.META.</code> schema.
            Failure to run this change will make for a slow cluster <sup>[<a name="d0e2406" href="#ftn.d0e2406" class="footnote">13</a>]</sup>
            .

          </p></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e2406" href="#d0e2406" class="para">13</a>] </sup>
            See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-3499" target="_top">HBASE-3499 Users upgrading to 0.90.0 need to have their .META. table updated with the right MEMSTORE_SIZE</a>
            </p></div></div></div><div class="chapter" title="Chapter&nbsp;4.&nbsp;The HBase Shell"><div class="titlepage"><div><div><h2 class="title"><a name="shell"></a>Chapter&nbsp;4.&nbsp;The HBase Shell</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#scripting">4.1. Scripting</a></span></dt><dt><span class="section"><a href="#shell_tricks">4.2. Shell Tricks</a></span></dt><dd><dl><dt><span class="section"><a href="#d0e2456">4.2.1. <code class="filename">irbrc</code></a></span></dt><dt><span class="section"><a href="#d0e2474">4.2.2. LOG data to timestamp</a></span></dt><dt><span class="section"><a href="#d0e2492">4.2.3. Debug</a></span></dt></dl></dd></dl></div><p>
        The HBase Shell is <a class="link" href="http://jruby.org" target="_top">(J)Ruby</a>'s
        IRB with some HBase particular commands added.  Anything you can do in
        IRB, you should be able to do in the HBase Shell.</p><p>To run the HBase shell, 
        do as follows:
        </p><pre class="programlisting">$ ./bin/hbase shell</pre><p>
        </p><p>Type <span class="command"><strong>help</strong></span> and then <span class="command"><strong>&lt;RETURN&gt;</strong></span>
            to see a listing of shell
            commands and options. Browse at least the paragraphs at the end of
            the help emission for the gist of how variables and command
            arguments are entered into the
            HBase shell; in particular note how table names, rows, and
            columns, etc., must be quoted.</p><p>See <a class="xref" href="#shell_exercises" title="1.2.3.&nbsp;Shell Exercises">Section&nbsp;1.2.3, &#8220;Shell Exercises&#8221;</a>
            for example basic shell operation.</p><div class="section" title="4.1.&nbsp;Scripting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="scripting"></a>4.1.&nbsp;Scripting</h2></div></div></div><p>For examples scripting HBase, look in the
            HBase <code class="filename">bin</code> directory.  Look at the files
            that end in <code class="filename">*.rb</code>.  To run one of these
            files, do as follows:
            </p><pre class="programlisting">$ ./bin/hbase org.jruby.Main PATH_TO_SCRIPT</pre><p>
        </p></div><div class="section" title="4.2.&nbsp;Shell Tricks"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="shell_tricks"></a>4.2.&nbsp;Shell Tricks</h2></div></div></div><div class="section" title="4.2.1.&nbsp;irbrc"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2456"></a>4.2.1.&nbsp;<code class="filename">irbrc</code></h3></div></div></div><p>Create an <code class="filename">.irbrc</code> file for yourself in your
                    home directory. Add customizations. A useful one is
                    command history so commands are save across Shell invocations:
                    </p><pre class="programlisting">
                        $ more .irbrc
                        require 'irb/ext/save-history'
                        IRB.conf[:SAVE_HISTORY] = 100
                        IRB.conf[:HISTORY_FILE] = "#{ENV['HOME']}/.irb-save-history"</pre><p>
                See the <span class="application">ruby</span> documentation of
                <code class="filename">.irbrc</code> to learn about other possible
                confiurations.
                </p></div><div class="section" title="4.2.2.&nbsp;LOG data to timestamp"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2474"></a>4.2.2.&nbsp;LOG data to timestamp</h3></div></div></div><p>
                To convert the date '08/08/16 20:56:29' from an hbase log into a timestamp, do:
                </p><pre class="programlisting">
                    hbase(main):021:0&gt; import java.text.SimpleDateFormat
                    hbase(main):022:0&gt; import java.text.ParsePosition
                    hbase(main):023:0&gt; SimpleDateFormat.new("yy/MM/dd HH:mm:ss").parse("08/08/16 20:56:29", ParsePosition.new(0)).getTime() =&gt; 1218920189000</pre><p>
            </p><p>
                To go the other direction:
                </p><pre class="programlisting">
                    hbase(main):021:0&gt; import java.util.Date
                    hbase(main):022:0&gt; Date.new(1218920189000).toString() =&gt; "Sat Aug 16 20:56:29 UTC 2008"</pre><p>
            </p><p>
                To output in a format that is exactly like that of the HBase log format will take a little messing with
                <a class="link" href="http://download.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html" target="_top">SimpleDateFormat</a>.
            </p></div><div class="section" title="4.2.3.&nbsp;Debug"><div class="titlepage"><div><div><h3 class="title"><a name="d0e2492"></a>4.2.3.&nbsp;Debug</h3></div></div></div><div class="section" title="4.2.3.1.&nbsp;Shell debug switch"><div class="titlepage"><div><div><h4 class="title"><a name="d0e2495"></a>4.2.3.1.&nbsp;Shell debug switch</h4></div></div></div><p>You can set a debug switch in the shell to see more output
                    -- e.g. more of the stack trace on exception --
                    when you run a command:
                    </p><pre class="programlisting">hbase&gt; debug &lt;RETURN&gt;</pre><p>
                 </p></div><div class="section" title="4.2.3.2.&nbsp;DEBUG log level"><div class="titlepage"><div><div><h4 class="title"><a name="d0e2503"></a>4.2.3.2.&nbsp;DEBUG log level</h4></div></div></div><p>To enable DEBUG level logging in the shell,
                    launch it with the <span class="command"><strong>-d</strong></span> option.
                    </p><pre class="programlisting">$ ./bin/hbase shell -d</pre><p>
               </p></div></div></div></div><div class="chapter" title="Chapter&nbsp;5.&nbsp;Data Model"><div class="titlepage"><div><div><h2 class="title"><a name="datamodel"></a>Chapter&nbsp;5.&nbsp;Data Model</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#conceptual.view">5.1. Conceptual View</a></span></dt><dt><span class="section"><a href="#physical.view">5.2. Physical View</a></span></dt><dt><span class="section"><a href="#table">5.3. Table</a></span></dt><dt><span class="section"><a href="#row">5.4. Row</a></span></dt><dt><span class="section"><a href="#columnfamily">5.5. Column Family</a></span></dt><dt><span class="section"><a href="#cells">5.6. Cells</a></span></dt><dt><span class="section"><a href="#data_model_operations">5.7. Data Model Operations</a></span></dt><dd><dl><dt><span class="section"><a href="#get">5.7.1. Get</a></span></dt><dt><span class="section"><a href="#put">5.7.2. Put</a></span></dt><dt><span class="section"><a href="#scan">5.7.3. Scans</a></span></dt><dt><span class="section"><a href="#delete">5.7.4. Delete</a></span></dt></dl></dd><dt><span class="section"><a href="#versions">5.8. Versions</a></span></dt><dd><dl><dt><span class="section"><a href="#versions.ops">5.8.1. Versions and HBase Operations</a></span></dt><dt><span class="section"><a href="#d0e3063">5.8.2. Current Limitations</a></span></dt></dl></dd></dl></div><p>In short, applications store data into an HBase table.
        Tables are made of rows and columns.
      All columns in HBase belong to a particular column family.
      Table cells -- the intersection of row and column
      coordinates -- are versioned.
      A cell&#8217;s content is an uninterpreted array of bytes.
  </p><p>Table row keys are also byte arrays so almost anything can
      serve as a row key from strings to binary representations of longs or
      even serialized data structures. Rows in HBase tables
      are sorted by row key. The sort is byte-ordered. All table accesses are
      via the table row key -- its primary key.
</p><div class="section" title="5.1.&nbsp;Conceptual View"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="conceptual.view"></a>5.1.&nbsp;Conceptual View</h2></div></div></div><p>
        The following example is a slightly modified form of the one on page
        2 of the <a class="link" href="http://labs.google.com/papers/bigtable.html" target="_top">BigTable</a> paper.
    There is a table called <code class="varname">webtable</code> that contains two column families named
    <code class="varname">contents</code> and <code class="varname">anchor</code>.
    In this example, <code class="varname">anchor</code> contains two
    columns (<code class="varname">anchor:cssnsi.com</code>, <code class="varname">anchor:my.look.ca</code>)
    and <code class="varname">contents</code> contains one column (<code class="varname">contents:html</code>).
    </p><div class="note" title="Column Names" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Column Names</h3><p>
      By convention, a column name is made of its column family prefix and a
      <span class="emphasis"><em>qualifier</em></span>. For example, the
      column
      <span class="emphasis"><em>contents:html</em></span> is of the column family <code class="varname">contents</code>
          The colon character (<code class="literal">:</code>) delimits the column family from the
          column family <span class="emphasis"><em>qualifier</em></span>.
    </p></div><p>
    </p><div class="table"><a name="d0e2574"></a><p class="title"><b>Table&nbsp;5.1.&nbsp;Table <code class="varname">webtable</code></b></p><div class="table-contents"><table summary="Table webtable" border="1"><colgroup><col align="left" class="c1"><col align="left" class="c2"><col align="left" class="c3"><col align="left" class="c4"></colgroup><thead><tr><th align="left">Row Key</th><th align="left">Time Stamp</th><th align="left">ColumnFamily <code class="varname">contents</code></th><th align="left">ColumnFamily <code class="varname">anchor</code></th></tr></thead><tbody><tr><td align="left">"com.cnn.www"</td><td align="left">t9</td><td align="left">&nbsp;</td><td align="left"><code class="varname">anchor:cnnsi.com</code> = "CNN"</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t8</td><td align="left">&nbsp;</td><td align="left"><code class="varname">anchor:my.look.ca</code> = "CNN.com"</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t6</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td><td align="left">&nbsp;</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t5</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td><td align="left">&nbsp;</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t3</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td><td align="left">&nbsp;</td></tr></tbody></table></div></div><p><br class="table-break">
	</p></div><div class="section" title="5.2.&nbsp;Physical View"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="physical.view"></a>5.2.&nbsp;Physical View</h2></div></div></div><p>
        Although at a conceptual level tables may be viewed as a sparse set of rows.
        Physically they are stored on a per-column family basis.  New columns
        (i.e., <code class="varname">columnfamily:column</code>) can be added to any
        column family without pre-announcing them. 
        </p><div class="table"><a name="d0e2658"></a><p class="title"><b>Table&nbsp;5.2.&nbsp;ColumnFamily <code class="varname">anchor</code></b></p><div class="table-contents"><table summary="ColumnFamily anchor" border="1"><colgroup><col align="left" class="c1"><col align="left" class="c2"><col align="left" class="c3"></colgroup><thead><tr><th align="left">Row Key</th><th align="left">Time Stamp</th><th align="left">Column Family <code class="varname">anchor</code></th></tr></thead><tbody><tr><td align="left">"com.cnn.www"</td><td align="left">t9</td><td align="left"><code class="varname">anchor:cnnsi.com</code> = "CNN"</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t8</td><td align="left"><code class="varname">anchor:my.look.ca</code> = "CNN.com"</td></tr></tbody></table></div></div><p><br class="table-break">
    </p><div class="table"><a name="d0e2697"></a><p class="title"><b>Table&nbsp;5.3.&nbsp;ColumnFamily <code class="varname">contents</code></b></p><div class="table-contents"><table summary="ColumnFamily contents" border="1"><colgroup><col align="left" class="c1"><col align="left" class="c2"><col align="left" class="c3"></colgroup><thead><tr><th align="left">Row Key</th><th align="left">Time Stamp</th><th align="left">ColumnFamily "contents:"</th></tr></thead><tbody><tr><td align="left">"com.cnn.www"</td><td align="left">t6</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t5</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td></tr><tr><td align="left">"com.cnn.www"</td><td align="left">t3</td><td align="left"><code class="varname">contents:html</code> = "&lt;html&gt;..."</td></tr></tbody></table></div></div><p><br class="table-break">
    It is important to note in the diagram above that the empty cells shown in the
    conceptual view are not stored since they need not be in a column-oriented
    storage format. Thus a request for the value of the <code class="varname">contents:html</code>
    column at time stamp <code class="literal">t8</code> would return no value. Similarly, a
    request for an <code class="varname">anchor:my.look.ca</code> value at time stamp
    <code class="literal">t9</code> would return no value.  However, if no timestamp is
    supplied, the most recent value for a particular column would be returned
    and would also be the first one found since timestamps are stored in
    descending order. Thus a request for the values of all columns in the row
    <code class="varname">com.cnn.www</code> if no timestamp is specified would be:
    the value of <code class="varname">contents:html</code> from time stamp
    <code class="literal">t6</code>, the value of <code class="varname">anchor:cnnsi.com</code>
    from time stamp <code class="literal">t9</code>, the value of 
    <code class="varname">anchor:my.look.ca</code> from time stamp <code class="literal">t8</code>.
	</p></div><div class="section" title="5.3.&nbsp;Table"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table"></a>5.3.&nbsp;Table</h2></div></div></div><p>
      Tables are declared up front at schema definition time.
      </p></div><div class="section" title="5.4.&nbsp;Row"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="row"></a>5.4.&nbsp;Row</h2></div></div></div><p>Row keys are uninterrpreted bytes. Rows are
      lexicographically sorted with the lowest order appearing first
      in a table.  The empty byte array is used to denote both the
      start and end of a tables' namespace.</p></div><div class="section" title="5.5.&nbsp;Column Family"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="columnfamily"></a>5.5.&nbsp;Column Family<a class="indexterm" name="d0e2789"></a></h2></div></div></div><p>
      Columns in HBase are grouped into <span class="emphasis"><em>column families</em></span>.
      All column members of a column family have the same prefix.  For example, the
      columns <span class="emphasis"><em>courses:history</em></span> and
      <span class="emphasis"><em>courses:math</em></span> are both members of the
      <span class="emphasis"><em>courses</em></span> column family.
          The colon character (<code class="literal">:</code>) delimits the column family from the
      <a class="indexterm" name="d0e2809"></a>.
        The column family prefix must be composed of
      <span class="emphasis"><em>printable</em></span> characters. The qualifying tail, the
      column family <span class="emphasis"><em>qualifier</em></span>, can be made of any
      arbitrary bytes. Column families must be declared up front
      at schema definition time whereas columns do not need to be
      defined at schema time but can be conjured on the fly while
      the table is up an running.</p><p>Physically, all column family members are stored together on the
      filesystem.  Because tunings and
      storage specifications are done at the column family level, it is
      advised that all column family members have the same general access
      pattern and size characteristics.</p><p></p></div><div class="section" title="5.6.&nbsp;Cells"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="cells"></a>5.6.&nbsp;Cells<a class="indexterm" name="d0e2828"></a></h2></div></div></div><p>A <span class="emphasis"><em>{row, column, version} </em></span>tuple exactly
      specifies a <code class="literal">cell</code> in HBase. 
      Cell content is uninterrpreted bytes</p></div><div class="section" title="5.7.&nbsp;Data Model Operations"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="data_model_operations"></a>5.7.&nbsp;Data Model Operations</h2></div></div></div><p>The four primary data model operations are Get, Put, Scan, and Delete.  Operations are applied via 
       <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a> instances.
       </p><div class="section" title="5.7.1.&nbsp;Get"><div class="titlepage"><div><div><h3 class="title"><a name="get"></a>5.7.1.&nbsp;Get</h3></div></div></div><p><a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Get.html" target="_top">Get</a> returns
        attributes for a specified row.  Gets are executed via 
        <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#get%28org.apache.hadoop.hbase.client.Get%29" target="_top">
        HTable.get</a>.
        </p></div><div class="section" title="5.7.2.&nbsp;Put"><div class="titlepage"><div><div><h3 class="title"><a name="put"></a>5.7.2.&nbsp;Put</h3></div></div></div><p><a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Put.html" target="_top">Put</a> either 
        adds new rows to a table (if the key is new) or can update existing rows (if the key already exists).  Puts are executed via
        <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#put%28org.apache.hadoop.hbase.client.Put%29" target="_top">
        HTable.put</a> (writeBuffer) or <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#batch%28java.util.List%29" target="_top">
        HTable.batch</a> (non-writeBuffer).  
        </p></div><div class="section" title="5.7.3.&nbsp;Scans"><div class="titlepage"><div><div><h3 class="title"><a name="scan"></a>5.7.3.&nbsp;Scans</h3></div></div></div><p><a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scan</a> allow
          iteration over multiple rows for specified attributes.
          </p><p>The following is an example of a 
           on an HTable table instance.  Assume that a table is populated with rows with keys "row1", "row2", "row3", 
           and then another set of rows with the keys "abc1", "abc2", and "abc3".  The following example shows how startRow and stopRow 
           can be applied to a Scan instance to return the rows beginning with "row".        
</p><pre class="programlisting">
HTable htable = ...      // instantiate HTable
    
Scan scan = new Scan();
scan.addColumn(Bytes.toBytes("cf"),Bytes.toBytes("attr"));
scan.setStartRow( Bytes.toBytes("row"));
scan.setStopRow( Bytes.toBytes("row" +  new byte[] {0}));  // note: stop key != start key
for(Result result : htable.getScanner(scan)) {
  // process Result instance
}
</pre><p>
         </p></div><div class="section" title="5.7.4.&nbsp;Delete"><div class="titlepage"><div><div><h3 class="title"><a name="delete"></a>5.7.4.&nbsp;Delete</h3></div></div></div><p><a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Delete.html" target="_top">Delete</a> removes
        a row from a table.  Deletes are executed via 
        <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/HTable.html#delete%28org.apache.hadoop.hbase.client.Delete%29" target="_top">
        HTable.delete</a>.
        </p></div></div><div class="section" title="5.8.&nbsp;Versions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="versions"></a>5.8.&nbsp;Versions<a class="indexterm" name="d0e2895"></a></h2></div></div></div><p>A <span class="emphasis"><em>{row, column, version} </em></span>tuple exactly
      specifies a <code class="literal">cell</code> in HBase. Its possible to have an
      unbounded number of cells where the row and column are the same but the
      cell address differs only in its version dimension.</p><p>While rows and column keys are expressed as bytes, the version is
      specified using a long integer. Typically this long contains time
      instances such as those returned by
      <code class="code">java.util.Date.getTime()</code> or
      <code class="code">System.currentTimeMillis()</code>, that is: <span class="quote">&#8220;<span class="quote">the difference,
      measured in milliseconds, between the current time and midnight, January
      1, 1970 UTC</span>&#8221;</span>.</p><p>The HBase version dimension is stored in decreasing order, so that
      when reading from a store file, the most recent values are found
      first.</p><p>There is a lot of confusion over the semantics of
      <code class="literal">cell</code> versions, in HBase. In particular, a couple
      questions that often come up are:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>If multiple writes to a cell have the same version, are all
            versions maintained or just the last?<sup>[<a name="d0e2928" href="#ftn.d0e2928" class="footnote">14</a>]</sup></p></li><li class="listitem"><p>Is it OK to write cells in a non-increasing version
            order?<sup>[<a name="d0e2934" href="#ftn.d0e2934" class="footnote">15</a>]</sup></p></li></ul></div><p>Below we describe how the version dimension in HBase currently
      works<sup>[<a name="d0e2939" href="#ftn.d0e2939" class="footnote">16</a>]</sup>.</p><div class="section" title="5.8.1.&nbsp;Versions and HBase Operations"><div class="titlepage"><div><div><h3 class="title"><a name="versions.ops"></a>5.8.1.&nbsp;Versions and HBase Operations</h3></div></div></div><p>In this section we look at the behavior of the version dimension
        for each of the core HBase operations.</p><div class="section" title="5.8.1.1.&nbsp;Get/Scan"><div class="titlepage"><div><div><h4 class="title"><a name="d0e2957"></a>5.8.1.1.&nbsp;Get/Scan</h4></div></div></div><p>Gets are implemented on top of Scans. The below discussion of
            <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Get.html" target="_top">Get</a> applies equally to <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scans</a>.</p><p>By default, i.e. if you specify no explicit version, when
          doing a <code class="literal">get</code>, the cell whose version has the
          largest value is returned (which may or may not be the latest one
          written, see later). The default behavior can be modified in the
          following ways:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>to return more than one version, see <a class="link" href="http://hbase.apache.org/docs/current/api/org/apache/hadoop/hbase/client/Get.html#setMaxVersions()" target="_top">Get.setMaxVersions()</a></p></li><li class="listitem"><p>to return versions other than the latest, see <a class="link" href="???" target="_top">Get.setTimeRange()</a></p><p>To retrieve the latest version that is less than or equal
              to a given value, thus giving the 'latest' state of the record
              at a certain point in time, just use a range from 0 to the
              desired version and set the max versions to 1.</p></li></ul></div></div><div class="section" title="5.8.1.2.&nbsp;Default Get Example"><div class="titlepage"><div><div><h4 class="title"><a name="default_get_example"></a>5.8.1.2.&nbsp;Default Get Example</h4></div></div></div><p>The following Get will only retrieve the current version of the row
</p><pre class="programlisting">
Get get = new Get(Bytes.toBytes("row1"));
Result r = htable.get(get);
byte[] b = r.getValue(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns current version of value          
</pre><p>
        </p></div><div class="section" title="5.8.1.3.&nbsp;Versioned Get Example"><div class="titlepage"><div><div><h4 class="title"><a name="versioned_get_example"></a>5.8.1.3.&nbsp;Versioned Get Example</h4></div></div></div><p>The following Get will return the last 3 versions of the row.
</p><pre class="programlisting">
Get get = new Get(Bytes.toBytes("row1"));
get.setMaxVersions(3);  // will return last 3 versions of row
Result r = htable.get(get);
byte[] b = r.getValue(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns current version of value
List&lt;KeyValue&gt; kv = r.getColumn(Bytes.toBytes("cf"), Bytes.toBytes("attr"));  // returns all versions of this column       
</pre><p>
        </p></div><div class="section" title="5.8.1.4.&nbsp;Put"><div class="titlepage"><div><div><h4 class="title"><a name="d0e3002"></a>5.8.1.4.&nbsp;Put</h4></div></div></div><p>Doing a put always creates a new version of a
          <code class="literal">cell</code>, at a certain timestamp. By default the
          system uses the server's <code class="literal">currentTimeMillis</code>, but
          you can specify the version (= the long integer) yourself, on a
          per-column level. This means you could assign a time in the past or
          the future, or use the long value for non-time purposes.</p><p>To overwrite an existing value, do a put at exactly the same
          row, column, and version as that of the cell you would
          overshadow.</p><div class="section" title="5.8.1.4.1.&nbsp;Implicit Version Example"><div class="titlepage"><div><div><h5 class="title"><a name="implicit_version_example"></a>5.8.1.4.1.&nbsp;Implicit Version Example</h5></div></div></div><p>The following Put will be implicitly versioned by HBase with the current time.
</p><pre class="programlisting">
Put put = new Put(Bytes.toBytes(row));
put.add(Bytes.toBytes("cf"), Bytes.toBytes("attr1"), Bytes.toBytes( data));
htable.put(put);
</pre><p>
          </p></div><div class="section" title="5.8.1.4.2.&nbsp;Explicit Version Example"><div class="titlepage"><div><div><h5 class="title"><a name="explicit_version_example"></a>5.8.1.4.2.&nbsp;Explicit Version Example</h5></div></div></div><p>The following Put has the version timestamp explicitly set.
</p><pre class="programlisting">
Put put = new Put( Bytes.toBytes(row));
long explicitTimeInMs = 555;  // just an example
put.add(Bytes.toBytes("cf"), Bytes.toBytes("attr1"), explicitTimeInMs, Bytes.toBytes(data));
htable.put(put);
</pre><p>
          Caution:  the version timestamp is internally by HBase for things like time-to-live calculations.  
          It's usually best to avoid setting this timestamp yourself.  Prefer using a separate 
          timestamp attribute of the row, or have the timestamp a part of the rowkey, or both.
          </p></div></div><div class="section" title="5.8.1.5.&nbsp;Delete"><div class="titlepage"><div><div><h4 class="title"><a name="d0e3031"></a>5.8.1.5.&nbsp;Delete</h4></div></div></div><p>When performing a delete operation in HBase, there are two
          ways to specify the versions to be deleted</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Delete all versions older than a certain timestamp</p></li><li class="listitem"><p>Delete the version at a specific timestamp</p></li></ul></div><p>A delete can apply to a complete row, a complete column
          family, or to just one column. It is only in the last case that you
          can delete explicit versions. For the deletion of a row or all the
          columns within a family, it always works by deleting all cells older
          than a certain version.</p><p>Deletes work by creating <span class="emphasis"><em>tombstone</em></span>
          markers. For example, let's suppose we want to delete a row. For
          this you can specify a version, or else by default the
          <code class="literal">currentTimeMillis</code> is used. What this means is
          <span class="quote">&#8220;<span class="quote">delete all cells where the version is less than or equal to
          this version</span>&#8221;</span>. HBase never modifies data in place, so for
          example a delete will not immediately delete (or mark as deleted)
          the entries in the storage file that correspond to the delete
          condition. Rather, a so-called <span class="emphasis"><em>tombstone</em></span> is
          written, which will mask the deleted values<sup>[<a name="d0e3059" href="#ftn.d0e3059" class="footnote">17</a>]</sup>. If the version you specified when deleting a row is
          larger than the version of any value in the row, then you can
          consider the complete row to be deleted.</p></div></div><div class="section" title="5.8.2.&nbsp;Current Limitations"><div class="titlepage"><div><div><h3 class="title"><a name="d0e3063"></a>5.8.2.&nbsp;Current Limitations</h3></div></div></div><p>There are still some bugs (or at least 'undecided behavior')
        with the version dimension that will be addressed by later HBase
        releases.</p><div class="section" title="5.8.2.1.&nbsp;Deletes mask Puts"><div class="titlepage"><div><div><h4 class="title"><a name="d0e3068"></a>5.8.2.1.&nbsp;Deletes mask Puts</h4></div></div></div><p>Deletes mask puts, even puts that happened after the delete
          was entered<sup>[<a name="d0e3073" href="#ftn.d0e3073" class="footnote">18</a>]</sup>. Remember that a delete writes a tombstone, which only
          disappears after then next major compaction has run. Suppose you do
          a delete of everything &lt;= T. After this you do a new put with a
          timestamp &lt;= T. This put, even if it happened after the delete,
          will be masked by the delete tombstone. Performing the put will not
          fail, but when you do a get you will notice the put did have no
          effect. It will start working again after the major compaction has
          run. These issues should not be a problem if you use
          always-increasing versions for new puts to a row. But they can occur
          even if you do not care about time: just do delete and put
          immediately after each other, and there is some chance they happen
          within the same millisecond.</p></div><div class="section" title="5.8.2.2.&nbsp;Major compactions change query results"><div class="titlepage"><div><div><h4 class="title"><a name="d0e3078"></a>5.8.2.2.&nbsp;Major compactions change query results</h4></div></div></div><p><span class="quote">&#8220;<span class="quote">...create three cell versions at t1, t2 and t3, with a
          maximum-versions setting of 2. So when getting all versions, only
          the values at t2 and t3 will be returned. But if you delete the
          version at t2 or t3, the one at t1 will appear again. Obviously,
          once a major compaction has run, such behavior will not be the case
          anymore...<sup>[<a name="d0e3084" href="#ftn.d0e3084" class="footnote">19</a>]</sup></span>&#8221;</span></p></div></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e2928" href="#d0e2928" class="para">14</a>] </sup>Currently, only the last written is fetchable.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e2934" href="#d0e2934" class="para">15</a>] </sup>Yes</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e2939" href="#d0e2939" class="para">16</a>] </sup>See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-2406" target="_top">HBASE-2406</a>
          for discussion of HBase versions. <a class="link" href="http://outerthought.org/blog/417-ot.html" target="_top">Bending time
          in HBase</a> makes for a good read on the version, or time,
          dimension in HBase. It has more detail on versioning than is
          provided here. As of this writing, the limiitation
          <span class="emphasis"><em>Overwriting values at existing timestamps</em></span>
          mentioned in the article no longer holds in HBase. This section is
          basically a synopsis of this article by Bruno Dumon.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e3059" href="#d0e3059" class="para">17</a>] </sup>When HBase does a major compaction, the tombstones are
              processed to actually remove the dead values, together with the
              tombstones themselves.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e3073" href="#d0e3073" class="para">18</a>] </sup><a class="link" href="https://issues.apache.org/jira/browse/HBASE-2256" target="_top">HBASE-2256</a></p></div><div class="footnote"><p><sup>[<a id="ftn.d0e3084" href="#d0e3084" class="para">19</a>] </sup>See <span class="emphasis"><em>Garbage Collection</em></span> in <a class="link" href="http://outerthought.org/blog/417-ot.html" target="_top">Bending
              time in HBase</a> </p></div></div></div><div class="chapter" title="Chapter&nbsp;6.&nbsp;HBase and Schema Design"><div class="titlepage"><div><div><h2 class="title"><a name="schema"></a>Chapter&nbsp;6.&nbsp;HBase and Schema Design</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#schema.creation">6.1. 
      Schema Creation
  </a></span></dt><dt><span class="section"><a href="#number.of.cfs">6.2. 
      On the number of column families
  </a></span></dt><dd><dl><dt><span class="section"><a href="#number.of.cfs.card">6.2.1. Cardinality of ColumnFamilies</a></span></dt></dl></dd><dt><span class="section"><a href="#rowkey.design">6.3. Rowkey Design</a></span></dt><dd><dl><dt><span class="section"><a href="#timeseries">6.3.1. 
    Monotonically Increasing Row Keys/Timeseries Data
    </a></span></dt><dt><span class="section"><a href="#keysize">6.3.2. Try to minimize row and column sizes</a></span></dt><dt><span class="section"><a href="#reverse.timestamp">6.3.3. Reverse Timestamps</a></span></dt><dt><span class="section"><a href="#rowkey.scope">6.3.4. Rowkeys and ColumnFamilies</a></span></dt><dt><span class="section"><a href="#changing.rowkeys">6.3.5. Immutability of Rowkeys</a></span></dt></dl></dd><dt><span class="section"><a href="#schema.versions">6.4. 
  Number of Versions
  </a></span></dt><dd><dl><dt><span class="section"><a href="#schema.versions.max">6.4.1. Maximum Number of Versions</a></span></dt><dt><span class="section"><a href="#schema.minversions">6.4.2. 
    Minimum Number of Versions
    </a></span></dt></dl></dd><dt><span class="section"><a href="#supported.datatypes">6.5. 
  Supported Datatypes
  </a></span></dt><dd><dl><dt><span class="section"><a href="#counters">6.5.1. Counters</a></span></dt></dl></dd><dt><span class="section"><a href="#ttl">6.6. Time To Live (TTL)</a></span></dt><dt><span class="section"><a href="#cf.keep.deleted">6.7. 
  Keeping Deleted Cells
  </a></span></dt><dt><span class="section"><a href="#secondary.indexes">6.8. 
  Secondary Indexes and Alternate Query Paths
  </a></span></dt><dd><dl><dt><span class="section"><a href="#secondary.indexes.filter">6.8.1. 
       Filter Query
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.periodic">6.8.2. 
       Periodic-Update Secondary Index
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.dualwrite">6.8.3. 
       Dual-Write Secondary Index
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.summary">6.8.4. 
       Summary Tables
      </a></span></dt><dt><span class="section"><a href="#secondary.indexes.coproc">6.8.5. 
       Coprocessor Secondary Index
      </a></span></dt></dl></dd><dt><span class="section"><a href="#schema.smackdown">6.9. Schema Design Smackdown</a></span></dt><dd><dl><dt><span class="section"><a href="#schema.smackdown.rowsversions">6.9.1. Rows vs. Versions</a></span></dt><dt><span class="section"><a href="#schema.smackdown.rowscols">6.9.2. Rows vs. Columns</a></span></dt></dl></dd><dt><span class="section"><a href="#schema.ops">6.10. Operational and Performance Configuration Options</a></span></dt></dl></div><p>A good general introduction on the strength and weaknesses modelling on
          the various non-rdbms datastores is Ian Varleys' Master thesis,
          <a class="link" href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf" target="_top">No Relation: The Mixed Blessings of Non-Relational Databases</a>.
          Recommended.  Also, read <a class="xref" href="#keyvalue" title="8.6.4.4.&nbsp;KeyValue">Section&nbsp;8.6.4.4, &#8220;KeyValue&#8221;</a> for how HBase stores data internally.
      </p><div class="section" title="6.1.&nbsp; Schema Creation"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="schema.creation"></a>6.1.&nbsp;
      Schema Creation
  </h2></div></div></div><p>HBase schemas can be created or updated with <a class="xref" href="#shell" title="Chapter&nbsp;4.&nbsp;The HBase Shell">Chapter&nbsp;4, <i>The HBase Shell</i></a>
      or by using <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html" target="_top">HBaseAdmin</a> in the Java API.
      </p><p>Tables must be disabled when making ColumnFamily modifications, for example..
      </p><pre class="programlisting">
Configuration config = HBaseConfiguration.create();  
HBaseAdmin admin = new HBaseAdmin(conf);    
String table = "myTable";

admin.disableTable(table);           

HColumnDescriptor cf1 = ...;
admin.addColumn(table, cf1  );      // adding new ColumnFamily
HColumnDescriptor cf2 = ...;
admin.modifyColumn(table, cf2 );    // modifying existing ColumnFamily

admin.enableTable(table);                
      </pre><p>
      </p>See <a class="xref" href="#client_dependencies" title="2.6.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster">Section&nbsp;2.6.4, &#8220;Client configuration and dependencies connecting to an HBase cluster&#8221;</a> for more information about configuring client connections.
      <p>Note:  online schema changes are supported in the 0.92.x codebase, but the 0.90.x codebase requires the table
      to be disabled.
      </p></div><div class="section" title="6.2.&nbsp; On the number of column families"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="number.of.cfs"></a>6.2.&nbsp;
      On the number of column families
  </h2></div></div></div><p>
      HBase currently does not do well with anything above two or three column families so keep the number
      of column families in your schema low.  Currently, flushing and compactions are done on a per Region basis so
      if one column family is carrying the bulk of the data bringing on flushes, the adjacent families
      will also be flushed though the amount of data they carry is small.  Compaction is currently triggered
      by the total number of files under a column family.  Its not size based.  When many column families the
      flushing and compaction interaction can make for a bunch of needless i/o loading (To be addressed by
      changing flushing and compaction to work on a per column family basis).
    </p><p>Try to make do with one column family if you can in your schemas.  Only introduce a
        second and third column family in the case where data access is usually column scoped;
        i.e. you query one column family or the other but usually not both at the one time.
    </p><div class="section" title="6.2.1.&nbsp;Cardinality of ColumnFamilies"><div class="titlepage"><div><div><h3 class="title"><a name="number.of.cfs.card"></a>6.2.1.&nbsp;Cardinality of ColumnFamilies</h3></div></div></div><p>Where multiple ColumnFamilies exist in a single table, be aware of the cardinality (i.e., number of rows).  
      If ColumnFamilyA has 1 million rows and ColumnFamilyB has 1 billion rows, ColumnFamilyA's data will likely be spread 
      across many, many regions (and RegionServers).  This makes mass scans for ColumnFamilyA less efficient.  
      </p></div></div><div class="section" title="6.3.&nbsp;Rowkey Design"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rowkey.design"></a>6.3.&nbsp;Rowkey Design</h2></div></div></div><div class="section" title="6.3.1.&nbsp; Monotonically Increasing Row Keys/Timeseries Data"><div class="titlepage"><div><div><h3 class="title"><a name="timeseries"></a>6.3.1.&nbsp;
    Monotonically Increasing Row Keys/Timeseries Data
    </h3></div></div></div><p>
      In the HBase chapter of Tom White's book Hadoop: The Definitive Guide (O'Reilly) there is a an optimization note on watching out for a phenomenon where an import process walks in lock-step with all clients in concert pounding one of the table's regions (and thus, a single node), then moving onto the next region, etc.  With monotonically increasing row-keys (i.e., using a timestamp), this will happen.  See this comic by IKai Lan on why monotonically increasing row keys are problematic in BigTable-like datastores:
      <a class="link" href="http://ikaisays.com/2011/01/25/app-engine-datastore-tip-monotonically-increasing-values-are-bad/" target="_top">monotonically increasing values are bad</a>.  The pile-up on a single region brought on
      by monotonically increasing keys can be mitigated by randomizing the input records to not be in sorted order, but in general its best to avoid using a timestamp or a sequence (e.g. 1, 2, 3) as the row-key. 
    </p><p>If you do need to upload time series data into HBase, you should
    study <a class="link" href="http://opentsdb.net/" target="_top">OpenTSDB</a> as a
    successful example.  It has a page describing the <a class="link" href=" http://opentsdb.net/schema.html" target="_top">schema</a> it uses in
    HBase.  The key format in OpenTSDB is effectively [metric_type][event_timestamp], which would appear at first glance to contradict the previous advice about not using a timestamp as the key.  However, the difference is that the timestamp is not in the <span class="emphasis"><em>lead</em></span> position of the key, and the design assumption is that there are dozens or hundreds (or more) of different metric types.  Thus, even with a continual stream of input data with a mix of metric types, the Puts are distributed across various points of regions in the table.
   </p></div><div class="section" title="6.3.2.&nbsp;Try to minimize row and column sizes"><div class="titlepage"><div><div><h3 class="title"><a name="keysize"></a>6.3.2.&nbsp;Try to minimize row and column sizes</h3></div><div><h4 class="subtitle">Or why are my StoreFile indices large?</h4></div></div></div><p>In HBase, values are always freighted with their coordinates; as a
          cell value passes through the system, it'll be accompanied by its
          row, column name, and timestamp - always.  If your rows and column names
          are large, especially compared to the size of the cell value, then
          you may run up against some interesting scenarios.  One such is
          the case described by Marc Limotte at the tail of
          HBASE-3551
          (recommended!).
          Therein, the indices that are kept on HBase storefiles (<a class="xref" href="#hfile" title="8.6.4.2.&nbsp;StoreFile (HFile)">Section&nbsp;8.6.4.2, &#8220;StoreFile (HFile)&#8221;</a>)
                  to facilitate random access may end up occupyng large chunks of the HBase
                  allotted RAM because the cell value coordinates are large.
                  Mark in the above cited comment suggests upping the block size so
                  entries in the store file index happen at a larger interval or
                  modify the table schema so it makes for smaller rows and column
                  names.
                  Compression will also make for larger indices.  See
                  the thread <a class="link" href="http://search-hadoop.com/m/hemBv1LiN4Q1/a+question+storefileIndexSize&amp;subj=a+question+storefileIndexSize" target="_top">a question storefileIndexSize</a>
                  up on the user mailing list.
       </p><p>Most of the time small inefficiencies don't matter all that much.  Unfortunately,
         this is a case where they do.  Whatever patterns are selected for ColumnFamilies, attributes, and rowkeys they could be repeated
       several billion times in your data. </p><p>See <a class="xref" href="#keyvalue" title="8.6.4.4.&nbsp;KeyValue">Section&nbsp;8.6.4.4, &#8220;KeyValue&#8221;</a> for more information on HBase stores data internally.</p><div class="section" title="6.3.2.1.&nbsp;Column Families"><div class="titlepage"><div><div><h4 class="title"><a name="keysize.cf"></a>6.3.2.1.&nbsp;Column Families</h4></div></div></div><p>Try to keep the ColumnFamily names as small as possible, preferably one character (e.g. "d" for data/default).
         </p></div><div class="section" title="6.3.2.2.&nbsp;Attributes"><div class="titlepage"><div><div><h4 class="title"><a name="keysize.atttributes"></a>6.3.2.2.&nbsp;Attributes</h4></div></div></div><p>Although verbose attribute names (e.g., "myVeryImportantAttribute") are easier to read, prefer shorter attribute names (e.g., "via")
         to store in HBase.
         </p></div><div class="section" title="6.3.2.3.&nbsp;Rowkey Length"><div class="titlepage"><div><div><h4 class="title"><a name="keysize.row"></a>6.3.2.3.&nbsp;Rowkey Length</h4></div></div></div><p>Keep them as short as is reasonable such that they can still be useful for required data access (e.g., Get vs. Scan). 
         A short key that is useless for data access is not better than a longer key with better get/scan properties.  Expect tradeoffs
         when designing rowkeys.
         </p></div><div class="section" title="6.3.2.4.&nbsp;Byte Patterns"><div class="titlepage"><div><div><h4 class="title"><a name="keysize.patterns"></a>6.3.2.4.&nbsp;Byte Patterns</h4></div></div></div><p>A long is 8 bytes.  You can store an unsigned number up to 18,446,744,073,709,551,615 in those eight bytes.
            If you stored this number as a String -- presuming a byte per character -- you need nearly 3x the bytes.
         </p><p>Not convinced?  Below is some sample code that you can run on your own.
</p><pre class="programlisting">
// long
//
long l = 1234567890L;
byte[] lb = Bytes.toBytes(l);
System.out.println("long bytes length: " + lb.length);   // returns 8
		
String s = "" + l;
byte[] sb = Bytes.toBytes(s);
System.out.println("long as string length: " + sb.length);    // returns 10
			
// hash 
//
MessageDigest md = MessageDigest.getInstance("MD5");
byte[] digest = md.digest(Bytes.toBytes(s));
System.out.println("md5 digest bytes length: " + digest.length);    // returns 16
		
String sDigest = new String(digest);
byte[] sbDigest = Bytes.toBytes(sDigest);
System.out.println("md5 digest as string length: " + sbDigest.length);    // returns 26		
</pre><p>               
         </p></div></div><div class="section" title="6.3.3.&nbsp;Reverse Timestamps"><div class="titlepage"><div><div><h3 class="title"><a name="reverse.timestamp"></a>6.3.3.&nbsp;Reverse Timestamps</h3></div></div></div><p>A common problem in database processing is quickly finding the most recent version of a value.  A technique using reverse timestamps
    as a part of the key can help greatly with a special case of this problem.  Also found in the HBase chapter of Tom White's book Hadoop:  The Definitive Guide (O'Reilly), 
    the technique involves appending (<code class="code">Long.MAX_VALUE - timestamp</code>) to the end of any key, e.g., [key][reverse_timestamp].
    </p><p>The most recent value for [key] in a table can be found by performing a Scan for [key] and obtaining the first record.  Since HBase keys
    are in sorted order, this key sorts before any older row-keys for [key] and thus is first.
    </p><p>This technique would be used instead of using <a class="xref" href="#schema.versions" title="6.4.&nbsp; Number of Versions">Section&nbsp;6.4, &#8220;
  Number of Versions
  &#8221;</a> where the intent is to hold onto all versions
    "forever" (or a very long time) and at the same time quickly obtain access to any other version by using the same Scan technique.
    </p></div><div class="section" title="6.3.4.&nbsp;Rowkeys and ColumnFamilies"><div class="titlepage"><div><div><h3 class="title"><a name="rowkey.scope"></a>6.3.4.&nbsp;Rowkeys and ColumnFamilies</h3></div></div></div><p>Rowkeys are scoped to ColumnFamilies.  Thus, the same rowkey could exist in each ColumnFamily that exists in a table without collision.
    </p></div><div class="section" title="6.3.5.&nbsp;Immutability of Rowkeys"><div class="titlepage"><div><div><h3 class="title"><a name="changing.rowkeys"></a>6.3.5.&nbsp;Immutability of Rowkeys</h3></div></div></div><p>Rowkeys cannot be changed.  The only way they can be "changed" in a table is if the row is deleted and then re-inserted.
    This is a fairly common question on the HBase dist-list so it pays to get the rowkeys right the first time (and/or before you've 
    inserted a lot of data).
    </p></div></div><div class="section" title="6.4.&nbsp; Number of Versions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="schema.versions"></a>6.4.&nbsp;
  Number of Versions
  </h2></div></div></div><div class="section" title="6.4.1.&nbsp;Maximum Number of Versions"><div class="titlepage"><div><div><h3 class="title"><a name="schema.versions.max"></a>6.4.1.&nbsp;Maximum Number of Versions</h3></div></div></div><p>The maximum number of row versions to store is configured per column
      family via <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a>.
      The default for max versions is 3.
      This is an important parameter because as described in <a class="xref" href="#datamodel" title="Chapter&nbsp;5.&nbsp;Data Model">Chapter&nbsp;5, <i>Data Model</i></a>
      section HBase does <span class="emphasis"><em>not</em></span> overwrite row values, but rather
      stores different values per row by time (and qualifier).  Excess versions are removed during major
      compactions.  The number of max versions may need to be increased or decreased depending on application needs.
      </p><p>It is not recommended setting the number of max versions to an exceedingly high level (e.g., hundreds or more) unless those old values are 
      very dear to you because this will greatly increase StoreFile size. 
      </p></div><div class="section" title="6.4.2.&nbsp; Minimum Number of Versions"><div class="titlepage"><div><div><h3 class="title"><a name="schema.minversions"></a>6.4.2.&nbsp;
    Minimum Number of Versions
    </h3></div></div></div><p>Like maximum number of row versions, the minimum number of row versions to keep is configured per column
      family via <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a>.
      The default for min versions is 0, which means the feature is disabled.
      The minimum number of row versions parameter is used together with the time-to-live parameter and can be combined with the
      number of row versions parameter to allow configurations such as
      "keep the last T minutes worth of data, at most N versions, <span class="emphasis"><em>but keep at least M versions around</em></span>"
      (where M is the value for minimum number of row versions, M&lt;N).
      This parameter should only be set when time-to-live is enabled for a column family and must be less than the
      number of row versions.
    </p></div></div><div class="section" title="6.5.&nbsp; Supported Datatypes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="supported.datatypes"></a>6.5.&nbsp;
  Supported Datatypes
  </h2></div></div></div><p>HBase supports a "bytes-in/bytes-out" interface via <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Put.html" target="_top">Put</a> and
  <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Result.html" target="_top">Result</a>, so anything that can be
  converted to an array of bytes can be stored as a value.  Input could be strings, numbers, complex objects, or even images as long as they can rendered as bytes.  
  </p><p>There are practical limits to the size of values (e.g., storing 10-50MB objects in HBase would probably be too much to ask);
  search the mailling list for conversations on this topic. All rows in HBase conform to the <a class="xref" href="#datamodel" title="Chapter&nbsp;5.&nbsp;Data Model">Chapter&nbsp;5, <i>Data Model</i></a>, and 
  that includes versioning.  Take that into consideration when making your design, as well as block size for the ColumnFamily.  
  </p><div class="section" title="6.5.1.&nbsp;Counters"><div class="titlepage"><div><div><h3 class="title"><a name="counters"></a>6.5.1.&nbsp;Counters</h3></div></div></div><p>
      One supported datatype that deserves special mention are "counters" (i.e., the ability to do atomic increments of numbers).  See 
      <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html#increment%28org.apache.hadoop.hbase.client.Increment%29" target="_top">Increment</a> in HTable.
      </p><p>Synchronization on counters are done on the RegionServer, not in the client.
      </p></div></div><div class="section" title="6.6.&nbsp;Time To Live (TTL)"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ttl"></a>6.6.&nbsp;Time To Live (TTL)</h2></div></div></div><p>ColumnFamilies can set a TTL length in seconds, and HBase will automatically delete rows once the expiration time is reached.
  This applies to <span class="emphasis"><em>all</em></span> versions of a row - even the current one.  The TTL time encoded in the HBase for the row is specified in UTC.
  </p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a> for more information.
  </p></div><div class="section" title="6.7.&nbsp; Keeping Deleted Cells"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="cf.keep.deleted"></a>6.7.&nbsp;
  Keeping Deleted Cells
  </h2></div></div></div><p>ColumnFamilies can optionally keep deleted cells. That means deleted cells can still be retrieved with
  <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html" target="_top">Get</a> or
  <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scan</a> operations,
  as long these operations have a time range specified that ends before the timestamp of any delete that would affect the cells.
  This allows for point in time queries even in the presence of deletes.
  </p><p>
  Deleted cells are still subject to TTL and there will never be more than "maximum number of versions" deleted cells.
  A new "raw" scan options returns all deleted rows and the delete markers.
  </p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a> for more information.
  </p></div><div class="section" title="6.8.&nbsp; Secondary Indexes and Alternate Query Paths"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="secondary.indexes"></a>6.8.&nbsp;
  Secondary Indexes and Alternate Query Paths
  </h2></div></div></div><p>This section could also be titled "what if my table rowkey looks like <span class="emphasis"><em>this</em></span> but I also want to query my table like <span class="emphasis"><em>that</em></span>."
  A common example on the dist-list is where a row-key is of the format "user-timestamp" but there are are reporting requirements on activity across users for certain 
  time ranges.  Thus, selecting by user is easy because it is in the lead position of the key, but time is not.
  </p><p>There is no single answer on the best way to handle this because it depends on...
   </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Number of users</li><li class="listitem">Data size and data arrival rate</li><li class="listitem">Flexibility of reporting requirements (e.g., completely ad-hoc date selection vs. pre-configured ranges) </li><li class="listitem">Desired execution speed of query (e.g., 90 seconds may be reasonable to some for an ad-hoc report, whereas it may be too long for others) </li></ul></div><p>
   ... and solutions are also influenced by the size of the cluster and how much processing power you have to throw at the solution.  
   Common techniques are in sub-sections below.  This is a comprehensive, but not exhaustive, list of approaches.   
  </p><p>It should not be a surprise that secondary indexes require additional cluster space and processing.  
  This is precisely what happens in an RDBMS because the act of creating an alternate index requires both space and processing cycles to update.  RBDMS products
  are more advanced in this regard to handle alternative index management out of the box.  However, HBase scales better at larger data volumes, so this is a feature trade-off. 
  </p><p>Pay attention to <a class="xref" href="#performance" title="Chapter&nbsp;10.&nbsp;Performance Tuning">Chapter&nbsp;10, <i>Performance Tuning</i></a> when implementing any of these approaches.</p><p>Additionally, see the David Butler response in this dist-list thread <a class="link" href="http://search-hadoop.com/m/nvbiBp2TDP/Stargate%252Bhbase&amp;subj=Stargate+hbase" target="_top">HBase, mail # user - Stargate+hbase</a>
   </p><div class="section" title="6.8.1.&nbsp; Filter Query"><div class="titlepage"><div><div><h3 class="title"><a name="secondary.indexes.filter"></a>6.8.1.&nbsp;
       Filter Query
      </h3></div></div></div><p>Depending on the case, it may be appropriate to use <a class="xref" href="#client.filter" title="8.3.&nbsp;Client Filters">Section&nbsp;8.3, &#8220;Client Filters&#8221;</a>.  In this case, no secondary index is created.
      However, don't try a full-scan on a large table like this from an application (i.e., single-threaded client).
      </p></div><div class="section" title="6.8.2.&nbsp; Periodic-Update Secondary Index"><div class="titlepage"><div><div><h3 class="title"><a name="secondary.indexes.periodic"></a>6.8.2.&nbsp;
       Periodic-Update Secondary Index
      </h3></div></div></div><p>A secondary index could be created in an other table which is periodically updated via a MapReduce job.  The job could be executed intra-day, but depending on 
      load-strategy it could still potentially be out of sync with the main data table.</p><p>See <a class="xref" href="#mapreduce.example.readwrite" title="7.2.2.&nbsp;HBase MapReduce Read/Write Example">Section&nbsp;7.2.2, &#8220;HBase MapReduce Read/Write Example&#8221;</a> for more information.</p></div><div class="section" title="6.8.3.&nbsp; Dual-Write Secondary Index"><div class="titlepage"><div><div><h3 class="title"><a name="secondary.indexes.dualwrite"></a>6.8.3.&nbsp;
       Dual-Write Secondary Index
      </h3></div></div></div><p>Another strategy is to build the secondary index while publishing data to the cluster (e.g., write to data table, write to index table). 
      If this is approach is taken after a data table already exists, then bootstrapping will be needed for the secondary index with a MapReduce job (see <a class="xref" href="#secondary.indexes.periodic" title="6.8.2.&nbsp; Periodic-Update Secondary Index">Section&nbsp;6.8.2, &#8220;
       Periodic-Update Secondary Index
      &#8221;</a>).</p></div><div class="section" title="6.8.4.&nbsp; Summary Tables"><div class="titlepage"><div><div><h3 class="title"><a name="secondary.indexes.summary"></a>6.8.4.&nbsp;
       Summary Tables
      </h3></div></div></div><p>Where time-ranges are very wide (e.g., year-long report) and where the data is voluminous, summary tables are a common approach.
      These would be generated with MapReduce jobs into another table.</p><p>See <a class="xref" href="#mapreduce.example.summary" title="7.2.4.&nbsp;HBase MapReduce Summary Example">Section&nbsp;7.2.4, &#8220;HBase MapReduce Summary Example&#8221;</a> for more information.</p></div><div class="section" title="6.8.5.&nbsp; Coprocessor Secondary Index"><div class="titlepage"><div><div><h3 class="title"><a name="secondary.indexes.coproc"></a>6.8.5.&nbsp;
       Coprocessor Secondary Index
      </h3></div></div></div><p>Coprocessors act like RDBMS triggers.  These are currently on TRUNK.
      </p></div></div><div class="section" title="6.9.&nbsp;Schema Design Smackdown"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="schema.smackdown"></a>6.9.&nbsp;Schema Design Smackdown</h2></div></div></div><p>This section will describe common schema design questions that appear on the dist-list.  These are 
    general guidelines and not laws - each application must consider it's own needs.  
    </p><div class="section" title="6.9.1.&nbsp;Rows vs. Versions"><div class="titlepage"><div><div><h3 class="title"><a name="schema.smackdown.rowsversions"></a>6.9.1.&nbsp;Rows vs. Versions</h3></div></div></div><p>A common question is whether one should prefer rows or HBase's built-in-versioning.  The context is typically where there are
      "a lot" of versions of a row to be retained (e.g., where it is significantly above the HBase default of 3 max versions).  The 
      rows-approach would require storing a timstamp in some portion of the rowkey so that they would not overwite with each successive update.
      </p><p>Preference:  Rows (generally speaking).
      </p></div><div class="section" title="6.9.2.&nbsp;Rows vs. Columns"><div class="titlepage"><div><div><h3 class="title"><a name="schema.smackdown.rowscols"></a>6.9.2.&nbsp;Rows vs. Columns</h3></div></div></div><p>Another common question is whether one should prefer rows or columns.  The context is typically in extreme cases of wide
      tables, such as having 1 row with 1 million attributes, or 1 million rows with 1 columns apiece.  
      </p><p>Preference:  Rows (generally speaking).  To be clear, this guideline is in the context is in extremely wide cases, not in the 
      standard use-case where one needs to store a few dozen or hundred columns.
      </p></div></div><div class="section" title="6.10.&nbsp;Operational and Performance Configuration Options"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="schema.ops"></a>6.10.&nbsp;Operational and Performance Configuration Options</h2></div></div></div><p>See the Performance section <a class="xref" href="#perf.schema" title="10.5.&nbsp;Schema Design">Section&nbsp;10.5, &#8220;Schema Design&#8221;</a> for more information operational and performance
    schema design options, such as Bloom Filters, Table-configured regionsizes, and blocksizes.
    </p></div></div><div class="chapter" title="Chapter&nbsp;7.&nbsp;HBase and MapReduce"><div class="titlepage"><div><div><h2 class="title"><a name="mapreduce"></a>Chapter&nbsp;7.&nbsp;HBase and MapReduce</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#splitter">7.1. Map-Task Spitting</a></span></dt><dd><dl><dt><span class="section"><a href="#splitter.default">7.1.1. The Default HBase MapReduce Splitter</a></span></dt><dt><span class="section"><a href="#splitter.custom">7.1.2. Custom Splitters</a></span></dt></dl></dd><dt><span class="section"><a href="#mapreduce.example">7.2. HBase MapReduce Examples</a></span></dt><dd><dl><dt><span class="section"><a href="#mapreduce.example.read">7.2.1. HBase MapReduce Read Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.readwrite">7.2.2. HBase MapReduce Read/Write Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.readwrite.multi">7.2.3. HBase MapReduce Read/Write Example With Multi-Table Output</a></span></dt><dt><span class="section"><a href="#mapreduce.example.summary">7.2.4. HBase MapReduce Summary Example</a></span></dt><dt><span class="section"><a href="#mapreduce.example.summary.file">7.2.5. HBase MapReduce Summary to File Example</a></span></dt></dl></dd><dt><span class="section"><a href="#mapreduce.htable.access">7.3. Accessing Other HBase Tables in a MapReduce Job</a></span></dt><dt><span class="section"><a href="#mapreduce.specex">7.4. Speculative Execution</a></span></dt></dl></div><p>See <a class="link" href="http://hbase.org/apidocs/org/apache/hadoop/hbase/mapreduce/package-summary.html#package_description" target="_top">HBase and MapReduce</a> up in javadocs.
  Start there.  Below is some additional help.</p><p>For more information about MapReduce, see the <a class="link" href="http://hadoop.apache.org/common/docs/current/mapred_tutorial.html" target="_top">Hadoop MapReduce Tutorial</a>.</p><div class="section" title="7.1.&nbsp;Map-Task Spitting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="splitter"></a>7.1.&nbsp;Map-Task Spitting</h2></div></div></div><div class="section" title="7.1.1.&nbsp;The Default HBase MapReduce Splitter"><div class="titlepage"><div><div><h3 class="title"><a name="splitter.default"></a>7.1.1.&nbsp;The Default HBase MapReduce Splitter</h3></div></div></div><p>When <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormat.html" target="_top">TableInputFormat</a>
    is used to source an HBase table in a MapReduce job,
    its splitter will make a map task for each region of the table.
    Thus, if there are 100 regions in the table, there will be
    100 map-tasks for the job - regardless of how many column families are selected in the Scan.</p></div><div class="section" title="7.1.2.&nbsp;Custom Splitters"><div class="titlepage"><div><div><h3 class="title"><a name="splitter.custom"></a>7.1.2.&nbsp;Custom Splitters</h3></div></div></div><p>For those interested in implementing custom splitters, see the method <code class="code">getSplits</code> in 
    <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.html" target="_top">TableInputFormatBase</a>.
    That is where the logic for map-task assignment resides.  
    </p></div></div><div class="section" title="7.2.&nbsp;HBase MapReduce Examples"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mapreduce.example"></a>7.2.&nbsp;HBase MapReduce Examples</h2></div></div></div><div class="section" title="7.2.1.&nbsp;HBase MapReduce Read Example"><div class="titlepage"><div><div><h3 class="title"><a name="mapreduce.example.read"></a>7.2.1.&nbsp;HBase MapReduce Read Example</h3></div></div></div><p>The following is an example of using HBase as a MapReduce source in read-only manner.  Specifically,
    there is a Mapper instance but no Reducer, and nothing is being emitted from the Mapper.  There job would be defined
    as follows...
	</p><pre class="programlisting">
Configuration config = HBaseConfiguration.create();
Job job = new Job(config, "ExampleRead");
job.setJarByClass(MyReadJob.class);     // class that contains mapper
	
Scan scan = new Scan();
scan.setCaching(500);        // 1 is the default in Scan, which will be bad for MapReduce jobs
scan.setCacheBlocks(false);  // don't set to true for MR jobs
// set other scan attrs
...
  
TableMapReduceUtil.initTableMapperJob(
  tableName,        // input HBase table name
  scan,             // Scan instance to control CF and attribute selection
  MyMapper.class,   // mapper
  null,             // mapper output key 
  null,             // mapper output value
  job);
job.setOutputFormatClass(NullOutputFormat.class);   // because we aren't emitting anything from mapper
	    
boolean b = job.waitForCompletion(true);
if (!b) {
  throw new IOException("error with job!");
}
  </pre><p>
  ...and the mapper instance would extend <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableMapper.html" target="_top">TableMapper</a>...
	</p><pre class="programlisting">
public static class MyMapper extends TableMapper&lt;Text, Text&gt; {

  public void map(ImmutableBytesWritable row, Result value, Context context) throws InterruptedException, IOException {
    // process data for the row from the Result instance.
   }
}    
    </pre><p>
  	  </p></div><div class="section" title="7.2.2.&nbsp;HBase MapReduce Read/Write Example"><div class="titlepage"><div><div><h3 class="title"><a name="mapreduce.example.readwrite"></a>7.2.2.&nbsp;HBase MapReduce Read/Write Example</h3></div></div></div><p>The following is an example of using HBase both as a source and as a sink with MapReduce. 
    This example will simply copy data from one table to another.
    </p><pre class="programlisting">
Configuration config = HBaseConfiguration.create();
Job job = new Job(config,"ExampleReadWrite");
job.setJarByClass(MyReadWriteJob.class);    // class that contains mapper
	        	        
Scan scan = new Scan();
scan.setCaching(500);        // 1 is the default in Scan, which will be bad for MapReduce jobs
scan.setCacheBlocks(false);  // don't set to true for MR jobs
// set other scan attrs
	        
TableMapReduceUtil.initTableMapperJob(
	sourceTable,      // input table
	scan,	          // Scan instance to control CF and attribute selection
	MyMapper.class,   // mapper class
	null,	          // mapper output key
	null,	          // mapper output value
	job);
TableMapReduceUtil.initTableReducerJob(
	targetTable,      // output table
	null,             // reducer class
	job);
job.setNumReduceTasks(0);
	        
boolean b = job.waitForCompletion(true);
if (!b) {
    throw new IOException("error with job!");
}
    </pre><p>
	An explanation is required of what <code class="classname">TableMapReduceUtil</code> is doing, especially with the reducer.  
	<a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html" target="_top">TableOutputFormat</a> is being used
	as the outputFormat class, and several parameters are being set on the config (e.g., TableOutputFormat.OUTPUT_TABLE), as
	well as setting the reducer output key to <code class="classname">ImmutableBytesWritable</code> and reducer value to <code class="classname">Writable</code>.
	These could be set by the programmer on the job and conf, but <code class="classname">TableMapReduceUtil</code> tries to make things easier.    
	</p><p>The following is the example mapper, which will create a <code class="classname">Put</code> and matching the input <code class="classname">Result</code>
	and emit it.  Note:  this is what the CopyTable utility does.
	</p><p>
    </p><pre class="programlisting">
public static class MyMapper extends TableMapper&lt;ImmutableBytesWritable, Put&gt;  {

	public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException, InterruptedException {
		// this example is just copying the data from the source table...
   		context.write(row, resultToPut(row,value));
   	}
        
  	private static Put resultToPut(ImmutableBytesWritable key, Result result) throws IOException {
  		Put put = new Put(key.get());
 		for (KeyValue kv : result.raw()) {
			put.add(kv);
		}
		return put;
   	}
}
    </pre><p>
    </p><p>There isn't actually a reducer step, so <code class="classname">TableOutputFormat</code> takes care of sending the <code class="classname">Put</code>
    to the target table. 
    </p><p>
    </p><p>This is just an example, developers could choose not to use <code class="classname">TableOutputFormat</code> and connect to the 
    target table themselves.
    </p><p>
    </p></div><div class="section" title="7.2.3.&nbsp;HBase MapReduce Read/Write Example With Multi-Table Output"><div class="titlepage"><div><div><h3 class="title"><a name="mapreduce.example.readwrite.multi"></a>7.2.3.&nbsp;HBase MapReduce Read/Write Example With Multi-Table Output</h3></div></div></div><p>TODO:  example for <code class="classname">MultiTableOutputFormat</code>.
    </p></div><div class="section" title="7.2.4.&nbsp;HBase MapReduce Summary Example"><div class="titlepage"><div><div><h3 class="title"><a name="mapreduce.example.summary"></a>7.2.4.&nbsp;HBase MapReduce Summary Example</h3></div></div></div><p>The following example uses HBase as a MapReduce source and sink with a summarization step.  This example will 
    count the number of distinct instances of a value in a table and write those summarized counts in another table.
    </p><pre class="programlisting">
Configuration config = HBaseConfiguration.create();
Job job = new Job(config,"ExampleSummary");
job.setJarByClass(MySummaryJob.class);     // class that contains mapper and reducer
	        
Scan scan = new Scan();
scan.setCaching(500);        // 1 is the default in Scan, which will be bad for MapReduce jobs
scan.setCacheBlocks(false);  // don't set to true for MR jobs
// set other scan attrs
	        
TableMapReduceUtil.initTableMapperJob(
	sourceTable,        // input table
	scan,               // Scan instance to control CF and attribute selection
	MyMapper.class,     // mapper class
	Text.class,         // mapper output key
	IntWritable.class,  // mapper output value
	job);
TableMapReduceUtil.initTableReducerJob(
	targetTable,        // output table
	MyTableReducer.class,    // reducer class
	job);
job.setNumReduceTasks(1);   // at least one, adjust as required
	    
boolean b = job.waitForCompletion(true);
if (!b) {
	throw new IOException("error with job!");
}    
    </pre><p>
    In this example mapper a column with a String-value is chosen as the value to summarize upon.  
    This value is used as the key to emit from the mapper, and an <code class="classname">IntWritable</code> represents an instance counter.
    </p><pre class="programlisting">
public static class MyMapper extends TableMapper&lt;Text, IntWritable&gt;  {

	private final IntWritable ONE = new IntWritable(1);
   	private Text text = new Text();
    	
   	public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException, InterruptedException {
        	String val = new String(value.getValue(Bytes.toBytes("cf"), Bytes.toBytes("attr1")));
          	text.set(val);     // we can only emit Writables...

        	context.write(text, ONE);
   	}
}
    </pre><p>
    In the reducer, the "ones" are counted (just like any other MR example that does this), and then emits a <code class="classname">Put</code>.
    </p><pre class="programlisting">
public static class MyTableReducer extends TableReducer&lt;Text, IntWritable, ImmutableBytesWritable&gt;  {
        
 	public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
    		int i = 0;
    		for (IntWritable val : values) {
    			i += val.get();
    		}
    		Put put = new Put(Bytes.toBytes(key.toString()));
    		put.add(Bytes.toBytes("cf"), Bytes.toBytes("count"), Bytes.toBytes(i));

    		context.write(null, put);
   	}
}
    </pre><p>
    </p></div><div class="section" title="7.2.5.&nbsp;HBase MapReduce Summary to File Example"><div class="titlepage"><div><div><h3 class="title"><a name="mapreduce.example.summary.file"></a>7.2.5.&nbsp;HBase MapReduce Summary to File Example</h3></div></div></div><p>This very similar to the summary example above, with exception that this is using HBase as a MapReduce source
       but HDFS as the sink.  The differences are in the job setup and in the reducer.  The mapper remains the same.
       </p><pre class="programlisting">
Configuration config = HBaseConfiguration.create();
Job job = new Job(config,"ExampleSummaryToFile");
job.setJarByClass(MySummaryFileJob.class);     // class that contains mapper and reducer
	        
Scan scan = new Scan();
scan.setCaching(500);        // 1 is the default in Scan, which will be bad for MapReduce jobs
scan.setCacheBlocks(false);  // don't set to true for MR jobs
// set other scan attrs
	        
TableMapReduceUtil.initTableMapperJob(
	sourceTable,        // input table
	scan,               // Scan instance to control CF and attribute selection
	MyMapper.class,     // mapper class
	Text.class,         // mapper output key
	IntWritable.class,  // mapper output value
	job);
job.setReducerClass(MyReducer.class);    // reducer class
job.setNumReduceTasks(1);    // at least one, adjust as required
FileOutputFormat.setOutputPath(job, new Path("/tmp/mr/mySummaryFile"));  // adjust directories as required
	    
boolean b = job.waitForCompletion(true);
if (!b) {
	throw new IOException("error with job!");
}    
    </pre>
    As stated above, the previous Mapper can run unchanged with this example.  
    As for the Reducer, it is a "generic" Reducer instead of extending TableMapper and emitting Puts.
    <pre class="programlisting">
 public static class MyReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;  {
        
	public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
		int i = 0;
		for (IntWritable val : values) {
			i += val.get();
		}	
		context.write(key, new IntWritable(i));
	}
}
    </pre></div></div><div class="section" title="7.3.&nbsp;Accessing Other HBase Tables in a MapReduce Job"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mapreduce.htable.access"></a>7.3.&nbsp;Accessing Other HBase Tables in a MapReduce Job</h2></div></div></div><p>Although the framework currently allows one HBase table as input to a
    MapReduce job, other HBase tables can 
	be accessed as lookup tables, etc., in a
    MapReduce job via creating an HTable instance in the setup method of the Mapper.
	</p><pre class="programlisting">public class MyMapper extends TableMapper&lt;Text, LongWritable&gt; {
  private HTable myOtherTable;

  public void setup(Context context) {
    myOtherTable = new HTable("myOtherTable");
  }
  
  public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException, InterruptedException {
	// process Result...
	// use 'myOtherTable' for lookups
  }
  
  </pre><p>
   </p></div><div class="section" title="7.4.&nbsp;Speculative Execution"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mapreduce.specex"></a>7.4.&nbsp;Speculative Execution</h2></div></div></div><p>It is generally advisable to turn off speculative execution for
      MapReduce jobs that use HBase as a source.  This can either be done on a
      per-Job basis through properties, on on the entire cluster.  Especially
      for longer running jobs, speculative execution will create duplicate
      map-tasks which will double-write your data to HBase; this is probably
      not what you want.
  </p></div></div><div class="chapter" title="Chapter&nbsp;8.&nbsp;Architecture"><div class="titlepage"><div><div><h2 class="title"><a name="architecture"></a>Chapter&nbsp;8.&nbsp;Architecture</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#arch.catalog">8.1. Catalog Tables</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.catalog.root">8.1.1. ROOT</a></span></dt><dt><span class="section"><a href="#arch.catalog.meta">8.1.2. META</a></span></dt><dt><span class="section"><a href="#arch.catalog.startup">8.1.3. Startup Sequencing</a></span></dt></dl></dd><dt><span class="section"><a href="#client">8.2. Client</a></span></dt><dd><dl><dt><span class="section"><a href="#client.connections">8.2.1. Connections</a></span></dt><dt><span class="section"><a href="#client.writebuffer">8.2.2. WriteBuffer and Batch Methods</a></span></dt><dt><span class="section"><a href="#client.external">8.2.3. External Clients</a></span></dt></dl></dd><dt><span class="section"><a href="#client.filter">8.3. Client Filters</a></span></dt><dd><dl><dt><span class="section"><a href="#client.filter.structural">8.3.1. Structural</a></span></dt><dt><span class="section"><a href="#client.filter.cv">8.3.2. Column Value</a></span></dt><dt><span class="section"><a href="#client.filter.cvp">8.3.3. Column Value Comparators</a></span></dt><dt><span class="section"><a href="#client.filter.kvm">8.3.4. KeyValue Metadata</a></span></dt><dt><span class="section"><a href="#client.filter.row">8.3.5. RowKey</a></span></dt><dt><span class="section"><a href="#client.filter.utility">8.3.6. Utility</a></span></dt></dl></dd><dt><span class="section"><a href="#master">8.4. Master</a></span></dt><dd><dl><dt><span class="section"><a href="#master.startup">8.4.1. Startup Behavior</a></span></dt><dt><span class="section"><a href="#master.api">8.4.2. Interface</a></span></dt><dt><span class="section"><a href="#master.processes">8.4.3. Processes</a></span></dt></dl></dd><dt><span class="section"><a href="#regionserver.arch">8.5. RegionServer</a></span></dt><dd><dl><dt><span class="section"><a href="#regionserver.arch.api">8.5.1. Interface</a></span></dt><dt><span class="section"><a href="#regionserver.arch.processes">8.5.2. Processes</a></span></dt><dt><span class="section"><a href="#block.cache">8.5.3. Block Cache</a></span></dt><dt><span class="section"><a href="#wal">8.5.4. Write Ahead Log (WAL)</a></span></dt></dl></dd><dt><span class="section"><a href="#regions.arch">8.6. Regions</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.regions.size">8.6.1. Region Size</a></span></dt><dt><span class="section"><a href="#d0e4152">8.6.2. Region Splits</a></span></dt><dt><span class="section"><a href="#regions.arch.balancer">8.6.3. Region Load Balancing</a></span></dt><dt><span class="section"><a href="#store">8.6.4. Store</a></span></dt><dt><span class="section"><a href="#blooms">8.6.5. Bloom Filters</a></span></dt></dl></dd><dt><span class="section"><a href="#arch.hdfs">8.7. HDFS</a></span></dt><dd><dl><dt><span class="section"><a href="#arch.hdfs.nn">8.7.1. NameNode</a></span></dt><dt><span class="section"><a href="#arch.hdfs.dn">8.7.2. DataNode</a></span></dt></dl></dd></dl></div><div class="section" title="8.1.&nbsp;Catalog Tables"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch.catalog"></a>8.1.&nbsp;Catalog Tables</h2></div></div></div><p>The catalog tables -ROOT- and .META. exist as HBase tables.  They are are filtered out 
	  of the HBase shell's <code class="code">list</code> command, but they are in fact tables just like any other.
     </p><div class="section" title="8.1.1.&nbsp;ROOT"><div class="titlepage"><div><div><h3 class="title"><a name="arch.catalog.root"></a>8.1.1.&nbsp;ROOT</h3></div></div></div><p>-ROOT- keeps track of where the .META. table is.  The -ROOT- table structure is as follows: 
       </p><p>Key:   
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">.META. region key (<code class="code">.META.,,1</code>)</li></ul></div><p>
       </p><p>Values:   
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><code class="code">info:regioninfo</code> (serialized <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HRegionInfo.html" target="_top">HRegionInfo</a>
               instance of .META.)</li><li class="listitem"><code class="code">info:server</code> (server:port of the RegionServer holding .META.)</li><li class="listitem"><code class="code">info:serverstartcode</code> (start-time of the RegionServer process holding .META.)</li></ul></div><p>
       </p></div><div class="section" title="8.1.2.&nbsp;META"><div class="titlepage"><div><div><h3 class="title"><a name="arch.catalog.meta"></a>8.1.2.&nbsp;META</h3></div></div></div><p>The .META. table keeps a list of all regions in the system. The .META. table structure is as follows: 
       </p><p>Key:   
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Region key of the format (<code class="code">[table],[region start key],[region id]</code>)</li></ul></div><p>
       </p><p>Values:   
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><code class="code">info:regioninfo</code> (serialized <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HRegionInfo.html" target="_top">
              HRegionInfo</a> instance for this region)
              </li><li class="listitem"><code class="code">info:server</code> (server:port of the RegionServer containing this region)</li><li class="listitem"><code class="code">info:serverstartcode</code> (start-time of the RegionServer process containing this region)</li></ul></div><p>
       </p><p>When a table is in the process of splitting two other columns will be created, <code class="code">info:splitA</code> and <code class="code">info:splitB</code> 
       which represent the two daughter regions.  The values for these columns are also serialized HRegionInfo instances.
       After the region has been split eventually this row will be deleted.
       </p><p>Notes on HRegionInfo:  the empty key is used to denote table start and table end.  A region with an empty start key
       is the first region in a table.  If region has both an empty start and an empty end key, its the only region in the table
       </p><p>In the (hopefully unlikely) event that programmatic processing of catalog metadata is required, see the
         <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/Writables.html#getHRegionInfo%28byte[]%29" target="_top">Writables</a> utility.
       </p></div><div class="section" title="8.1.3.&nbsp;Startup Sequencing"><div class="titlepage"><div><div><h3 class="title"><a name="arch.catalog.startup"></a>8.1.3.&nbsp;Startup Sequencing</h3></div></div></div><p>The META location is set in ROOT first.  Then META is updated with server and startcode values.
	    </p></div></div><div class="section" title="8.2.&nbsp;Client"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="client"></a>8.2.&nbsp;Client</h2></div></div></div><p>The HBase client
         <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>
         is responsible for finding RegionServers that are serving the
         particular row range of interest.  It does this by querying
         the <code class="code">.META.</code> and <code class="code">-ROOT-</code> catalog tables
         (TODO: Explain).  After locating the required
         region(s), the client <span class="emphasis"><em>directly</em></span> contacts
         the RegionServer serving that region (i.e., it does not go
         through the master) and issues the read or write request.
         This information is cached in the client so that subsequent requests
         need not go through the lookup process.  Should a region be reassigned
         either by the master load balancer or because a RegionServer has died,
         the client will requery the catalog tables to determine the new
         location of the user region. 
    </p><p>Administrative functions are handled through <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html" target="_top">HBaseAdmin</a>
    </p><div class="section" title="8.2.1.&nbsp;Connections"><div class="titlepage"><div><div><h3 class="title"><a name="client.connections"></a>8.2.1.&nbsp;Connections</h3></div></div></div><p>For connection configuration information, see <a class="xref" href="#client_dependencies" title="2.6.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster">Section&nbsp;2.6.4, &#8220;Client configuration and dependencies connecting to an HBase cluster&#8221;</a>. 
         </p><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>
instances are not thread-safe.  When creating HTable instances, it is advisable to use the same <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration" target="_top">HBaseConfiguration</a>
instance.  This will ensure sharing of ZooKeeper and socket instances to the RegionServers
which is usually what you want.  For example, this is preferred:
		</p><pre class="programlisting">HBaseConfiguration conf = HBaseConfiguration.create();
HTable table1 = new HTable(conf, "myTable");
HTable table2 = new HTable(conf, "myTable");</pre><p>
		as opposed to this:
        </p><pre class="programlisting">HBaseConfiguration conf1 = HBaseConfiguration.create();
HTable table1 = new HTable(conf1, "myTable");
HBaseConfiguration conf2 = HBaseConfiguration.create();
HTable table2 = new HTable(conf2, "myTable");</pre><p>
        For more information about how connections are handled in the HBase client,
        see <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HConnectionManager.html" target="_top">HConnectionManager</a>.
          </p><div class="section" title="8.2.1.1.&nbsp;Connection Pooling"><div class="titlepage"><div><div><h4 class="title"><a name="client.connection.pooling"></a>8.2.1.1.&nbsp;Connection Pooling</h4></div></div></div><p>For applications which require high-end multithreaded access (e.g., web-servers or application servers that may serve many application threads
            in a single JVM), see <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTablePool.html" target="_top">HTablePool</a>.
            </p></div></div><div class="section" title="8.2.2.&nbsp;WriteBuffer and Batch Methods"><div class="titlepage"><div><div><h3 class="title"><a name="client.writebuffer"></a>8.2.2.&nbsp;WriteBuffer and Batch Methods</h3></div></div></div><p>If <a class="xref" href="#perf.hbase.client.autoflush" title="10.6.4.&nbsp;HBase Client: AutoFlush">Section&nbsp;10.6.4, &#8220;HBase Client:  AutoFlush&#8221;</a> is turned off on
               <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>,
               <code class="classname">Put</code>s are sent to RegionServers when the writebuffer
               is filled.  The writebuffer is 2MB by default.  Before an HTable instance is
               discarded, either <code class="methodname">close()</code> or
               <code class="methodname">flushCommits()</code> should be invoked so Puts
               will not be lost.   
	      </p><p>Note: <code class="code">htable.delete(Delete);</code> does not go in the writebuffer!  This only applies to Puts.   
	      </p><p>For additional information on write durability, review the <a class="link" href="acid-semantics.html" target="_top">ACID semantics</a> page.
	      </p><p>For fine-grained control of batching of
           <code class="classname">Put</code>s or <code class="classname">Delete</code>s,
           see the <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html#batch%28java.util.List%29" target="_top">batch</a> methods on HTable.
	   </p></div><div class="section" title="8.2.3.&nbsp;External Clients"><div class="titlepage"><div><div><h3 class="title"><a name="client.external"></a>8.2.3.&nbsp;External Clients</h3></div></div></div><p>Information on non-Java clients and custom protocols is covered in <a class="xref" href="#external_apis" title="Chapter&nbsp;9.&nbsp;External APIs">Chapter&nbsp;9, <i>External APIs</i></a>
           </p></div></div><div class="section" title="8.3.&nbsp;Client Filters"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="client.filter"></a>8.3.&nbsp;Client Filters</h2></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html" target="_top">Get</a> and <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scan</a> instances can be
       optionally configured with <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/Filter.html" target="_top">filters</a> which are applied on the RegionServer. 
      </p><p>Filters can be confusing because there are many different types, and it is best to approach them by understanding the groups
      of Filter functionality.
      </p><div class="section" title="8.3.1.&nbsp;Structural"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.structural"></a>8.3.1.&nbsp;Structural</h3></div></div></div><p>Structural Filters contain other Filters.</p><div class="section" title="8.3.1.1.&nbsp;FilterList"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.structural.fl"></a>8.3.1.1.&nbsp;FilterList</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FilterList.html" target="_top">FilterList</a>
          represents a list of Filters with a relationship of <code class="code">FilterList.Operator.MUST_PASS_ALL</code> or 
          <code class="code">FilterList.Operator.MUST_PASS_ONE</code> between the Filters.  The following example shows an 'or' between two 
          Filters (checking for either 'my value' or 'my other value' on the same attribute).
</p><pre class="programlisting">
FilterList list = new FilterList(FilterList.Operator.MUST_PASS_ONE);
SingleColumnValueFilter filter1 = new SingleColumnValueFilter(
	cf,
	column,
	CompareOp.EQUAL,
	Bytes.toBytes("my value")
	);
list.add(filter1);
SingleColumnValueFilter filter2 = new SingleColumnValueFilter(
	cf,
	column,
	CompareOp.EQUAL,
	Bytes.toBytes("my other value")
	);
list.add(filter2);
scan.setFilter(list);
</pre><p>
          </p></div></div><div class="section" title="8.3.2.&nbsp;Column Value"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.cv"></a>8.3.2.&nbsp;Column Value</h3></div></div></div><div class="section" title="8.3.2.1.&nbsp;SingleColumnValueFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.cv.scvf"></a>8.3.2.1.&nbsp;SingleColumnValueFilter</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.html" target="_top">SingleColumnValueFilter</a>
          can be used to test column values for equivalence (<code class="code"><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/CompareFilter.CompareOp.html" target="_top">CompareOp.EQUAL</a>
          </code>), inequality (<code class="code">CompareOp.NOT_EQUAL</code>), or ranges
          (e.g., <code class="code">CompareOp.GREATER</code>).  The folowing is example of testing equivalence a column to a String value "my value"...
</p><pre class="programlisting">
SingleColumnValueFilter filter = new SingleColumnValueFilter(
	cf,
	column,
	CompareOp.EQUAL,
	Bytes.toBytes("my value")
	);
scan.setFilter(filter);
</pre><p>
          </p></div></div><div class="section" title="8.3.3.&nbsp;Column Value Comparators"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.cvp"></a>8.3.3.&nbsp;Column Value Comparators</h3></div></div></div><p>There are several Comparator classes in the Filter package that deserve special mention.
        These Comparators are used in concert with other Filters, such as  <a class="xref" href="#client.filter.cv.scvf" title="8.3.2.1.&nbsp;SingleColumnValueFilter">Section&nbsp;8.3.2.1, &#8220;SingleColumnValueFilter&#8221;</a>.
        </p><div class="section" title="8.3.3.1.&nbsp;RegexStringComparator"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.cvp.rcs"></a>8.3.3.1.&nbsp;RegexStringComparator</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/RegexStringComparator.html" target="_top">RegexStringComparator</a>
          supports regular expressions for value comparisons. 
</p><pre class="programlisting">
RegexStringComparator comp = new RegexStringComparator("my.");   // any value that starts with 'my'
SingleColumnValueFilter filter = new SingleColumnValueFilter(
	cf,
	column,
	CompareOp.EQUAL,
	comp
	);
scan.setFilter(filter);
</pre><p>
          See the Oracle JavaDoc for <a class="link" href="http://download.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html" target="_top">supported RegEx patterns in Java</a>. 
          </p></div><div class="section" title="8.3.3.2.&nbsp;SubstringComparator"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.cvp.rcs"></a>8.3.3.2.&nbsp;SubstringComparator</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/SubstringComparator.html" target="_top">SubstringComparator</a>
          can be used to determine if a given substring exists in a value.  The comparison is case-insensitive.
          </p><pre class="programlisting">
SubstringComparator comp = new SubstringComparator("y val");   // looking for 'my value'
SingleColumnValueFilter filter = new SingleColumnValueFilter(
	cf,
	column,
	CompareOp.EQUAL,
	comp
	);
scan.setFilter(filter);
</pre></div><div class="section" title="8.3.3.3.&nbsp;BinaryPrefixComparator"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.cvp.bfp"></a>8.3.3.3.&nbsp;BinaryPrefixComparator</h4></div></div></div><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/BinaryPrefixComparator.html" target="_top">BinaryPrefixComparator</a>.</p></div><div class="section" title="8.3.3.4.&nbsp;BinaryComparator"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.cvp.bc"></a>8.3.3.4.&nbsp;BinaryComparator</h4></div></div></div><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/BinaryComparator.html" target="_top">BinaryComparator</a>.</p></div></div><div class="section" title="8.3.4.&nbsp;KeyValue Metadata"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.kvm"></a>8.3.4.&nbsp;KeyValue Metadata</h3></div></div></div><p>As HBase stores data internally as KeyValue pairs, KeyValue Metadata Filters evaluate the existence of keys (i.e., ColumnFamily:Column qualifiers)
        for a row, as opposed to values the previous section.
        </p><div class="section" title="8.3.4.1.&nbsp;FamilyFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.kvm.ff"></a>8.3.4.1.&nbsp;FamilyFilter</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FamilyFilter.html" target="_top">FamilyFilter</a> can be used
          to filter on the ColumnFamily.  It is generally a better idea to select ColumnFamilies in the Scan than to do it with a Filter.</p></div><div class="section" title="8.3.4.2.&nbsp;QualifierFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.kvm.qf"></a>8.3.4.2.&nbsp;QualifierFilter</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/QualifierFilter.html" target="_top">QualifierFilter</a> can be used
          to filter based on Column (aka Qualifier) name.
          </p></div><div class="section" title="8.3.4.3.&nbsp;ColumnPrefixFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.kvm.cpf"></a>8.3.4.3.&nbsp;ColumnPrefixFilter</h4></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.html" target="_top">ColumnPrefixFilter</a> can be used
          to filter based on the lead portion of Column (aka Qualifier) names.
          </p></div></div><div class="section" title="8.3.5.&nbsp;RowKey"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.row"></a>8.3.5.&nbsp;RowKey</h3></div></div></div><div class="section" title="8.3.5.1.&nbsp;RowFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.row.rf"></a>8.3.5.1.&nbsp;RowFilter</h4></div></div></div><p>It is generally a better idea to use the startRow/stopRow methods on Scan for row selection, however 
          <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/RowFilter.html" target="_top">RowFilter</a> can also be used.</p></div></div><div class="section" title="8.3.6.&nbsp;Utility"><div class="titlepage"><div><div><h3 class="title"><a name="client.filter.utility"></a>8.3.6.&nbsp;Utility</h3></div></div></div><div class="section" title="8.3.6.1.&nbsp;FirstKeyOnlyFilter"><div class="titlepage"><div><div><h4 class="title"><a name="client.filter.utility.fkof"></a>8.3.6.1.&nbsp;FirstKeyOnlyFilter</h4></div></div></div><p>This is primarily used for rowcount jobs.  
          See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html" target="_top">FirstKeyOnlyFilter</a>.</p></div></div></div><div class="section" title="8.4.&nbsp;Master"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="master"></a>8.4.&nbsp;Master</h2></div></div></div><p><code class="code">HMaster</code> is the implementation of the Master Server.  The Master server
       is responsible for monitoring all RegionServer instances in the cluster, and is
       the interface for all metadata changes.  In a distributed cluster, the Master typically runs on the <a class="xref" href="#arch.hdfs.nn" title="8.7.1.&nbsp;NameNode">Section&nbsp;8.7.1, &#8220;NameNode&#8221;</a>.
       </p><div class="section" title="8.4.1.&nbsp;Startup Behavior"><div class="titlepage"><div><div><h3 class="title"><a name="master.startup"></a>8.4.1.&nbsp;Startup Behavior</h3></div></div></div><p>If run in a multi-Master environment, all Masters compete to run the cluster.  If the active
         Master loses it's lease in ZooKeeper (or the Master shuts down), then then the remaining Masters jostle to 
         take over the Master role.
         </p></div><div class="section" title="8.4.2.&nbsp;Interface"><div class="titlepage"><div><div><h3 class="title"><a name="master.api"></a>8.4.2.&nbsp;Interface</h3></div></div></div><p>The methods exposed by <code class="code">HMasterInterface</code> are primarily metadata-oriented methods:
         </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Table (createTable, modifyTable, removeTable, enable, disable)
            </li><li class="listitem">ColumnFamily (addColumn, modifyColumn, removeColumn) 
            </li><li class="listitem">Region (move, assign, unassign)
            </li></ul></div><p>
         For example, when the <code class="code">HBaseAdmin</code> method <code class="code">disableTable</code> is invoked, it is serviced by the Master server. 
         </p></div><div class="section" title="8.4.3.&nbsp;Processes"><div class="titlepage"><div><div><h3 class="title"><a name="master.processes"></a>8.4.3.&nbsp;Processes</h3></div></div></div><p>The Master runs several background threads:
         </p><div class="section" title="8.4.3.1.&nbsp;LoadBalancer"><div class="titlepage"><div><div><h4 class="title"><a name="master.processes.loadbalancer"></a>8.4.3.1.&nbsp;LoadBalancer</h4></div></div></div><p>Periodically, and when there are not any regions in transition,
             a load balancer will run and move regions around to balance cluster load.
             See <a class="xref" href="#balancer_config" title="2.8.3.1.&nbsp;Balancer">Section&nbsp;2.8.3.1, &#8220;Balancer&#8221;</a> for configuring this property.</p></div><div class="section" title="8.4.3.2.&nbsp;CatalogJanitor"><div class="titlepage"><div><div><h4 class="title"><a name="master.processes.catalog"></a>8.4.3.2.&nbsp;CatalogJanitor</h4></div></div></div><p>Periodically checks and cleans up the .META. table.  See <a class="xref" href="#arch.catalog.meta" title="8.1.2.&nbsp;META">Section&nbsp;8.1.2, &#8220;META&#8221;</a> for more information on META.</p></div></div></div><div class="section" title="8.5.&nbsp;RegionServer"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="regionserver.arch"></a>8.5.&nbsp;RegionServer</h2></div></div></div><p><code class="code">HRegionServer</code> is the RegionServer implementation.  It is responsible for serving and managing regions.
       In a distributed cluster, a RegionServer runs on a <a class="xref" href="#arch.hdfs.dn" title="8.7.2.&nbsp;DataNode">Section&nbsp;8.7.2, &#8220;DataNode&#8221;</a>.  
       </p><div class="section" title="8.5.1.&nbsp;Interface"><div class="titlepage"><div><div><h3 class="title"><a name="regionserver.arch.api"></a>8.5.1.&nbsp;Interface</h3></div></div></div><p>The methods exposed by <code class="code">HRegionRegionInterface</code> contain both data-oriented and region-maintenance methods:
         </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Data (get, put, delete, next, etc.)
            </li><li class="listitem">Region (splitRegion, compactRegion, etc.)  
            </li></ul></div><p>
         For example, when the <code class="code">HBaseAdmin</code> method <code class="code">majorCompact</code> is invoked on a table, the client is actually iterating through
         all regions for the specified table and requesting a major compaction directly to each region. 
         </p></div><div class="section" title="8.5.2.&nbsp;Processes"><div class="titlepage"><div><div><h3 class="title"><a name="regionserver.arch.processes"></a>8.5.2.&nbsp;Processes</h3></div></div></div><p>The RegionServer runs a variety of background threads:</p><div class="section" title="8.5.2.1.&nbsp;CompactSplitThread"><div class="titlepage"><div><div><h4 class="title"><a name="regionserver.arch.processes.compactsplit"></a>8.5.2.1.&nbsp;CompactSplitThread</h4></div></div></div><p>Checks for splits and handle minor compactions.</p></div><div class="section" title="8.5.2.2.&nbsp;MajorCompactionChecker"><div class="titlepage"><div><div><h4 class="title"><a name="regionserver.arch.processes.majorcompact"></a>8.5.2.2.&nbsp;MajorCompactionChecker</h4></div></div></div><p>Checks for major compactions.</p></div><div class="section" title="8.5.2.3.&nbsp;MemStoreFlusher"><div class="titlepage"><div><div><h4 class="title"><a name="regionserver.arch.processes.memstore"></a>8.5.2.3.&nbsp;MemStoreFlusher</h4></div></div></div><p>Periodically flushes in-memory writes in the MemStore to StoreFiles.</p></div><div class="section" title="8.5.2.4.&nbsp;LogRoller"><div class="titlepage"><div><div><h4 class="title"><a name="regionserver.arch.processes.log"></a>8.5.2.4.&nbsp;LogRoller</h4></div></div></div><p>Periodically checks the RegionServer's HLog.</p></div></div><div class="section" title="8.5.3.&nbsp;Block Cache"><div class="titlepage"><div><div><h3 class="title"><a name="block.cache"></a>8.5.3.&nbsp;Block Cache</h3></div></div></div><p>The Block Cache contains three levels of block priority to allow for scan-resistance and in-memory ColumnFamilies.  A block is added with an in-memory
       flag if the containing ColumnFamily is defined in-memory, otherwise a block becomes a single access priority.  Once a block is accessed again, it changes to multiple access. 
       This is used to prevent scans from thrashing the cache, adding a least-frequently-used element to the eviction algorithm.  Blocks from in-memory ColumnFamilies
       are the last to be evicted.
       </p><p>
        For more information, see the <a class="link" href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/LruBlockCache.html" target="_top">LruBlockCache source</a>
        </p></div><div class="section" title="8.5.4.&nbsp;Write Ahead Log (WAL)"><div class="titlepage"><div><div><h3 class="title"><a name="wal"></a>8.5.4.&nbsp;Write Ahead Log (WAL)</h3></div></div></div><div class="section" title="8.5.4.1.&nbsp;Purpose"><div class="titlepage"><div><div><h4 class="title"><a name="purpose.wal"></a>8.5.4.1.&nbsp;Purpose</h4></div></div></div><p>Each RegionServer adds updates (Puts, Deletes) to its write-ahead log (WAL)
            first, and then to the <a class="xref" href="#store.memstore" title="8.6.4.1.&nbsp;MemStore">Section&nbsp;8.6.4.1, &#8220;MemStore&#8221;</a> for the affected <a class="xref" href="#store" title="8.6.4.&nbsp;Store">Section&nbsp;8.6.4, &#8220;Store&#8221;</a>.  
        This ensures that HBase has durable writes. Without WAL, there is the possibility of data loss in the case of a RegionServer failure 
        before each MemStore is flushed and new StoreFiles are written.  <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/wal/HLog.html" target="_top">HLog</a> 
        is the HBase WAL implementation, and there is one HLog instance per RegionServer.
       </p>The WAL is in HDFS in <code class="filename">/hbase/.logs/</code> with subdirectories per region.
       <p>
        For more general information about the concept of write ahead logs, see the Wikipedia
        <a class="link" href="http://en.wikipedia.org/wiki/Write-ahead_logging" target="_top">Write-Ahead Log</a> article.
       </p></div><div class="section" title="8.5.4.2.&nbsp;WAL Flushing"><div class="titlepage"><div><div><h4 class="title"><a name="wal_flush"></a>8.5.4.2.&nbsp;WAL Flushing</h4></div></div></div><p>TODO (describe).
          </p></div><div class="section" title="8.5.4.3.&nbsp;WAL Splitting"><div class="titlepage"><div><div><h4 class="title"><a name="wal_splitting"></a>8.5.4.3.&nbsp;WAL Splitting</h4></div></div></div><div class="section" title="8.5.4.3.1.&nbsp;How edits are recovered from a crashed RegionServer"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4075"></a>8.5.4.3.1.&nbsp;How edits are recovered from a crashed RegionServer</h5></div></div></div><p>When a RegionServer crashes, it will lose its ephemeral lease in
         ZooKeeper...TODO</p></div><div class="section" title="8.5.4.3.2.&nbsp;hbase.hlog.split.skip.errors"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4080"></a>8.5.4.3.2.&nbsp;<code class="varname">hbase.hlog.split.skip.errors</code></h5></div></div></div><p>When set to <code class="constant">true</code>, the default, any error
        encountered splitting will be logged, the problematic WAL will be
        moved into the <code class="filename">.corrupt</code> directory under the hbase
        <code class="varname">rootdir</code>, and processing will continue. If set to
        <code class="constant">false</code>, the exception will be propagated and the
        split logged as failed.<sup>[<a name="d0e4098" href="#ftn.d0e4098" class="footnote">20</a>]</sup></p></div><div class="section" title="8.5.4.3.3.&nbsp;How EOFExceptions are treated when splitting a crashed RegionServers' WALs"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4104"></a>8.5.4.3.3.&nbsp;How EOFExceptions are treated when splitting a crashed
        RegionServers' WALs</h5></div></div></div><p>If we get an EOF while splitting logs, we proceed with the split
        even when <code class="varname">hbase.hlog.split.skip.errors</code> ==
        <code class="constant">false</code>. An EOF while reading the last log in the
        set of files to split is near-guaranteed since the RegionServer likely
        crashed mid-write of a record. But we'll continue even if we got an
        EOF reading other than the last file in the set.<sup>[<a name="d0e4115" href="#ftn.d0e4115" class="footnote">21</a>]</sup></p></div></div></div></div><div class="section" title="8.6.&nbsp;Regions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="regions.arch"></a>8.6.&nbsp;Regions</h2></div></div></div><p>This section is all about Regions.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Regions are comprised of a Store per Column Family.
        </p></div><div class="section" title="8.6.1.&nbsp;Region Size"><div class="titlepage"><div><div><h3 class="title"><a name="arch.regions.size"></a>8.6.1.&nbsp;Region Size</h3></div></div></div><p>Region size is one of those tricky things, there are a few factors
      to consider:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>Regions are the basic element of availability and
          distribution.</p></li><li class="listitem"><p>HBase scales by having regions across many servers. Thus if
          you have 2 regions for 16GB data, on a 20 node machine you are a net
          loss there.</p></li><li class="listitem"><p>High region count has been known to make things slow, this is
          getting better, but it is probably better to have 700 regions than
          3000 for the same amount of data.</p></li><li class="listitem"><p>Low region count prevents parallel scalability as per point
          #2. This really cant be stressed enough, since a common problem is
          loading 200MB data into HBase then wondering why your awesome 10
          node cluster is mostly idle.</p></li><li class="listitem"><p>There is not much memory footprint difference between 1 region
          and 10 in terms of indexes, etc, held by the RegionServer.</p></li></ul></div><p>Its probably best to stick to the default, perhaps going smaller
      for hot tables (or manually split hot regions to spread the load over
      the cluster), or go with a 1GB region size if your cell sizes tend to be
      largish (100k and up).</p></div><div class="section" title="8.6.2.&nbsp;Region Splits"><div class="titlepage"><div><div><h3 class="title"><a name="d0e4152"></a>8.6.2.&nbsp;Region Splits</h3></div></div></div><p>Splits run unaided on the RegionServer; i.e. the Master does not
        participate. The RegionServer splits a region, offlines the split
        region and then adds the daughter regions to META, opens daughters on
        the parent's hosting RegionServer and then reports the split to the
        Master. See <a class="xref" href="#disable.splitting" title="2.8.2.7.&nbsp;Managed Splitting">Section&nbsp;2.8.2.7, &#8220;Managed Splitting&#8221;</a> for how to manually manage
        splits (and for why you might do this)</p></div><div class="section" title="8.6.3.&nbsp;Region Load Balancing"><div class="titlepage"><div><div><h3 class="title"><a name="regions.arch.balancer"></a>8.6.3.&nbsp;Region Load Balancing</h3></div></div></div><p>
        Regions can be periodically moved by the <a class="xref" href="#master.processes.loadbalancer" title="8.4.3.1.&nbsp;LoadBalancer">Section&nbsp;8.4.3.1, &#8220;LoadBalancer&#8221;</a>.
        </p></div><div class="section" title="8.6.4.&nbsp;Store"><div class="titlepage"><div><div><h3 class="title"><a name="store"></a>8.6.4.&nbsp;Store</h3></div></div></div><p>A Store hosts a MemStore and 0 or more StoreFiles (HFiles). A Store corresponds to a column family for a table for a given region.
          </p><div class="section" title="8.6.4.1.&nbsp;MemStore"><div class="titlepage"><div><div><h4 class="title"><a name="store.memstore"></a>8.6.4.1.&nbsp;MemStore</h4></div></div></div><p>The MemStore holds in-memory modifications to the Store.  Modifications are KeyValues.
       When asked to flush, current memstore is moved to snapshot and is cleared. 
       HBase continues to serve edits out of new memstore and backing snapshot until flusher reports in that the 
       flush succeeded. At this point the snapshot is let go.</p></div><div class="section" title="8.6.4.2.&nbsp;StoreFile (HFile)"><div class="titlepage"><div><div><h4 class="title"><a name="hfile"></a>8.6.4.2.&nbsp;StoreFile (HFile)</h4></div></div></div><div class="section" title="8.6.4.2.1.&nbsp;HFile Format"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4179"></a>8.6.4.2.1.&nbsp;HFile Format</h5></div></div></div><p>The <span class="emphasis"><em>hfile</em></span> file format is based on
              the SSTable file described in the <a class="link" href="http://labs.google.com/papers/bigtable.html" target="_top">BigTable [2006]</a> paper and on
              Hadoop's <a class="link" href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html" target="_top">tfile</a>
              (The unit test suite and the compression harness were taken directly from tfile). 
              Schubert Zhang's blog post on HFile: A Block-Indexed File Format to Store Sorted Key-Value Pairs makes for a thorough introduction to HBase's hfile.  Matteo Bertozzi has also put up a
              helpful description, <a class="link" href="http://th30z.blogspot.com/2011/02/hbase-io-hfile.html?spref=tw" target="_top">HBase I/O: HFile</a>.
          </p><p>For more information, see the <a class="link" href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFile.html" target="_top">HFile source code</a>.
          </p></div><div class="section" title="8.6.4.2.2.&nbsp;HFile Tool"><div class="titlepage"><div><div><h5 class="title"><a name="hfile_tool"></a>8.6.4.2.2.&nbsp;HFile Tool</h5></div></div></div><p>To view a textualized version of hfile content, you can do use
        the <code class="classname">org.apache.hadoop.hbase.io.hfile.HFile
        </code>tool. Type the following to see usage:</p><pre class="programlisting"><code class="code">$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile </code> </pre><p>For
        example, to view the content of the file
        <code class="filename">hdfs://10.81.47.41:8020/hbase/TEST/1418428042/DSMP/4759508618286845475</code>,
        type the following:</p><pre class="programlisting"> <code class="code">$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f hdfs://10.81.47.41:8020/hbase/TEST/1418428042/DSMP/4759508618286845475 </code> </pre><p>If
        you leave off the option -v to see just a summary on the hfile. See
        usage for other things to do with the <code class="classname">HFile</code>
        tool.</p></div><div class="section" title="8.6.4.2.3.&nbsp;StoreFile Directory Structure on HDFS"><div class="titlepage"><div><div><h5 class="title"><a name="store.file.dir"></a>8.6.4.2.3.&nbsp;StoreFile Directory Structure on HDFS</h5></div></div></div><p>For more information of what StoreFiles look like on HDFS with respect to the directory structure, see <a class="xref" href="#trouble.namenode.hbase.objects" title="11.5.2.&nbsp;Browsing HDFS for HBase Objects">Section&nbsp;11.5.2, &#8220;Browsing HDFS for HBase Objects&#8221;</a>.
        </p></div></div><div class="section" title="8.6.4.3.&nbsp;Blocks"><div class="titlepage"><div><div><h4 class="title"><a name="hfile.blocks"></a>8.6.4.3.&nbsp;Blocks</h4></div></div></div><p>StoreFiles are composed of blocks.  The blocksize is configured on a per-ColumnFamily basis.
        </p><p>For more information, see the <a class="link" href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFileBlock.html" target="_top">HFileBlock source code</a>.
        </p></div><div class="section" title="8.6.4.4.&nbsp;KeyValue"><div class="titlepage"><div><div><h4 class="title"><a name="keyvalue"></a>8.6.4.4.&nbsp;KeyValue</h4></div></div></div><p>The KeyValue class is the heart of data storage in HBase.  KeyValue wraps a byte array and takes offsets and lengths into passed array
         at where to start interpreting the content as KeyValue.
        </p><p>The KeyValue format inside a byte array is:
           </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">keylength</li><li class="listitem">valuelength</li><li class="listitem">key</li><li class="listitem">value</li></ul></div><p>
        </p><p>The Key is further decomposed as:
           </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">rowlength</li><li class="listitem">row (i.e., the rowkey)</li><li class="listitem">columnfamilylength</li><li class="listitem">columnfamily</li><li class="listitem">columnqualifier</li><li class="listitem">timestamp</li><li class="listitem">keytype (e.g., Put, Delete)</li></ul></div><p>
        </p><p>For more information, see the <a class="link" href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/KeyValue.html" target="_top">KeyValue source code</a>.
        </p><div class="section" title="8.6.4.4.1.&nbsp;Example"><div class="titlepage"><div><div><h5 class="title"><a name="keyvalue.example"></a>8.6.4.4.1.&nbsp;Example</h5></div></div></div><p>To emphasize the points above, examine what happens with two Puts for two different columns for the same row:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Put #1:  <code class="code">rowkey=row1, cf:attr1=value1</code></li><li class="listitem">Put #2:  <code class="code">rowkey=row1, cf:attr2=value2</code></li></ul></div><p>Even though these are for the same row, a KeyValue is created for each column:</p><p>Key portion for Put #1:
           </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">rowlength <code class="code">------------&gt; 4</code></li><li class="listitem">row <code class="code">-----------------&gt; row1</code></li><li class="listitem">columnfamilylength <code class="code">---&gt; 2</code></li><li class="listitem">columnfamily <code class="code">--------&gt; cf</code></li><li class="listitem">columnqualifier <code class="code">------&gt; attr1</code></li><li class="listitem">timestamp <code class="code">-----------&gt; server time of Put</code></li><li class="listitem">keytype <code class="code">-------------&gt; Put</code></li></ul></div><p>
          </p><p>Key portion for Put #2:
           </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">rowlength <code class="code">------------&gt; 4</code></li><li class="listitem">row <code class="code">-----------------&gt; row1</code></li><li class="listitem">columnfamilylength <code class="code">---&gt; 2</code></li><li class="listitem">columnfamily <code class="code">--------&gt; cf</code></li><li class="listitem">columnqualifier <code class="code">------&gt; attr2</code></li><li class="listitem">timestamp <code class="code">-----------&gt; server time of Put</code></li><li class="listitem">keytype <code class="code">-------------&gt; Put</code></li></ul></div><p>
           
          </p></div><p>It is critical to understand that the rowkey, ColumnFamily, and column (aka columnqualifier) are embedded within
       the KeyValue instance.  The longer these identifiers are, the bigger the KeyValue is.</p></div><div class="section" title="8.6.4.5.&nbsp;Compaction"><div class="titlepage"><div><div><h4 class="title"><a name="compaction"></a>8.6.4.5.&nbsp;Compaction</h4></div></div></div><p>There are two types of compactions:  minor and major.  Minor compactions will usually pick up a couple of the smaller adjacent
         files and rewrite them as one.  Minors do not drop deletes or expired cells, only major compactions do this.  Sometimes a minor compaction
         will pick up all  the files in the store and in this case it actually promotes itself to being a major compaction.  
         For a description of how a minor compaction picks files to compact, see the <a class="link" href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/Store.html#836" target="_top">ascii diagram in the Store source code.</a>
         </p><p>After a major compaction runs there will be a single storefile per store, and this will help performance usually.  Caution:  major compactions rewrite all of the stores data and on a loaded system, this may not be tenable;
             major compactions will usually have to be done manually on large systems.  See <a class="xref" href="#managed.compactions" title="2.8.2.8.&nbsp;Managed Compactions">Section&nbsp;2.8.2.8, &#8220;Managed Compactions&#8221;</a>.
        </p></div></div><div class="section" title="8.6.5.&nbsp;Bloom Filters"><div class="titlepage"><div><div><h3 class="title"><a name="blooms"></a>8.6.5.&nbsp;Bloom Filters</h3></div></div></div><p><a class="link" href="http://en.wikipedia.org/wiki/Bloom_filter" target="_top">Bloom filters</a> were developed over in <a class="link" href="https://issues.apache.org/jira/browse/HBASE-1200" target="_top">HBase-1200
    Add bloomfilters</a>.<sup>[<a name="d0e4394" href="#ftn.d0e4394" class="footnote">22</a>]</sup><sup>[<a name="d0e4406" href="#ftn.d0e4406" class="footnote">23</a>]</sup></p><p>See also <a class="xref" href="#schema.bloom" title="10.5.4.&nbsp;Bloom Filters">Section&nbsp;10.5.4, &#8220;Bloom Filters&#8221;</a> and <a class="xref" href="#config.bloom" title="2.9.&nbsp;Bloom Filter Configuration">Section&nbsp;2.9, &#8220;Bloom Filter Configuration&#8221;</a>.
        </p><div class="section" title="8.6.5.1.&nbsp;Bloom StoreFile footprint"><div class="titlepage"><div><div><h4 class="title"><a name="bloom_footprint"></a>8.6.5.1.&nbsp;Bloom StoreFile footprint</h4></div></div></div><p>Bloom filters add an entry to the <code class="classname">StoreFile</code>
      general <code class="classname">FileInfo</code> data structure and then two
      extra entries to the <code class="classname">StoreFile</code> metadata
      section.</p><div class="section" title="8.6.5.1.1.&nbsp;BloomFilter in the StoreFile FileInfo data structure"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4432"></a>8.6.5.1.1.&nbsp;BloomFilter in the <code class="classname">StoreFile</code>
        <code class="classname">FileInfo</code> data structure</h5></div></div></div><p><code class="classname">FileInfo</code> has a
          <code class="varname">BLOOM_FILTER_TYPE</code> entry which is set to
          <code class="varname">NONE</code>, <code class="varname">ROW</code> or
          <code class="varname">ROWCOL.</code></p></div><div class="section" title="8.6.5.1.2.&nbsp;BloomFilter entries in StoreFile metadata"><div class="titlepage"><div><div><h5 class="title"><a name="d0e4456"></a>8.6.5.1.2.&nbsp;BloomFilter entries in <code class="classname">StoreFile</code>
        metadata</h5></div></div></div><p><code class="varname">BLOOM_FILTER_META</code> holds Bloom Size, Hash
          Function used, etc. Its small in size and is cached on
          <code class="classname">StoreFile.Reader</code> load</p><p><code class="varname">BLOOM_FILTER_DATA</code> is the actual bloomfilter
          data. Obtained on-demand. Stored in the LRU cache, if it is enabled
          (Its enabled by default).</p></div></div></div></div><div class="section" title="8.7.&nbsp;HDFS"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch.hdfs"></a>8.7.&nbsp;HDFS</h2></div></div></div><p>As HBase runs on HDFS (and each StoreFile is written as a file on HDFS),
        it is important to have an understanding of the HDFS Architecture
         especially in terms of how it stores files, handles failovers, and replicates blocks.
       </p><p>See the Hadoop documentation on <a class="link" href="http://hadoop.apache.org/common/docs/current/hdfs_design.html" target="_top">HDFS Architecture</a>
       for more information.
       </p><div class="section" title="8.7.1.&nbsp;NameNode"><div class="titlepage"><div><div><h3 class="title"><a name="arch.hdfs.nn"></a>8.7.1.&nbsp;NameNode</h3></div></div></div><p>The NameNode is responsible for maintaining the filesystem metadata.  See the above HDFS Architecture link
         for more information.
         </p></div><div class="section" title="8.7.2.&nbsp;DataNode"><div class="titlepage"><div><div><h3 class="title"><a name="arch.hdfs.dn"></a>8.7.2.&nbsp;DataNode</h3></div></div></div><p>The DataNodes are responsible for storing HDFS blocks.  See the above HDFS Architecture link
         for more information.
         </p></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e4098" href="#d0e4098" class="para">20</a>] </sup>See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-2958" target="_top">HBASE-2958
            When hbase.hlog.split.skip.errors is set to false, we fail the
            split but thats it</a>. We need to do more than just fail split
            if this flag is set.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e4115" href="#d0e4115" class="para">21</a>] </sup>For background, see <a class="link" href="https://issues.apache.org/jira/browse/HBASE-2643" target="_top">HBASE-2643
            Figure how to deal with eof splitting logs</a></p></div><div class="footnote"><p><sup>[<a id="ftn.d0e4394" href="#d0e4394" class="para">22</a>] </sup>For description of the development process -- why static blooms
        rather than dynamic -- and for an overview of the unique properties
        that pertain to blooms in HBase, as well as possible future
        directions, see the <span class="emphasis"><em>Development Process</em></span> section
        of the document <a class="link" href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf" target="_top">BloomFilters
        in HBase</a> attached to <a class="link" href="https://issues.apache.org/jira/browse/HBASE-1200" target="_top">HBase-1200</a>.</p></div><div class="footnote"><p><sup>[<a id="ftn.d0e4406" href="#d0e4406" class="para">23</a>] </sup>The bloom filters described here are actually version two of
        blooms in HBase. In versions up to 0.19.x, HBase had a dynamic bloom
        option based on work done by the <a class="link" href="http://www.one-lab.org" target="_top">European Commission One-Lab
        Project 034819</a>. The core of the HBase bloom work was later
        pulled up into Hadoop to implement org.apache.hadoop.io.BloomMapFile.
        Version 1 of HBase blooms never worked that well. Version 2 is a
        rewrite from scratch though again it starts with the one-lab
        work.</p></div></div></div><div class="chapter" title="Chapter&nbsp;9.&nbsp;External APIs"><div class="titlepage"><div><div><h2 class="title"><a name="external_apis"></a>Chapter&nbsp;9.&nbsp;External APIs</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#nonjava.jvm">9.1. Non-Java Languages Talking to the JVM</a></span></dt><dt><span class="section"><a href="#rest">9.2. REST</a></span></dt><dt><span class="section"><a href="#thrift">9.3. Thrift</a></span></dt><dd><dl><dt><span class="section"><a href="#thrift.filter-language">9.3.1. Filter Language</a></span></dt></dl></dd></dl></div>
  This chapter will cover access to HBase either through non-Java languages, or through custom protocols.
  
  <div class="section" title="9.1.&nbsp;Non-Java Languages Talking to the JVM"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="nonjava.jvm"></a>9.1.&nbsp;Non-Java Languages Talking to the JVM</h2></div></div></div><p>Currently the documentation on this topic in the 
      <a class="link" href="http://wiki.apache.org/hadoop/Hbase" target="_top">HBase Wiki</a>.
    </p></div><div class="section" title="9.2.&nbsp;REST"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="rest"></a>9.2.&nbsp;REST</h2></div></div></div><p>Currently most of the documentation on REST exists in the 
      <a class="link" href="http://wiki.apache.org/hadoop/Hbase/Stargate" target="_top">HBase Wiki on REST</a>.
    </p></div><div class="section" title="9.3.&nbsp;Thrift"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="thrift"></a>9.3.&nbsp;Thrift</h2></div></div></div><p>Currently most of the documentation on Thrift exists in the 
      <a class="link" href="http://wiki.apache.org/hadoop/Hbase/ThriftApi" target="_top">HBase Wiki on Thrift</a>.
    </p><div class="section" title="9.3.1.&nbsp;Filter Language"><div class="titlepage"><div><div><h3 class="title"><a name="thrift.filter-language"></a>9.3.1.&nbsp;Filter Language</h3></div></div></div><div class="section" title="9.3.1.1.&nbsp;Use Case"><div class="titlepage"><div><div><h4 class="title"><a name="use-case"></a>9.3.1.1.&nbsp;Use Case</h4></div></div></div><p>This allows the user to perform server-side filtering when accessing HBase over Thrift. The user specifies a filter via a string. The string is parsed on the server to construct the filter</p></div><div class="section" title="9.3.1.2.&nbsp;General Filter String Syntax"><div class="titlepage"><div><div><h4 class="title"><a name="general-syntax"></a>9.3.1.2.&nbsp;General Filter String Syntax</h4></div></div></div><p>A simple filter expression is expressed as: <code class="code">&#8220;FilterName (argument, argument, ... , argument)&#8221;</code></p><p>You must specify the name of the filter followed by the argument list in parenthesis. Commas separate the individual arguments</p><p>If the argument represents a string, it should be enclosed in single quotes.</p><p>If it represents a boolean, an integer or a comparison operator like &lt;,
                 &gt;, != etc. it should not be enclosed in quotes</p><p>The filter name must be one word. All ASCII characters are allowed except for whitespace, single quotes and parenthesis.</p><p>The filter&#8217;s arguments can contain any ASCII character. <code class="code">If single quotes are present in the argument, they must be escaped by a
                   preceding single quote</code></p></div><div class="section" title="9.3.1.3.&nbsp;Compound Filters and Operators"><div class="titlepage"><div><div><h4 class="title"><a name="compound-filters-and-operators"></a>9.3.1.3.&nbsp;Compound Filters and Operators</h4></div></div></div><p>Currently, two binary operators &#8211; AND/OR and two unary operators &#8211; WHILE/SKIP are supported.</p><p>Note: the operators are all in uppercase</p><p><span class="bold"><strong>AND</strong></span> &#8211; as the name suggests, if this
                 operator is used, the key-value must pass both the filters</p><p><span class="bold"><strong>OR</strong></span> &#8211; as the name suggests, if this operator
                 is used, the key-value must pass at least one of the filters</p><p><span class="bold"><strong>SKIP</strong></span> &#8211; For a particular row, if any of the
                 key-values don&#8217;t pass the filter condition, the entire row is skipped</p><p><span class="bold"><strong>WHILE</strong></span> - For a particular row, it continues
                 to emit key-values until a key-value is reached that fails the filter condition</p><p><span class="bold"><strong>Compound Filters:</strong></span> Using these operators, a
                 hierarchy of filters can be created. For example: <code class="code">&#8220;(Filter1 AND Filter2) OR (Filter3 AND Filter4)&#8221;</code></p></div><div class="section" title="9.3.1.4.&nbsp;Order of Evaluation"><div class="titlepage"><div><div><h4 class="title"><a name="order-of-evaluation"></a>9.3.1.4.&nbsp;Order of Evaluation</h4></div></div></div><p>Parenthesis have the highest precedence. The SKIP and WHILE operators are next and have the same precedence.The AND operator has the next highest precedence followed by the OR operator.</p><p>For example:</p><p>A filter string of the form:<code class="code">&#8220;Filter1 AND Filter2 OR Filter3&#8221;</code>
                 will be evaluated as:<code class="code">&#8220;(Filter1 AND Filter2) OR Filter3&#8221;</code></p><p>A filter string of the form:<code class="code">&#8220;Filter1 AND SKIP Filter2 OR Filter3&#8221;</code>
                 will be evaluated as:<code class="code">&#8220;(Filter1 AND (SKIP Filter2)) OR Filter3&#8221;</code></p></div><div class="section" title="9.3.1.5.&nbsp;Compare Operator"><div class="titlepage"><div><div><h4 class="title"><a name="compare-operator"></a>9.3.1.5.&nbsp;Compare Operator</h4></div></div></div><p>A compare operator can be any of the following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>LESS (&lt;)</p></li><li class="listitem"><p>LESS_OR_EQUAL (&lt;=)</p></li><li class="listitem"><p>EQUAL (=)</p></li><li class="listitem"><p>NOT_EQUAL (!=)</p></li><li class="listitem"><p>GREATER_OR_EQUAL (&gt;=)</p></li><li class="listitem"><p>GREATER (&gt;)</p></li><li class="listitem"><p>NO_OP (no operation)</p></li></ol></div><p>The client should use the symbols (&lt;, &lt;=, =, !=, &gt;, &gt;=) to express
                 compare operators.</p></div><div class="section" title="9.3.1.6.&nbsp;Comparator"><div class="titlepage"><div><div><h4 class="title"><a name="comparator"></a>9.3.1.6.&nbsp;Comparator</h4></div></div></div><p>A comparator can be any of the following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p><span class="bold"><strong>BinaryComparator</strong></span> - This
                     lexicographically compares against the specified byte array using
                     Bytes.compareTo(byte[], byte[])</p></li><li class="listitem"><p><span class="bold"><strong>BinaryPrefixComparator</strong></span> - This
                     lexicographically compares against a specified byte array. It only compares up to
                     the length of this byte array.</p></li><li class="listitem"><p><span class="bold"><strong>RegexStringComparator</strong></span> - This compares
                     against the specified byte array using the given regular expression. Only EQUAL
                     and NOT_EQUAL comparisons are valid with this comparator</p></li><li class="listitem"><p><span class="bold"><strong>SubStringComparator</strong></span> - This tests if
                     the given substring appears in a specified byte array. The comparison is case
                     insensitive. Only EQUAL and NOT_EQUAL comparisons are valid with this
                     comparator</p></li></ol></div><p>The general syntax of a comparator is:<code class="code"> ComparatorType:ComparatorValue</code></p><p>The ComparatorType for the various comparators is as follows:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p><span class="bold"><strong>BinaryComparator</strong></span> - binary</p></li><li class="listitem"><p><span class="bold"><strong>BinaryPrefixComparator</strong></span> - binaryprefix</p></li><li class="listitem"><p><span class="bold"><strong>RegexStringComparator</strong></span> - regexstring</p></li><li class="listitem"><p><span class="bold"><strong>SubStringComparator</strong></span> - substring</p></li></ol></div><p>The ComparatorValue can be any value.</p><p>Example1:<code class="code"> &gt;, 'binary:abc' </code>will match everything that is lexicographically greater than "abc" </p><p>Example2:<code class="code"> =, 'binaryprefix:abc' </code>will match everything whose first 3 characters are lexicographically equal to "abc"</p><p>Example3:<code class="code"> !=, 'regexstring:ab*yz' </code>will match everything that doesn't begin with "ab" and ends with "yz"</p><p>Example4:<code class="code"> =, 'substring:abc123' </code>will match everything that begins with the substring "abc123"</p></div><div class="section" title="9.3.1.7.&nbsp;Example PHP Client Program that uses the Filter Language"><div class="titlepage"><div><div><h4 class="title"><a name="example PHP Client Program"></a>9.3.1.7.&nbsp;Example PHP Client Program that uses the Filter Language</h4></div></div></div><pre class="programlisting">
&lt;? $_SERVER['PHP_ROOT'] = realpath(dirname(__FILE__).'/..');
   require_once $_SERVER['PHP_ROOT'].'/flib/__flib.php';
   flib_init(FLIB_CONTEXT_SCRIPT);
   require_module('storage/hbase');
   $hbase = new HBase('&lt;server_name_running_thrift_server&gt;', &lt;port on which thrift server is running&gt;);
   $hbase-&gt;open();
   $client = $hbase-&gt;getClient();
   $result = $client-&gt;scannerOpenWithFilterString('table_name', "(PrefixFilter ('row2') AND (QualifierFilter (&gt;=, 'binary:xyz'))) AND (TimestampsFilter ( 123, 456))");
   $to_print = $client-&gt;scannerGetList($result,1);
   while ($to_print) {
      print_r($to_print);
      $to_print = $client-&gt;scannerGetList($result,1);
    }
   $client-&gt;scannerClose($result);
?&gt;
        </pre></div><div class="section" title="9.3.1.8.&nbsp;Example Filter Strings"><div class="titlepage"><div><div><h4 class="title"><a name="example-filter-strings"></a>9.3.1.8.&nbsp;Example Filter Strings</h4></div></div></div><p>
          </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="code">&#8220;PrefixFilter (&#8216;Row&#8217;) AND PageFilter (1) AND FirstKeyOnlyFilter ()&#8221;</code> will return all key-value pairs that match the following conditions:</p><p>1) The row containing the key-value should have prefix &#8220;Row&#8221; </p><p>2) The key-value must be located in the first row of the table </p><p>3) The key-value pair must be the first key-value in the row </p></li></ul></div><p>
        </p><div class="orderedlist"><p>
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="code">&#8220;(RowFilter (=, &#8216;binary:Row 1&#8217;) AND TimeStampsFilter (74689, 89734)) OR
                    ColumnRangeFilter (&#8216;abc&#8217;, true, &#8216;xyz&#8217;, false))&#8221;</code> will return all key-value pairs that match both the following conditions:</p><p>1) The key-value is in a row having row key &#8220;Row 1&#8221; </p><p>2) The key-value must have a timestamp of either 74689 or 89734.</p><p>Or it must match the following condition:</p><p>1) The key-value pair must be in a column that is lexicographically &gt;= abc and &lt; xyz&nbsp;</p></li></ul></div><p>
          </p><ol class="orderedlist" type="1"></ol></div><p>
          </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><code class="code">&#8220;SKIP ValueFilter (0)&#8221;</code> will skip the entire row if any of the values in the row is not 0</p></li></ul></div><p>
        </p></div><div class="section" title="9.3.1.9.&nbsp;Individual Filter Syntax"><div class="titlepage"><div><div><h4 class="title"><a name="Individual Filter Syntax"></a>9.3.1.9.&nbsp;Individual Filter Syntax</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p><span class="bold"><strong><span class="underline">KeyOnlyFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter doesn&#8217;t take any
              arguments. It returns only the key component of each key-value. </p><p><span class="bold"><strong>Syntax:</strong></span> KeyOnlyFilter () </p><p><span class="bold"><strong>Example:</strong></span> "KeyOnlyFilter ()"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">FirstKeyOnlyFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter doesn&#8217;t take any
              arguments. It returns only the first key-value from each row. </p><p><span class="bold"><strong>Syntax:</strong></span> FirstKeyOnlyFilter () </p><p><span class="bold"><strong>Example:</strong></span> "FirstKeyOnlyFilter ()" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">PrefixFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes one argument &#8211; a prefix of a
              row key. It returns only those key-values present in a row that starts with the
              specified row prefix</p><p><span class="bold"><strong>Syntax:</strong></span> PrefixFilter (&#8216;&lt;row_prefix&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "PrefixFilter (&#8216;Row&#8217;)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">
                  ColumnPrefixFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes one argument
              &#8211; a column prefix. It returns only those key-values present in a column that starts
              with the specified column prefix. The column prefix must be of the form: <code class="code">&#8220;qualifier&#8221; </code></p><p><span class="bold"><strong>Syntax:</strong></span>ColumnPrefixFilter(&#8216;&lt;column_prefix&gt;&#8217;)</p><p><span class="bold"><strong>Example:</strong></span> "ColumnPrefixFilter(&#8216;Col&#8217;)"</p></li><li class="listitem"><p><span class="underline"><span class="bold"><strong>MultipleColumnPrefixFilter</strong></span></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a list of
              column prefixes. It returns key-values that are present in a column that starts with
              any of the specified column prefixes. Each of the column prefixes must be of the form: <code class="code">&#8220;qualifier&#8221;</code></p><p><span class="bold"><strong>Syntax:</strong></span>MultipleColumnPrefixFilter(&#8216;&lt;column_prefix&gt;&#8217;, &#8216;&lt;column_prefix&gt;&#8217;, &#8230;, &#8216;&lt;column_prefix&gt;&#8217;)</p><p><span class="bold"><strong>Example:</strong></span> "MultipleColumnPrefixFilter(&#8216;Col1&#8217;, &#8216;Col2&#8217;)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">ColumnCountGetFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes one argument
              &#8211; a limit. It returns the first limit number of columns in the table</p><p><span class="bold"><strong>Syntax:</strong></span> ColumnCountGetFilter (&#8216;&lt;limit&gt;&#8217;)</p><p><span class="bold"><strong>Example:</strong></span> "ColumnCountGetFilter (4)"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">PageFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes one argument
              &#8211; a page size. It returns page size number of rows from the table. </p><p><span class="bold"><strong>Syntax:</strong></span> PageFilter (&#8216;&lt;page_size&gt;&#8217;)</p><p><span class="bold"><strong>Example:</strong></span> "PageFilter (2)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">ColumnPaginationFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes two
              arguments &#8211; a limit and offset. It returns limit number of columns after offset number
              of columns. It does this for all the rows</p><p><span class="bold"><strong>Syntax:</strong></span> ColumnPaginationFilter(&#8216;&lt;limit&gt;&#8217;, &#8216;&lt;offest&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "ColumnPaginationFilter (3, 5)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">InclusiveStopFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes one argument
              &#8211; a row key on which to stop scanning. It returns all key-values present in rows up to
              and including the specified row</p><p><span class="bold"><strong>Syntax:</strong></span> InclusiveStopFilter(&#8216;&lt;stop_row_key&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "InclusiveStopFilter ('Row2')" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">TimeStampsFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a list of
              timestamps. It returns those key-values whose timestamps matches any of the specified
              timestamps</p><p> <span class="bold"><strong>Syntax:</strong></span> TimeStampsFilter (&lt;timestamp&gt;, &lt;timestamp&gt;, ... ,&lt;timestamp&gt;) </p><p> <span class="bold"><strong>Example:</strong></span> "TimeStampsFilter (5985489, 48895495, 58489845945)"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">RowFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a compare
              operator and a comparator. It compares each row key with the comparator using the
              compare operator and if the comparison returns true, it returns all the key-values in
              that row</p><p><span class="bold"><strong>Syntax:</strong></span> RowFilter (&lt;compareOp&gt;, &#8216;&lt;row_comparator&gt;&#8217;) </p><p><span class="bold"><strong>Example: </strong></span>"RowFilter (&lt;=, &#8216;xyz)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">Family Filter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a compare
              operator and a comparator. It compares each qualifier name with the comparator using
              the compare operator and if the comparison returns true, it returns all the key-values
              in that column</p><p><span class="bold"><strong>Syntax:</strong></span> QualifierFilter (&lt;compareOp&gt;, &#8216;&lt;qualifier_comparator&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "QualifierFilter (=, &#8216;Column1&#8217;)"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">QualifierFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a compare
              operator and a comparator. It compares each qualifier name with the comparator using
              the compare operator and if the comparison returns true, it returns all the key-values
              in that column</p><p><span class="bold"><strong>Syntax:</strong></span> QualifierFilter (&lt;compareOp&gt;,&#8216;&lt;qualifier_comparator&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "QualifierFilter (=,&#8216;Column1&#8217;)"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">ValueFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a compare operator and a
              comparator. It compares each value with the comparator using the compare operator and
              if the comparison returns true, it returns that key-value</p><p><span class="bold"><strong>Syntax:</strong></span> ValueFilter (&lt;compareOp&gt;,&#8216;&lt;value_comparator&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "ValueFilter (!=, &#8216;Value&#8217;)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">DependentColumnFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes two arguments &#8211; a family
              and a qualifier. It tries to locate this column in each row and returns all key-values
              in that row that have the same timestamp. If the row doesn&#8217;t contain the specified
              column &#8211; none of the key-values in that row will be returned.</p><p>The filter can also take an optional boolean argument &#8211; dropDependentColumn. If set to true, the column we were depending on doesn&#8217;t get returned.</p><p>The filter can also take two more additional optional arguments &#8211; a compare operator and a value comparator, which are further checks in addition to the family and qualifier. If the dependent column is found, its value should also pass the value check and then only is its timestamp taken into consideration</p><p><span class="bold"><strong>Syntax:</strong></span> DependentColumnFilter (&#8216;&lt;family&gt;&#8217;, &#8216;&lt;qualifier&gt;&#8217;, &lt;boolean&gt;, &lt;compare operator&gt;, &#8216;&lt;value comparator&#8217;)</p><p><span class="bold"><strong>Syntax:</strong></span> DependentColumnFilter (&#8216;&lt;family&gt;&#8217;, &#8216;&lt;qualifier&gt;&#8217;, &lt;boolean&gt;) </p><p><span class="bold"><strong>Syntax:</strong></span> DependentColumnFilter (&#8216;&lt;family&gt;&#8217;, &#8216;&lt;qualifier&gt;&#8217;) </p><p><span class="bold"><strong>Example:</strong></span> "DependentColumnFilter (&#8216;conf&#8217;, &#8216;blacklist&#8217;, false, &gt;=, &#8216;zebra&#8217;)" </p><p><span class="bold"><strong>Example:</strong></span> "DependentColumnFilter (&#8216;conf&#8217;, 'blacklist', true)"</p><p><span class="bold"><strong>Example:</strong></span> "DependentColumnFilter (&#8216;conf&#8217;, 'blacklist')"</p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">SingleColumnValueFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes a column family, a
              qualifier, a compare operator and a comparator. If the specified column is not found &#8211;
              all the columns of that row will be emitted. If the column is found and the comparison
              with the comparator returns true, all the columns of the row will be emitted. If the
              condition fails, the row will not be emitted. </p><p>This filter also takes two additional optional boolean arguments &#8211; filterIfColumnMissing and setLatestVersionOnly</p><p>If the filterIfColumnMissing flag is set to true the columns of the row will not be emitted if the specified column to check is not found in the row. The default value is false.</p><p>If the setLatestVersionOnly flag is set to false, it will test previous versions (timestamps) too. The default value is true.</p><p>These flags are optional and if you must set neither or both</p><p><span class="bold"><strong>Syntax:</strong></span> SingleColumnValueFilter(&lt;compare operator&gt;, &#8216;&lt;comparator&gt;&#8217;, &#8216;&lt;family&gt;&#8217;, &#8216;&lt;qualifier&gt;&#8217;,&lt;filterIfColumnMissing_boolean&gt;, &lt;latest_version_boolean&gt;) </p><p><span class="bold"><strong>Syntax:</strong></span> SingleColumnValueFilter(&lt;compare operator&gt;, &#8216;&lt;comparator&gt;&#8217;, &#8216;&lt;family&gt;&#8217;, &#8216;&lt;qualifier&gt;) </p><p><span class="bold"><strong>Example:</strong></span> "SingleColumnValueFilter (&lt;=, &#8216;abc&#8217;,&#8216;FamilyA&#8217;, &#8216;Column1&#8217;, true, false)" </p><p><span class="bold"><strong>Example:</strong></span> "SingleColumnValueFilter (&lt;=, &#8216;abc&#8217;,&#8216;FamilyA&#8217;, &#8216;Column1&#8217;)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">SingleColumnValueExcludeFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter takes the same arguments and
              behaves same as SingleColumnValueFilter &#8211; however, if the column is found and the
              condition passes, all the columns of the row will be emitted except for the tested
              column value. </p><p><span class="bold"><strong>Syntax:</strong></span> SingleColumnValueExcludeFilter(&lt;compare operator&gt;, '&lt;comparator&gt;', '&lt;family&gt;', '&lt;qualifier&gt;',&lt;latest_version_boolean&gt;, &lt;filterIfColumnMissing_boolean&gt;)</p><p><span class="bold"><strong>Syntax:</strong></span> SingleColumnValueExcludeFilter(&lt;compare operator&gt;, '&lt;comparator&gt;', '&lt;family&gt;', '&lt;qualifier&gt;') </p><p><span class="bold"><strong>Example:</strong></span> "SingleColumnValueExcludeFilter (&#8216;&lt;=&#8217;, &#8216;abc&#8217;,&#8216;FamilyA&#8217;, &#8216;Column1&#8217;, &#8216;false&#8217;, &#8216;true&#8217;)"</p><p><span class="bold"><strong>Example:</strong></span> "SingleColumnValueExcludeFilter (&#8216;&lt;=&#8217;, &#8216;abc&#8217;, &#8216;FamilyA&#8217;, &#8216;Column1&#8217;)" </p></li><li class="listitem"><p><span class="bold"><strong><span class="underline">ColumnRangeFilter</span></strong></span></p><p><span class="bold"><strong>Description:</strong></span> This filter is used for selecting only those
              keys with columns that are between minColumn and maxColumn. It also takes two boolean
              variables to indicate whether to include the minColumn and maxColumn or not.</p><p>If you don&#8217;t want to set the minColumn or the maxColumn &#8211; you can pass in an empty argument.</p><p><span class="bold"><strong>Syntax:</strong></span> ColumnRangeFilter (&#8216;&lt;minColumn&gt;&#8217;, &lt;minColumnInclusive_bool&gt;, &#8216;&lt;maxColumn&gt;&#8217;, &lt;maxColumnInclusive_bool&gt;)</p><p><span class="bold"><strong>Example:</strong></span> "ColumnRangeFilter (&#8216;abc&#8217;, true, &#8216;xyz&#8217;, false)"</p></li></ol></div></div></div></div></div><div class="chapter" title="Chapter&nbsp;10.&nbsp;Performance Tuning"><div class="titlepage"><div><div><h2 class="title"><a name="performance"></a>Chapter&nbsp;10.&nbsp;Performance Tuning</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#perf.os">10.1. Operating System</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.os.ram">10.1.1. Memory</a></span></dt><dt><span class="section"><a href="#perf.os.64">10.1.2. 64-bit</a></span></dt><dt><span class="section"><a href="#perf.os.swap">10.1.3. Swapping</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.network">10.2. Network</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.network.1switch">10.2.1. Single Switch</a></span></dt><dt><span class="section"><a href="#perf.network.2switch">10.2.2. Multiple Switches</a></span></dt><dt><span class="section"><a href="#perf.network.multirack">10.2.3. Multiple Racks</a></span></dt></dl></dd><dt><span class="section"><a href="#jvm">10.3. Java</a></span></dt><dd><dl><dt><span class="section"><a href="#gc">10.3.1. The Garbage Collector and HBase</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.configurations">10.4. HBase Configurations</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.number.of.regions">10.4.1. Number of Regions</a></span></dt><dt><span class="section"><a href="#perf.compactions.and.splits">10.4.2. Managing Compactions</a></span></dt><dt><span class="section"><a href="#perf.handlers">10.4.3. <code class="varname">hbase.regionserver.handler.count</code></a></span></dt><dt><span class="section"><a href="#perf.hfile.block.cache.size">10.4.4. <code class="varname">hfile.block.cache.size</code></a></span></dt><dt><span class="section"><a href="#perf.rs.memstore.upperlimit">10.4.5. <code class="varname">hbase.regionserver.global.memstore.upperLimit</code></a></span></dt><dt><span class="section"><a href="#perf.rs.memstore.lowerlimit">10.4.6. <code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></a></span></dt><dt><span class="section"><a href="#perf.hstore.blockingstorefiles">10.4.7. <code class="varname">hbase.hstore.blockingStoreFiles</code></a></span></dt><dt><span class="section"><a href="#perf.hregion.memstore.block.multiplier">10.4.8. <code class="varname">hbase.hregion.memstore.block.multiplier</code></a></span></dt></dl></dd><dt><span class="section"><a href="#perf.schema">10.5. Schema Design</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.number.of.cfs">10.5.1. Number of Column Families</a></span></dt><dt><span class="section"><a href="#perf.schema.keys">10.5.2. Key and Attribute Lengths</a></span></dt><dt><span class="section"><a href="#schema.regionsize">10.5.3. Table RegionSize</a></span></dt><dt><span class="section"><a href="#schema.bloom">10.5.4. Bloom Filters</a></span></dt><dt><span class="section"><a href="#schema.cf.blocksize">10.5.5. ColumnFamily BlockSize</a></span></dt><dt><span class="section"><a href="#cf.in.memory">10.5.6. In-Memory ColumnFamilies</a></span></dt><dt><span class="section"><a href="#perf.compression">10.5.7. Compression</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.writing">10.6. Writing to HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.batch.loading">10.6.1. Batch Loading</a></span></dt><dt><span class="section"><a href="#precreate.regions">10.6.2. 
    Table Creation: Pre-Creating Regions
    </a></span></dt><dt><span class="section"><a href="#def.log.flush">10.6.3. 
    Table Creation: Deferred Log Flush
    </a></span></dt><dt><span class="section"><a href="#perf.hbase.client.autoflush">10.6.4. HBase Client:  AutoFlush</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.putwal">10.6.5. HBase Client:  Turn off WAL on Puts</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.regiongroup">10.6.6. HBase Client: Group Puts by RegionServer</a></span></dt><dt><span class="section"><a href="#perf.hbase.write.mr.reducer">10.6.7. MapReduce:  Skip The Reducer</a></span></dt><dt><span class="section"><a href="#perf.one.region">10.6.8. Anti-Pattern:  One Hot Region</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.reading">10.7. Reading from HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.hbase.client.caching">10.7.1. Scan Caching</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.selection">10.7.2. Scan Attribute Selection</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.scannerclose">10.7.3. Close ResultScanners</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.blockcache">10.7.4. Block Cache</a></span></dt><dt><span class="section"><a href="#perf.hbase.client.rowkeyonly">10.7.5. Optimal Loading of Row Keys</a></span></dt><dt><span class="section"><a href="#perf.hbase.read.dist">10.7.6. Concurrency:  Monitor Data Spread</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.deleting">10.8. Deleting from HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.deleting.queue">10.8.1. Using HBase Tables as Queues</a></span></dt><dt><span class="section"><a href="#perf.deleting.rpc">10.8.2. Delete RPC Behavior</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.hdfs">10.9. HDFS</a></span></dt><dd><dl><dt><span class="section"><a href="#perf.hdfs.curr">10.9.1. Current Issues With Low-Latency Reads</a></span></dt><dt><span class="section"><a href="#perf.hdfs.comp">10.9.2. Performance Comparisons of HBase vs. HDFS</a></span></dt></dl></dd><dt><span class="section"><a href="#perf.ec2">10.10. Amazon EC2</a></span></dt></dl></div><div class="section" title="10.1.&nbsp;Operating System"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.os"></a>10.1.&nbsp;Operating System</h2></div></div></div><div class="section" title="10.1.1.&nbsp;Memory"><div class="titlepage"><div><div><h3 class="title"><a name="perf.os.ram"></a>10.1.1.&nbsp;Memory</h3></div></div></div><p>RAM, RAM, RAM.  Don't starve HBase.</p></div><div class="section" title="10.1.2.&nbsp;64-bit"><div class="titlepage"><div><div><h3 class="title"><a name="perf.os.64"></a>10.1.2.&nbsp;64-bit</h3></div></div></div><p>Use a 64-bit platform (and 64-bit JVM).</p></div><div class="section" title="10.1.3.&nbsp;Swapping"><div class="titlepage"><div><div><h3 class="title"><a name="perf.os.swap"></a>10.1.3.&nbsp;Swapping</h3></div></div></div><p>Watch out for swapping.  Set swappiness to 0.</p></div></div><div class="section" title="10.2.&nbsp;Network"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.network"></a>10.2.&nbsp;Network</h2></div></div></div><p>
    Perhaps the most important factor in avoiding network issues degrading Hadoop and HBbase performance is the switching hardware
    that is used, decisions made early in the scope of the project can cause major problems when you double or triple the size of your cluster (or more). 
    </p><p>
    Important items to consider:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Switching capacity of the device</li><li class="listitem">Number of systems connected</li><li class="listitem">Uplink capacity</li></ul></div><p>
    </p><div class="section" title="10.2.1.&nbsp;Single Switch"><div class="titlepage"><div><div><h3 class="title"><a name="perf.network.1switch"></a>10.2.1.&nbsp;Single Switch</h3></div></div></div><p>The single most important factor in this configuration is that the switching capacity of the hardware is capable of 
      handling the traffic which can be generated by all systems connected to the switch. Some lower priced commodity hardware
      can have a slower switching capacity than could be utilized by a full switch. 
      </p></div><div class="section" title="10.2.2.&nbsp;Multiple Switches"><div class="titlepage"><div><div><h3 class="title"><a name="perf.network.2switch"></a>10.2.2.&nbsp;Multiple Switches</h3></div></div></div><p>Multiple switches are a potential pitfall in the architecture.   The most common configuration of lower priced hardware is a
      simple 1Gbps uplink from one switch to another. This often overlooked pinch point can easily become a bottleneck for cluster communication. 
      Especially with MapReduce jobs that are both reading and writing a lot of data the communication across this uplink could be saturated.
      </p><p>Mitigation of this issue is fairly simple and can be accomplished in multiple ways:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Use appropriate hardware for the scale of the cluster which you're attempting to build.</li><li class="listitem">Use larger single switch configurations i.e. single 48 port as opposed to 2x 24 port</li><li class="listitem">Configure port trunking for uplinks to utilize multiple interfaces to increase cross switch bandwidth.</li></ul></div><p>
      </p></div><div class="section" title="10.2.3.&nbsp;Multiple Racks"><div class="titlepage"><div><div><h3 class="title"><a name="perf.network.multirack"></a>10.2.3.&nbsp;Multiple Racks</h3></div></div></div><p>Multiple rack configurations carry the same potential issues as multiple switches, and can suffer performance degradation from two main areas:
         </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Poor switch capacity performance</li><li class="listitem">Insufficient uplink to another rack</li></ul></div><p>
      If the the switches in your rack have appropriate switching capacity to handle all the hosts at full speed, the next most likely issue will be caused by homing 
      more of your cluster across racks.  The easiest way to avoid issues when spanning multiple racks is to use port trunking to create a bonded uplink to other racks.
      The downside of this method however, is in the overhead of ports that could potentially be used. An example of this is, creating an 8Gbps port channel from rack
      A to rack B, using 8 of your 24 ports to communicate between racks gives you a poor ROI, using too few however can mean you're not getting the most out of your cluster. 
      </p><p>Using 10Gbe links between racks will greatly increase performance, and assuming your switches support a 10Gbe uplink or allow for an expansion card will allow you to
      save your ports for machines as opposed to uplinks.
      </p></div></div><div class="section" title="10.3.&nbsp;Java"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="jvm"></a>10.3.&nbsp;Java</h2></div></div></div><div class="section" title="10.3.1.&nbsp;The Garbage Collector and HBase"><div class="titlepage"><div><div><h3 class="title"><a name="gc"></a>10.3.1.&nbsp;The Garbage Collector and HBase</h3></div></div></div><div class="section" title="10.3.1.1.&nbsp;Long GC pauses"><div class="titlepage"><div><div><h4 class="title"><a name="gcpause"></a>10.3.1.1.&nbsp;Long GC pauses</h4></div></div></div><p>In his presentation, <a class="link" href="http://www.slideshare.net/cloudera/hbase-hug-presentation" target="_top">Avoiding
        Full GCs with MemStore-Local Allocation Buffers</a>, Todd Lipcon
        describes two cases of stop-the-world garbage collections common in
        HBase, especially during loading; CMS failure modes and old generation
        heap fragmentation brought. To address the first, start the CMS
        earlier than default by adding
        <code class="code">-XX:CMSInitiatingOccupancyFraction</code> and setting it down
        from defaults. Start at 60 or 70 percent (The lower you bring down the
        threshold, the more GCing is done, the more CPU used). To address the
        second fragmentation issue, Todd added an experimental facility that
        must be explicitly enabled in HBase 0.90.x (Its defaulted to be on in
        0.92.x HBase). See <code class="code">hbase.hregion.memstore.mslab.enabled</code>
        to true in your <code class="classname">Configuration</code>. See the cited
        slides for background and detail<sup>[<a name="d0e5213" href="#ftn.d0e5213" class="footnote">24</a>]</sup>.</p><p>For more information about GC logs, see <a class="xref" href="#trouble.log.gc" title="11.2.3.&nbsp;JVM Garbage Collection Logs">Section&nbsp;11.2.3, &#8220;JVM Garbage Collection Logs&#8221;</a>.
        </p></div></div></div><div class="section" title="10.4.&nbsp;HBase Configurations"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.configurations"></a>10.4.&nbsp;HBase Configurations</h2></div></div></div><p>See <a class="xref" href="#recommended_configurations" title="2.8.2.&nbsp;Recommended Configuations">Section&nbsp;2.8.2, &#8220;Recommended Configuations&#8221;</a>.</p><div class="section" title="10.4.1.&nbsp;Number of Regions"><div class="titlepage"><div><div><h3 class="title"><a name="perf.number.of.regions"></a>10.4.1.&nbsp;Number of Regions</h3></div></div></div><p>The number of regions for an HBase table is driven by the <a class="xref" href="#bigger.regions" title="2.8.2.6.&nbsp;Bigger Regions">Section&nbsp;2.8.2.6, &#8220;Bigger Regions&#8221;</a>. Also, see the architecture
          section on <a class="xref" href="#arch.regions.size" title="8.6.1.&nbsp;Region Size">Section&nbsp;8.6.1, &#8220;Region Size&#8221;</a></p><p>A lower number of regions is preferred, generally in the range of 20 to low-hundreds
       per RegionServer.  Adjust the regionsize as appropriate to achieve this number. 
       </p><p>For the 0.90.x codebase, the upper-bound of regionsize is about 4Gb.
       For 0.92.x codebase, due to the HFile v2 change much larger regionsizes can be supported (e.g., 20Gb).
       </p><p>You may need to experiment with this setting based on your hardware configuration and application needs.
       </p></div><div class="section" title="10.4.2.&nbsp;Managing Compactions"><div class="titlepage"><div><div><h3 class="title"><a name="perf.compactions.and.splits"></a>10.4.2.&nbsp;Managing Compactions</h3></div></div></div><p>For larger systems, managing <a class="link" href="#disable.splitting" title="2.8.2.7.&nbsp;Managed Splitting">compactions and splits</a> may be
      something you want to consider.</p></div><div class="section" title="10.4.3.&nbsp;hbase.regionserver.handler.count"><div class="titlepage"><div><div><h3 class="title"><a name="perf.handlers"></a>10.4.3.&nbsp;<code class="varname">hbase.regionserver.handler.count</code></h3></div></div></div><p>See <a class="xref" href="#hbase.regionserver.handler.count" title="hbase.regionserver.handler.count"><code class="varname">hbase.regionserver.handler.count</code></a>. 
            This setting in essence sets how many requests are
            concurrently being processed inside the RegionServer at any
            one time.  If set too high, then throughput may suffer as
            the concurrent requests contend; if set too low, requests will
            be stuck waiting to get into the machine.  You can get a
            sense of whether you have too little or too many handlers by
            <a class="xref" href="#rpc.logging" title="11.2.2.1.&nbsp;Enabling RPC-level logging">Section&nbsp;11.2.2.1, &#8220;Enabling RPC-level logging&#8221;</a>
            on an individual RegionServer then tailing its logs (Queued requests
            consume memory).</p></div><div class="section" title="10.4.4.&nbsp;hfile.block.cache.size"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hfile.block.cache.size"></a>10.4.4.&nbsp;<code class="varname">hfile.block.cache.size</code></h3></div></div></div><p>See <a class="xref" href="#hfile.block.cache.size" title="hfile.block.cache.size"><code class="varname">hfile.block.cache.size</code></a>. 
        A memory setting for the RegionServer process.
        </p></div><div class="section" title="10.4.5.&nbsp;hbase.regionserver.global.memstore.upperLimit"><div class="titlepage"><div><div><h3 class="title"><a name="perf.rs.memstore.upperlimit"></a>10.4.5.&nbsp;<code class="varname">hbase.regionserver.global.memstore.upperLimit</code></h3></div></div></div><p>See <a class="xref" href="#hbase.regionserver.global.memstore.upperLimit" title="hbase.regionserver.global.memstore.upperLimit"><code class="varname">hbase.regionserver.global.memstore.upperLimit</code></a>.  
        This memory setting is often adjusted for the RegionServer process depending on needs.
        </p></div><div class="section" title="10.4.6.&nbsp;hbase.regionserver.global.memstore.lowerLimit"><div class="titlepage"><div><div><h3 class="title"><a name="perf.rs.memstore.lowerlimit"></a>10.4.6.&nbsp;<code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></h3></div></div></div><p>See <a class="xref" href="#hbase.regionserver.global.memstore.lowerLimit" title="hbase.regionserver.global.memstore.lowerLimit"><code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></a>.  
        This memory setting is often adjusted for the RegionServer process depending on needs.
        </p></div><div class="section" title="10.4.7.&nbsp;hbase.hstore.blockingStoreFiles"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hstore.blockingstorefiles"></a>10.4.7.&nbsp;<code class="varname">hbase.hstore.blockingStoreFiles</code></h3></div></div></div><p>See <a class="xref" href="#hbase.hstore.blockingStoreFiles" title="hbase.hstore.blockingStoreFiles"><code class="varname">hbase.hstore.blockingStoreFiles</code></a>.  
        If there is blocking in the RegionServer logs, increasing this can help.
        </p></div><div class="section" title="10.4.8.&nbsp;hbase.hregion.memstore.block.multiplier"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hregion.memstore.block.multiplier"></a>10.4.8.&nbsp;<code class="varname">hbase.hregion.memstore.block.multiplier</code></h3></div></div></div><p>See <a class="xref" href="#hbase.hregion.memstore.block.multiplier" title="hbase.hregion.memstore.block.multiplier"><code class="varname">hbase.hregion.memstore.block.multiplier</code></a>.  
        If there is enough RAM, increasing this can help.  
        </p></div></div><div class="section" title="10.5.&nbsp;Schema Design"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.schema"></a>10.5.&nbsp;Schema Design</h2></div></div></div><div class="section" title="10.5.1.&nbsp;Number of Column Families"><div class="titlepage"><div><div><h3 class="title"><a name="perf.number.of.cfs"></a>10.5.1.&nbsp;Number of Column Families</h3></div></div></div><p>See <a class="xref" href="#number.of.cfs" title="6.2.&nbsp; On the number of column families">Section&nbsp;6.2, &#8220;
      On the number of column families
  &#8221;</a>.</p></div><div class="section" title="10.5.2.&nbsp;Key and Attribute Lengths"><div class="titlepage"><div><div><h3 class="title"><a name="perf.schema.keys"></a>10.5.2.&nbsp;Key and Attribute Lengths</h3></div></div></div><p>See <a class="xref" href="#keysize" title="6.3.2.&nbsp;Try to minimize row and column sizes">Section&nbsp;6.3.2, &#8220;Try to minimize row and column sizes&#8221;</a>.</p></div><div class="section" title="10.5.3.&nbsp;Table RegionSize"><div class="titlepage"><div><div><h3 class="title"><a name="schema.regionsize"></a>10.5.3.&nbsp;Table RegionSize</h3></div></div></div><p>The regionsize can be set on a per-table basis via <code class="code">setFileSize</code> on
    <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html" target="_top">HTableDescriptor</a> in the 
    event where certain tables require different regionsizes than the configured default regionsize.
    </p><p>See <a class="xref" href="#perf.number.of.regions" title="10.4.1.&nbsp;Number of Regions">Section&nbsp;10.4.1, &#8220;Number of Regions&#8221;</a> for more information.
    </p></div><div class="section" title="10.5.4.&nbsp;Bloom Filters"><div class="titlepage"><div><div><h3 class="title"><a name="schema.bloom"></a>10.5.4.&nbsp;Bloom Filters</h3></div></div></div><p>Bloom Filters can be enabled per-ColumnFamily.
        Use <code class="code">HColumnDescriptor.setBloomFilterType(NONE | ROW |
        ROWCOL)</code> to enable blooms per Column Family. Default =
        <code class="varname">NONE</code> for no bloom filters. If
        <code class="varname">ROW</code>, the hash of the row will be added to the bloom
        on each insert. If <code class="varname">ROWCOL</code>, the hash of the row +
        column family + column family qualifier will be added to the bloom on
        each key insert.</p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a> and 
    <a class="xref" href="#blooms" title="8.6.5.&nbsp;Bloom Filters">Section&nbsp;8.6.5, &#8220;Bloom Filters&#8221;</a> for more information.
    </p></div><div class="section" title="10.5.5.&nbsp;ColumnFamily BlockSize"><div class="titlepage"><div><div><h3 class="title"><a name="schema.cf.blocksize"></a>10.5.5.&nbsp;ColumnFamily BlockSize</h3></div></div></div><p>The blocksize can be configured for each ColumnFamily in a table, and this defaults to 64k.  Larger cell values require larger blocksizes. 
    There is an inverse relationship between blocksize and the resulting StoreFile indexes (i.e., if the blocksize is doubled then the resulting
    indexes should be roughly halved).
    </p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a> 
    and <a class="xref" href="#store" title="8.6.4.&nbsp;Store">Section&nbsp;8.6.4, &#8220;Store&#8221;</a>for more information.
    </p></div><div class="section" title="10.5.6.&nbsp;In-Memory ColumnFamilies"><div class="titlepage"><div><div><h3 class="title"><a name="cf.in.memory"></a>10.5.6.&nbsp;In-Memory ColumnFamilies</h3></div></div></div><p>ColumnFamilies can optionally be defined as in-memory.  Data is still persisted to disk, just like any other ColumnFamily.  
    In-memory blocks have the highest priority in the <a class="xref" href="#block.cache" title="8.5.3.&nbsp;Block Cache">Section&nbsp;8.5.3, &#8220;Block Cache&#8221;</a>, but it is not a guarantee that the entire table
    will be in memory.
    </p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html" target="_top">HColumnDescriptor</a> for more information.
    </p></div><div class="section" title="10.5.7.&nbsp;Compression"><div class="titlepage"><div><div><h3 class="title"><a name="perf.compression"></a>10.5.7.&nbsp;Compression</h3></div></div></div><p>Production systems should use compression with their ColumnFamily definitions.  See <a class="xref" href="#compression" title="Appendix&nbsp;A.&nbsp;Compression In HBase">Appendix&nbsp;A, <i>Compression In HBase</i></a> for more information.
      </p></div></div><div class="section" title="10.6.&nbsp;Writing to HBase"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.writing"></a>10.6.&nbsp;Writing to HBase</h2></div></div></div><div class="section" title="10.6.1.&nbsp;Batch Loading"><div class="titlepage"><div><div><h3 class="title"><a name="perf.batch.loading"></a>10.6.1.&nbsp;Batch Loading</h3></div></div></div><p>Use the bulk load tool if you can.  See
        <a class="link" href="http://hbase.apache.org/bulk-loads.html" target="_top">Bulk Loads</a>.
        Otherwise, pay attention to the below.
      </p></div><div class="section" title="10.6.2.&nbsp; Table Creation: Pre-Creating Regions"><div class="titlepage"><div><div><h3 class="title"><a name="precreate.regions"></a>10.6.2.&nbsp;
    Table Creation: Pre-Creating Regions
    </h3></div></div></div><p>
Tables in HBase are initially created with one region by default.  For bulk imports, this means that all clients will write to the same region until it is large enough to split and become distributed across the cluster.  A useful pattern to speed up the bulk import process is to pre-create empty regions.  Be somewhat conservative in this, because too-many regions can actually degrade performance.  An example of pre-creation using hex-keys is as follows (note:  this example may need to be tweaked to the individual applications keys):
</p><p>
</p><pre class="programlisting">public static boolean createTable(HBaseAdmin admin, HTableDescriptor table, byte[][] splits)
throws IOException {
  try {
    admin.createTable( table, splits );
    return true;
  } catch (TableExistsException e) {
    logger.info("table " + table.getNameAsString() + " already exists");
    // the table already exists...
    return false;  
  }
}

public static byte[][] getHexSplits(String startKey, String endKey, int numRegions) {
  byte[][] splits = new byte[numRegions-1][];
  BigInteger lowestKey = new BigInteger(startKey, 16);
  BigInteger highestKey = new BigInteger(endKey, 16);
  BigInteger range = highestKey.subtract(lowestKey);
  BigInteger regionIncrement = range.divide(BigInteger.valueOf(numRegions));
  lowestKey = lowestKey.add(regionIncrement);
  for(int i=0; i &lt; numRegions-1;i++) {
    BigInteger key = lowestKey.add(regionIncrement.multiply(BigInteger.valueOf(i)));
    byte[] b = String.format("%016x", key).getBytes();
    splits[i] = b;
  }
  return splits;
}</pre><p>
  </p></div><div class="section" title="10.6.3.&nbsp; Table Creation: Deferred Log Flush"><div class="titlepage"><div><div><h3 class="title"><a name="def.log.flush"></a>10.6.3.&nbsp;
    Table Creation: Deferred Log Flush
    </h3></div></div></div><p>
The default behavior for Puts using the Write Ahead Log (WAL) is that <code class="classname">HLog</code> edits will be written immediately.  If deferred log flush is used, 
WAL edits are kept in memory until the flush period.  The benefit is aggregated and asynchronous <code class="classname">HLog</code>- writes, but the potential downside is that if
 the RegionServer goes down the yet-to-be-flushed edits are lost.  This is safer, however, than not using WAL at all with Puts.
</p><p>
Deferred log flush can be configured on tables via <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html" target="_top">HTableDescriptor</a>.  The default value of <code class="varname">hbase.regionserver.optionallogflushinterval</code> is 1000ms.
</p></div><div class="section" title="10.6.4.&nbsp;HBase Client: AutoFlush"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.autoflush"></a>10.6.4.&nbsp;HBase Client:  AutoFlush</h3></div></div></div><p>When performing a lot of Puts, make sure that setAutoFlush is set
      to false on your <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>
      instance. Otherwise, the Puts will be sent one at a time to the
      RegionServer. Puts added via <code class="code"> htable.add(Put)</code> and <code class="code"> htable.add( &lt;List&gt; Put)</code>
      wind up in the same write buffer. If <code class="code">autoFlush = false</code>,
      these messages are not sent until the write-buffer is filled. To
      explicitly flush the messages, call <code class="methodname">flushCommits</code>.
      Calling <code class="methodname">close</code> on the <code class="classname">HTable</code>
      instance will invoke <code class="methodname">flushCommits</code>.</p></div><div class="section" title="10.6.5.&nbsp;HBase Client: Turn off WAL on Puts"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.putwal"></a>10.6.5.&nbsp;HBase Client:  Turn off WAL on Puts</h3></div></div></div><p>A frequently discussed option for increasing throughput on <code class="classname">Put</code>s is to call <code class="code">writeToWAL(false)</code>.  Turning this off means
          that the RegionServer will <span class="emphasis"><em>not</em></span> write the <code class="classname">Put</code> to the Write Ahead Log,
          only into the memstore, HOWEVER the consequence is that if there
          is a RegionServer failure <span class="emphasis"><em>there will be data loss</em></span>.
          If <code class="code">writeToWAL(false)</code> is used, do so with extreme caution.  You may find in actuality that
          it makes little difference if your load is well distributed across the cluster.
      </p><p>In general, it is best to use WAL for Puts, and where loading throughput
          is a concern to use <a class="link" href="#perf.batch.loading" title="10.6.1.&nbsp;Batch Loading">bulk loading</a> techniques instead.  
      </p></div><div class="section" title="10.6.6.&nbsp;HBase Client: Group Puts by RegionServer"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.regiongroup"></a>10.6.6.&nbsp;HBase Client: Group Puts by RegionServer</h3></div></div></div><p>In addition to using the writeBuffer, grouping <code class="classname">Put</code>s by RegionServer can reduce the number of client RPC calls per writeBuffer flush. 
      There is a utility <code class="classname">HTableUtil</code> currently on TRUNK that does this, but you can either copy that or implement your own verison for
      those still on 0.90.x or earlier.
      </p></div><div class="section" title="10.6.7.&nbsp;MapReduce: Skip The Reducer"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.write.mr.reducer"></a>10.6.7.&nbsp;MapReduce:  Skip The Reducer</h3></div></div></div><p>When writing a lot of data to an HBase table from a MR job (e.g., with <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html" target="_top">TableOutputFormat</a>), and specifically where Puts are being emitted
      from the Mapper, skip the Reducer step.  When a Reducer step is used, all of the output (Puts) from the Mapper will get spooled to disk, then sorted/shuffled to other 
      Reducers that will most likely be off-node.  It's far more efficient to just write directly to HBase.   
      </p><p>For summary jobs where HBase is used as a source and a sink, then writes will be coming from the Reducer step (e.g., summarize values then write out result). 
      This is a different processing problem than from the the above case. 
      </p></div><div class="section" title="10.6.8.&nbsp;Anti-Pattern: One Hot Region"><div class="titlepage"><div><div><h3 class="title"><a name="perf.one.region"></a>10.6.8.&nbsp;Anti-Pattern:  One Hot Region</h3></div></div></div><p>If all your data is being written to one region at a time, then re-read the
    section on processing <a class="link" href="#timeseries" title="6.3.1.&nbsp; Monotonically Increasing Row Keys/Timeseries Data">timeseries</a> data.</p><p>Also, see <a class="xref" href="#precreate.regions" title="10.6.2.&nbsp; Table Creation: Pre-Creating Regions">Section&nbsp;10.6.2, &#8220;
    Table Creation: Pre-Creating Regions
    &#8221;</a>, as well as <a class="xref" href="#perf.configurations" title="10.4.&nbsp;HBase Configurations">Section&nbsp;10.4, &#8220;HBase Configurations&#8221;</a> </p></div></div><div class="section" title="10.7.&nbsp;Reading from HBase"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.reading"></a>10.7.&nbsp;Reading from HBase</h2></div></div></div><div class="section" title="10.7.1.&nbsp;Scan Caching"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.caching"></a>10.7.1.&nbsp;Scan Caching</h3></div></div></div><p>If HBase is used as an input source for a MapReduce job, for
      example, make sure that the input <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scan</a>
      instance to the MapReduce job has <code class="methodname">setCaching</code> set to something greater
      than the default (which is 1). Using the default value means that the
      map-task will make call back to the region-server for every record
      processed. Setting this value to 500, for example, will transfer 500
      rows at a time to the client to be processed. There is a cost/benefit to
      have the cache value be large because it costs more in memory for both
      client and RegionServer, so bigger isn't always better.</p><div class="section" title="10.7.1.1.&nbsp;Scan Caching in MapReduce Jobs"><div class="titlepage"><div><div><h4 class="title"><a name="perf.hbase.client.caching.mr"></a>10.7.1.1.&nbsp;Scan Caching in MapReduce Jobs</h4></div></div></div><p>Scan settings in MapReduce jobs deserve special attention.  Timeouts can result (e.g., UnknownScannerException)
        in Map tasks if it takes longer to process a batch of records before the client goes back to the RegionServer for the
        next set of data.  This problem can occur because there is non-trivial processing occuring per row.  If you process
        rows quickly, set caching higher.  If you process rows more slowly (e.g., lots of transformations per row, writes), 
        then set caching lower.
        </p><p>Timeouts can also happen in a non-MapReduce use case (i.e., single threaded HBase client doing a Scan), but the
        processing that is often performed in MapReduce jobs tends to exacerbate this issue.
        </p></div></div><div class="section" title="10.7.2.&nbsp;Scan Attribute Selection"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.selection"></a>10.7.2.&nbsp;Scan Attribute Selection</h3></div></div></div><p>Whenever a Scan is used to process large numbers of rows (and especially when used
      as a MapReduce source), be aware of which attributes are selected.   If <code class="code">scan.addFamily</code> is called
      then <span class="emphasis"><em>all</em></span> of the attributes in the specified ColumnFamily will be returned to the client.
      If only a small number of the available attributes are to be processed, then only those attributes should be specified
      in the input scan because attribute over-selection is a non-trivial performance penalty over large datasets.
      </p></div><div class="section" title="10.7.3.&nbsp;Close ResultScanners"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.scannerclose"></a>10.7.3.&nbsp;Close ResultScanners</h3></div></div></div><p>This isn't so much about improving performance but rather
      <span class="emphasis"><em>avoiding</em></span> performance problems. If you forget to
      close <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/ResultScanner.html" target="_top">ResultScanners</a>
      you can cause problems on the RegionServers. Always have ResultScanner
      processing enclosed in try/catch blocks... </p><pre class="programlisting">
Scan scan = new Scan();
// set attrs...
ResultScanner rs = htable.getScanner(scan);
try {
  for (Result r = rs.next(); r != null; r = rs.next()) {
  // process result...
} finally {
  rs.close();  // always close the ResultScanner!
}
htable.close();</pre></div><div class="section" title="10.7.4.&nbsp;Block Cache"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.blockcache"></a>10.7.4.&nbsp;Block Cache</h3></div></div></div><p><a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" target="_top">Scan</a>
      instances can be set to use the block cache in the RegionServer via the
      <code class="methodname">setCacheBlocks</code> method. For input Scans to MapReduce jobs, this should be
      <code class="varname">false</code>. For frequently accessed rows, it is advisable to use the block
      cache.</p></div><div class="section" title="10.7.5.&nbsp;Optimal Loading of Row Keys"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.client.rowkeyonly"></a>10.7.5.&nbsp;Optimal Loading of Row Keys</h3></div></div></div><p>When performing a table <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html" target="_top">scan</a>
            where only the row keys are needed (no families, qualifiers, values or timestamps), add a FilterList with a
            <code class="varname">MUST_PASS_ALL</code> operator to the scanner using <code class="methodname">setFilter</code>. The filter list
            should include both a <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html" target="_top">FirstKeyOnlyFilter</a>
            and a <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/KeyOnlyFilter.html" target="_top">KeyOnlyFilter</a>.
            Using this filter combination will result in a worst case scenario of a RegionServer reading a single value from disk
            and minimal network traffic to the client for a single row.
      </p></div><div class="section" title="10.7.6.&nbsp;Concurrency: Monitor Data Spread"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hbase.read.dist"></a>10.7.6.&nbsp;Concurrency:  Monitor Data Spread</h3></div></div></div><p>When performing a high number of concurrent reads, monitor the data spread of the target tables.  If the target table(s) have 
      too few regions then the reads could likely be served from too few nodes.  </p><p>See <a class="xref" href="#precreate.regions" title="10.6.2.&nbsp; Table Creation: Pre-Creating Regions">Section&nbsp;10.6.2, &#8220;
    Table Creation: Pre-Creating Regions
    &#8221;</a>, as well as <a class="xref" href="#perf.configurations" title="10.4.&nbsp;HBase Configurations">Section&nbsp;10.4, &#8220;HBase Configurations&#8221;</a> </p></div></div><div class="section" title="10.8.&nbsp;Deleting from HBase"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.deleting"></a>10.8.&nbsp;Deleting from HBase</h2></div></div></div><div class="section" title="10.8.1.&nbsp;Using HBase Tables as Queues"><div class="titlepage"><div><div><h3 class="title"><a name="perf.deleting.queue"></a>10.8.1.&nbsp;Using HBase Tables as Queues</h3></div></div></div><p>HBase tables are sometimes used as queues.  In this case, special care must be taken to regularly perform major compactions on tables used in
       this manner.  As is documented in <a class="xref" href="#datamodel" title="Chapter&nbsp;5.&nbsp;Data Model">Chapter&nbsp;5, <i>Data Model</i></a>, marking rows as deleted creates additional StoreFiles which then need to be processed
       on reads.  Tombstones only get cleaned up with major compactions.
       </p><p>See also <a class="xref" href="#compaction" title="8.6.4.5.&nbsp;Compaction">Section&nbsp;8.6.4.5, &#8220;Compaction&#8221;</a> and <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HBaseAdmin.html#majorCompact%28java.lang.String%29" target="_top">HBaseAdmin.majorCompact</a>.
       </p></div><div class="section" title="10.8.2.&nbsp;Delete RPC Behavior"><div class="titlepage"><div><div><h3 class="title"><a name="perf.deleting.rpc"></a>10.8.2.&nbsp;Delete RPC Behavior</h3></div></div></div><p>Be aware that <code class="code">htable.delete(Delete)</code> doesn't use the writeBuffer.  It will execute an RegionServer RPC with each invocation.
       For a large number of deletes, consider <code class="code">htable.delete(List)</code>.
       </p><p>See <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html#delete%28org.apache.hadoop.hbase.client.Delete%29" target="_top">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html#delete%28org.apache.hadoop.hbase.client.Delete%29</a>
       </p></div></div><div class="section" title="10.9.&nbsp;HDFS"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.hdfs"></a>10.9.&nbsp;HDFS</h2></div></div></div><p>Because HBase runs on <a class="xref" href="#arch.hdfs" title="8.7.&nbsp;HDFS">Section&nbsp;8.7, &#8220;HDFS&#8221;</a> it is important to understand how it works and how it affects
   HBase.
   </p><div class="section" title="10.9.1.&nbsp;Current Issues With Low-Latency Reads"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hdfs.curr"></a>10.9.1.&nbsp;Current Issues With Low-Latency Reads</h3></div></div></div><p>The original use-case for HDFS was batch processing.  As such, there low-latency reads were historically not a priority.
      With the increased adoption of HBase this is changing, and several improvements are already in development.
      See the 
      <a class="link" href="https://issues.apache.org/jira/browse/HDFS-1599" target="_top">Umbrella Jira Ticket for HDFS Improvements for HBase</a>.
      </p></div><div class="section" title="10.9.2.&nbsp;Performance Comparisons of HBase vs. HDFS"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hdfs.comp"></a>10.9.2.&nbsp;Performance Comparisons of HBase vs. HDFS</h3></div></div></div><p>A fairly common question on the dist-list is why HBase isn't as performant as HDFS files in a batch context (e.g., as 
     a MapReduce source or sink).  The short answer is that HBase is doing a lot more than HDFS (e.g., reading the KeyValues, 
     returning the most current row or specified timestamps, etc.), and as such HBase is 4-5 times slower than HDFS in this 
     processing context.  Not that there isn't room for improvement (and this gap will, over time, be reduced), but HDFS
      will always be faster in this use-case.
     </p></div></div><div class="section" title="10.10.&nbsp;Amazon EC2"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.ec2"></a>10.10.&nbsp;Amazon EC2</h2></div></div></div><p>Performance questions are common on Amazon EC2 environments because it is a shared environment.  You will
   not see the same throughput as a dedicated server.  In terms of running tests on EC2, run them several times for the same
   reason (i.e., it's a shared environment and you don't know what else is happening on the server).
   </p><p>If you are running on EC2 and post performance questions on the dist-list, please state this fact up-front that
    because EC2 issues are practically a separate class of performance issues.
   </p></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e5213" href="#d0e5213" class="para">24</a>] </sup>The latest jvms do better
        regards fragmentation so make sure you are running a recent release.
        Read down in the message,
        <a class="link" href="http://osdir.com/ml/hotspot-gc-use/2011-11/msg00002.html" target="_top">Identifying concurrent mode failures caused by fragmentation</a>.</p></div></div></div><div class="chapter" title="Chapter&nbsp;11.&nbsp;Troubleshooting and Debugging HBase"><div class="titlepage"><div><div><h2 class="title"><a name="trouble"></a>Chapter&nbsp;11.&nbsp;Troubleshooting and Debugging HBase</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#trouble.general">11.1. General Guidelines</a></span></dt><dt><span class="section"><a href="#trouble.log">11.2. Logs</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.log.locations">11.2.1. Log Locations</a></span></dt><dt><span class="section"><a href="#trouble.log.levels">11.2.2. Log Levels</a></span></dt><dt><span class="section"><a href="#trouble.log.gc">11.2.3. JVM Garbage Collection Logs</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.tools">11.3. Tools</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.tools.builtin">11.3.1. Builtin Tools</a></span></dt><dt><span class="section"><a href="#trouble.tools.external">11.3.2. External Tools</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.client">11.4. Client</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.client.scantimeout">11.4.1. ScannerTimeoutException or UnknownScannerException</a></span></dt><dt><span class="section"><a href="#trouble.client.scarylogs">11.4.2. Shell or client application throws lots of scary exceptions during normal operation</a></span></dt><dt><span class="section"><a href="#trouble.client.longpauseswithcompression">11.4.3. Long Client Pauses With Compression</a></span></dt><dt><span class="section"><a href="#trouble.client.zookeeper">11.4.4. ZooKeeper Client Connection Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.namenode">11.5. NameNode</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.namenode.disk">11.5.1. HDFS Utilization of Tables and Regions</a></span></dt><dt><span class="section"><a href="#trouble.namenode.hbase.objects">11.5.2. Browsing HDFS for HBase Objects</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.rs">11.6. RegionServer</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.rs.startup">11.6.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.rs.runtime">11.6.2. Runtime Errors</a></span></dt><dt><span class="section"><a href="#trouble.rs.shutdown">11.6.3. Shutdown Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.master">11.7. Master</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.master.startup">11.7.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.master.shutdown">11.7.2. Shutdown Errors</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.zookeeper">11.8. ZooKeeper</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.zookeeper.startup">11.8.1. Startup Errors</a></span></dt><dt><span class="section"><a href="#trouble.zookeeper.general">11.8.2. ZooKeeper, The Cluster Canary</a></span></dt></dl></dd><dt><span class="section"><a href="#trouble.ec2">11.9. Amazon EC2</a></span></dt><dd><dl><dt><span class="section"><a href="#trouble.ec2.zookeeper">11.9.1. ZooKeeper does not seem to work on Amazon EC2</a></span></dt><dt><span class="section"><a href="#trouble.ec2.instability">11.9.2. Instability on Amazon EC2</a></span></dt><dt><span class="section"><a href="#trouble.ec2.connection">11.9.3. Remote Java Connection into EC2 Cluster Not Working</a></span></dt></dl></dd></dl></div><div class="section" title="11.1.&nbsp;General Guidelines"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.general"></a>11.1.&nbsp;General Guidelines</h2></div></div></div><p>
          Always start with the master log (TODO: Which lines?).
          Normally it&#8217;s just printing the same lines over and over again.
          If not, then there&#8217;s an issue.
          Google or <a class="link" href="http://search-hadoop.com" target="_top">search-hadoop.com</a>
          should return some hits for those exceptions you&#8217;re seeing.
      </p><p>
          An error rarely comes alone in HBase, usually when something gets screwed up what will
          follow may be hundreds of exceptions and stack traces coming from all over the place.
          The best way to approach this type of problem is to walk the log up to where it all
          began, for example one trick with RegionServers is that they will print some
          metrics when aborting so grepping for <span class="emphasis"><em>Dump</em></span>
          should get you around the start of the problem.
      </p><p>
          RegionServer suicides are &#8220;normal&#8221;, as this is what they do when something goes wrong.
          For example, if ulimit and xcievers (the two most important initial settings, see <a class="xref" href="#ulimit" title="2.2.4.&nbsp; ulimit and nproc">Section&nbsp;2.2.4, &#8220;
          <code class="varname">ulimit</code>
            and
          <code class="varname">nproc</code>
        &#8221;</a>)
          aren&#8217;t changed, it will make it impossible at some point for DataNodes to create new threads
          that from the HBase point of view is seen as if HDFS was gone. Think about what would happen if your
          MySQL database was suddenly unable to access files on your local file system, well it&#8217;s the same with
          HBase and HDFS. Another very common reason to see RegionServers committing seppuku is when they enter
          prolonged garbage collection pauses that last longer than the default ZooKeeper session timeout.
          For more information on GC pauses, see the
          <a class="link" href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/" target="_top">3 part blog post</a>  by Todd Lipcon
          and <a class="xref" href="#gcpause" title="10.3.1.1.&nbsp;Long GC pauses">Section&nbsp;10.3.1.1, &#8220;Long GC pauses&#8221;</a> above. 
      </p></div><div class="section" title="11.2.&nbsp;Logs"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.log"></a>11.2.&nbsp;Logs</h2></div></div></div><p>
      The key process logs are as follows...   (replace &lt;user&gt; with the user that started the service, and &lt;hostname&gt; for the machine name)
      </p><p>
      NameNode:  <code class="filename">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-namenode-&lt;hostname&gt;.log</code>
      </p><p>
      DataNode:  <code class="filename">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-datanode-&lt;hostname&gt;.log</code>
      </p><p>
      JobTracker:  <code class="filename">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-jobtracker-&lt;hostname&gt;.log</code>
      </p><p>
      TaskTracker:  <code class="filename">$HADOOP_HOME/logs/hadoop-&lt;user&gt;-jobtracker-&lt;hostname&gt;.log</code>
      </p><p>
      HMaster:  <code class="filename">$HBASE_HOME/logs/hbase-&lt;user&gt;-master-&lt;hostname&gt;.log</code>
      </p><p>
      RegionServer:  <code class="filename">$HBASE_HOME/logs/hbase-&lt;user&gt;-regionserver-&lt;hostname&gt;.log</code>
      </p><p>
      ZooKeeper:  <code class="filename">TODO</code>
      </p><div class="section" title="11.2.1.&nbsp;Log Locations"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.log.locations"></a>11.2.1.&nbsp;Log Locations</h3></div></div></div><p>For stand-alone deployments the logs are obviously going to be on a single machine, however this is a development configuration only.
        Production deployments need to run on a cluster.</p><div class="section" title="11.2.1.1.&nbsp;NameNode"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.log.locations.namenode"></a>11.2.1.1.&nbsp;NameNode</h4></div></div></div><p>The NameNode log is on the NameNode server.  The HBase Master is typically run on the NameNode server, and well as ZooKeeper.</p><p>For smaller clusters the JobTracker is typically run on the NameNode server as well.</p></div><div class="section" title="11.2.1.2.&nbsp;DataNode"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.log.locations.datanode"></a>11.2.1.2.&nbsp;DataNode</h4></div></div></div><p>Each DataNode server will have a DataNode log for HDFS, as well as a RegionServer log for HBase.</p><p>Additionally, each DataNode server will also have a TaskTracker log for MapReduce task execution.</p></div></div><div class="section" title="11.2.2.&nbsp;Log Levels"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.log.levels"></a>11.2.2.&nbsp;Log Levels</h3></div></div></div><div class="section" title="11.2.2.1.&nbsp;Enabling RPC-level logging"><div class="titlepage"><div><div><h4 class="title"><a name="rpc.logging"></a>11.2.2.1.&nbsp;Enabling RPC-level logging</h4></div></div></div><p>Enabling the RPC-level logging on a RegionServer can often given
           insight on timings at the server.  Once enabled, the amount of log
           spewed is voluminous.  It is not recommended that you leave this
           logging on for more than short bursts of time.  To enable RPC-level
           logging, browse to the RegionServer UI and click on 
           <span class="emphasis"><em>Log Level</em></span>.  Set the log level to <code class="varname">DEBUG</code> for the package
           <code class="classname">org.apache.hadoop.ipc</code> (Thats right, for
           <code class="classname">hadoop.ipc</code>, NOT, <code class="classname">hbase.ipc</code>).  Then tail the RegionServers log.  Analyze.</p><p>To disable, set the logging level back to <code class="varname">INFO</code> level.
           </p></div></div><div class="section" title="11.2.3.&nbsp;JVM Garbage Collection Logs"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.log.gc"></a>11.2.3.&nbsp;JVM Garbage Collection Logs</h3></div></div></div><p>HBase is memory intensive, and using the default GC you can see long pauses in all threads including the <span class="emphasis"><em>Juliet Pause</em></span> aka "GC of Death". 
           To help debug this or confirm this is happening GC logging can be turned on in the Java virtual machine.  
          </p><p>
          To enable, in <code class="filename">hbase-env.sh</code> add:
          </p><pre class="programlisting"> 
export HBASE_OPTS="-XX:+UseConcMarkSweepGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/home/hadoop/hbase/logs/gc-hbase.log"
          </pre><p>
           Adjust the log directory to wherever you log.  Note:  The GC log does NOT roll automatically, so you'll have to keep an eye on it so it doesn't fill up the disk. 
          </p><p>
         At this point you should see logs like so:
          </p><pre class="programlisting">
64898.952: [GC [1 CMS-initial-mark: 2811538K(3055704K)] 2812179K(3061272K), 0.0007360 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
64898.953: [CMS-concurrent-mark-start]
64898.971: [GC 64898.971: [ParNew: 5567K-&gt;576K(5568K), 0.0101110 secs] 2817105K-&gt;2812715K(3061272K), 0.0102200 secs] [Times: user=0.07 sys=0.00, real=0.01 secs] 
          </pre><p>
          </p><p>
           In this section, the first line indicates a 0.0007360 second pause for the CMS to initially mark. This pauses the entire VM, all threads for that period of time.
            </p><p>
           The third line indicates a "minor GC", which pauses the VM for 0.0101110 seconds - aka 10 milliseconds. It has reduced the "ParNew" from about 5.5m to 576k.
           Later on in this cycle we see:
           </p><pre class="programlisting"> 
64901.445: [CMS-concurrent-mark: 1.542/2.492 secs] [Times: user=10.49 sys=0.33, real=2.49 secs] 
64901.445: [CMS-concurrent-preclean-start]
64901.453: [GC 64901.453: [ParNew: 5505K-&gt;573K(5568K), 0.0062440 secs] 2868746K-&gt;2864292K(3061272K), 0.0063360 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
64901.476: [GC 64901.476: [ParNew: 5563K-&gt;575K(5568K), 0.0072510 secs] 2869283K-&gt;2864837K(3061272K), 0.0073320 secs] [Times: user=0.05 sys=0.01, real=0.01 secs] 
64901.500: [GC 64901.500: [ParNew: 5517K-&gt;573K(5568K), 0.0120390 secs] 2869780K-&gt;2865267K(3061272K), 0.0121150 secs] [Times: user=0.09 sys=0.00, real=0.01 secs] 
64901.529: [GC 64901.529: [ParNew: 5507K-&gt;569K(5568K), 0.0086240 secs] 2870200K-&gt;2865742K(3061272K), 0.0087180 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
64901.554: [GC 64901.555: [ParNew: 5516K-&gt;575K(5568K), 0.0107130 secs] 2870689K-&gt;2866291K(3061272K), 0.0107820 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 
64901.578: [CMS-concurrent-preclean: 0.070/0.133 secs] [Times: user=0.48 sys=0.01, real=0.14 secs] 
64901.578: [CMS-concurrent-abortable-preclean-start]
64901.584: [GC 64901.584: [ParNew: 5504K-&gt;571K(5568K), 0.0087270 secs] 2871220K-&gt;2866830K(3061272K), 0.0088220 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
64901.609: [GC 64901.609: [ParNew: 5512K-&gt;569K(5568K), 0.0063370 secs] 2871771K-&gt;2867322K(3061272K), 0.0064230 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 
64901.615: [CMS-concurrent-abortable-preclean: 0.007/0.037 secs] [Times: user=0.13 sys=0.00, real=0.03 secs] 
64901.616: [GC[YG occupancy: 645 K (5568 K)]64901.616: [Rescan (parallel) , 0.0020210 secs]64901.618: [weak refs processing, 0.0027950 secs] [1 CMS-remark: 2866753K(3055704K)] 2867399K(3061272K), 0.0049380 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] 
64901.621: [CMS-concurrent-sweep-start]
            </pre><p>
            </p><p>
            The first line indicates that the CMS concurrent mark (finding garbage) has taken 2.4 seconds. But this is a _concurrent_ 2.4 seconds, Java has not been paused at any point in time.
            </p><p>
            There are a few more minor GCs, then there is a pause at the 2nd last line:
            </p><pre class="programlisting">  
64901.616: [GC[YG occupancy: 645 K (5568 K)]64901.616: [Rescan (parallel) , 0.0020210 secs]64901.618: [weak refs processing, 0.0027950 secs] [1 CMS-remark: 2866753K(3055704K)] 2867399K(3061272K), 0.0049380 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] 
            </pre><p>
            </p><p>
            The pause here is 0.0049380 seconds (aka 4.9 milliseconds) to 'remark' the heap.  
            </p><p>
            At this point the sweep starts, and you can watch the heap size go down:
            </p><pre class="programlisting">
64901.637: [GC 64901.637: [ParNew: 5501K-&gt;569K(5568K), 0.0097350 secs] 2871958K-&gt;2867441K(3061272K), 0.0098370 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
...  lines removed ...
64904.936: [GC 64904.936: [ParNew: 5532K-&gt;568K(5568K), 0.0070720 secs] 1365024K-&gt;1360689K(3061272K), 0.0071930 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
64904.953: [CMS-concurrent-sweep: 2.030/3.332 secs] [Times: user=9.57 sys=0.26, real=3.33 secs] 
            </pre><p>
            At this point, the CMS sweep took 3.332 seconds, and heap went from about ~ 2.8 GB to 1.3 GB (approximate).
            </p><p>
            The key points here is to keep all these pauses low. CMS pauses are always low, but if your ParNew starts growing, you can see minor GC pauses approach 100ms, exceed 100ms and hit as high at 400ms.
            </p><p>
            This can be due to the size of the ParNew, which should be relatively small. If your ParNew is very large after running HBase for a while, in one example a ParNew was about 150MB, then you might have to constrain the size of ParNew (The larger it is, the longer the collections take but if its too small, objects are promoted to old gen too quickly). In the below we constrain new gen size to 64m.
            </p><p>
             Add this to HBASE_OPTS:
            </p><pre class="programlisting"> 
export HBASE_OPTS="-XX:NewSize=64m -XX:MaxNewSize=64m &lt;cms options from above&gt; &lt;gc logging options from above&gt;"
            </pre><p>
            </p><p>
            For more information on GC pauses, see the <a class="link" href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/" target="_top">3 part blog post</a>  by Todd Lipcon
            and <a class="xref" href="#gcpause" title="10.3.1.1.&nbsp;Long GC pauses">Section&nbsp;10.3.1.1, &#8220;Long GC pauses&#8221;</a> above.
            </p></div></div><div class="section" title="11.3.&nbsp;Tools"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.tools"></a>11.3.&nbsp;Tools</h2></div></div></div><div class="section" title="11.3.1.&nbsp;Builtin Tools"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.tools.builtin"></a>11.3.1.&nbsp;Builtin Tools</h3></div></div></div><div class="section" title="11.3.1.1.&nbsp;Master Web Interface"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.builtin.webmaster"></a>11.3.1.1.&nbsp;Master Web Interface</h4></div></div></div><p>The Master starts a web-interface on port 60010 by default.
              </p><p>The Master web UI lists created tables and their definition (e.g., ColumnFamilies, blocksize, etc.).  Additionally, 
              the available RegionServers in the cluster are listed along with selected high-level metrics (requests, number of regions, usedHeap, maxHeap).
              The Master web UI allows navigation to each RegionServer's web UI.
              </p></div><div class="section" title="11.3.1.2.&nbsp;RegionServer Web Interface"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.builtin.webregion"></a>11.3.1.2.&nbsp;RegionServer Web Interface</h4></div></div></div><p>RegionServers starts a web-interface on port 60030 by default.
              </p><p>The RegionServer web UI lists online regions and their start/end keys, as well as point-in-time RegionServer metrics (requests, regions, storeFileIndexSize, compactionQueueSize, etc.).
              </p><p>See <a class="xref" href="#hbase_metrics" title="12.3.&nbsp;Metrics">Section&nbsp;12.3, &#8220;Metrics&#8221;</a> for more information in metric definitions.
            </p></div></div><div class="section" title="11.3.2.&nbsp;External Tools"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.tools.external"></a>11.3.2.&nbsp;External Tools</h3></div></div></div><div class="section" title="11.3.2.1.&nbsp;search-hadoop.com"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.searchhadoop"></a>11.3.2.1.&nbsp;search-hadoop.com</h4></div></div></div><p>
        <a class="link" href="http://search-hadoop.com" target="_top">search-hadoop.com</a> indexes all the mailing lists and <a class="link" href="https://issues.apache.org/jira/browse/HBASE" target="_top">JIRA</a>, it&#8217;s really helpful when looking for Hadoop/HBase-specific issues.
        </p></div><div class="section" title="11.3.2.2.&nbsp;tail"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.tail"></a>11.3.2.2.&nbsp;tail</h4></div></div></div><p>
        <code class="code">tail</code> is the command line tool that lets you look at the end of a file. Add the &#8220;-f&#8221; option and it will refresh when new data is available. It&#8217;s useful when you are wondering what&#8217;s happening, for example, when a cluster is taking a long time to shutdown or startup as you can just fire a new terminal and tail the master log (and maybe a few RegionServers).
        </p></div><div class="section" title="11.3.2.3.&nbsp;top"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.top"></a>11.3.2.3.&nbsp;top</h4></div></div></div><p>         
        <code class="code">top</code> is probably one of the most important tool when first trying to see what&#8217;s running on a machine and how the resources are consumed. Here&#8217;s an example from production system:
        </p><pre class="programlisting">
top - 14:46:59 up 39 days, 11:55,  1 user,  load average: 3.75, 3.57, 3.84
Tasks: 309 total,   1 running, 308 sleeping,   0 stopped,   0 zombie
Cpu(s):  4.5%us,  1.6%sy,  0.0%ni, 91.7%id,  1.4%wa,  0.1%hi,  0.6%si,  0.0%st
Mem:  24414432k total, 24296956k used,   117476k free,     7196k buffers
Swap: 16008732k total,	14348k used, 15994384k free, 11106908k cached
 
  PID USER  	PR  NI  VIRT  RES  SHR S %CPU %MEM	TIME+  COMMAND                                                                                                                                                                      
15558 hadoop	18  -2 3292m 2.4g 3556 S   79 10.4   6523:52 java                                                                                                                                                                          
13268 hadoop	18  -2 8967m 8.2g 4104 S   21 35.1   5170:30 java                                                                                                                                                                          
 8895 hadoop	18  -2 1581m 497m 3420 S   11  2.1   4002:32 java
&#8230;
        </pre><p>
        </p><p>
        Here we can see that the system load average during the last five minutes is 3.75, which very roughly means that on average 3.75 threads were waiting for CPU time during these 5 minutes.  In general, the &#8220;perfect&#8221; utilization equals to the number of cores, under that number the machine is under utilized and over that the machine is over utilized.  This is an important concept, see this article to understand it more: <a class="link" href="http://www.linuxjournal.com/article/9001" target="_top">http://www.linuxjournal.com/article/9001</a>.
        </p><p>
        Apart from load, we can see that the system is using almost all its available RAM but most of it is used for the OS cache (which is good). The swap only has a few KBs in it and this is wanted, high numbers would indicate swapping activity which is the nemesis of performance of Java systems. Another way to detect swapping is when the load average goes through the roof (although this could also be caused by things like a dying disk, among others).
        </p><p>
        The list of processes isn&#8217;t super useful by default, all we know is that 3 java processes are using about 111% of the CPUs. To know which is which, simply type &#8220;c&#8221; and each line will be expanded. Typing &#8220;1&#8221; will give you the detail of how each CPU is used instead of the average for all of them like shown here.
        </p></div><div class="section" title="11.3.2.4.&nbsp;jps"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.jps"></a>11.3.2.4.&nbsp;jps</h4></div></div></div><p>
        <code class="code">jps</code> is shipped with every JDK and gives the java process ids for the current user (if root, then it gives the ids for all users). Example:
        </p><pre class="programlisting">
hadoop@sv4borg12:~$ jps
1322 TaskTracker
17789 HRegionServer
27862 Child
1158 DataNode
25115 HQuorumPeer
2950 Jps
19750 ThriftServer
18776 jmx
        </pre><p>
        In order, we see a:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Hadoop TaskTracker, manages the local Childs</li><li class="listitem">HBase RegionServer, serves regions</li><li class="listitem">Child, its MapReduce task, cannot tell which type exactly</li><li class="listitem">Hadoop TaskTracker, manages the local Childs</li><li class="listitem">Hadoop DataNode, serves blocks</li><li class="listitem">HQuorumPeer, a ZooKeeper ensemble member</li><li class="listitem">Jps, well&#8230; it&#8217;s the current process</li><li class="listitem">ThriftServer, it&#8217;s a special one will be running only if thrift was started</li><li class="listitem">jmx, this is a local process that&#8217;s part of our monitoring platform ( poorly named maybe). You probably don&#8217;t have that.</li></ul></div><p>
        </p><p>
      You can then do stuff like checking out the full command line that started the process:
        </p><pre class="programlisting">
hadoop@sv4borg12:~$ ps aux | grep HRegionServer
hadoop   17789  155 35.2 9067824 8604364 ?     S&lt;l  Mar04 9855:48 /usr/java/jdk1.6.0_14/bin/java -Xmx8000m -XX:+DoEscapeAnalysis -XX:+AggressiveOpts -XX:+UseConcMarkSweepGC -XX:NewSize=64m -XX:MaxNewSize=64m -XX:CMSInitiatingOccupancyFraction=88 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/export1/hadoop/logs/gc-hbase.log -Dcom.sun.management.jmxremote.port=10102 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=/home/hadoop/hbase/conf/jmxremote.password -Dcom.sun.management.jmxremote -Dhbase.log.dir=/export1/hadoop/logs -Dhbase.log.file=hbase-hadoop-regionserver-sv4borg12.log -Dhbase.home.dir=/home/hadoop/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,DRFA -Djava.library.path=/home/hadoop/hbase/lib/native/Linux-amd64-64 -classpath /home/hadoop/hbase/bin/../conf:[many jars]:/home/hadoop/hadoop/conf org.apache.hadoop.hbase.regionserver.HRegionServer start
        </pre><p>      
        </p></div><div class="section" title="11.3.2.5.&nbsp;jstack"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.jstack"></a>11.3.2.5.&nbsp;jstack</h4></div></div></div><p>
        <code class="code">jstack</code> is one of the most important tools when trying to figure out what a java process is doing apart from looking at the logs. It has to be used in conjunction with jps in order to give it a process id. It shows a list of threads, each one has a name, and they appear in the order that they were created (so the top ones are the most recent threads). Here&#8217;s a few example:
        </p><p>
        The main thread of a RegionServer that&#8217;s waiting for something to do from the master:
        </p><pre class="programlisting">
      "regionserver60020" prio=10 tid=0x0000000040ab4000 nid=0x45cf waiting on condition [0x00007f16b6a96000..0x00007f16b6a96a70]
   java.lang.Thread.State: TIMED_WAITING (parking)
        	at sun.misc.Unsafe.park(Native Method)
        	- parking to wait for  &lt;0x00007f16cd5c2f30&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)
        	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1963)
        	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:395)
        	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:647)
        	at java.lang.Thread.run(Thread.java:619)
 
        	The MemStore flusher thread that is currently flushing to a file:
"regionserver60020.cacheFlusher" daemon prio=10 tid=0x0000000040f4e000 nid=0x45eb in Object.wait() [0x00007f16b5b86000..0x00007f16b5b87af0]
   java.lang.Thread.State: WAITING (on object monitor)
        	at java.lang.Object.wait(Native Method)
        	at java.lang.Object.wait(Object.java:485)
        	at org.apache.hadoop.ipc.Client.call(Client.java:803)
        	- locked &lt;0x00007f16cb14b3a8&gt; (a org.apache.hadoop.ipc.Client$Call)
        	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:221)
        	at $Proxy1.complete(Unknown Source)
        	at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        	at java.lang.reflect.Method.invoke(Method.java:597)
        	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        	at $Proxy1.complete(Unknown Source)
        	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3390)
        	- locked &lt;0x00007f16cb14b470&gt; (a org.apache.hadoop.hdfs.DFSClient$DFSOutputStream)
        	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3304)
        	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:61)
        	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:86)
        	at org.apache.hadoop.hbase.io.hfile.HFile$Writer.close(HFile.java:650)
        	at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:853)
        	at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:467)
        	- locked &lt;0x00007f16d00e6f08&gt; (a java.lang.Object)
        	at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:427)
        	at org.apache.hadoop.hbase.regionserver.Store.access$100(Store.java:80)
        	at org.apache.hadoop.hbase.regionserver.Store$StoreFlusherImpl.flushCache(Store.java:1359)
        	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:907)
        	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:834)
        	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:786)
        	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:250)
        	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:224)
        	at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:146)
        </pre><p>
        </p><p>
        	A handler thread that&#8217;s waiting for stuff to do (like put, delete, scan, etc):
        </p><pre class="programlisting">
"IPC Server handler 16 on 60020" daemon prio=10 tid=0x00007f16b011d800 nid=0x4a5e waiting on condition [0x00007f16afefd000..0x00007f16afefd9f0]
   java.lang.Thread.State: WAITING (parking)
        	at sun.misc.Unsafe.park(Native Method)
        	- parking to wait for  &lt;0x00007f16cd3f8dd8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)
        	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1925)
        	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)
        	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1013)
        </pre><p>
        </p><p>
              	And one that&#8217;s busy doing an increment of a counter (it&#8217;s in the phase where it&#8217;s trying to create a scanner in order to read the last value):
        </p><pre class="programlisting">
"IPC Server handler 66 on 60020" daemon prio=10 tid=0x00007f16b006e800 nid=0x4a90 runnable [0x00007f16acb77000..0x00007f16acb77cf0]
   java.lang.Thread.State: RUNNABLE
        	at org.apache.hadoop.hbase.regionserver.KeyValueHeap.&lt;init&gt;(KeyValueHeap.java:56)
        	at org.apache.hadoop.hbase.regionserver.StoreScanner.&lt;init&gt;(StoreScanner.java:79)
        	at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:1202)
        	at org.apache.hadoop.hbase.regionserver.HRegion$RegionScanner.&lt;init&gt;(HRegion.java:2209)
        	at org.apache.hadoop.hbase.regionserver.HRegion.instantiateInternalScanner(HRegion.java:1063)
        	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1055)
        	at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:1039)
        	at org.apache.hadoop.hbase.regionserver.HRegion.getLastIncrement(HRegion.java:2875)
        	at org.apache.hadoop.hbase.regionserver.HRegion.incrementColumnValue(HRegion.java:2978)
        	at org.apache.hadoop.hbase.regionserver.HRegionServer.incrementColumnValue(HRegionServer.java:2433)
        	at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
        	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        	at java.lang.reflect.Method.invoke(Method.java:597)
        	at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:560)
        	at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1027)
        </pre><p>
        </p><p>
        	A thread that receives data from HDFS:
        </p><pre class="programlisting">        	
"IPC Client (47) connection to sv4borg9/10.4.24.40:9000 from hadoop" daemon prio=10 tid=0x00007f16a02d0000 nid=0x4fa3 runnable [0x00007f16b517d000..0x00007f16b517dbf0]
   java.lang.Thread.State: RUNNABLE
        	at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        	at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:215)
        	at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
        	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
        	- locked &lt;0x00007f17d5b68c00&gt; (a sun.nio.ch.Util$1)
        	- locked &lt;0x00007f17d5b68be8&gt; (a java.util.Collections$UnmodifiableSet)
        	- locked &lt;0x00007f1877959b50&gt; (a sun.nio.ch.EPollSelectorImpl)
        	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
        	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:332)
        	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
        	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
        	at java.io.FilterInputStream.read(FilterInputStream.java:116)
        	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:304)
        	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
        	at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
        	- locked &lt;0x00007f1808539178&gt; (a java.io.BufferedInputStream)
        	at java.io.DataInputStream.readInt(DataInputStream.java:370)
        	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:569)
        	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:477)
          </pre><p>
          </p><p>
           	And here is a master trying to recover a lease after a RegionServer died:
          </p><pre class="programlisting">
"LeaseChecker" daemon prio=10 tid=0x00000000407ef800 nid=0x76cd waiting on condition [0x00007f6d0eae2000..0x00007f6d0eae2a70]
--
   java.lang.Thread.State: WAITING (on object monitor)
        	at java.lang.Object.wait(Native Method)
        	at java.lang.Object.wait(Object.java:485)
        	at org.apache.hadoop.ipc.Client.call(Client.java:726)
        	- locked &lt;0x00007f6d1cd28f80&gt; (a org.apache.hadoop.ipc.Client$Call)
        	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
        	at $Proxy1.recoverBlock(Unknown Source)
        	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2636)
        	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.&lt;init&gt;(DFSClient.java:2832)
        	at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:529)
        	at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:186)
        	at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:530)
        	at org.apache.hadoop.hbase.util.FSUtils.recoverFileLease(FSUtils.java:619)
        	at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:1322)
        	at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:1210)
        	at org.apache.hadoop.hbase.master.HMaster.splitLogAfterStartup(HMaster.java:648)
        	at org.apache.hadoop.hbase.master.HMaster.joinCluster(HMaster.java:572)
        	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:503)
          </pre><p>
          </p></div><div class="section" title="11.3.2.6.&nbsp;OpenTSDB"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.opentsdb"></a>11.3.2.6.&nbsp;OpenTSDB</h4></div></div></div><p>
          <a class="link" href="http://opentsdb.net" target="_top">OpenTSDB</a> is an excellent alternative to Ganglia as it uses HBase to store all the time series and doesn&#8217;t have to downsample. Monitoring your own HBase cluster that hosts OpenTSDB is a good exercise.
          </p><p>
          Here&#8217;s an example of a cluster that&#8217;s suffering from hundreds of compactions launched almost all around the same time, which severely affects the IO performance:  (TODO:  insert graph plotting compactionQueueSize)
          </p><p>
          It&#8217;s a good practice to build dashboards with all the important graphs per machine and per cluster so that debugging issues can be done with a single quick look. For example, at StumbleUpon there&#8217;s one dashboard per cluster with the most important metrics from both the OS and HBase. You can then go down at the machine level and get even more detailed metrics.
          </p></div><div class="section" title="11.3.2.7.&nbsp;clusterssh+top"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.tools.clustersshtop"></a>11.3.2.7.&nbsp;clusterssh+top</h4></div></div></div><p> 
          clusterssh+top, it&#8217;s like a poor man&#8217;s monitoring system and it can be quite useful when you have only a few machines as it&#8217;s very easy to setup. Starting clusterssh will give you one terminal per machine and another terminal in which whatever you type will be retyped in every window. This means that you can type &#8220;top&#8221; once and it will start it for all of your machines at the same time giving you full view of the current state of your cluster. You can also tail all the logs at the same time, edit files, etc.      
          </p></div></div></div><div class="section" title="11.4.&nbsp;Client"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.client"></a>11.4.&nbsp;Client</h2></div></div></div><p>For more information on the HBase client, see <a class="xref" href="#client" title="8.2.&nbsp;Client">Section&nbsp;8.2, &#8220;Client&#8221;</a>. 
       </p><div class="section" title="11.4.1.&nbsp;ScannerTimeoutException or UnknownScannerException"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.client.scantimeout"></a>11.4.1.&nbsp;ScannerTimeoutException or UnknownScannerException</h3></div></div></div><p>This is thrown if the time between RPC calls from the client to RegionServer exceeds the scan timeout.  
            For example, if <code class="code">Scan.setCaching</code> is set to 500, then there will be an RPC call to fetch the next batch of rows every 500 <code class="code">.next()</code> calls on the ResultScanner
            because data is being transferred in blocks of 500 rows to the client.  Reducing the setCaching value may be an option, but setting this value too low makes for inefficient
            processing on numbers of rows.
            </p><p>See <a class="xref" href="#perf.hbase.client.caching" title="10.7.1.&nbsp;Scan Caching">Section&nbsp;10.7.1, &#8220;Scan Caching&#8221;</a>.
            </p></div><div class="section" title="11.4.2.&nbsp;Shell or client application throws lots of scary exceptions during normal operation"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.client.scarylogs"></a>11.4.2.&nbsp;Shell or client application throws lots of scary exceptions during normal operation</h3></div></div></div><p>Since 0.20.0 the default log level for <code class="code">org.apache.hadoop.hbase.*</code>is DEBUG. </p><p>
            On your clients, edit <code class="filename">$HBASE_HOME/conf/log4j.properties</code> and change this: <code class="code">log4j.logger.org.apache.hadoop.hbase=DEBUG</code> to this: <code class="code">log4j.logger.org.apache.hadoop.hbase=INFO</code>, or even <code class="code">log4j.logger.org.apache.hadoop.hbase=WARN</code>. 
            </p></div><div class="section" title="11.4.3.&nbsp;Long Client Pauses With Compression"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.client.longpauseswithcompression"></a>11.4.3.&nbsp;Long Client Pauses With Compression</h3></div></div></div><p>This is a fairly frequent question on the HBase dist-list.  The scenario is that a client is typically inserting a lot of data into a 
            relatively un-optimized HBase cluster.  Compression can exacerbate the pauses, although it is not the source of the problem.</p><p>See <a class="xref" href="#precreate.regions" title="10.6.2.&nbsp; Table Creation: Pre-Creating Regions">Section&nbsp;10.6.2, &#8220;
    Table Creation: Pre-Creating Regions
    &#8221;</a> on the pattern for pre-creating regions and confirm that the table isn't starting with a single region.</p><p>See <a class="xref" href="#perf.configurations" title="10.4.&nbsp;HBase Configurations">Section&nbsp;10.4, &#8220;HBase Configurations&#8221;</a> for cluster configuration, particularly <code class="code">hbase.hstore.blockingStoreFiles</code>, <code class="code">hbase.hregion.memstore.block.multiplier</code>, 
            <code class="code">MAX_FILESIZE</code> (region size), and <code class="code">MEMSTORE_FLUSHSIZE.</code>  </p><p>A slightly longer explanation of why pauses can happen is as follows:  Puts are sometimes blocked on the MemStores which are blocked by the flusher thread which is blocked because there are 
            too many files to compact because the compactor is given too many small files to compact and has to compact the same data repeatedly.  This situation can occur even with minor compactions.
            Compounding this situation, HBase doesn't compress data in memory.  Thus, the 64MB that lives in the MemStore could become a 6MB file after compression - which results in a smaller StoreFile.  The upside is that
            more data is packed into the same region, but performance is achieved by being able to write larger files - which is why HBase waits until the flushize before writing a new StoreFile.  And smaller StoreFiles
            become targets for compaction.  Without compression the files are much bigger and don't need as much compaction, however this is at the expense of I/O.   
            </p><p>
            For additional information, see this thread on <a class="link" href="http://search-hadoop.com/m/WUnLM6ojHm1/Long+client+pauses+with+compression&amp;subj=Long+client+pauses+with+compression" target="_top">Long client pauses with compression</a>.
            </p></div><div class="section" title="11.4.4.&nbsp;ZooKeeper Client Connection Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.client.zookeeper"></a>11.4.4.&nbsp;ZooKeeper Client Connection Errors</h3></div></div></div><p>Errors like this...
</p><pre class="programlisting">
11/07/05 11:26:41 WARN zookeeper.ClientCnxn: Session 0x0 for server null,
 unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection refused: no further information
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1078)
 11/07/05 11:26:43 INFO zookeeper.ClientCnxn: Opening socket connection to
 server localhost/127.0.0.1:2181
 11/07/05 11:26:44 WARN zookeeper.ClientCnxn: Session 0x0 for server null,
 unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: Connection refused: no further information
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1078)
 11/07/05 11:26:45 INFO zookeeper.ClientCnxn: Opening socket connection to
 server localhost/127.0.0.1:2181
</pre><p>
            ... are either due to ZooKeeper being down, or unreachable due to network issues.            
            </p></div></div><div class="section" title="11.5.&nbsp;NameNode"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.namenode"></a>11.5.&nbsp;NameNode</h2></div></div></div><p>For more information on the NameNode, see <a class="xref" href="#arch.hdfs" title="8.7.&nbsp;HDFS">Section&nbsp;8.7, &#8220;HDFS&#8221;</a>. 
       </p><div class="section" title="11.5.1.&nbsp;HDFS Utilization of Tables and Regions"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.namenode.disk"></a>11.5.1.&nbsp;HDFS Utilization of Tables and Regions</h3></div></div></div><p>To determine how much space HBase is using on HDFS use the <code class="code">hadoop</code> shell commands from the NameNode.  For example... </p><pre class="programlisting">hadoop fs -dus /hbase/</pre><p> ...returns the summarized disk utilization for all HBase objects.  </p><pre class="programlisting">hadoop fs -dus /hbase/myTable</pre><p> ...returns the summarized disk utilization for the HBase table 'myTable'. </p><pre class="programlisting">hadoop fs -du /hbase/myTable</pre><p> ...returns a list of the regions under the HBase table 'myTable' and their disk utilization. </p><p>For more information on HDFS shell commands, see the <a class="link" href="http://hadoop.apache.org/common/docs/current/file_system_shell.html" target="_top">HDFS FileSystem Shell documentation</a>.
            </p></div><div class="section" title="11.5.2.&nbsp;Browsing HDFS for HBase Objects"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.namenode.hbase.objects"></a>11.5.2.&nbsp;Browsing HDFS for HBase Objects</h3></div></div></div><p>Somtimes it will be necessary to explore the HBase objects that exist on HDFS.  These objects could include the WALs (Write Ahead Logs), tables, regions, StoreFiles, etc.
            The easiest way to do this is with the NameNode web application that runs on port 50070.  The NameNode web application will provide links to the all the DataNodes in the cluster so that
            they can be browsed seamlessly. </p><p>The HDFS directory structure of HBase tables in the cluster is...
            </p><pre class="programlisting">
<code class="filename">/hbase</code>
     <code class="filename">/&lt;Table&gt;</code>             (Tables in the cluster)
          <code class="filename">/&lt;Region&gt;</code>           (Regions for the table)
               <code class="filename">/&lt;ColumnFamiy&gt;</code>      (ColumnFamilies for the Region for the table)
                    <code class="filename">/&lt;StoreFile&gt;</code>        (StoreFiles for the ColumnFamily for the Regions for the table)
            </pre><p>
            </p><p>The HDFS directory structure of HBase WAL is..
            </p><pre class="programlisting">
<code class="filename">/hbase</code>
     <code class="filename">/.logs</code>     
          <code class="filename">/&lt;RegionServer&gt;</code>    (RegionServers)
               <code class="filename">/&lt;HLog&gt;</code>           (WAL HLog files for the RegionServer)
            </pre><p>
            </p><p>See the <a class="link" href="see http://hadoop.apache.org/common/docs/current/hdfs_user_guide.html" target="_top">HDFS User Guide</a> for other non-shell diagnostic 
		    utilities like <code class="code">fsck</code>. 
            </p><div class="section" title="11.5.2.1.&nbsp;Use Cases"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.namenode.uncompaction"></a>11.5.2.1.&nbsp;Use Cases</h4></div></div></div><p>Two common use-cases for querying HDFS for HBase objects is research the degree of uncompaction of a table.  If there are a large number of StoreFiles for each ColumnFamily it could 
              indicate the need for a major compaction.  Additionally, after a major compaction if the resulting StoreFile is "small" it could indicate the need for a reduction of ColumnFamilies for
              the table.
		    </p></div></div></div><div class="section" title="11.6.&nbsp;RegionServer"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.rs"></a>11.6.&nbsp;RegionServer</h2></div></div></div><p>For more information on the RegionServers, see <a class="xref" href="#regionserver.arch" title="8.5.&nbsp;RegionServer">Section&nbsp;8.5, &#8220;RegionServer&#8221;</a>. 
       </p><div class="section" title="11.6.1.&nbsp;Startup Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.rs.startup"></a>11.6.1.&nbsp;Startup Errors</h3></div></div></div><div class="section" title="11.6.1.1.&nbsp;Master Starts, But RegionServers Do Not"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.startup.master-no-region"></a>11.6.1.1.&nbsp;Master Starts, But RegionServers Do Not</h4></div></div></div><p>The Master believes the RegionServers have the IP of 127.0.0.1 - which is localhost and resolves to the master's own localhost.
            </p><p>The RegionServers are erroneously informing the Master that their IP addresses are 127.0.0.1. 
            </p><p>Modify <code class="filename">/etc/hosts</code> on the region servers, from...  
            </p><pre class="programlisting">
# Do not remove the following line, or various programs
# that require network functionality will fail.
127.0.0.1               fully.qualified.regionservername regionservername  localhost.localdomain localhost
::1             localhost6.localdomain6 localhost6
            </pre><p>
            ... to (removing the master node's name from localhost)...
            </p><pre class="programlisting">
# Do not remove the following line, or various programs
# that require network functionality will fail.
127.0.0.1               localhost.localdomain localhost
::1             localhost6.localdomain6 localhost6
            </pre><p>
            </p></div><div class="section" title="11.6.1.2.&nbsp;Compression Link Errors"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.startup.compression"></a>11.6.1.2.&nbsp;Compression Link Errors</h4></div></div></div><p>
            Since compression algorithms such as LZO need to be installed and configured on each cluster this is a frequent source of startup error.  If you see messages like this...
            </p><pre class="programlisting">
11/02/20 01:32:15 ERROR lzo.GPLNativeCodeLoader: Could not load native gpl library
java.lang.UnsatisfiedLinkError: no gplcompression in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1734)
        at java.lang.Runtime.loadLibrary0(Runtime.java:823)
        at java.lang.System.loadLibrary(System.java:1028)
            </pre><p>
            .. then there is a path issue with the compression libraries.  See the Configuration section on <a class="link" href="#lzo.compression" title="A.3.&nbsp; LZO">LZO compression configuration</a>.
            </p></div></div><div class="section" title="11.6.2.&nbsp;Runtime Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.rs.runtime"></a>11.6.2.&nbsp;Runtime Errors</h3></div></div></div><div class="section" title="11.6.2.1.&nbsp;RegionServer Hanging"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.hang"></a>11.6.2.1.&nbsp;RegionServer Hanging</h4></div></div></div><p>
            Are you running an old JVM (&lt; 1.6.0_u21?)?  When you look at a thread dump,
            does it look like threads are BLOCKED but no one holds the lock all are
            blocked on?  See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-3622" target="_top">HBASE 3622 Deadlock in HBaseServer (JVM bug?)</a>.
            Adding <code class="code">-XX:+UseMembar</code> to the HBase <code class="varname">HBASE_OPTS</code> in <code class="filename">conf/hbase-env.sh</code>
            may fix it.
            </p></div><div class="section" title="11.6.2.2.&nbsp;java.io.IOException...(Too many open files)"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.filehandles"></a>11.6.2.2.&nbsp;java.io.IOException...(Too many open files)</h4></div></div></div><p>
           If you see log messages like this...
</p><pre class="programlisting">
2010-09-13 01:24:17,336 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: 
Disk-related IOException in BlockReceiver constructor. Cause is java.io.IOException: Too many open files
        at java.io.UnixFileSystem.createFileExclusively(Native Method)
        at java.io.File.createNewFile(File.java:883)
</pre><p>
           ... see the Getting Started section on <a class="link" href="#ulimit" title="2.2.4.&nbsp; ulimit and nproc">ulimit and nproc configuration</a>.
           </p></div><div class="section" title="11.6.2.3.&nbsp;xceiverCount 258 exceeds the limit of concurrent xcievers 256"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.xceivers"></a>11.6.2.3.&nbsp;xceiverCount 258 exceeds the limit of concurrent xcievers 256</h4></div></div></div><p>
           This typically shows up in the DataNode logs.
           </p><p>
           See the Getting Started section on <a class="link" href="#dfs.datanode.max.xcievers" title="2.3.2.&nbsp;dfs.datanode.max.xcievers">xceivers configuration</a>.
           </p></div><div class="section" title="11.6.2.4.&nbsp;System instability, and the presence of &#34;java.lang.OutOfMemoryError: unable to create new native thread in exceptions&#34; HDFS DataNode logs or that of any system daemon"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.oom-nt"></a>11.6.2.4.&nbsp;System instability, and the presence of "java.lang.OutOfMemoryError: unable to create new native thread in exceptions" HDFS DataNode logs or that of any system daemon</h4></div></div></div><p>
           See the Getting Started section on <a class="link" href="#ulimit" title="2.2.4.&nbsp; ulimit and nproc">ulimit and nproc configuration</a>.  The default on recent Linux
           distributions is 1024 - which is far too low for HBase.
           </p></div><div class="section" title="11.6.2.5.&nbsp;DFS instability and/or RegionServer lease timeouts"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.gc"></a>11.6.2.5.&nbsp;DFS instability and/or RegionServer lease timeouts</h4></div></div></div><p>
           If you see warning messages like this...
           </p><pre class="programlisting">
2009-02-24 10:01:33,516 WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: 10000
2009-02-24 10:01:33,516 WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: 15000
2009-02-24 10:01:36,472 WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master for xxx milliseconds - retrying      
           </pre><p>
           ... or see full GC compactions then you may be experiencing full GC's.
           </p></div><div class="section" title="11.6.2.6.&nbsp;&#34;No live nodes contain current block&#34; and/or YouAreDeadException"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.nolivenodes"></a>11.6.2.6.&nbsp;"No live nodes contain current block" and/or YouAreDeadException</h4></div></div></div><p>
           These errors can happen either when running out of OS file handles or in periods of severe network problems where the nodes are unreachable.
           </p><p>
           See the Getting Started section on <a class="link" href="#ulimit" title="2.2.4.&nbsp; ulimit and nproc">ulimit and nproc configuration</a> and check your network.
           </p></div><div class="section" title="11.6.2.7.&nbsp;ZooKeeper SessionExpired events"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.zkexpired"></a>11.6.2.7.&nbsp;ZooKeeper SessionExpired events</h4></div></div></div><p>Master or RegionServers shutting down with messages like those in the logs: </p><pre class="programlisting">
WARN org.apache.zookeeper.ClientCnxn: Exception
closing session 0x278bd16a96000f to sun.nio.ch.SelectionKeyImpl@355811ec
java.io.IOException: TIMED OUT
       at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:906)
WARN org.apache.hadoop.hbase.util.Sleeper: We slept 79410ms, ten times longer than scheduled: 5000
INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server hostname/IP:PORT
INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/IP:PORT remote=hostname/IP:PORT]
INFO org.apache.zookeeper.ClientCnxn: Server connection successful
WARN org.apache.zookeeper.ClientCnxn: Exception closing session 0x278bd16a96000d to sun.nio.ch.SelectionKeyImpl@3544d65e
java.io.IOException: Session Expired
       at org.apache.zookeeper.ClientCnxn$SendThread.readConnectResult(ClientCnxn.java:589)
       at org.apache.zookeeper.ClientCnxn$SendThread.doIO(ClientCnxn.java:709)
       at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:945)
ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: ZooKeeper session expired           
           </pre><p>
           The JVM is doing a long running garbage collecting which is pausing every threads (aka "stop the world").
           Since the RegionServer's local ZooKeeper client cannot send heartbeats, the session times out.
           By design, we shut down any node that isn't able to contact the ZooKeeper ensemble after getting a timeout so that it stops serving data that may already be assigned elsewhere.  
           </p><p>
            </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Make sure you give plenty of RAM (in <code class="filename">hbase-env.sh</code>), the default of 1GB won't be able to sustain long running imports.</li><li class="listitem">Make sure you don't swap, the JVM never behaves well under swapping.</li><li class="listitem">Make sure you are not CPU starving the RegionServer thread. For example, if you are running a MapReduce job using 6 CPU-intensive tasks on a machine with 4 cores, you are probably starving the RegionServer enough to create longer garbage collection pauses.</li><li class="listitem">Increase the ZooKeeper session timeout</li></ul></div><p>
           If you wish to increase the session timeout, add the following to your <code class="filename">hbase-site.xml</code> to increase the timeout from the default of 60 seconds to 120 seconds. 
           </p><pre class="programlisting">
&lt;property&gt;
    &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;
    &lt;value&gt;1200000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.tickTime&lt;/name&gt;
    &lt;value&gt;6000&lt;/value&gt;
&lt;/property&gt;
            </pre><p>
           </p><p>
           Be aware that setting a higher timeout means that the regions served by a failed RegionServer will take at least
           that amount of time to be transfered to another RegionServer. For a production system serving live requests, we would instead 
           recommend setting it lower than 1 minute and over-provision your cluster in order the lower the memory load on each machines (hence having 
           less garbage to collect per machine).
           </p><p>
           If this is happening during an upload which only happens once (like initially loading all your data into HBase), consider bulk loading.
           </p>
           See <a class="xref" href="#trouble.zookeeper.general" title="11.8.2.&nbsp;ZooKeeper, The Cluster Canary">Section&nbsp;11.8.2, &#8220;ZooKeeper, The Cluster Canary&#8221;</a> for other general information about ZooKeeper troubleshooting.
        </div><div class="section" title="11.6.2.8.&nbsp;NotServingRegionException"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.notservingregion"></a>11.6.2.8.&nbsp;NotServingRegionException</h4></div></div></div><p>This exception is "normal" when found in the RegionServer logs at DEBUG level.  This exception is returned back to the client
           and then the client goes back to .META. to find the new location of the moved region.</p><p>However, if the NotServingRegionException is logged ERROR, then the client ran out of retries and something probably wrong.</p></div><div class="section" title="11.6.2.9.&nbsp;Regions listed by domain name, then IP"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.rs.runtime.double_listed_regions"></a>11.6.2.9.&nbsp;Regions listed by domain name, then IP</h4></div></div></div><p>
           Fix your DNS.  In versions of HBase before 0.92.x, reverse DNS needs to give same answer
           as forward lookup. See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-3431" target="_top">HBASE 3431
           RegionServer is not using the name given it by the master; double entry in master listing of servers</a> for gorey details.
          </p></div></div><div class="section" title="11.6.3.&nbsp;Shutdown Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.rs.shutdown"></a>11.6.3.&nbsp;Shutdown Errors</h3></div></div></div></div></div><div class="section" title="11.7.&nbsp;Master"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.master"></a>11.7.&nbsp;Master</h2></div></div></div><p>For more information on the Master, see <a class="xref" href="#master" title="8.4.&nbsp;Master">Section&nbsp;8.4, &#8220;Master&#8221;</a>. 
       </p><div class="section" title="11.7.1.&nbsp;Startup Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.master.startup"></a>11.7.1.&nbsp;Startup Errors</h3></div></div></div><div class="section" title="11.7.1.1.&nbsp;Master says that you need to run the hbase migrations script"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.master.startup.migration"></a>11.7.1.1.&nbsp;Master says that you need to run the hbase migrations script</h4></div></div></div><p>Upon running that, the hbase migrations script says no files in root directory.</p><p>HBase expects the root directory to either not exist, or to have already been initialized by hbase running a previous time. If you create a new directory for HBase using Hadoop DFS, this error will occur. 
             Make sure the HBase root directory does not currently exist or has been initialized by a previous run of HBase. Sure fire solution is to just use Hadoop dfs to delete the HBase root and let HBase create and initialize the directory itself. 
             </p></div></div><div class="section" title="11.7.2.&nbsp;Shutdown Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.master.shutdown"></a>11.7.2.&nbsp;Shutdown Errors</h3></div></div></div></div></div><div class="section" title="11.8.&nbsp;ZooKeeper"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.zookeeper"></a>11.8.&nbsp;ZooKeeper</h2></div></div></div><div class="section" title="11.8.1.&nbsp;Startup Errors"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.zookeeper.startup"></a>11.8.1.&nbsp;Startup Errors</h3></div></div></div><div class="section" title="11.8.1.1.&nbsp;Could not find my address: xyz in list of ZooKeeper quorum servers"><div class="titlepage"><div><div><h4 class="title"><a name="trouble.zookeeper.startup.address"></a>11.8.1.1.&nbsp;Could not find my address: xyz in list of ZooKeeper quorum servers</h4></div></div></div><p>A ZooKeeper server wasn't able to start, throws that error. xyz is the name of your server.</p><p>This is a name lookup problem. HBase tries to start a ZooKeeper server on some machine but that machine isn't able to find itself in the <code class="varname">hbase.zookeeper.quorum</code> configuration.  
             </p><p>Use the hostname presented in the error message instead of the value you used. If you have a DNS server, you can set <code class="varname">hbase.zookeeper.dns.interface</code> and <code class="varname">hbase.zookeeper.dns.nameserver</code> in <code class="filename">hbase-site.xml</code> to make sure it resolves to the correct FQDN.   
             </p></div></div><div class="section" title="11.8.2.&nbsp;ZooKeeper, The Cluster Canary"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.zookeeper.general"></a>11.8.2.&nbsp;ZooKeeper, The Cluster Canary</h3></div></div></div><p>ZooKeeper is the cluster's "canary in the mineshaft". It'll be the first to notice issues if any so making sure its happy is the short-cut to a humming cluster.
          </p><p>
          See the <a class="link" href="http://wiki.apache.org/hadoop/ZooKeeper/Troubleshooting" target="_top">ZooKeeper Operating Environment Troubleshooting</a> page. It has suggestions and tools for checking disk and networking performance; i.e. the operating environment your ZooKeeper and HBase are running in.
          </p></div></div><div class="section" title="11.9.&nbsp;Amazon EC2"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="trouble.ec2"></a>11.9.&nbsp;Amazon EC2</h2></div></div></div><div class="section" title="11.9.1.&nbsp;ZooKeeper does not seem to work on Amazon EC2"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.ec2.zookeeper"></a>11.9.1.&nbsp;ZooKeeper does not seem to work on Amazon EC2</h3></div></div></div><p>HBase does not start when deployed as Amazon EC2 instances.  Exceptions like the below appear in the Master and/or RegionServer logs: </p><pre class="programlisting">
  2009-10-19 11:52:27,030 INFO org.apache.zookeeper.ClientCnxn: Attempting
  connection to server ec2-174-129-15-236.compute-1.amazonaws.com/10.244.9.171:2181
  2009-10-19 11:52:27,032 WARN org.apache.zookeeper.ClientCnxn: Exception
  closing session 0x0 to sun.nio.ch.SelectionKeyImpl@656dc861
  java.net.ConnectException: Connection refused
             </pre><p>
             Security group policy is blocking the ZooKeeper port on a public address. 
             Use the internal EC2 host names when configuring the ZooKeeper quorum peer list. 
             </p></div><div class="section" title="11.9.2.&nbsp;Instability on Amazon EC2"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.ec2.instability"></a>11.9.2.&nbsp;Instability on Amazon EC2</h3></div></div></div><p>Questions on HBase and Amazon EC2 come up frequently on the HBase dist-list. Search for old threads using <a class="link" href="http://search-hadoop.com/" target="_top">Search Hadoop</a>
             </p></div><div class="section" title="11.9.3.&nbsp;Remote Java Connection into EC2 Cluster Not Working"><div class="titlepage"><div><div><h3 class="title"><a name="trouble.ec2.connection"></a>11.9.3.&nbsp;Remote Java Connection into EC2 Cluster Not Working</h3></div></div></div><p>
             See Andrew's answer here, up on the user list: <a class="link" href="http://search-hadoop.com/m/sPdqNFAwyg2" target="_top">Remote Java client connection into EC2 instance</a>.
             </p></div></div></div><div class="chapter" title="Chapter&nbsp;12.&nbsp;HBase Operational Management"><div class="titlepage"><div><div><h2 class="title"><a name="ops_mgt"></a>Chapter&nbsp;12.&nbsp;HBase Operational Management</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#tools">12.1. HBase Tools and Utilities</a></span></dt><dd><dl><dt><span class="section"><a href="#hbck">12.1.1. HBase <span class="application">hbck</span></a></span></dt><dt><span class="section"><a href="#hfile_tool2">12.1.2. HFile Tool</a></span></dt><dt><span class="section"><a href="#wal_tools">12.1.3. WAL Tools</a></span></dt><dt><span class="section"><a href="#compression.tool">12.1.4. Compression Tool</a></span></dt><dt><span class="section"><a href="#copytable">12.1.5. CopyTable</a></span></dt><dt><span class="section"><a href="#export">12.1.6. Export</a></span></dt><dt><span class="section"><a href="#import">12.1.7. Import</a></span></dt><dt><span class="section"><a href="#rowcounter">12.1.8. RowCounter</a></span></dt></dl></dd><dt><span class="section"><a href="#node.management">12.2. Node Management</a></span></dt><dd><dl><dt><span class="section"><a href="#decommission">12.2.1. Node Decommission</a></span></dt><dt><span class="section"><a href="#rolling">12.2.2. Rolling Restart</a></span></dt></dl></dd><dt><span class="section"><a href="#hbase_metrics">12.3. Metrics</a></span></dt><dd><dl><dt><span class="section"><a href="#metric_setup">12.3.1. Metric Setup</a></span></dt><dt><span class="section"><a href="#rs_metrics">12.3.2. RegionServer Metrics</a></span></dt></dl></dd><dt><span class="section"><a href="#ops.monitoring">12.4. HBase Monitoring</a></span></dt><dt><span class="section"><a href="#cluster_replication">12.5. Cluster Replication</a></span></dt><dt><span class="section"><a href="#ops.backup">12.6. HBase Backup</a></span></dt><dd><dl><dt><span class="section"><a href="#ops.backup.fullshutdown">12.6.1. Full Shutdown Backup</a></span></dt><dt><span class="section"><a href="#ops.backup.live.replication">12.6.2. Live Cluster Backup - Replication</a></span></dt><dt><span class="section"><a href="#ops.backup.live.copytable">12.6.3. Live Cluster Backup - CopyTable</a></span></dt><dt><span class="section"><a href="#ops.backup.live.export">12.6.4. Live Cluster Backup - Export</a></span></dt></dl></dd><dt><span class="section"><a href="#ops.capacity">12.7. Capacity Planning</a></span></dt><dd><dl><dt><span class="section"><a href="#ops.capacity.storage">12.7.1. Storage</a></span></dt><dt><span class="section"><a href="#ops.capacity.regions">12.7.2. Regions</a></span></dt></dl></dd></dl></div>
  This chapter will cover operational tools and practices required of a running HBase cluster.
  The subject of operations is related to the topics of <a class="xref" href="#trouble" title="Chapter&nbsp;11.&nbsp;Troubleshooting and Debugging HBase">Chapter&nbsp;11, <i>Troubleshooting and Debugging HBase</i></a>, <a class="xref" href="#performance" title="Chapter&nbsp;10.&nbsp;Performance Tuning">Chapter&nbsp;10, <i>Performance Tuning</i></a>,
  and <a class="xref" href="#configuration" title="Chapter&nbsp;2.&nbsp;Configuration">Chapter&nbsp;2, <i>Configuration</i></a> but is a distinct topic in itself.  
  
  <div class="section" title="12.1.&nbsp;HBase Tools and Utilities"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tools"></a>12.1.&nbsp;HBase Tools and Utilities</h2></div></div></div><p>Here we list HBase tools for administration, analysis, fixup, and
    debugging.</p><div class="section" title="12.1.1.&nbsp;HBase hbck"><div class="titlepage"><div><div><h3 class="title"><a name="hbck"></a>12.1.1.&nbsp;HBase <span class="application">hbck</span></h3></div><div><h4 class="subtitle">An <span class="emphasis"><em>fsck</em></span> for your HBase install</h4></div></div></div><p>To run <span class="application">hbck</span> against your HBase cluster run
        </p><pre class="programlisting">$ ./bin/hbase hbck</pre><p>
        At the end of the commands output it prints <span class="emphasis"><em>OK</em></span>
        or <span class="emphasis"><em>INCONSISTENCY</em></span>. If your cluster reports
        inconsistencies, pass <span class="command"><strong>-details</strong></span> to see more detail emitted.
        If inconsistencies, run <span class="command"><strong>hbck</strong></span> a few times because the
        inconsistency may be transient (e.g. cluster is starting up or a region is
        splitting).
        Passing <span class="command"><strong>-fix</strong></span> may correct the inconsistency (This latter
        is an experimental feature).
        </p></div><div class="section" title="12.1.2.&nbsp;HFile Tool"><div class="titlepage"><div><div><h3 class="title"><a name="hfile_tool2"></a>12.1.2.&nbsp;HFile Tool</h3></div></div></div><p>See <a class="xref" href="#hfile_tool" title="8.6.4.2.2.&nbsp;HFile Tool">Section&nbsp;8.6.4.2.2, &#8220;HFile Tool&#8221;</a>.</p></div><div class="section" title="12.1.3.&nbsp;WAL Tools"><div class="titlepage"><div><div><h3 class="title"><a name="wal_tools"></a>12.1.3.&nbsp;WAL Tools</h3></div></div></div><div class="section" title="12.1.3.1.&nbsp;HLog tool"><div class="titlepage"><div><div><h4 class="title"><a name="hlog_tool"></a>12.1.3.1.&nbsp;<code class="classname">HLog</code> tool</h4></div></div></div><p>The main method on <code class="classname">HLog</code> offers manual
        split and dump facilities. Pass it WALs or the product of a split, the
        content of the <code class="filename">recovered.edits</code>. directory.</p><p>You can get a textual dump of a WAL file content by doing the
        following:</p><pre class="programlisting"> <code class="code">$ ./bin/hbase org.apache.hadoop.hbase.regionserver.wal.HLog --dump hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3A60020.1283973724012</code> </pre><p>The
        return code will be non-zero if issues with the file so you can test
        wholesomeness of file by redirecting <code class="varname">STDOUT</code> to
        <code class="code">/dev/null</code> and testing the program return.</p><p>Similarily you can force a split of a log file directory by
        doing:</p><pre class="programlisting"> $ ./<code class="code">bin/hbase org.apache.hadoop.hbase.regionserver.wal.HLog --split hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/</code></pre></div></div><div class="section" title="12.1.4.&nbsp;Compression Tool"><div class="titlepage"><div><div><h3 class="title"><a name="compression.tool"></a>12.1.4.&nbsp;Compression Tool</h3></div></div></div><p>See <a class="xref" href="#compression.tool" title="12.1.4.&nbsp;Compression Tool">Section&nbsp;12.1.4, &#8220;Compression Tool&#8221;</a>.</p></div><div class="section" title="12.1.5.&nbsp;CopyTable"><div class="titlepage"><div><div><h3 class="title"><a name="copytable"></a>12.1.5.&nbsp;CopyTable</h3></div></div></div><p>
            CopyTable is a utility that can copy part or of all of a table, either to the same cluster or another cluster. The usage is as follows:
</p><pre class="programlisting">$ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable [--rs.class=CLASS] [--rs.impl=IMPL] [--starttime=X] [--endtime=Y] [--new.name=NEW] [--peer.adr=ADR] tablename
</pre><p>
        </p><p>
        Options:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><code class="varname">rs.class</code> hbase.regionserver.class of the peer cluster.  Specify if different from current cluster.</li><li class="listitem"><code class="varname">rs.impl</code>  hbase.regionserver.impl of the peer cluster. </li><li class="listitem"><code class="varname">starttime</code>  Beginning of the time range.  Without endtime means starttime to forever.</li><li class="listitem"><code class="varname">endtime</code>  End of the time range.  Without endtime means starttime to forever.</li><li class="listitem"><code class="varname">new.name</code>  New table's name.</li><li class="listitem"><code class="varname">peer.adr</code>  Address of the peer cluster given in the format hbase.zookeeper.quorum:hbase.zookeeper.client.port:zookeeper.znode.parent</li><li class="listitem"><code class="varname">families</code>  Comma-separated list of ColumnFamilies to copy.</li></ul></div><p>
         Args:
        </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">tablename  Name of table to copy.</li></ul></div><p>
        </p><p>Example of copying 'TestTable' to a cluster that uses replication for a 1 hour window:
</p><pre class="programlisting">$ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable
--rs.class=org.apache.hadoop.hbase.ipc.ReplicationRegionInterface
--rs.impl=org.apache.hadoop.hbase.regionserver.replication.ReplicationRegionServer
--starttime=1265875194289 --endtime=1265878794289
--peer.adr=server1,server2,server3:2181:/hbase TestTable</pre><p>
        </p></div><div class="section" title="12.1.6.&nbsp;Export"><div class="titlepage"><div><div><h3 class="title"><a name="export"></a>12.1.6.&nbsp;Export</h3></div></div></div><p>Export is a utility that will dump the contents of table to HDFS in a sequence file.  Invoke via:
</p><pre class="programlisting">$ bin/hbase org.apache.hadoop.hbase.mapreduce.Export &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; [&lt;starttime&gt; [&lt;endtime&gt;]]]
</pre><p>
       </p></div><div class="section" title="12.1.7.&nbsp;Import"><div class="titlepage"><div><div><h3 class="title"><a name="import"></a>12.1.7.&nbsp;Import</h3></div></div></div><p>Import is a utility that will load data that has been exported back into HBase.  Invoke via:
</p><pre class="programlisting">$ bin/hbase org.apache.hadoop.hbase.mapreduce.Import &lt;tablename&gt; &lt;inputdir&gt;
</pre><p>
       </p></div><div class="section" title="12.1.8.&nbsp;RowCounter"><div class="titlepage"><div><div><h3 class="title"><a name="rowcounter"></a>12.1.8.&nbsp;RowCounter</h3></div></div></div><p>RowCounter is a utility that will count all the rows of a table.  This is a good utility to use
       as a sanity check to ensure that HBase can read all the blocks of a table if there are any concerns of metadata inconsistency.
</p><pre class="programlisting">$ bin/hbase org.apache.hadoop.hbase.mapreduce.RowCounter &lt;tablename&gt; [&lt;column1&gt; &lt;column2&gt;...]
</pre><p>
       </p></div></div><div class="section" title="12.2.&nbsp;Node Management"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="node.management"></a>12.2.&nbsp;Node Management</h2></div></div></div><div class="section" title="12.2.1.&nbsp;Node Decommission"><div class="titlepage"><div><div><h3 class="title"><a name="decommission"></a>12.2.1.&nbsp;Node Decommission</h3></div></div></div><p>You can stop an individual RegionServer by running the following
            script in the HBase directory on the particular  node:
            </p><pre class="programlisting">$ ./bin/hbase-daemon.sh stop regionserver</pre><p>
            The RegionServer will first close all regions and then shut itself down.
            On shutdown, the RegionServer's ephemeral node in ZooKeeper will expire.
            The master will notice the RegionServer gone and will treat it as
            a 'crashed' server; it will reassign the nodes the RegionServer was carrying.
            </p><div class="note" title="Disable the Load Balancer before Decommissioning a node" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Disable the Load Balancer before Decommissioning a node</h3><p>If the load balancer runs while a node is shutting down, then
                 there could be contention between the Load Balancer and the
                 Master's recovery of the just decommissioned RegionServer.
                 Avoid any problems by disabling the balancer first.
                 See <a class="xref" href="#lb" title="Load Balancer">Load Balancer</a> below.
             </p></div><p>
        </p><p>
        A downside to the above stop of a RegionServer is that regions could be offline for
        a good period of time.  Regions are closed in order.  If many regions on the server, the
        first region to close may not be back online until all regions close and after the master
        notices the RegionServer's znode gone.  In HBase 0.90.2, we added facility for having
        a node gradually shed its load and then shutdown itself down.  HBase 0.90.2 added the
            <code class="filename">graceful_stop.sh</code> script.  Here is its usage:
            </p><pre class="programlisting">$ ./bin/graceful_stop.sh 
Usage: graceful_stop.sh [--config &amp;conf-dir&gt;] [--restart] [--reload] [--thrift] [--rest] &amp;hostname&gt;
 thrift      If we should stop/start thrift before/after the hbase stop/start
 rest        If we should stop/start rest before/after the hbase stop/start
 restart     If we should restart after graceful stop
 reload      Move offloaded regions back on to the stopped server
 debug       Move offloaded regions back on to the stopped server
 hostname    Hostname of server we are to stop</pre><p>
        </p><p>
            To decommission a loaded RegionServer, run the following:
            </p><pre class="programlisting">$ ./bin/graceful_stop.sh HOSTNAME</pre><p>
            where <code class="varname">HOSTNAME</code> is the host carrying the RegionServer
            you would decommission.  
            </p><div class="note" title="On HOSTNAME" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">On <code class="varname">HOSTNAME</code></h3><p>The <code class="varname">HOSTNAME</code> passed to <code class="filename">graceful_stop.sh</code>
            must match the hostname that hbase is using to identify RegionServers.
            Check the list of RegionServers in the master UI for how HBase is
            referring to servers. Its usually hostname but can also be FQDN.
            Whatever HBase is using, this is what you should pass the
            <code class="filename">graceful_stop.sh</code> decommission
            script.  If you pass IPs, the script is not yet smart enough to make
            a hostname (or FQDN) of it and so it will fail when it checks if server is
            currently running; the graceful unloading of regions will not run.
            </p></div><p> The <code class="filename">graceful_stop.sh</code> script will move the regions off the
            decommissioned RegionServer one at a time to minimize region churn.
            It will verify the region deployed in the new location before it
            will moves the next region and so on until the decommissioned server
            is carrying zero regions.  At this point, the <code class="filename">graceful_stop.sh</code>
            tells the RegionServer <span class="command"><strong>stop</strong></span>.  The master will at this point notice the
            RegionServer gone but all regions will have already been redeployed
            and because the RegionServer went down cleanly, there will be no
            WAL logs to split.
            </p><div class="note" title="Load Balancer" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a name="lb"></a>Load Balancer</h3><p> 
                It is assumed that the Region Load Balancer is disabled while the
                <span class="command"><strong>graceful_stop</strong></span> script runs (otherwise the balancer
                and the decommission script will end up fighting over region deployments).
                Use the shell to disable the balancer:
                </p><pre class="programlisting">hbase(main):001:0&gt; balance_switch false
true
0 row(s) in 0.3590 seconds</pre><p>
This turns the balancer OFF.  To reenable, do:
                </p><pre class="programlisting">hbase(main):001:0&gt; balance_switch true
false
0 row(s) in 0.3590 seconds</pre><p>
            </p></div><p>
        </p></div><div class="section" title="12.2.2.&nbsp;Rolling Restart"><div class="titlepage"><div><div><h3 class="title"><a name="rolling"></a>12.2.2.&nbsp;Rolling Restart</h3></div></div></div><p>
            You can also ask this script to restart a RegionServer after the shutdown
            AND move its old regions back into place.  The latter you might do to
            retain data locality.  A primitive rolling restart might be effected by
            running something like the following:
            </p><pre class="programlisting">$ for i in `cat conf/regionservers|sort`; do ./bin/graceful_stop.sh --restart --reload --debug $i; done &amp;&gt; /tmp/log.txt &amp;
            </pre><p>
            Tail the output of <code class="filename">/tmp/log.txt</code> to follow the scripts
            progress. The above does RegionServers only.  Be sure to disable the
            load balancer before doing the above.  You'd need to do the master
            update separately.  Do it before you run the above script.
            Here is a pseudo-script for how you might craft a rolling restart script:
            </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Untar your release, make sure of its configuration and
                        then rsync it across the cluster. If this is 0.90.2, patch it
                        with HBASE-3744 and HBASE-3756.
                    </p></li><li class="listitem"><p>Run hbck to ensure the cluster consistent
                        </p><pre class="programlisting">$ ./bin/hbase hbck</pre><p>
                    Effect repairs if inconsistent.
                    </p></li><li class="listitem"><p>Restart the Master: </p><pre class="programlisting">$ ./bin/hbase-daemon.sh stop master; ./bin/hbase-daemon.sh start master</pre><p>
                    </p></li><li class="listitem"><p>
                       Disable the region balancer:</p><pre class="programlisting">$ echo "balance_switch false" | ./bin/hbase shell</pre><p>
                    </p></li><li class="listitem"><p>Run the <code class="filename">graceful_stop.sh</code> script per RegionServer.  For example:
            </p><pre class="programlisting">$ for i in `cat conf/regionservers|sort`; do ./bin/graceful_stop.sh --restart --reload --debug $i; done &amp;&gt; /tmp/log.txt &amp;
            </pre><p>
                     If you are running thrift or rest servers on the RegionServer, pass --thrift or --rest options (See usage
                     for <code class="filename">graceful_stop.sh</code> script).
                 </p></li><li class="listitem"><p>Restart the Master again.  This will clear out dead servers list and reenable the balancer.
                    </p></li><li class="listitem"><p>Run hbck to ensure the cluster is consistent.
                    </p></li></ol></div><p>
        </p></div></div><div class="section" title="12.3.&nbsp;Metrics"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="hbase_metrics"></a>12.3.&nbsp;Metrics</h2></div></div></div><div class="section" title="12.3.1.&nbsp;Metric Setup"><div class="titlepage"><div><div><h3 class="title"><a name="metric_setup"></a>12.3.1.&nbsp;Metric Setup</h3></div></div></div><p>See <a class="link" href="http://hbase.apache.org/metrics.html" target="_top">Metrics</a> for
  an introduction and how to enable Metrics emission.
  </p></div><div class="section" title="12.3.2.&nbsp;RegionServer Metrics"><div class="titlepage"><div><div><h3 class="title"><a name="rs_metrics"></a>12.3.2.&nbsp;RegionServer Metrics</h3></div></div></div><div class="section" title="12.3.2.1.&nbsp;hbase.regionserver.blockCacheCount"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.blockCacheCount"></a>12.3.2.1.&nbsp;<code class="varname">hbase.regionserver.blockCacheCount</code></h4></div></div></div><p>Block cache item count in memory.  This is the number of blocks of storefiles (HFiles) in the cache.</p></div><div class="section" title="12.3.2.2.&nbsp;hbase.regionserver.blockCacheFree"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.blockCacheFree"></a>12.3.2.2.&nbsp;<code class="varname">hbase.regionserver.blockCacheFree</code></h4></div></div></div><p>Block cache memory available (bytes).</p></div><div class="section" title="12.3.2.3.&nbsp;hbase.regionserver.blockCacheHitRatio"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.blockCacheHitRatio"></a>12.3.2.3.&nbsp;<code class="varname">hbase.regionserver.blockCacheHitRatio</code></h4></div></div></div><p>Block cache hit ratio (0 to 100).  TODO:  describe impact to ratio where read requests that have cacheBlocks=false</p></div><div class="section" title="12.3.2.4.&nbsp;hbase.regionserver.blockCacheSize"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.blockCacheSize"></a>12.3.2.4.&nbsp;<code class="varname">hbase.regionserver.blockCacheSize</code></h4></div></div></div><p>Block cache size in memory (bytes).  i.e., memory in use by the BlockCache</p></div><div class="section" title="12.3.2.5.&nbsp;hbase.regionserver.compactionQueueSize"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.compactionQueueSize"></a>12.3.2.5.&nbsp;<code class="varname">hbase.regionserver.compactionQueueSize</code></h4></div></div></div><p>Size of the compaction queue.  This is the number of stores in the region that have been targeted for compaction.</p></div><div class="section" title="12.3.2.6.&nbsp;hbase.regionserver.fsReadLatency_avg_time"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsReadLatency_avg_time"></a>12.3.2.6.&nbsp;<code class="varname">hbase.regionserver.fsReadLatency_avg_time</code></h4></div></div></div><p>Filesystem read latency (ms).  This is the average time to read from HDFS.</p></div><div class="section" title="12.3.2.7.&nbsp;hbase.regionserver.fsReadLatency_num_ops"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsReadLatency_num_ops"></a>12.3.2.7.&nbsp;<code class="varname">hbase.regionserver.fsReadLatency_num_ops</code></h4></div></div></div><p>TODO</p></div><div class="section" title="12.3.2.8.&nbsp;hbase.regionserver.fsSyncLatency_avg_time"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsSyncLatency_avg_time"></a>12.3.2.8.&nbsp;<code class="varname">hbase.regionserver.fsSyncLatency_avg_time</code></h4></div></div></div><p>Filesystem sync latency (ms)</p></div><div class="section" title="12.3.2.9.&nbsp;hbase.regionserver.fsSyncLatency_num_ops"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsSyncLatency_num_ops"></a>12.3.2.9.&nbsp;<code class="varname">hbase.regionserver.fsSyncLatency_num_ops</code></h4></div></div></div><p>TODO</p></div><div class="section" title="12.3.2.10.&nbsp;hbase.regionserver.fsWriteLatency_avg_time"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsWriteLatency_avg_time"></a>12.3.2.10.&nbsp;<code class="varname">hbase.regionserver.fsWriteLatency_avg_time</code></h4></div></div></div><p>Filesystem write latency (ms)</p></div><div class="section" title="12.3.2.11.&nbsp;hbase.regionserver.fsWriteLatency_num_ops"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.fsWriteLatency_num_ops"></a>12.3.2.11.&nbsp;<code class="varname">hbase.regionserver.fsWriteLatency_num_ops</code></h4></div></div></div><p>TODO</p></div><div class="section" title="12.3.2.12.&nbsp;hbase.regionserver.memstoreSizeMB"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.memstoreSizeMB"></a>12.3.2.12.&nbsp;<code class="varname">hbase.regionserver.memstoreSizeMB</code></h4></div></div></div><p>Sum of all the memstore sizes in this RegionServer (MB)</p></div><div class="section" title="12.3.2.13.&nbsp;hbase.regionserver.regions"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.regions"></a>12.3.2.13.&nbsp;<code class="varname">hbase.regionserver.regions</code></h4></div></div></div><p>Number of regions served by the RegionServer</p></div><div class="section" title="12.3.2.14.&nbsp;hbase.regionserver.requests"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.requests"></a>12.3.2.14.&nbsp;<code class="varname">hbase.regionserver.requests</code></h4></div></div></div><p>Total number of read and write requests.  Requests correspond to RegionServer RPC calls, thus a single Get will result in 1 request, but a Scan with caching set to 1000 will result in 1 request for each 'next' call (i.e., not each row).  A bulk-load request will constitute 1 request per HFile.</p></div><div class="section" title="12.3.2.15.&nbsp;hbase.regionserver.storeFileIndexSizeMB"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.storeFileIndexSizeMB"></a>12.3.2.15.&nbsp;<code class="varname">hbase.regionserver.storeFileIndexSizeMB</code></h4></div></div></div><p>Sum of all the storefile index sizes in this RegionServer (MB)</p></div><div class="section" title="12.3.2.16.&nbsp;hbase.regionserver.stores"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.stores"></a>12.3.2.16.&nbsp;<code class="varname">hbase.regionserver.stores</code></h4></div></div></div><p>Number of stores open on the RegionServer.  A store corresponds to a column family.  For example, if a table (which contains the column family) has 3 regions on a RegionServer, there will be 3 stores open for that column family. </p></div><div class="section" title="12.3.2.17.&nbsp;hbase.regionserver.storeFiles"><div class="titlepage"><div><div><h4 class="title"><a name="hbase.regionserver.storeFiles"></a>12.3.2.17.&nbsp;<code class="varname">hbase.regionserver.storeFiles</code></h4></div></div></div><p>Number of store filles open on the RegionServer.  A store may have more than one storefile (HFile).</p></div></div></div><div class="section" title="12.4.&nbsp;HBase Monitoring"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ops.monitoring"></a>12.4.&nbsp;HBase Monitoring</h2></div></div></div><p>TODO
    </p></div><div class="section" title="12.5.&nbsp;Cluster Replication"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="cluster_replication"></a>12.5.&nbsp;Cluster Replication</h2></div></div></div><p>See <a class="link" href="http://hbase.apache.org/replication.html" target="_top">Cluster Replication</a>.
    </p></div><div class="section" title="12.6.&nbsp;HBase Backup"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ops.backup"></a>12.6.&nbsp;HBase Backup</h2></div></div></div><p>There are two broad strategies for performing HBase backups: backing up with a full cluster shutdown, and backing up on a live cluster. 
    Each approach has pros and cons.   
    </p><p>For additional information, see <a class="link" href="http://blog.sematext.com/2011/03/11/hbase-backup-options/" target="_top">HBase Backup Options</a> over on the Sematext Blog.
    </p><div class="section" title="12.6.1.&nbsp;Full Shutdown Backup"><div class="titlepage"><div><div><h3 class="title"><a name="ops.backup.fullshutdown"></a>12.6.1.&nbsp;Full Shutdown Backup</h3></div></div></div><p>Some environments can tolerate a periodic full shutdown of their HBase cluster, for example if it is being used a back-end analytic capacity
      and not serving front-end web-pages.  The benefits are that the NameNode/Master are RegionServers are down, so there is no chance of missing
      any in-flight changes to either StoreFiles or metadata.  The obvious con is that the cluster is down.  The steps include:
      </p><div class="section" title="12.6.1.1.&nbsp;Stop HBase"><div class="titlepage"><div><div><h4 class="title"><a name="ops.backup.fullshutdown.stop"></a>12.6.1.1.&nbsp;Stop HBase</h4></div></div></div><p>
        </p></div><div class="section" title="12.6.1.2.&nbsp;Distcp"><div class="titlepage"><div><div><h4 class="title"><a name="ops.backup.fullshutdown.distcp"></a>12.6.1.2.&nbsp;Distcp</h4></div></div></div><p>Distcp could be used to either copy the contents of the HBase directory in HDFS to either the same cluster in another directory, or 
        to a different cluster.
        </p><p>Note:  Distcp works in this situation because the cluster is down and there are no in-flight edits to files.  
        Distcp-ing of files in the HBase directory is not generally recommended on a live cluster.
        </p></div><div class="section" title="12.6.1.3.&nbsp;Restore (if needed)"><div class="titlepage"><div><div><h4 class="title"><a name="ops.backup.fullshutdown.restore"></a>12.6.1.3.&nbsp;Restore (if needed)</h4></div></div></div><p>The backup of the hbase directory from HDFS is copied onto the 'real' hbase directory via distcp.  The act of copying these files 
        creates new HDFS metadata, which is why a restore of the NameNode edits from the time of the HBase backup isn't required for this kind of
        restore, because it's a restore (via distcp) of a specific HDFS directory (i.e., the HBase part) not the entire HDFS file-system.
        </p></div></div><div class="section" title="12.6.2.&nbsp;Live Cluster Backup - Replication"><div class="titlepage"><div><div><h3 class="title"><a name="ops.backup.live.replication"></a>12.6.2.&nbsp;Live Cluster Backup - Replication</h3></div></div></div><p>This approach assumes that there is a second cluster.  
      See the HBase page on <a class="link" href="http://hbase.apache.org/replication.html" target="_top">replication</a> for more information.
      </p></div><div class="section" title="12.6.3.&nbsp;Live Cluster Backup - CopyTable"><div class="titlepage"><div><div><h3 class="title"><a name="ops.backup.live.copytable"></a>12.6.3.&nbsp;Live Cluster Backup - CopyTable</h3></div></div></div><p>The <a class="xref" href="#copytable" title="12.1.5.&nbsp;CopyTable">Section&nbsp;12.1.5, &#8220;CopyTable&#8221;</a> utility could either be used to copy data from one table to another on the 
      same cluster, or to copy data to another table on another cluster.
      </p><p>Since the cluster is up, there is a risk that edits could be missed in the copy process.
      </p></div><div class="section" title="12.6.4.&nbsp;Live Cluster Backup - Export"><div class="titlepage"><div><div><h3 class="title"><a name="ops.backup.live.export"></a>12.6.4.&nbsp;Live Cluster Backup - Export</h3></div></div></div><p>The <a class="xref" href="#export" title="12.1.6.&nbsp;Export">Section&nbsp;12.1.6, &#8220;Export&#8221;</a> approach dumps the content of a table to HDFS on the same cluster.  To restore the data, the
      <a class="xref" href="#import" title="12.1.7.&nbsp;Import">Section&nbsp;12.1.7, &#8220;Import&#8221;</a> utility would be used.
      </p><p>Since the cluster is up, there is a risk that edits could be missed in the export process.
      </p></div></div><div class="section" title="12.7.&nbsp;Capacity Planning"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ops.capacity"></a>12.7.&nbsp;Capacity Planning</h2></div></div></div><div class="section" title="12.7.1.&nbsp;Storage"><div class="titlepage"><div><div><h3 class="title"><a name="ops.capacity.storage"></a>12.7.1.&nbsp;Storage</h3></div></div></div><p>A common question for HBase administrators is estimating how much storage will be required for an HBase cluster.
      There are several apsects to consider, the most important of which is what data load into the cluster.  Start
      with a solid understanding of how HBase handles data internally (KeyValue).
      </p><div class="section" title="12.7.1.1.&nbsp;KeyValue"><div class="titlepage"><div><div><h4 class="title"><a name="ops.capacity.storage.kv"></a>12.7.1.1.&nbsp;KeyValue</h4></div></div></div><p>HBase storage will be dominated by KeyValues.  See <a class="xref" href="#keyvalue" title="8.6.4.4.&nbsp;KeyValue">Section&nbsp;8.6.4.4, &#8220;KeyValue&#8221;</a> and <a class="xref" href="#keysize" title="6.3.2.&nbsp;Try to minimize row and column sizes">Section&nbsp;6.3.2, &#8220;Try to minimize row and column sizes&#8221;</a> for 
        how HBase stores data internally.  
        </p><p>It is critical to understand that there is a KeyValue instance for every attribute stored in a row, and the 
        rowkey-length, ColumnFamily name-length and attribute lengths will drive the size of the database more than any other
        factor.
        </p></div><div class="section" title="12.7.1.2.&nbsp;StoreFiles and Blocks"><div class="titlepage"><div><div><h4 class="title"><a name="ops.capacity.storage.sf"></a>12.7.1.2.&nbsp;StoreFiles and Blocks</h4></div></div></div><p>KeyValue instances are aggregated into blocks, and the blocksize is configurable on a per-ColumnFamily basis.
        Blocks are aggregated into StoreFile's.  See <a class="xref" href="#regions.arch" title="8.6.&nbsp;Regions">Section&nbsp;8.6, &#8220;Regions&#8221;</a>.
        </p></div><div class="section" title="12.7.1.3.&nbsp;HDFS Block Replication"><div class="titlepage"><div><div><h4 class="title"><a name="ops.capacity.storage.hdfs"></a>12.7.1.3.&nbsp;HDFS Block Replication</h4></div></div></div><p>Because HBase runs on top of HDFS, factor in HDFS block replication into storage calculations.
        </p></div></div><div class="section" title="12.7.2.&nbsp;Regions"><div class="titlepage"><div><div><h3 class="title"><a name="ops.capacity.regions"></a>12.7.2.&nbsp;Regions</h3></div></div></div><p>Another common question for HBase administrators is determining the right number of regions per
      RegionServer.  This affects both storage and hardware planning. See <a class="xref" href="#perf.number.of.regions" title="10.4.1.&nbsp;Number of Regions">Section&nbsp;10.4.1, &#8220;Number of Regions&#8221;</a>.
      </p></div></div></div><div class="chapter" title="Chapter&nbsp;13.&nbsp;Building and Developing HBase"><div class="titlepage"><div><div><h2 class="title"><a name="developer"></a>Chapter&nbsp;13.&nbsp;Building and Developing HBase</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#repos">13.1. HBase Repositories</a></span></dt><dd><dl><dt><span class="section"><a href="#svn">13.1.1. SVN</a></span></dt><dt><span class="section"><a href="#git">13.1.2. Git</a></span></dt></dl></dd><dt><span class="section"><a href="#ides">13.2. IDEs</a></span></dt><dd><dl><dt><span class="section"><a href="#eclipse">13.2.1. Eclipse</a></span></dt></dl></dd><dt><span class="section"><a href="#build">13.3. Building HBase</a></span></dt><dd><dl><dt><span class="section"><a href="#build.snappy">13.3.1. Building in snappy compression support</a></span></dt><dt><span class="section"><a href="#mvn_repo">13.3.2. Adding an HBase release to Apache's Maven Repository</a></span></dt></dl></dd><dt><span class="section"><a href="#maven.build.commands">13.4. Maven Build Commands</a></span></dt><dd><dl><dt><span class="section"><a href="#maven.build.commands.compile">13.4.1. Compile</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unitall">13.4.2. Run all Unit Tests</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit">13.4.3. Run a Single Unit Test</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit2">13.4.4. Run a Few Unit Tests</a></span></dt><dt><span class="section"><a href="#maven.build.commands.unit.package">13.4.5. Run all Unit Tests for a Package</a></span></dt><dt><span class="section"><a href="#maven.build.commanas.integration.tests">13.4.6. Integration Tests</a></span></dt></dl></dd><dt><span class="section"><a href="#getting.involved">13.5. Getting Involved</a></span></dt><dd><dl><dt><span class="section"><a href="#mailing.list">13.5.1. Mailing Lists</a></span></dt><dt><span class="section"><a href="#jira">13.5.2. Jira</a></span></dt></dl></dd><dt><span class="section"><a href="#developing">13.6. Developing</a></span></dt><dd><dl><dt><span class="section"><a href="#codelines">13.6.1. Codelines</a></span></dt><dt><span class="section"><a href="#unit.tests">13.6.2. Unit Tests</a></span></dt></dl></dd><dt><span class="section"><a href="#submitting.patches">13.7. Submitting Patches</a></span></dt><dd><dl><dt><span class="section"><a href="#submitting.patches.create">13.7.1. Create Patch</a></span></dt><dt><span class="section"><a href="#submitting.patches.naming">13.7.2. Patch File Naming</a></span></dt><dt><span class="section"><a href="#submitting.patches.tests">13.7.3. Unit Tests</a></span></dt><dt><span class="section"><a href="#submitting.patches.jira">13.7.4. Attach Patch to Jira</a></span></dt><dt><span class="section"><a href="#common.patch.feedback">13.7.5. Common Patch Feedback</a></span></dt><dt><span class="section"><a href="#reviewboard">13.7.6. ReviewBoard</a></span></dt><dt><span class="section"><a href="#committing.patches">13.7.7. Committing Patches</a></span></dt></dl></dd></dl></div><p>This chapter will be of interest only to those building and developing HBase (i.e., as opposed to
    just downloading the latest distribution).
    </p><div class="section" title="13.1.&nbsp;HBase Repositories"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="repos"></a>13.1.&nbsp;HBase Repositories</h2></div></div></div><div class="section" title="13.1.1.&nbsp;SVN"><div class="titlepage"><div><div><h3 class="title"><a name="svn"></a>13.1.1.&nbsp;SVN</h3></div></div></div><pre class="programlisting">
svn co http://svn.apache.org/repos/asf/hbase/trunk hbase-core-trunk 
        </pre></div><div class="section" title="13.1.2.&nbsp;Git"><div class="titlepage"><div><div><h3 class="title"><a name="git"></a>13.1.2.&nbsp;Git</h3></div></div></div><pre class="programlisting">
git clone git://git.apache.org/hbase.git
        </pre></div></div><div class="section" title="13.2.&nbsp;IDEs"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ides"></a>13.2.&nbsp;IDEs</h2></div></div></div><div class="section" title="13.2.1.&nbsp;Eclipse"><div class="titlepage"><div><div><h3 class="title"><a name="eclipse"></a>13.2.1.&nbsp;Eclipse</h3></div></div></div><div class="section" title="13.2.1.1.&nbsp;Code Formatting"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.code.formatting"></a>13.2.1.1.&nbsp;Code Formatting</h4></div></div></div><p>See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-3678" target="_top">HBASE-3678 Add Eclipse-based Apache Formatter to HBase Wiki</a>
              for an Eclipse formatter to help ensure your code conforms to HBase'y coding convention.
            The issue includes instructions for loading the attached formatter.</p><p>Also, no @author tags - that's a rule.  Quality Javadoc comments are appreciated.  And include the Apache license.</p></div><div class="section" title="13.2.1.2.&nbsp;Subversive Plugin"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.svn"></a>13.2.1.2.&nbsp;Subversive Plugin</h4></div></div></div><p>Download and install the Subversive plugin.</p><p>Set up an SVN Repository target from <a class="xref" href="#svn" title="13.1.1.&nbsp;SVN">Section&nbsp;13.1.1, &#8220;SVN&#8221;</a>, then check out the code.</p></div><div class="section" title="13.2.1.3.&nbsp;HBase Project Setup"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.maven.setup"></a>13.2.1.3.&nbsp;HBase Project Setup</h4></div></div></div>
            To set up your Eclipse environment for HBase, close Eclipse and execute...
            <pre class="programlisting">
mvn eclipse:eclipse
            </pre>
            ... from your local HBase project directory in your workspace to generate some new <code class="filename">.project</code> 
            and <code class="filename">.classpath</code>files.  Then reopen Eclipse.
            </div><div class="section" title="13.2.1.4.&nbsp;Maven Plugin"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.maven.plugin"></a>13.2.1.4.&nbsp;Maven Plugin</h4></div></div></div><p>Download and install the Maven plugin.  For example, Help -&gt; Install New Software -&gt; (search for Maven Plugin)</p></div><div class="section" title="13.2.1.5.&nbsp;Maven Classpath Variable"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.maven.class"></a>13.2.1.5.&nbsp;Maven Classpath Variable</h4></div></div></div><p>The <code class="varname">M2_REPO</code> classpath variable needs to be set up for the project.  This needs to be set to 
            your local Maven repository, which is usually <code class="filename">~/.m2/repository</code></p>
            If this classpath variable is not configured, you will see compile errors in Eclipse like this...
            <pre class="programlisting">
Description	Resource	Path	Location	Type
The project cannot be built until build path errors are resolved	hbase		Unknown	Java Problem 
Unbound classpath variable: 'M2_REPO/asm/asm/3.1/asm-3.1.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar' in project 'hbase'	hbase		Build path	Build Path Problem 
Unbound classpath variable: 'M2_REPO/com/google/guava/guava/r09/guava-r09.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/google/protobuf/protobuf-java/2.3.0/protobuf-java-2.3.0.jar' in project 'hbase'	hbase		Build path	Build Path Problem Unbound classpath variable:
            </pre></div><div class="section" title="13.2.1.6.&nbsp;Import via m2eclipse"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.m2eclipse"></a>13.2.1.6.&nbsp;Import via m2eclipse</h4></div></div></div><p>If you install the m2eclipse and import the HBase pom.xml in your workspace, you will have to fix your eclipse Build Path.
            Remove <code class="filename">target</code> folder, add <code class="filename">target/generated-jamon</code>
            and <code class="filename">target/generated-sources/java</code> folders. You may also remove from your Build Path
            the exclusions on the <code class="filename">src/main/resources</code> and <code class="filename">src/test/resources</code>
            to avoid error message in the console 'Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (default) on project hbase: 
            'An Ant BuildException has occured: Replace: source file .../target/classes/hbase-default.xml doesn't exist'. This will also
            reduce the eclipse build cycles and make your life easier when developing.</p></div><div class="section" title="13.2.1.7.&nbsp;Eclipse Known Issues"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.issues"></a>13.2.1.7.&nbsp;Eclipse Known Issues</h4></div></div></div><p>Eclipse will currently complain about <code class="filename">Bytes.java</code>.  It is not possible to turn these errors off.</p><pre class="programlisting">            
Description	Resource	Path	Location	Type
Access restriction: The method arrayBaseOffset(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1061	Java Problem
Access restriction: The method arrayIndexScale(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1064	Java Problem
Access restriction: The method getLong(Object, long) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1111	Java Problem
             </pre></div><div class="section" title="13.2.1.8.&nbsp;Eclipse - More Information"><div class="titlepage"><div><div><h4 class="title"><a name="eclipse.more"></a>13.2.1.8.&nbsp;Eclipse - More Information</h4></div></div></div><p>For additional information on setting up Eclipse for HBase development on Windows, see 
             <a class="link" href="http://michaelmorello.blogspot.com/2011/09/hbase-subversion-eclipse-windows.html" target="_top">Michael Morello's blog</a> on the topic.
             </p></div></div></div><div class="section" title="13.3.&nbsp;Building HBase"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="build"></a>13.3.&nbsp;Building HBase</h2></div></div></div><p>This section will be of interest only to those building HBase from source.
      </p><div class="section" title="13.3.1.&nbsp;Building in snappy compression support"><div class="titlepage"><div><div><h3 class="title"><a name="build.snappy"></a>13.3.1.&nbsp;Building in snappy compression support</h3></div></div></div><p>Pass <code class="code">-Dsnappy</code> to trigger the snappy maven profile for building
            snappy native libs into hbase.</p></div><div class="section" title="13.3.2.&nbsp;Adding an HBase release to Apache's Maven Repository"><div class="titlepage"><div><div><h3 class="title"><a name="mvn_repo"></a>13.3.2.&nbsp;Adding an HBase release to Apache's Maven Repository</h3></div></div></div><p>Follow the instructions at
        <a class="link" href="http://www.apache.org/dev/publishing-maven-artifacts.html" target="_top">Publishing Maven Artifacts</a>.
            The 'trick' to making it all work is answering the questions put to you by the mvn release plugin properly,
            making sure it is using the actual branch AND before doing the <span class="command"><strong>mvn release:perform</strong></span> step,
            VERY IMPORTANT, hand edit the release.properties file that was put under <code class="varname">${HBASE_HOME}</code>
            by the previous step, <span class="command"><strong>release:perform</strong></span>. You need to edit it to make it point at
            right locations in SVN.
        </p><p>If you see run into the below, its because you need to edit version in the pom.xml and add
        <code class="code">-SNAPSHOT</code> to the version (and commit).
        </p><pre class="programlisting">[INFO] Scanning for projects...
[INFO] Searching repository for plugin with prefix: 'release'.
[INFO] ------------------------------------------------------------------------
[INFO] Building HBase
[INFO]    task-segment: [release:prepare] (aggregator-style)
[INFO] ------------------------------------------------------------------------
[INFO] [release:prepare {execution: default-cli}]
[INFO] ------------------------------------------------------------------------
[ERROR] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] You don't have a SNAPSHOT project in the reactor projects list.
[INFO] ------------------------------------------------------------------------
[INFO] For more information, run Maven with the -e switch
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3 seconds
[INFO] Finished at: Sat Mar 26 18:11:07 PDT 2011
[INFO] Final Memory: 35M/423M
[INFO] -----------------------------------------------------------------------</pre><p>
        </p></div></div><div class="section" title="13.4.&nbsp;Maven Build Commands"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="maven.build.commands"></a>13.4.&nbsp;Maven Build Commands</h2></div></div></div><p>All commands executed from the local HBase project directory.
       </p><p>Note: use Maven 3 (Maven 2 may work but we suggest you use Maven 3).
       </p><div class="section" title="13.4.1.&nbsp;Compile"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.compile"></a>13.4.1.&nbsp;Compile</h3></div></div></div><pre class="programlisting">
mvn compile
          </pre></div><div class="section" title="13.4.2.&nbsp;Run all Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.unitall"></a>13.4.2.&nbsp;Run all Unit Tests</h3></div></div></div><pre class="programlisting">
mvn test
          </pre></div><div class="section" title="13.4.3.&nbsp;Run a Single Unit Test"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.unit"></a>13.4.3.&nbsp;Run a Single Unit Test</h3></div></div></div><pre class="programlisting">
mvn test -Dtest=TestXYZ
          </pre></div><div class="section" title="13.4.4.&nbsp;Run a Few Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.unit2"></a>13.4.4.&nbsp;Run a Few Unit Tests</h3></div></div></div><pre class="programlisting">
mvn test -Dtest=TestXYZ,TestABC
          </pre></div><div class="section" title="13.4.5.&nbsp;Run all Unit Tests for a Package"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commands.unit.package"></a>13.4.5.&nbsp;Run all Unit Tests for a Package</h3></div></div></div><pre class="programlisting">
mvn test -Dtest=org.apache.hadoop.hbase.client.*
          </pre></div><div class="section" title="13.4.6.&nbsp;Integration Tests"><div class="titlepage"><div><div><h3 class="title"><a name="maven.build.commanas.integration.tests"></a>13.4.6.&nbsp;Integration Tests</h3></div></div></div><p>HBase 0.92 added a <code class="varname">verify</code> maven target. Invoking it with run all the phases up to and including the verify phase via the maven <a class="link" href="http://maven.apache.org/plugins/maven-failsafe-plugin/" target="_top">failsafe plugin</a>, running all the unit tests as well as the long running unit and integration tests.
          </p><pre class="programlisting">
mvn verify
          </pre></div></div><div class="section" title="13.5.&nbsp;Getting Involved"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="getting.involved"></a>13.5.&nbsp;Getting Involved</h2></div></div></div><p>HBase gets better only when people contribute!
        </p><p>As HBase is an Apache Software Foundation project, see <a class="xref" href="#asf" title="Appendix&nbsp;E.&nbsp;HBase and the Apache Software Foundation">Appendix&nbsp;E, <i>HBase and the Apache Software Foundation</i></a> for more information about how the ASF functions.
        </p><div class="section" title="13.5.1.&nbsp;Mailing Lists"><div class="titlepage"><div><div><h3 class="title"><a name="mailing.list"></a>13.5.1.&nbsp;Mailing Lists</h3></div></div></div><p>Sign up for the dev-list and the user-list.  See the 
          <a class="link" href="http://hbase.apache.org/mail-lists.html" target="_top">mailing lists</a> page.
          Posing questions - and helping to answer other people's questions - is encouraged!  
          There are varying levels of experience on both lists so patience and politeness are encouraged (and please 
          stay on topic.)  
          </p></div><div class="section" title="13.5.2.&nbsp;Jira"><div class="titlepage"><div><div><h3 class="title"><a name="jira"></a>13.5.2.&nbsp;Jira</h3></div></div></div><p>Check for existing issues in <a class="link" href="https://issues.apache.org/jira/browse/HBASE" target="_top">Jira</a>.  
          If it's either a new feature request, enhancement, or a bug, file a ticket.
          </p><div class="section" title="13.5.2.1.&nbsp;Jira Priorities"><div class="titlepage"><div><div><h4 class="title"><a name="jira.priorities"></a>13.5.2.1.&nbsp;Jira Priorities</h4></div></div></div><p>The following is a guideline on setting Jira issue priorities:
                </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">Blocker: Should only be used if the issue WILL cause data loss or cluster instability reliably.</li><li class="listitem">Critical: The issue described can cause data loss or cluster instability in some cases.</li><li class="listitem">Major: Important but not tragic issues, like updates to the client API that will add a lot of much-needed functionality or significant
                bugs that need to be fixed but that don't cause data loss.</li><li class="listitem">Minor: Useful enhancements and annoying but not damaging bugs.</li><li class="listitem">Trivial: Useful enhancements but generally cosmetic.</li></ul></div><p>  
             </p></div><div class="section" title="13.5.2.2.&nbsp;Code Blocks in Jira Comments"><div class="titlepage"><div><div><h4 class="title"><a name="submitting.patches.jira.code"></a>13.5.2.2.&nbsp;Code Blocks in Jira Comments</h4></div></div></div><p>A commonly used macro in Jira is {code}. If you do this in a Jira comment...
</p><pre class="programlisting">
{code}
   code snippet
{code}
</pre><p>
              ... Jira will format the code snippet like code, instead of a regular comment.  It improves readability.
          </p></div></div></div><div class="section" title="13.6.&nbsp;Developing"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="developing"></a>13.6.&nbsp;Developing</h2></div></div></div><div class="section" title="13.6.1.&nbsp;Codelines"><div class="titlepage"><div><div><h3 class="title"><a name="codelines"></a>13.6.1.&nbsp;Codelines</h3></div></div></div><p>Most development is done on TRUNK.  However, there are branches for minor releases (e.g., 0.90.1, 0.90.2, and 0.90.3 are on the 0.90 branch).</p><p>If you have any questions on this just send an email to the dev dist-list.</p></div><div class="section" title="13.6.2.&nbsp;Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="unit.tests"></a>13.6.2.&nbsp;Unit Tests</h3></div></div></div><p>In HBase we use <a class="link" href="http://junit.org" target="_top">JUnit</a> 4.
            If you need to run miniclusters of HDFS, ZooKeeper, HBase, or MapReduce testing,
            be sure to checkout the <code class="classname">HBaseTestingUtility</code>.
            Alex Baranau of Sematext describes how it can be used in
            <a class="link" href="http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/" target="_top">HBase Case-Study: Using HBaseTestingUtility for Local Testing and Development</a> (2010).
          </p><div class="section" title="13.6.2.1.&nbsp;Mockito"><div class="titlepage"><div><div><h4 class="title"><a name="mockito"></a>13.6.2.1.&nbsp;Mockito</h4></div></div></div><p>Sometimes you don't need a full running server
              unit testing.  For example, some methods can make do with a
              a <code class="classname">org.apache.hadoop.hbase.Server</code> instance
              or a <code class="classname">org.apache.hadoop.hbase.master.MasterServices</code>
              Interface reference rather than a full-blown
              <code class="classname">org.apache.hadoop.hbase.master.HMaster</code>.
              In these cases, you maybe able to get away with a mocked
              <code class="classname">Server</code> instance.  For example:
              </p><pre class="programlisting">
              TODO...
              </pre><p>
           </p></div><div class="section" title="13.6.2.2.&nbsp;Code Standards"><div class="titlepage"><div><div><h4 class="title"><a name="code.standards"></a>13.6.2.2.&nbsp;Code Standards</h4></div></div></div><p>See <a class="xref" href="#eclipse.code.formatting" title="13.2.1.1.&nbsp;Code Formatting">Section&nbsp;13.2.1.1, &#8220;Code Formatting&#8221;</a> and <a class="xref" href="#common.patch.feedback" title="13.7.5.&nbsp;Common Patch Feedback">Section&nbsp;13.7.5, &#8220;Common Patch Feedback&#8221;</a>.
           </p></div></div></div><div class="section" title="13.7.&nbsp;Submitting Patches"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="submitting.patches"></a>13.7.&nbsp;Submitting Patches</h2></div></div></div><div class="section" title="13.7.1.&nbsp;Create Patch"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.create"></a>13.7.1.&nbsp;Create Patch</h3></div></div></div><p>Patch files can be easily generated from Eclipse, for example by selecting "Team -&gt; Create Patch".
          Patches can also be created by git diff and svn diff.
          </p><p>Please submit one patch-file per Jira.  For example, if multiple files are changed make sure the 
          selected resource when generating the patch is a directory.  Patch files can reflect changes in multiple files. </p><p>Make sure you review <a class="xref" href="#eclipse.code.formatting" title="13.2.1.1.&nbsp;Code Formatting">Section&nbsp;13.2.1.1, &#8220;Code Formatting&#8221;</a> for code style. </p></div><div class="section" title="13.7.2.&nbsp;Patch File Naming"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.naming"></a>13.7.2.&nbsp;Patch File Naming</h3></div></div></div><p>The patch file should have the HBase Jira ticket in the name.  For example, if a patch was submitted for <code class="filename">Foo.java</code>, then
          a patch file called <code class="filename">Foo_HBASE_XXXX.patch</code> would be acceptable where XXXX is the HBase Jira number.
          </p><p>If you generating from a branch, then including the target branch in the filename is advised, e.g., <code class="filename">HBASE-XXXX-0.90.patch</code>.
          </p></div><div class="section" title="13.7.3.&nbsp;Unit Tests"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.tests"></a>13.7.3.&nbsp;Unit Tests</h3></div></div></div><p>Yes, please.  Please try to include unit tests with every code patch (and especially new classes and large changes).
            Make sure unit tests pass locally before submitting the patch.</p><p>Also, see <a class="xref" href="#mockito" title="13.6.2.1.&nbsp;Mockito">Section&nbsp;13.6.2.1, &#8220;Mockito&#8221;</a>.</p></div><div class="section" title="13.7.4.&nbsp;Attach Patch to Jira"><div class="titlepage"><div><div><h3 class="title"><a name="submitting.patches.jira"></a>13.7.4.&nbsp;Attach Patch to Jira</h3></div></div></div><p>The patch should be attached to the associated Jira ticket "More Actions -&gt; Attach Files".  Make sure you click the
            ASF license inclusion, otherwise the patch can't be considered for inclusion.
            </p><p>Once attached to the ticket, click "Submit Patch" and 
            the status of the ticket will change.  Committers will review submitted patches for inclusion into the codebase.  Please
            understand that not every patch may get committed, and that feedback will likely be provided on the patch.  Fear not, though,
            because the HBase community is helpful!
            </p></div><div class="section" title="13.7.5.&nbsp;Common Patch Feedback"><div class="titlepage"><div><div><h3 class="title"><a name="common.patch.feedback"></a>13.7.5.&nbsp;Common Patch Feedback</h3></div></div></div><p>The following items are representative of common patch feedback. Your patch process will go faster if these are
          taken into account <span class="emphasis"><em>before</em></span> submission.
          </p><p>
          See the <a class="link" href="http://www.oracle.com/technetwork/java/codeconv-138413.html" target="_top">Java coding standards</a> 
          for more information on coding conventions in Java.
          </p><div class="section" title="13.7.5.1.&nbsp;Space Invaders"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.space.invaders"></a>13.7.5.1.&nbsp;Space Invaders</h4></div></div></div><p>Rather than do this...
</p><pre class="programlisting">
if ( foo.equals( bar ) ) {     // don't do this
</pre><p>
			... do this instead...        
</p><pre class="programlisting">
if (foo.equals(bar)) {
</pre><p>
          </p><p>Also, rather than do this...
</p><pre class="programlisting">
foo = barArray[ i ];     // don't do this
</pre><p>
			... do this instead...        
</p><pre class="programlisting">
foo = barArray[i];   
</pre><p>
          </p></div><div class="section" title="13.7.5.2.&nbsp;Auto Generated Code"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.autogen"></a>13.7.5.2.&nbsp;Auto Generated Code</h4></div></div></div><p>Auto-generated code in Eclipse often looks like this...
</p><pre class="programlisting">
 public void readFields(DataInput arg0) throws IOException {    // don't do this
   foo = arg0.readUTF();                                       // don't do this
</pre><p>
			... do this instead ...        
</p><pre class="programlisting">
 public void readFields(DataInput di) throws IOException {
   foo = di.readUTF();
</pre><p>
           See the difference?  'arg0' is what Eclipse uses for arguments by default.
           </p></div><div class="section" title="13.7.5.3.&nbsp;Long Lines"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.longlines"></a>13.7.5.3.&nbsp;Long Lines</h4></div></div></div><p>
            Keep lines less than 80 characters.
</p><pre class="programlisting">
Bar bar = foo.veryLongMethodWithManyArguments(argument1, argument2, argument3, argument4, argument5);  // don't do this
</pre><p>
			... do this instead ...        
</p><pre class="programlisting">
Bar bar = foo.veryLongMethodWithManyArguments(argument1,
 argument2, argument3,argument4, argument5); 
</pre><p>
           ... or this, whichever looks better ...
</p><pre class="programlisting">
Bar bar = foo.veryLongMethodWithManyArguments(
 argument1, argument2, argument3,argument4, argument5); 
</pre><p>
           </p></div><div class="section" title="13.7.5.4.&nbsp;Trailing Spaces"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.trailingspaces"></a>13.7.5.4.&nbsp;Trailing Spaces</h4></div></div></div><p>
            This happens more than people would imagine.
</p><pre class="programlisting">
Bar bar = foo.getBar();     &lt;--- imagine there's an extra space(s) after the semicolon instead of a line break.
</pre><p>
            Make sure there's a line-break after the end of your code, and also avoid lines that have nothing
            but whitespace. 
            </p></div><div class="section" title="13.7.5.5.&nbsp;Implementing Writable"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.writable"></a>13.7.5.5.&nbsp;Implementing Writable</h4></div></div></div><p>Every class returned by RegionServers must implement <code class="code">Writable</code>.  If you
            are creating a new class that needs to implement this interface, don't forget the default constructor.
            </p></div><div class="section" title="13.7.5.6.&nbsp;Javadoc"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.javadoc"></a>13.7.5.6.&nbsp;Javadoc</h4></div></div></div><p>This is also a very common feedback item.  Don't forget Javadoc!
            </p></div><div class="section" title="13.7.5.7.&nbsp;Javadoc - Useless Defaults"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.javadoc.defaults"></a>13.7.5.7.&nbsp;Javadoc - Useless Defaults</h4></div></div></div><p>Don't just leave the @param arguments the way your IDE generated them.  Don't do this...
</p><pre class="programlisting">
  /**
   * 
   * @param bar             &lt;---- don't do this!!!!
   * @return                &lt;---- or this!!!!
   */
  public Foo getFoo(Bar bar);
</pre><p> 
            ... either add something descriptive to the @param and @return lines, or just remove them. 
            But the preference is to add something descriptive and useful.          
            </p></div><div class="section" title="13.7.5.8.&nbsp;One Thing At A Time, Folks"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.onething"></a>13.7.5.8.&nbsp;One Thing At A Time, Folks</h4></div></div></div><p>If you submit a patch for one thing, don't do auto-reformatting or unrelated reformatting of code on a completely
            different area of code. 
            </p><p>Likewise, don't add unrelated cleanup or refactorings outside the scope of your Jira. 
            </p></div><div class="section" title="13.7.5.9.&nbsp;Ambigious Unit Tests"><div class="titlepage"><div><div><h4 class="title"><a name="common.patch.feedback.tests"></a>13.7.5.9.&nbsp;Ambigious Unit Tests</h4></div></div></div><p>Make sure that you're clear about what you are testing in your unit tests and why. 
            </p></div></div><div class="section" title="13.7.6.&nbsp;ReviewBoard"><div class="titlepage"><div><div><h3 class="title"><a name="reviewboard"></a>13.7.6.&nbsp;ReviewBoard</h3></div></div></div><p>Larger patches should go through <a class="link" href="http://reviews.apache.org" target="_top">ReviewBoard</a>.
          </p><p>For more information on how to use ReviewBoard, see
           <a class="link" href="http://www.reviewboard.org/docs/manual/1.5/" target="_top">the ReviewBoard documentation</a>.
          </p></div><div class="section" title="13.7.7.&nbsp;Committing Patches"><div class="titlepage"><div><div><h3 class="title"><a name="committing.patches"></a>13.7.7.&nbsp;Committing Patches</h3></div></div></div><p>
          Committers do this.  See <a class="link" href="http://wiki.apache.org/hadoop/Hbase/HowToCommit" target="_top">How To Commit</a> in the HBase wiki.
          </p><p>Commiters will also resolve the Jira, typically after the patch passes a build.
          </p></div></div></div><div class="appendix" title="Appendix&nbsp;A.&nbsp;Compression In HBase"><div class="titlepage"><div><div><h2 class="title"><a name="compression"></a>Appendix&nbsp;A.&nbsp;Compression In HBase<a class="indexterm" name="d0e7421"></a></h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#compression.test">A.1. CompressionTest Tool</a></span></dt><dt><span class="section"><a href="#hbase.regionserver.codecs">A.2. 
    <code class="varname">
    hbase.regionserver.codecs
    </code>
    </a></span></dt><dt><span class="section"><a href="#lzo.compression">A.3. 
    LZO
    </a></span></dt><dt><span class="section"><a href="#gzip.compression">A.4. 
    GZIP
    </a></span></dt><dt><span class="section"><a href="#snappy.compression">A.5. 
    SNAPPY
    </a></span></dt></dl></div><div class="section" title="A.1.&nbsp;CompressionTest Tool"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="compression.test"></a>A.1.&nbsp;CompressionTest Tool</h2></div></div></div><p>
    HBase includes a tool to test compression is set up properly.
    To run it, type <code class="code">/bin/hbase org.apache.hadoop.hbase.util.CompressionTest</code>. 
    This will emit usage on how to run the tool.
    </p></div><div class="section" title="A.2.&nbsp; hbase.regionserver.codecs"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="hbase.regionserver.codecs"></a>A.2.&nbsp;
    <code class="varname">
    hbase.regionserver.codecs
    </code>
    </h2></div></div></div><p>
    To have a RegionServer test a set of codecs and fail-to-start if any
    code is missing or misinstalled, add the configuration
    <code class="varname">
    hbase.regionserver.codecs
    </code>
    to your <code class="filename">hbase-site.xml</code> with a value of
    codecs to test on startup.  For example if the 
    <code class="varname">
    hbase.regionserver.codecs
    </code> value is <code class="code">lzo,gz</code> and if lzo is not present
    or improperly installed, the misconfigured RegionServer will fail
    to start.
    </p><p>
    Administrators might make use of this facility to guard against
    the case where a new server is added to cluster but the cluster
    requires install of a particular coded.
    </p></div><div class="section" title="A.3.&nbsp; LZO"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="lzo.compression"></a>A.3.&nbsp;
    LZO
    </h2></div></div></div><p>Unfortunately, HBase cannot ship with LZO because of
      the licensing issues; HBase is Apache-licensed, LZO is GPL.
      Therefore LZO install is to be done post-HBase install.
      See the <a class="link" href="http://wiki.apache.org/hadoop/UsingLzoCompression" target="_top">Using LZO Compression</a>
      wiki page for how to make LZO work with HBase.
      </p><p>A common problem users run into when using LZO is that while initial
      setup of the cluster runs smooth, a month goes by and some sysadmin goes to
      add a machine to the cluster only they'll have forgotten to do the LZO
      fixup on the new machine.  In versions since HBase 0.90.0, we should
      fail in a way that makes it plain what the problem is, but maybe not. </p><p>See <a class="xref" href="#hbase.regionserver.codecs" title="A.2.&nbsp; hbase.regionserver.codecs">Section&nbsp;A.2, &#8220;
    <code class="varname">
    hbase.regionserver.codecs
    </code>
    &#8221;</a>
      for a feature to help protect against failed LZO install.</p></div><div class="section" title="A.4.&nbsp; GZIP"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gzip.compression"></a>A.4.&nbsp;
    GZIP
    </h2></div></div></div><p>
    GZIP will generally compress better than LZO though slower.
    For some setups, better compression may be preferred.
    Java will use java's GZIP unless the native Hadoop libs are
    available on the CLASSPATH; in this case it will use native
    compressors instead (If the native libs are NOT present,
    you will see lots of <span class="emphasis"><em>Got brand-new compressor</em></span>
    reports in your logs; see <a class="xref" href="#brand.new.compressor">Q:&nbsp;</a>).
    </p></div><div class="section" title="A.5.&nbsp; SNAPPY"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="snappy.compression"></a>A.5.&nbsp;
    SNAPPY
    </h2></div></div></div><p>
        If snappy is installed, HBase can make use of it (courtesy of
        <a class="link" href="http://code.google.com/p/hadoop-snappy/" target="_top">hadoop-snappy</a>
        <sup>[<a name="d0e7486" href="#ftn.d0e7486" class="footnote">25</a>]</sup>).

        </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>
                    Build and install <a class="link" href="http://code.google.com/p/snappy/" target="_top">snappy</a> on all nodes
                    of your cluster.
                </p></li><li class="listitem"><p>
        Use CompressionTest to verify snappy support is enabled and the libs can be loaded ON ALL NODES of your cluster:
        </p><pre class="programlisting">$ hbase org.apache.hadoop.hbase.util.CompressionTest hdfs://host/path/to/hbase snappy</pre><p>
                </p></li><li class="listitem"><p>
        Create a column family with snappy compression and verify it in the hbase shell:
        </p><pre class="programlisting">$ hbase&gt; create 't1', { NAME =&gt; 'cf1', COMPRESSION =&gt; 'SNAPPY' }
hbase&gt; describe 't1'</pre><p>
        In the output of the "describe" command, you need to ensure it lists "COMPRESSION =&gt; 'SNAPPY'"
                </p></li></ol></div><p>

    </p></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e7486" href="#d0e7486" class="para">25</a>] </sup>See <a class="link" href="http://search-hadoop.com/m/Ds8d51c263B1/%2522Hadoop-Snappy+in+synch+with+Hadoop+trunk%2522&amp;subj=Hadoop+Snappy+in+synch+with+Hadoop+trunk" target="_top">Alejandro's note</a> up on the list on difference between Snappy in Hadoop
        and Snappy in HBase</p></div></div></div><div class="appendix" title="Appendix&nbsp;B.&nbsp;FAQ"><div class="titlepage"><div><div><h2 class="title"><a name="faq"></a>Appendix&nbsp;B.&nbsp;FAQ</h2></div></div></div><div class="qandaset" title="Frequently Asked Questions"><a name="d0e7516"></a><dl><dt>B.1.  <a href="#d0e7517">General</a></dt><dd><dl><dt> <a href="#d0e7520">When should I use HBase?</a></dt><dt> <a href="#d0e7532">Are there other HBase FAQs?</a></dt><dt> <a href="#faq.sql">Does HBase support SQL?</a></dt><dt> <a href="#faq.hdfs.hbase">How does HBase work on top of HDFS?</a></dt><dt> <a href="#faq.changing.rowkeys">Can I change a table's rowkeys?</a></dt></dl></dd><dt>B.2.  <a href="#ec2">Amazon EC2</a></dt><dd><dl><dt> <a href="#d0e7580">
            I am running HBase on Amazon EC2 and...
            </a></dt></dl></dd><dt>B.3.  <a href="#d0e7591">Building HBase</a></dt><dd><dl><dt> <a href="#d0e7594">
When I build, why do I always get Unable to find resource 'VM_global_library.vm'?
            </a></dt></dl></dd><dt>B.4.  <a href="#d0e7607">Runtime</a></dt><dd><dl><dt> <a href="#d0e7610">
                    I'm having problems with my HBase cluster, how can I troubleshoot it?
            </a></dt><dt> <a href="#d0e7619">
                   How can I improve HBase cluster performance?
            </a></dt><dt> <a href="#brand.new.compressor">Why are logs flooded with '2011-01-10 12:40:48,407 INFO org.apache.hadoop.io.compress.CodecPool: Got
            brand-new compressor' messages?</a></dt></dl></dd><dt>B.5.  <a href="#d0e7638">How do I...?</a></dt><dd><dl><dt> <a href="#secondary.indices">
                    Secondary Indexes in HBase?
            </a></dt><dt> <a href="#d0e7650">
                    Store (fill in the blank) in HBase?
            </a></dt><dt> <a href="#d0e7659">
                    Back up my HBase Cluster?
            </a></dt><dt> <a href="#d0e7668">
                    Get a column 'slice': i.e. I have a million columns in my row but I only want to look at columns bbbb-bbbd?
            </a></dt></dl></dd></dl><table border="0" width="100%" summary="Q and A Set"><col align="left" width="1%"><col><tbody><tr class="qandadiv"><td align="left" valign="top" colspan="2"><h3 class="title"><a name="d0e7517"></a>B.1. General</h3></td></tr><tr class="toc"><td align="left" valign="top" colspan="2"><dl><dt> <a href="#d0e7520">When should I use HBase?</a></dt><dt> <a href="#d0e7532">Are there other HBase FAQs?</a></dt><dt> <a href="#faq.sql">Does HBase support SQL?</a></dt><dt> <a href="#faq.hdfs.hbase">How does HBase work on top of HDFS?</a></dt><dt> <a href="#faq.changing.rowkeys">Can I change a table's rowkeys?</a></dt></dl></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7520"></a><a name="d0e7521"></a></td><td align="left" valign="top"><p>When should I use HBase?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
              Anybody can download and give HBase a spin, even on a laptop.  The scope of this answer is when 
              would it be best to use HBase in a <span class="emphasis"><em>real</em></span> deployment.
                </p><p>First, make sure you have enough hardware.  Even HDFS doesn't do well with anything less than
                5 DataNodes (due to things such as HDFS block replication which has a default of 3), plus a NameNode.
                Second, make sure you have enough data.  HBase isn't suitable for every problem.  If you have 
                hundreds of millions or billions of rows, then HBase is a good candidate.  If you only have a few 
                thousand/million rows, then using a traditional RDBMS might be a better choice due to the 
                fact that all of your data might wind up on a single node (or two) and the rest of the cluster may
                be sitting idle.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7532"></a><a name="d0e7533"></a></td><td align="left" valign="top"><p>Are there other HBase FAQs?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
              See the FAQ that is up on the wiki, <a class="link" href="http://wiki.apache.org/hadoop/Hbase/FAQ" target="_top">HBase Wiki FAQ</a>.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="faq.sql"></a><a name="d0e7543"></a></td><td align="left" valign="top"><p>Does HBase support SQL?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    Not really.  SQL-ish support for HBase via <a class="link" href="http://hive.apache.org/" target="_top">Hive</a> is in development, however Hive is based on MapReduce which is not generally suitable for low-latency requests.
                    See the <a class="xref" href="#datamodel" title="Chapter&nbsp;5.&nbsp;Data Model">Chapter&nbsp;5, <i>Data Model</i></a> section for examples on the HBase client.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="faq.hdfs.hbase"></a><a name="d0e7555"></a></td><td align="left" valign="top"><p>How does HBase work on top of HDFS?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    <a class="link" href="http://hadoop.apache.org/hdfs/" target="_top">HDFS</a> is a distributed file system that is well suited for the storage of large files.  It's documentation 
                    states that it is not, however, a general purpose file system, and does not provide fast individual record lookups in files. 
                    HBase, on the other hand, is built on top of HDFS and provides fast record lookups (and updates) for large tables.  This can sometimes be a point of conceptual confusion.
                    See the <a class="xref" href="#datamodel" title="Chapter&nbsp;5.&nbsp;Data Model">Chapter&nbsp;5, <i>Data Model</i></a> and <a class="xref" href="#architecture" title="Chapter&nbsp;8.&nbsp;Architecture">Chapter&nbsp;8, <i>Architecture</i></a> sections for more information on how HBase achieves its goals.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="faq.changing.rowkeys"></a><a name="d0e7569"></a></td><td align="left" valign="top"><p>Can I change a table's rowkeys?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    No.  See <a class="xref" href="#changing.rowkeys" title="6.3.5.&nbsp;Immutability of Rowkeys">Section&nbsp;6.3.5, &#8220;Immutability of Rowkeys&#8221;</a>.
                </p></td></tr><tr class="qandadiv"><td align="left" valign="top" colspan="2"><h3 class="title"><a name="ec2"></a>B.2. Amazon EC2</h3></td></tr><tr class="toc"><td align="left" valign="top" colspan="2"><dl><dt> <a href="#d0e7580">
            I am running HBase on Amazon EC2 and...
            </a></dt></dl></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7580"></a><a name="d0e7581"></a></td><td align="left" valign="top"><p>
            I am running HBase on Amazon EC2 and...
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
 	            See Troubleshooting <a class="xref" href="#trouble.ec2" title="11.9.&nbsp;Amazon EC2">Section&nbsp;11.9, &#8220;Amazon EC2&#8221;</a> and Performance <a class="xref" href="#perf.ec2" title="10.10.&nbsp;Amazon EC2">Section&nbsp;10.10, &#8220;Amazon EC2&#8221;</a> sections.                
               </p></td></tr><tr class="qandadiv"><td align="left" valign="top" colspan="2"><h3 class="title"><a name="d0e7591"></a>B.3. Building HBase</h3></td></tr><tr class="toc"><td align="left" valign="top" colspan="2"><dl><dt> <a href="#d0e7594">
When I build, why do I always get Unable to find resource 'VM_global_library.vm'?
            </a></dt></dl></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7594"></a><a name="d0e7595"></a></td><td align="left" valign="top"><p>
When I build, why do I always get <code class="code">Unable to find resource 'VM_global_library.vm'</code>?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    Ignore it.  Its not an error.  It is <a class="link" href="http://jira.codehaus.org/browse/MSITE-286" target="_top">officially ugly</a> though.
                </p></td></tr><tr class="qandadiv"><td align="left" valign="top" colspan="2"><h3 class="title"><a name="d0e7607"></a>B.4. Runtime</h3></td></tr><tr class="toc"><td align="left" valign="top" colspan="2"><dl><dt> <a href="#d0e7610">
                    I'm having problems with my HBase cluster, how can I troubleshoot it?
            </a></dt><dt> <a href="#d0e7619">
                   How can I improve HBase cluster performance?
            </a></dt><dt> <a href="#brand.new.compressor">Why are logs flooded with '2011-01-10 12:40:48,407 INFO org.apache.hadoop.io.compress.CodecPool: Got
            brand-new compressor' messages?</a></dt></dl></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7610"></a><a name="d0e7611"></a></td><td align="left" valign="top"><p>
                    I'm having problems with my HBase cluster, how can I troubleshoot it?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                See <a class="xref" href="#trouble" title="Chapter&nbsp;11.&nbsp;Troubleshooting and Debugging HBase">Chapter&nbsp;11, <i>Troubleshooting and Debugging HBase</i></a>.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7619"></a><a name="d0e7620"></a></td><td align="left" valign="top"><p>
                   How can I improve HBase cluster performance?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                See <a class="xref" href="#performance" title="Chapter&nbsp;10.&nbsp;Performance Tuning">Chapter&nbsp;10, <i>Performance Tuning</i></a>.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="brand.new.compressor"></a><a name="d0e7629"></a></td><td align="left" valign="top"><p>Why are logs flooded with '2011-01-10 12:40:48,407 INFO org.apache.hadoop.io.compress.CodecPool: Got
            brand-new compressor' messages?</p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    Because we are not using the native versions of compression
                    libraries.  See <a class="link" href="https://issues.apache.org/jira/browse/HBASE-1900" target="_top">HBASE-1900 Put back native support when hadoop 0.21 is released</a>.
                    Copy the native libs from hadoop under hbase lib dir or
                    symlink them into place and the message should go away.
                </p></td></tr><tr class="qandadiv"><td align="left" valign="top" colspan="2"><h3 class="title"><a name="d0e7638"></a>B.5. How do I...?</h3></td></tr><tr class="toc"><td align="left" valign="top" colspan="2"><dl><dt> <a href="#secondary.indices">
                    Secondary Indexes in HBase?
            </a></dt><dt> <a href="#d0e7650">
                    Store (fill in the blank) in HBase?
            </a></dt><dt> <a href="#d0e7659">
                    Back up my HBase Cluster?
            </a></dt><dt> <a href="#d0e7668">
                    Get a column 'slice': i.e. I have a million columns in my row but I only want to look at columns bbbb-bbbd?
            </a></dt></dl></td></tr><tr class="question"><td align="left" valign="top"><a name="secondary.indices"></a><a name="d0e7642"></a></td><td align="left" valign="top"><p>
                    Secondary Indexes in HBase?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                See <a class="xref" href="#secondary.indexes" title="6.8.&nbsp; Secondary Indexes and Alternate Query Paths">Section&nbsp;6.8, &#8220;
  Secondary Indexes and Alternate Query Paths
  &#8221;</a>
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7650"></a><a name="d0e7651"></a></td><td align="left" valign="top"><p>
                    Store (fill in the blank) in HBase?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                See <a class="xref" href="#supported.datatypes" title="6.5.&nbsp; Supported Datatypes">Section&nbsp;6.5, &#8220;
  Supported Datatypes
  &#8221;</a>.
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7659"></a><a name="d0e7660"></a></td><td align="left" valign="top"><p>
                    Back up my HBase Cluster?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                    See <a class="xref" href="#ops.backup" title="12.6.&nbsp;HBase Backup">Section&nbsp;12.6, &#8220;HBase Backup&#8221;</a>
                </p></td></tr><tr class="question"><td align="left" valign="top"><a name="d0e7668"></a><a name="d0e7669"></a></td><td align="left" valign="top"><p>
                    Get a column 'slice': i.e. I have a million columns in my row but I only want to look at columns bbbb-bbbd?
            </p></td></tr><tr class="answer"><td align="left" valign="top"></td><td align="left" valign="top"><p>
                  See <code class="classname">org.apache.hadoop.hbase.filter.ColumnRangeFilter</code>    
                </p></td></tr></tbody></table></div></div><div class="appendix" title="Appendix&nbsp;C.&nbsp;YCSB: The Yahoo! Cloud Serving Benchmark and HBase"><div class="titlepage"><div><div><h2 class="title"><a name="d0e7678"></a>Appendix&nbsp;C.&nbsp;<a class="link" href="https://github.com/brianfrankcooper/YCSB/" target="_top">YCSB: The Yahoo! Cloud Serving Benchmark</a> and HBase</h2></div></div></div><p>TODO: Describe how YCSB is poor for putting up a decent cluster load.</p><p>TODO: Describe setup of YCSB for HBase</p><p>Ted Dunning redid YCSB so its mavenized and added facility for verifying workloads.  See <a class="link" href="https://github.com/tdunning/YCSB" target="_top">Ted Dunning's YCSB</a>.</p></div><div class="appendix" title="Appendix&nbsp;D.&nbsp;HFile format version 2"><div class="titlepage"><div><div><h2 class="title"><a name="hfilev2"></a>Appendix&nbsp;D.&nbsp;HFile format version 2</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#d0e7695">D.1. Motivation </a></span></dt><dt><span class="section"><a href="#d0e7706">D.2. HFile format version 1 overview </a></span></dt><dd><dl><dt><span class="section"><a href="#d0e7728">D.2.1.  Block index format in version 1 </a></span></dt></dl></dd><dt><span class="section"><a href="#d0e7752">D.3. 
      HBase file format with inline blocks (version 2)
      </a></span></dt><dd><dl><dt><span class="section"><a href="#d0e7755">D.3.1.  Overview</a></span></dt><dt><span class="section"><a href="#d0e7770">D.3.2. Unified version 2 block format</a></span></dt><dt><span class="section"><a href="#d0e7839">D.3.3.  Block index in version 2</a></span></dt><dt><span class="section"><a href="#d0e7864">D.3.4. 
      Root block index format in version 2</a></span></dt><dt><span class="section"><a href="#d0e7917">D.3.5. 
      Non-root block index format in version 2</a></span></dt><dt><span class="section"><a href="#d0e7942">D.3.6. 
      Bloom filters in version 2</a></span></dt><dt><span class="section"><a href="#d0e7979">D.3.7. File Info format in versions 1 and 2</a></span></dt><dt><span class="section"><a href="#d0e8025">D.3.8. 
      Fixed file trailer format differences between versions 1 and 2</a></span></dt></dl></dd></dl></div><div class="section" title="D.1.&nbsp;Motivation"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e7695"></a>D.1.&nbsp;Motivation </h2></div></div></div><p>We found it necessary to revise the HFile format after encountering high memory usage and slow startup times caused by large Bloom filters and block indexes in the region server. Bloom filters can get as large as 100 MB per HFile, which adds up to 2 GB when aggregated over 20 regions. Block indexes can grow as large as 6 GB in aggregate size over the same set of regions. A region is not considered opened until all of its block index data is loaded. Large Bloom filters produce a different performance problem: the first get request that requires a Bloom filter lookup will incur the latency of loading the entire Bloom filter bit array.</p><p>To speed up region server startup we break Bloom filters and block indexes into multiple blocks and write those blocks out as they fill up, which also reduces the HFile writer&#8217;s memory footprint. In the Bloom filter case, &#8220;filling up a block&#8221; means accumulating enough keys to efficiently utilize a fixed-size bit array, and in the block index case we accumulate an &#8220;index block&#8221; of the desired size. Bloom filter blocks and index blocks (we call these &#8220;inline blocks&#8221;) become interspersed with data blocks, and as a side effect we can no longer rely on the difference between block offsets to determine data block length, as it was done in version 1.</p><p>HFile is a low-level file format by design, and it should not deal with application-specific details such as Bloom filters, which are handled at StoreFile level. Therefore, we call Bloom filter blocks in an HFile "inline" blocks. We also supply HFile with an interface to write those inline blocks. </p><p>Another format modification aimed at reducing the region server startup time is to use a contiguous &#8220;load-on-open&#8221; section that has to be loaded in memory at the time an HFile is being opened. Currently, as an HFile opens, there are separate seek operations to read the trailer, data/meta indexes, and file info. To read the Bloom filter, there are two more seek operations for its &#8220;data&#8221; and &#8220;meta&#8221; portions. In version 2, we seek once to read the trailer and seek again to read everything else we need to open the file from a contiguous block.</p></div><div class="section" title="D.2.&nbsp;HFile format version 1 overview"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e7706"></a>D.2.&nbsp;HFile format version 1 overview </h2></div></div></div><p>As we will be discussing the changes we are making to the HFile format, it is useful to give a short overview of the previous (HFile version 1) format. An HFile in the existing format is structured as follows:
           <span class="inlinemediaobject"><img src="images/hfile.png" align="middle" alt="HFile Version 1"></span>
           <sup>[<a name="d0e7721" href="#ftn.d0e7721" class="footnote">26</a>]</sup>
       </p><div class="section" title="D.2.1.&nbsp; Block index format in version 1"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7728"></a>D.2.1.&nbsp; Block index format in version 1 </h3></div></div></div><p>The block index in version 1 is very straightforward. For each entry, it contains: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Offset (long)</p></li><li class="listitem"><p>Uncompressed size (int)</p></li><li class="listitem"><p>Key (a serialized byte array written using Bytes.writeByteArray) </p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Key length as a variable-length integer (VInt)
                  </p></li><li class="listitem"><p>
                     Key bytes
                 </p></li></ol></div></li></ol></div><p>The number of entries in the block index is stored in the fixed file trailer, and has to be passed in to the method that reads the block index. One of the limitations of the block index in version 1 is that it does not provide the compressed size of a block, which turns out to be necessary for decompression. Therefore, the HFile reader has to infer this compressed size from the offset difference between blocks. We fix this limitation in version 2, where we store on-disk block size instead of uncompressed size, and get uncompressed size from the block header.</p></div></div><div class="section" title="D.3.&nbsp; HBase file format with inline blocks (version 2)"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d0e7752"></a>D.3.&nbsp;
      HBase file format with inline blocks (version 2)
      </h2></div></div></div><div class="section" title="D.3.1.&nbsp; Overview"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7755"></a>D.3.1.&nbsp; Overview</h3></div></div></div><p>The version of HBase introducing the above features reads both version 1 and 2 HFiles, but only writes version 2 HFiles. A version 2 HFile is structured as follows:
           <span class="inlinemediaobject"><img src="images/hfilev2.png" align="middle" alt="HFile Version 2"></span>

   </p></div><div class="section" title="D.3.2.&nbsp;Unified version 2 block format"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7770"></a>D.3.2.&nbsp;Unified version 2 block format</h3></div></div></div><p>In the version 2 every block in the data section contains the following fields: </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>8 bytes: Block type, a sequence of bytes equivalent to version 1's "magic records". Supported block types are: </p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>DATA &#8211; data blocks
                  </p></li><li class="listitem"><p>
                     LEAF_INDEX &#8211; leaf-level index blocks in a multi-level-block-index
                 </p></li><li class="listitem"><p>
                     BLOOM_CHUNK &#8211; Bloom filter chunks
                  </p></li><li class="listitem"><p>
                     META &#8211; meta blocks (not used for Bloom filters in version 2 anymore) 
                  </p></li><li class="listitem"><p>
                     INTERMEDIATE_INDEX &#8211; intermediate-level index blocks in a multi-level blockindex
                  </p></li><li class="listitem"><p>
                     ROOT_INDEX &#8211; root&gt;level index blocks in a multi&gt;level block index
                  </p></li><li class="listitem"><p>
                     FILE_INFO &#8211; the &#8220;file info&#8221; block, a small key&gt;value map of metadata
                  </p></li><li class="listitem"><p>
                     BLOOM_META &#8211; a Bloom filter metadata block in the load&gt;on&gt;open section
                  </p></li><li class="listitem"><p>
                     TRAILER &#8211; a fixed&gt;size file trailer. As opposed to the above, this is not an 
                     HFile v2 block but a fixed&gt;size (for each HFile version) data structure
                  </p></li><li class="listitem"><p>
                      INDEX_V1 &#8211; this block type is only used for legacy HFile v1 block
                  </p></li></ol></div></li><li class="listitem"><p>Compressed size of the block's data, not including the header (int).
         </p><p>
Can be used for skipping the current data block when scanning HFile data. 
                  </p></li><li class="listitem"><p>Uncompressed size of the block's data, not including the header (int)</p><p>
 This is equal to the compressed size if the compression algorithm is NON
                  </p></li><li class="listitem"><p>File offset of the previous block of the same type (long)</p><p>
 Can be used for seeking to the previous data/index block
                  </p></li><li class="listitem"><p>Compressed data (or uncompressed data if the compression algorithm is NONE).</p></li></ol></div><p>The above format of blocks is used in the following HFile sections:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Scanned block section. The section is named so because it contains all data blocks that need to be read when an HFile is scanned sequentially. &nbsp;Also contains leaf block index and Bloom chunk blocks. </p></li><li class="listitem"><p>Non-scanned block section. This section still contains unified-format v2 blocks but it does not have to be read when doing a sequential scan. This section contains &#8220;meta&#8221; blocks and intermediate-level index blocks.
         </p></li></ol></div><p>We are supporting &#8220;meta&#8221; blocks in version 2 the same way they were supported in version 1, even though we do not store Bloom filter data in these blocks anymore. </p></div><div class="section" title="D.3.3.&nbsp; Block index in version 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7839"></a>D.3.3.&nbsp; Block index in version 2</h3></div></div></div><p>There are three types of block indexes in HFile version 2, stored in two different formats (root and non-root): </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Data index &#8212; version 2 multi-level block index, consisting of:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>
 Version 2 root index, stored in the data block index section of the file
             </p></li><li class="listitem"><p>
Optionally, version 2 intermediate levels, stored in the non%root format in   the data index section of the file.    Intermediate levels can only be present if leaf level blocks are present
             </p></li><li class="listitem"><p>
Optionally, version 2 leaf levels, stored in the non%root format inline with   data blocks
             </p></li></ol></div></li><li class="listitem"><p>Meta index &#8212; version 2 root index format only, stored in the meta index section of the file</p></li><li class="listitem"><p>Bloom index &#8212; version 2 root index format only, stored in the &#8220;load-on-open&#8221; section as part of Bloom filter metadata.</p></li></ol></div></div><div class="section" title="D.3.4.&nbsp; Root block index format in version 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7864"></a>D.3.4.&nbsp;
      Root block index format in version 2</h3></div></div></div><p>This format applies to:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Root level of the version 2 data index</p></li><li class="listitem"><p>Entire meta and Bloom indexes in version 2, which are always single-level. </p></li></ol></div><p>A version 2 root index block is a sequence of entries of the following format, similar to entries of a version 1 block index, but storing on-disk size instead of uncompressed size. </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Offset (long) </p><p>
This offset may point to a data block or to a deeper&gt;level index block.
             </p></li><li class="listitem"><p>On-disk size (int) </p></li><li class="listitem"><p>Key (a serialized byte array stored using Bytes.writeByteArray) </p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Key (VInt)
             </p></li><li class="listitem"><p>Key bytes
             </p></li></ol></div></li></ol></div><p>A single-level version 2 block index consists of just a single root index block. To read a root index block of version 2, one needs to know the number of entries. For the data index and the meta index the number of entries is stored in the trailer, and for the Bloom index it is stored in the compound Bloom filter metadata.</p><p>For a multi-level block index we also store the following fields in the root index block in the load-on-open section of the HFile, in addition to the data structure described above:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Middle leaf index block offset</p></li><li class="listitem"><p>Middle leaf block on-disk size (meaning the leaf index block containing the reference to the &#8220;middle&#8221; data block of the file) </p></li><li class="listitem"><p>The index of the mid-key (defined below) in the middle leaf-level block.</p></li></ol></div><p></p><p>These additional fields are used to efficiently retrieve the mid-key of the HFile used in HFile splits, which we define as the first key of the block with a zero-based index of (n &#8211; 1) / 2, if the total number of blocks in the HFile is n. This definition is consistent with how the mid-key was determined in HFile version 1, and is reasonable in general, because blocks are likely to be the same size on average, but we don&#8217;t have any estimates on individual key/value pair sizes. </p><p></p><p>When writing a version 2 HFile, the total number of data blocks pointed to by every leaf-level index block is kept track of. When we finish writing and the total number of leaf-level blocks is determined, it is clear which leaf-level block contains the mid-key, and the fields listed above are computed. &nbsp;When reading the HFile and the mid-key is requested, we retrieve the middle leaf index block (potentially from the block cache) and get the mid-key value from the appropriate position inside that leaf block.</p></div><div class="section" title="D.3.5.&nbsp; Non-root block index format in version 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7917"></a>D.3.5.&nbsp;
      Non-root block index format in version 2</h3></div></div></div><p>This format applies to intermediate-level and leaf index blocks of a version 2 multi-level data block index. Every non-root index block is structured as follows. </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>numEntries: the number of entries (int). </p></li><li class="listitem"><p>entryOffsets: the &#8220;secondary index&#8221; of offsets of entries in the block, to facilitate a quick binary search on the key (numEntries + 1 int values). The last value is the total length of all entries in this index block. For example, in a non-root index block with entry sizes 60, 80, 50 the &#8220;secondary index&#8221; will contain the following int array: {0, 60, 140, 190}.</p></li><li class="listitem"><p>Entries. Each entry contains: </p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>
Offset of the block referenced by this entry in the file (long) 
             </p></li><li class="listitem"><p>
On&gt;disk size of the referenced block (int) 
             </p></li><li class="listitem"><p>
Key. The length can be calculated from entryOffsets.
             </p></li></ol></div></li></ol></div></div><div class="section" title="D.3.6.&nbsp; Bloom filters in version 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7942"></a>D.3.6.&nbsp;
      Bloom filters in version 2</h3></div></div></div><p>In contrast with version 1, in a version 2 HFile Bloom filter metadata is stored in the load-on-open section of the HFile for quick startup. </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>A compound Bloom filter. </p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>
 Bloom filter version = 3 (int). There used to be a DynamicByteBloomFilter class that had the Bloom   filter version number 2
             </p></li><li class="listitem"><p>
The total byte size of all compound Bloom filter chunks (long)
             </p></li><li class="listitem"><p>
 Number of hash functions (int
             </p></li><li class="listitem"><p>
Type of hash functions (int)
             </p></li><li class="listitem"><p>
The total key count inserted into the Bloom filter (long)
             </p></li><li class="listitem"><p>
The maximum total number of keys in the Bloom filter (long)
             </p></li><li class="listitem"><p>
The number of chunks (int)
             </p></li><li class="listitem"><p>
Comparator class used for Bloom filter keys, a UTF&gt;8 encoded string stored   using Bytes.writeByteArray
             </p></li><li class="listitem"><p>
 Bloom block index in the version 2 root block index format
             </p></li></ol></div></li></ol></div></div><div class="section" title="D.3.7.&nbsp;File Info format in versions 1 and 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e7979"></a>D.3.7.&nbsp;File Info format in versions 1 and 2</h3></div></div></div><p>The file info block is a serialized <a class="ulink" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/io/HbaseMapWritable.html" target="_top">HbaseMapWritable</a> (essentially a map from byte arrays to byte arrays) with the following keys, among others. StoreFile-level logic adds more keys to this.</p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><tbody><tr><td>
               <p>hfile.LASTKEY </p>
            </td><td>
               <p>The last key of the file (byte array) </p>
            </td></tr><tr><td>
               <p>hfile.AVG_KEY_LEN </p>
            </td><td>
               <p>The average key length in the file (int) </p>
            </td></tr><tr><td>
               <p>hfile.AVG_VALUE_LEN </p>
            </td><td>
               <p>The average value length in the file (int) </p>
            </td></tr></tbody></table></div><p>File info format did not change in version 2. However, we moved the file info to the final section of the file, which can be loaded as one block at the time the HFile is being opened. Also, we do not store comparator in the version 2 file info anymore. Instead, we store it in the fixed file trailer. This is because we need to know the comparator at the time of parsing the load-on-open section of the HFile.</p></div><div class="section" title="D.3.8.&nbsp; Fixed file trailer format differences between versions 1 and 2"><div class="titlepage"><div><div><h3 class="title"><a name="d0e8025"></a>D.3.8.&nbsp;
      Fixed file trailer format differences between versions 1 and 2</h3></div></div></div><p>The following table shows common and different fields between fixed file trailers in versions 1 and 2. Note that the size of the trailer is different depending on the version, so it is &#8220;fixed&#8221; only within one version. However, the version is always stored as the last four-byte integer in the file. </p><p></p><div class="informaltable"><table border="1"><colgroup><col class="c1"><col class="c2"></colgroup><tbody><tr><td>
               <p>Version 1 </p>
            </td><td>
               <p>Version 2 </p>
            </td></tr><tr><td colspan="2" align="center">
               <p>File info offset (long) </p>
            </td></tr><tr><td>
               <p>Data index offset (long) </p>
            </td><td>
                <p>loadOnOpenOffset (long)</p>
                <p><span class="emphasis"><em>The offset of the section that we need toload when opening the file.</em></span></p>
            </td></tr><tr><td colspan="2" align="center">
               <p>Number of data index entries (int) </p>
            </td></tr><tr><td>
               <p>metaIndexOffset (long)</p>
               <p>This field is not being used by the version 1 reader, so we removed it from version 2.</p>
            </td><td>
               <p>uncompressedDataIndexSize (long)</p>
               <p>The total uncompressed size of the whole data block index, including root-level, intermediate-level, and leaf-level blocks.</p>
            </td></tr><tr><td colspan="2" align="center">
               <p>Number of meta index entries (int) </p>
            </td></tr><tr><td colspan="2" align="center">
               <p>Total uncompressed bytes (long) </p>
            </td></tr><tr><td>
               <p>numEntries (int) </p>
            </td><td>
               <p>numEntries (long) </p>
            </td></tr><tr><td colspan="2" align="center">
               <p>Compression codec: 0 = LZO, 1 = GZ, 2 = NONE (int) </p>
            </td></tr><tr><td>
               <p></p>
            </td><td>
               <p>The number of levels in the data block index (int) </p>
            </td></tr><tr><td>
               <p></p>
            </td><td>
               <p>firstDataBlockOffset (long)</p>
               <p>The offset of the first first data block. Used when scanning. </p>
            </td></tr><tr><td>
               <p></p>
            </td><td>
               <p>lastDataBlockEnd (long)</p>
               <p>The offset of the first byte after the last key/value data block. We don't need to go beyond this offset when scanning. </p>
            </td></tr><tr><td>
               <p>Version: 1 (int) </p>
            </td><td>
               <p>Version: 2 (int) </p>
            </td></tr></tbody></table></div><p></p></div></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d0e7721" href="#d0e7721" class="para">26</a>] </sup>Image courtesy of Lars George, <a class="link" href="http://www.larsgeorge.com/2009/10/hbase-architecture-101-storage.html" target="_top">hbase-architecture-101-storage.html</a>.</p></div></div></div><div class="appendix" title="Appendix&nbsp;E.&nbsp;HBase and the Apache Software Foundation"><div class="titlepage"><div><div><h2 class="title"><a name="asf"></a>Appendix&nbsp;E.&nbsp;HBase and the Apache Software Foundation</h2></div></div></div><p>HBase is a project in the Apache Software Foundation and as such there are responsibilities to the ASF to ensure
    a healthy project.
       </p><div class="section" title="1.&nbsp;ASF Development Process"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="asf.devprocess"></a>1.&nbsp;ASF Development Process</h2></div></div></div><p>See the <a class="link" href="http://www.apache.org/dev/#committers" target="_top">Apache Development Process page</a> 
        for all sorts of information on how the ASF is structured (e.g., PMC, committers, contributors), to tips on contributing
        and getting involved, and how open-source works at ASF.     
        </p></div><p>
       </p><div class="section" title="2.&nbsp;ASF Board Reporting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="asf.reporting"></a>2.&nbsp;ASF Board Reporting</h2></div></div></div><p>Once a quarter, each project in the ASF portfolio submits a report to the ASF board.  This is done by the HBase project
         lead and the committers.  See <a class="link" href="http://www.apache.org/foundation/board/reporting" target="_top">ASF board reporting</a> for more information.
         </p></div><p>
    </p></div><div class="index" title="Index"><div class="titlepage"><div><div><h2 class="title"><a name="book_index"></a>Index</h2></div></div></div><div class="index"><div class="indexdiv"><h3>C</h3><dl><dt>Cells, <a class="indexterm" href="#cells">Cells</a></dt><dt>Column Family, <a class="indexterm" href="#columnfamily">Column Family</a></dt><dt>Column Family Qualifier, <a class="indexterm" href="#columnfamily">Column Family</a></dt><dt>Compression, <a class="indexterm" href="#compression">Compression In HBase</a></dt></dl></div><div class="indexdiv"><h3>H</h3><dl><dt>Hadoop, <a class="indexterm" href="#hadoop">Hadoop</a></dt></dl></div><div class="indexdiv"><h3>N</h3><dl><dt>nproc, <a class="indexterm" href="#ulimit">
          ulimit
            and
          nproc
        </a></dt></dl></div><div class="indexdiv"><h3>U</h3><dl><dt>ulimit, <a class="indexterm" href="#ulimit">
          ulimit
            and
          nproc
        </a></dt></dl></div><div class="indexdiv"><h3>V</h3><dl><dt>Versions, <a class="indexterm" href="#versions">Versions</a></dt></dl></div><div class="indexdiv"><h3>X</h3><dl><dt>xcievers, <a class="indexterm" href="#dfs.datanode.max.xcievers">dfs.datanode.max.xcievers</a></dt></dl></div><div class="indexdiv"><h3>Z</h3><dl><dt>ZooKeeper, <a class="indexterm" href="#zookeeper">ZooKeeper</a></dt></dl></div></div></div></div></body></html>